# 🎮Review🎮



# JavaSE





qw

## 自动装箱与自动拆箱原理



**自动装箱：**

> 自动装箱就是Java自动将原始类型值转换成对应的**包装类对象**，比如将int的变量转换成Integer对象，这个过程叫做装箱，反之将Integer类对象转换成对应基本类型int值，这个过程叫做拆箱；
>


从Java SE5开始就提供了自动装箱特性，如果要生成一个数值为`10`的`Integer`对象，只需要这样就可以了:

 ```java
 Integer i=10;  
 //这个过程会自动根据数值的类型创建Integer对象(前提是数值范围在IntegerCache内部类定义的low-high范围内！！)，即自动装箱
     
 // 同理
 Integer i=10;  
 int j=i;
 第二行代码则涉及到自动拆箱，将Integer对象i自动拆箱为int基本类型的j
 ```

Java基本包装类型都提供了缓存机制，装箱调用的是包装类中的**`ValueOf`**方法。

1. **`Integer` 缓存源码:	**

```java
public static Integer valueOf(int i) {
        if (i >= IntegerCache.low && i <= IntegerCache.high)
            return IntegerCache.cache[i + (-IntegerCache.low)];//直接随机访问
        return new Integer(i);
    }
//
private static class IntegerCache {
    static final Integer[] cache; //存储元素类型为Integer的数组
    static final int low = -128;
    static final int high;
    static {
        // high value may be configured by property
        int h = 127;
        high = h;
        cache = new Integer[(high - low) + 1];  //初始化
        int j = low;
        for(int k = 0; k < cache.length; k++)
            cache[k] = new Integer(j++); //为该数组赋值
    }
}
```

2. **`Character` 缓存源码:**

```java
public static Character valueOf(char c) {
    if (c <= 127) { //  检查传入的字符是否在 ASCII 码范围内（即 0 到 127）
      return CharacterCache.cache[(int)c];
    }
    return new Character(c);
}

//类加载时就初始化了cache数组
private static class CharacterCache {
    private CharacterCache(){}
    static final Character cache[] = new Character[127 + 1];
    static {
        for (int i = 0; i < cache.length; i++)
            cache[i] = new Character((char)i);
    }
}
```

```java
Integer i1 = 40;  //等价于 Integer i2=Integer.valueOf(40)

//使用了构造函数new Integer(40)，它会创建一个新的Integer对象，即使该值在缓存范围内
Integer i2 = new Integer(40);

System.out.println(i1==i2);  //false

```

`Integer i1=40` 这一行代码会发生装箱，等价于 `Integer i1=Integer.valueOf(40)；` 因此，`i1` 直接使用的是缓存中的对象。而`Integer i2 = new Integer(40)` 会直接创建新的对象

再补充一句:如果想要比较两个`Integer`类对象的数值大小，应该调用`equals()`方法：

```java
//Integer类重写了equals方法
public boolean equals(Object obj) {
        if (obj instanceof Integer) {
            return value == ((Integer)obj).intValue();
        }
        return false;
    }
```



---



**自动拆箱：**

```java
Integer i=10;
int j=i;  //拆箱
装箱调用了包装类的valueOf()方法，而拆箱实际上调用了xxxValue()方法
```

• `Integer i = 10` 等价于 `Integer i = Integer.valueOf(10)；`

• `int n = i` 等价于 `int n = i.intValue()；`

来看看`Integer`类的源码：

```java
private final int value;  //value一旦赋值即不可改变
public Integer(int value) {
        this.value = value;  //每个Integer对象有一个value成员属性
    }

public int intValue() {
        return value; //返回该Integer对象的value成员属性值
    }
```



>  问题存疑： 
>
> ```java
> Integer i=100;  
> i=10;
> ```
>
> 这段代码执行时，引用i指向对象的内存地址变化了吗？ 个人觉得是变化了的，只是没有创建新对象🤔   

在Java中，基本数据类型（如int）是按值传递的，而不是按引用传递的。因此，当你执行 `Integer i = 100;` 后，`i` 中存储的是一个指向内存中值为100的对象的引用，而不是直接存储100这个值。当你执行 `i = 10;` 时，实际上是将 `i` 中存储的引用从指向值为100的对象改变为指向值为10的对象。这意味着 `i` 指向的内存地址确实发生了变化。





## 不同类型变量在JVM中的存储方式



直接上例子：

```java
package 内存分配原理;
 
public class Demo {
    
    
    
    
    
    /*
    1.成员变量(隶属于对象实例)
    分配时机：new创建对象时
    分配位置：堆
     */
     // 举例说明：在创建对象时（C1 c = new C1();）会给对象c的成员变量分配内存，其中基本类型数据i及引用s、s1作为对象c的实例数据存储在堆中；引用s指向的对象new String("a")存储在另一块堆空间
    private int i = 1; // 堆
    private String s/*引用：堆*/ = new String("a")/*对象实例：另一块堆空间中*/;
    private String s1/*引用：堆*/ = "aa"/*字面量aa：字符串常量池*/; // 字符串常量池是运行时常量池的一部分，在jdk7之前位于方法区，jdk7开始移至堆中
 
    
    
    
    /*
    2.类（静态）变量&常量&静态常量
    分配时机：类加载时
    分配位置：方法区(jdk7之前) -> 堆(jdk7及以后)
     */
    // 静态变量
    private static int ii = 2; // 方法区(jdk7之前) -> 堆(jdk7及以后)
    private static String ss/*引用：方法区(jdk7之前) -> 堆(jdk7及以后)*/ = new String("b")/*对象实例：堆*/;
    
    
    
    // 常量
    private final int iii = 3;// 方法区(jdk7之前) -> 堆(jdk7及以后)
    private final String sss/*引用：方法区(jdk7之前) -> 堆(jdk7及以后)*/ = new String("c")/*对象实例：堆*/;
    
    
    
    // 静态常量
    private final static String ssss/*引用：方法区(jdk7之前) -> 堆(jdk7及以后)*/ = new String("d")/*对象实例：堆*/;
 
    
    
    
    /*
    3.局部变量
    分配时机：线程执行方法时
    分配位置：栈
    注：对于引用类型，其引用存在栈中，其引用所指向的对象实例存在堆中
     */
    void m() {
        int i4 = 4; // JAVA虚拟机栈
        Demo d/*引用：JAVA虚拟机栈*/ = new Demo()/*堆*/;
    }
}
```

总结起来：

- **实例变量存储在堆内存中的对象实例中**，每个对象都有自己的副本；
- 静态变量存储在方法区中，它们被所有类的实例共享(`java7`及之后静态变量被分配到堆中)；
- 局部变量存储在每个线程的jvm栈的栈帧中，它们只在方法或代码块的作用域内可见；







## 深拷贝 浅拷贝 引用拷贝



先来了解一下`Object`类中的`clone()`方法：

```java
protected native Object clone() throws CloneNotSupportedException;
```

需要注意的是，`clone()` 方法同时是一个本地（`native`）方法，它的具体实现会交给 `HotSpot` 虚拟机，那就意味着**虚拟机在运行该方法的时候，会将其替换为更高效的 C/C++ 代码，进而调用操作系统去完成对象的克隆工作**

而`age`是一个基本数据类型，而不是引用类型。因此，即使进行了浅拷贝，拷贝对象和原对象都会有各自独立的`age`值。修改拷贝对象的`age`不会影响原对象的`age`，因为基本数据类型在Java中是按值传递的，拷贝对象和原对象各自持有的是`age`的值，而不是引用。



### **浅拷贝**

**如果原对象内部的属性是引用类型的话，浅拷贝会直接复制内部对象的引用地址**（传递该引用的副本），也就是说拷贝对象和原对象共用同一个内部对象，**对拷贝对象所拥有的引用类型的内部属性进行修改后，同样会影响到原对象的属性值**

```java
class Writer implements Cloneable{
    private int age;
    private String name;
            //省略其他
    }
```

`Cloneable` 接口是一个标记接口，只是，如果一个类没有实现 `Cloneable` 接口，即便它重写了 `clone()` 方法，依然是无法调用该方法进行对象克隆的，程序在执行 `clone()` 方法的时候会抛出 `CloneNotSupportedException` 异常

测试类如下：

```java
    class TestClone {
        public static void main(String[] args) throws CloneNotSupportedException {
            Writer writer1 = new Writer(18,"二哥");
            Writer writer2 = (Writer) writer1.clone();  //浅拷贝

            System.out.println("浅拷贝后：");
            System.out.println("writer1：" + writer1);
            System.out.println("writer2：" + writer2);

            writer2.setName("三妹");

            System.out.println("调整了 writer2 的 name 后：");
            System.out.println("writer1：" + writer1);
            System.out.println("writer2：" + writer2);
        }
    }

```

来看一下输出结果：

```
浅拷贝后：
writer1：Writer@68837a77{age=18, name='二哥'}
writer2：Writer@b97c004{age=18, name='二哥'}
调整了 writer2 的 name 后：
writer1：Writer@68837a77{age=18, name='二哥'}
writer2：Writer@b97c004{age=18, name='三妹'}
```

可以看得出，浅拷贝后，`writer1` 和 `writer2` 引用了不同的对象，但值是相同的，说明拷贝成功。

<img src="https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/core-points/deep-copy-01.png" alt="img" style="zoom: 50%;" />







再来看一个包含内部引用的例子：为 `Writer` 类增加一个自定义的引用类型字段 **`Book`**

```java
class Writer implements Cloneable{
    private int age;
    private String name;
    private Book book;
    
     @Override
    protected Object clone() throws CloneNotSupportedException {
        /*
     确保在拷贝对象时，先执行父类的 clone() 方法，
     再对子类的特殊属性进行拷贝。这样可以保证子类对象的特殊属性也能正确地进行拷贝   
        */
        return super.clone();
    }
}

class Book {
    private String bookName;
    private int price;

    // getter/setter 和构造方法都已省略
}

```



测试类：

```java
class TestClone {
    public static void main(String[] args) throws CloneNotSupportedException {
        Writer writer1 = new Writer(18,"二哥");
        Book book1 = new Book("编译原理",100);
        writer1.setBook(book1);

        Writer writer2 = (Writer) writer1.clone();
        System.out.println("浅拷贝后：");

        System.out.println("writer1：" + writer1);
        System.out.println("writer2：" + writer2);

        Book book2 = writer2.getBook();
        book2.setBookName("永恒的图灵");
        book2.setPrice(70);
        System.out.println("writer2.book 变更后：");

        System.out.println("writer1：" + writer1);
        System.out.println("writer2：" + writer2);
    }
}

```



输出结果为：

```java

浅拷贝后：
writer1：Writer@68837a77 age=18, name='二哥', book=Book@32e6e9c3 bookName='编译原理', price=100}}
writer2：Writer@6d00a15d age=18, name='二哥', book=Book@32e6e9c3 bookName='编译原理', price=100}}


writer2.book 变更后：
writer1：Writer@68837a77 age=18, name='二哥', book=Book@32e6e9c3 bookName='永恒的图灵', price=70}}
writer2：Writer@36d4b5c age=18, name='二哥', book=Book@32e6e9c3 bookName='永恒的图灵', price=70}}
```

与之前例子不同的是，`writer2.book` 变更后，`writer1.book` 也发生了改变。这是因为字符串 `String` 是不可变对象，一个新的值必须在字符串常量池中开辟一段新的内存空间，而自定义对象`Book`的内存地址并没有发生改变，只是对应的字段值发生了改变(浅拷贝)



> 浅拷贝复制对象时，**只复制对象本身及其所有直接引用的对象引用，而不会复制对象引用所指向的对象**。因此，浅拷贝得到的是一个新对象，但**该新对象中的成员引用变量指向的是原对象中相同引用的对象**







### **深拷贝**

深拷贝会完全复制整个对象，包括这个对象所包含的内部对象，这样**对原对象内部引用变量指向的对象属性的修改不会影响另一个通过深拷贝生成的对象**

即深拷贝不仅复制对象本身，还复制对象引用所指向的对象。深拷贝得到的是一个全新的独立对象，其中的引用指向的是复制后的对象，还是上面那个例子：`Book`类也重写`clone()`方法

```java
class Book implements Cloneable{
    private String bookName;
    private int price;

    // getter/setter 和构造方法都已省略

    @Override
    protected Object clone() throws CloneNotSupportedException {
        return super.clone();
    }
}


class Writer implements Cloneable{
    private int age;
    private String name;
    private Book book;

    // getter/setter 和构造方法都已省略

    @Override
    protected Object clone() throws CloneNotSupportedException {
        Writer writer = (Writer) super.clone();
        writer.setBook((Book) writer.getBook().clone());//核心
        return writer;
    }
}

```

- 此时的 `Book` 类和浅拷贝时不同，重写了 `clone()` 方法，并实现了 `Cloneable` 接口。为的就是深拷贝的时候也能够克隆该字段
- 此时的 `Writer` 类也与之前的不同，`clone()` 方法当中，不再只调用 `Object` 的 `clone()` 方法对 `Writer` 进行克隆了，**还对 `Book` 也进行了克隆**————外部对象调用内部对象的`clone()`方法



来看测试类：

```java
class TestClone {
    public static void main(String[] args) throws CloneNotSupportedException {
        Writer writer1 = new Writer(18,"二哥");
        Book book1 = new Book("编译原理",100);
        writer1.setBook(book1);

        Writer writer2 = (Writer) writer1.clone();
        System.out.println("深拷贝后：");

        System.out.println("writer1：" + writer1);
        System.out.println("writer2：" + writer2);

        Book book2 = writer2.getBook();
        book2.setBookName("永恒的图灵");
        book2.setPrice(70);
        System.out.println("writer2.book 变更后：");

        System.out.println("writer1：" + writer1);
        System.out.println("writer2：" + writer2);
    }
}

```

这个测试类和之前的浅拷贝的测试类完全一样，但运行结果是不同的:

```
深拷贝后：

writer1：Writer@6be46e8f age=18, name='二哥', book=Book@5056dfcb bookName='编译原理', price=100}}
writer2：Writer@6d00a15d age=18, name='二哥', book=Book@51efea79 bookName='编译原理', price=100}}


writer2.book 变更后：
writer1：Writer@6be46e8f age=18, name='二哥', book=Book@5056dfcb bookName='编译原理', price=100}}
writer2：Writer@6d00a15d age=18, name='二哥', book=Book@51efea79 bookName='永恒的图灵', price=70}}

```

不只是 writer1 和 writer2 是不同的对象，它们中的 book 也是不同的对象。所以，改变了 writer2 中的 book 并不会影响到 writer1

<img src="https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/core-points/deep-copy-03.png" alt="img" style="zoom: 50%;" />

通过 `clone()` 方法实现的深拷贝比较笨重，因为要将所有的引用类型都重写 `clone()` 方法，当嵌套的对象比较多的时候，就非常繁琐了，可以利用序列化(每个要序列化的类都要实现`Serializable`接口——标记型接口)来实现深拷贝









实现浅拷贝/深拷贝，可以实现`Cloneable`接口并重写`clone()`，两者实现的不同之处则在于是否要在外部对象的`clone（）`内部调用内部对象的`clone()`：

```java
public class Address implements Cloneable{
    private String name;
    // 省略构造函数、Getter&Setter方法
    @Override
    public Address clone() {
        try {
            return (Address) super.clone();
        } catch (CloneNotSupportedException e) {
            throw new AssertionError();
        }
    }
}


public class Person implements Cloneable {
    private Address address;
    // 省略构造函数、Getter&Setter方法
    
    
    //浅拷贝
    @Override
    public Person clone() {
        try {
            Person person = (Person) super.clone();
            return person;
        } catch (CloneNotSupportedException e) {
            throw new AssertionError();
        }
    }
---------------------------------------------------------------------------------------------------  
    //深拷贝
    @Override
    public Person clone() {
    try {
        Person person = (Person) super.clone();
        person.setAddress(person.getAddress().clone());//调用内部对象的clone方法，拷贝出一个新的Address对象作为其新对象的内部属性
        return person;
    } catch (CloneNotSupportedException e) {
        throw new AssertionError();
    }
}
}
```









### **引用拷贝**

 简单来说，引用拷贝就是两个不同的引用指向同一个对象

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/shallow&deep-copy.png)

这样，对其中一个引用所指向的对象进行修改，另一个引用也会反映出相同的修改

```java
Person person1 = new Person("Alice");

// 引用拷贝  person1和person2两个引用指向同一对象实例
Person person2 = person1;

// 修改 person2 的属性   person1.name也会一起更改
person2.setName("Bob");
```









## Java的值传递和引用传递

**Java 中的对象引用传递，实际上是将对象的引用（内存地址）复制一份传递给方法，方法内部对参数的操作会影响原始对象；而如果传递的数据类型是基本数据类型，则传递的是基本数据类型参数值的副本**  :exclamation: :exclamation: :exclamation:

先来看看基本数据类型和引用数据类型之间的差别：

```java
int age = 18;
String name = "二哥";
```

age 是基本类型，值就保存在变量中，而 name 是引用类型，变量中保存的是对象的地址。一般称这种变量为对象的引用，引用(如果声明在方法里——局部变量)存放在栈中，而对象存放在堆中。

当用 = 赋值运算符改变 age 和 name 的值时

```java
age = 16;
name = "三妹";
```

对于基本类型 age，赋值运算符会直接改变变量的值，原来的值被覆盖。

对于引用类型 name，赋值运算符会改变对象引用中保存的地址，引用指向的地址变化了，但**原来的对象不会被覆盖**。

<img src="https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/core-points/pass-by-value-02.png" alt="img" style="zoom: 50%;" />

> 在java中：
>
> **如果参数是基本类型，传递的是基本类型的字面量值的拷贝**
>
> 
>
> **如果参数是引用类型，传递的是引用的对象在堆中地址的拷贝，即新的引用和旧的引用指向同一堆中对象**



然后再来看一看数据类型的传递：



### 基本数据类型传递

```java
class PrimitiveTypeDemo {
    public static void main(String[] args) {
        int age = 18;
        modify(age);
        System.out.println(age);
    }

    private static void modify(int age1) {
        age1 = 30;
    }
}
```

1）`main()` 方法中的 age 为基本类型，所以它的值 18 直接存储在变量中。

2）调用 `modify()` 方法的时候，将会把 age 的值 18 复制给形参 age1（**传递了值的拷贝**）。

3）`modify()` 方法中，对 age1 做出了修改。

4）回到 `main()` 方法中，age 的值仍然为 18，并没有发生改变。



如何从`JVM`的角度来理解？

在 Java 中，方法参数的传递是通过栈帧（Stack Frame）来实现的。每个方法在被调用时都会创建一个栈帧，用于存储方法的局部变量、参数和返回地址等信息。栈帧在方法执行完毕后会被销毁。

对于基本数据类型，方法参数存储的是实际值的拷贝。当调用 `modify(age)` 方法时，`age` 的值 18 会被拷贝到 `modify` 方法的栈帧中的局部变量 `age1` 中。因此，`age1` 是 `age` 的一份拷贝，它们分别在不同的栈帧中存储。

修改 `modify` 方法内部的 `age1` 对 `age` 没有影响，因为**它们是两个独立的变量存储在不同的栈帧中**。所以，当方法 `modify` 执行完毕后，`age1` 所在的栈帧被销毁，而 `age` 所在的栈帧仍然存在，因此 `age` 的值仍然是 18

可以将方法的栈帧看作一个临时的工作区域，每个方法调用都有自己的栈帧。**方法参数的传递就是将值从一个栈帧拷贝到另一个栈帧中，而不会影响到原始栈帧中的值。这样，每个方法在执行时都可以独立操作自己的参数和局部变量，互不干扰，实现了方法之间的隔离和安全性。**







### 引用类型传递

直接看例子

例子1：传递数组类型

```java
	public static void main(String[] args) {
      int[] arr = { 1, 2, 3, 4, 5 };
      System.out.println(arr[0]);
      change(arr);
      System.out.println(arr[0]);
	}

	public static void change(int[] array) {
      // 将数组的第一个元素变为0
      array[0] = 0;
	}
```

以上代码输出结果为：

```java
1
0
```

实际上`change()`传递的是实参arr的地址，此时在jvm中有两个引用arr、array同时指向堆中的数组，因此对array[]的修改将会影响到原来arr[]的值； **数组也属于引用类型(非基本数据类型，因此传递的是引用对象的内存地址)**





例子2：传递引用类型变量(`String`)

```java
class ReferenceTypeDemo {
    public static void main(String[] args) {
        String name = "二哥";
        modify(name);
        System.out.println(name);
    }

    private static void modify(String name1) {
        name1 = "三妹";
    }
}
```

刚刚进入`modify()`方法时，会在当前线程(这里应该是主线程)的虚拟机栈中创建一个新栈帧

> `main()` 方法在主线程所拥有的虚拟机栈中对应一个栈帧。
>
> 当运行一个 Java 程序时，JVM 会在主线程的虚拟机栈上执行 `main()` 方法。**`main()` 方法作为程序的入口点，会在主线程的栈上创建一个栈帧，用于存储 `main()` 方法的局部变量、参数和操作数栈等信息**。这个栈帧代表了 `main()` 方法的执行上下文，包含了 `main()` 方法的局部变量表和操作数栈，以及一些用于方法调用和返回的信息。
>
> 当 `main()` 方法执行完毕，或者**在其中调用其他方法，就会在主线程的栈上创建新的栈帧，继续执行其他方法的代码。每当方法调用发生，就会创建新的栈帧；方法执行完毕后，对应的栈帧就会被销毁，回到上一个栈帧，直到回到主线程的栈顶**，也就是回到 `main()` 方法的栈帧
>
> 所以，`main()` 方法在主线程的虚拟机栈中对应一个栈帧，它是程序执行的起点和入口。所有的方法调用都发生在主线程的栈上，直到整个程序执行完毕。

<img src="https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/core-points/pass-by-value-03.png" alt="img" style="zoom:50%;" />z

**注：上图中的 栈 指的是main()方法对应的主线程所拥有的jvm栈中  存放的不同的栈帧**

在进入 `modify()` 方法时，形参 `name1` 的指向复制了`name` 的地址，指向的同样是堆中“二哥”的位置





而在完成`modify()`方法后，变化如下所示：

``<img src="https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/core-points/pass-by-value-04.png" alt="img" style="zoom:50%;" />



**因此main()方法中的引用类型变量name的值 自然是没有变化的，依然指向的是堆中的字符串常量"二哥"**







例子3(这个容易混淆)：

```java
public class Person {
    private String name;
   // 省略构造函数、Getter&Setter方法
}

public static void main(String[] args) {
    Person xiaoZhang = new Person("小张");
    Person xiaoLi = new Person("小李");
    swap1(xiaoZhang, xiaoLi);
    System.out.println("xiaoZhang:" + xiaoZhang.getName());
    System.out.println("xiaoLi:" + xiaoLi.getName());
    
    swap2(xiaoZhang, xiaoLi);
    System.out.println("xiaoZhang:" + xiaoZhang.getName());
    System.out.println("xiaoLi:" + xiaoLi.getName());
}

public static void swap1(Person person1, Person person2) {
    Person temp = person1;
    person1 = person2;
    person2 = temp;
}

 public static void swap2(Person person1, Person person2) {
        Person temp = person1;
        temp.setName("xiaowang");
        person1=person2;
        person2 = temp;
    }

```

在调用`swap1()`函数时：

(1) Main线程开辟的新栈帧中的局部引用变量`person1`，最开始存放的是`Person`型引用变量`xiaozhang`存放的堆空间地址(指向堆空间中的 `new Person("小张")` )，`person2`同理

(2) temp引用指向了堆空间中的 `new Person("小张")`，`person1`指向了堆空间中的 `new Person("小李")`，最后`person2`指向了堆空间中的 `new Person("小张")`

(3) 因此`swap1()`这一栈帧中引用变量指向的变化对`main()`方法对应的栈帧中的局部引用类型变量`xiaoLi`、`xiaoZhang`完全没有影响！！！





在调用`swap2()`函数时：

`temp.setName("xiaowang")`这一行代码改变了`temp`指向的堆中对象的属性值，即该`swap2()`方法进入时`person1`指向的堆中对象——`new Person("小张")`，该对象的成员属性`name`的值，因此最后`person2`引用指向的堆中对象所拥有的name属性值就是"`xiaowang`"

故以上代码输出结果为：

```java
xiaoZhang:小张
xiaoLi:小李
    
xiaoZhang:xiaowang
xiaoLi:小李
```



**可以看出来JVM的相关知识能够很好的帮助我们理解为什么Java只有值传递 ** :happy:





## Java异常机制



<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/types-of-exceptions-in-java.png" style="zoom: 80%;" />



`Exception` 和 `Error` 有什么区别？

在 Java 中，所有的异常都有一个共同的祖先 `java.lang` 包中的 `Throwable` 类。`Throwable` 类有两个重要的子类:

- **`Exception`**:程序本身可以处理的异常，可以通过 `try-catch` 来进行捕获。`Exception` 又可以分为 `Checked Exception` (受检查异常，必须处理,**如果受检查异常没有被 `catch`或者`throws` 关键字处理的话，就没办法通过编译**) 和 `Unchecked Exception` (在编译过程中，即使**不处理不受检查异常也可以正常通过编译**)
- **`Error`：**`Error` 属于**程序无法处理的错误** ，不建议通过`catch`捕获。例如 Java 虚拟机运行错误（`Virtual MachineError`）、虚拟机内存不够错误(`OutOfMemoryError`)、类定义错误（`NoClassDefFoundError`）等 。这些异常发生时，Java 虚拟机一般会选择线程终止

**Checked Exception** 即**受检查异常**(需要`try catch`捕获！！) ，Java代码在编译过程中，如果受检查异常没有被 `catch`或者`throws` 关键字处理的话，就没办法通过编译,除了`RuntimeException`及其子类以外，其他的`Exception`类及其子类都属于受检查异常。常见的受检查异常有：`IOException`、`ClassNotFoundException` 、`SQLException`等

**Unchecked Exception** 即**不受检查异常**，Java代码在编译过程中,我们即使不处理不受检查异常也可以正常通过编译,`RuntimeException` 及其子类都统称为非受检查异常，常见的有（建议记下来，日常开发中会经常用到）：

- `NullPointerException`(空指针错误)
- `IllegalArgumentException`(参数错误比如方法入参类型错误)
- `NumberFormatException`（字符串转换为数字格式错误，`IllegalArgumentException`的子类）
- `ArrayIndexOutOfBoundsException`（数组越界错误）
- `ClassCastException`（类型转换错误）

**Error：** `Error` 是一种特殊类型的异常，不属于程序逻辑的一部分，表示程序在运行过程(**一个java文件执行过程包括.java编译生成.class字节码文件，然后在运行阶段翻译成机器码**)中遇到了严重的错误，这些错误大多数情况下是无法恢复或处理的。通常`Error` 表示 `JVM` 或者底层系统发生了一些不可预期的问题，导致程序无法继续执行,例如：

`OutOfMemoryError`:堆内存溢出

`StackOverflowError`:java虚拟机栈溢出



> **`try-with-resources`是什么？**

`try-with-resources` 是 Java 7 引入的一个语言特性，用于简化资源的管理和关闭。它可以在代码块结束时自动关闭资源，无需显式地使用 `finally` 块来关闭资源，从而使代码更加简洁和易于维护。

传统的资源关闭方式需要在 `finally` 块中手动关闭资源，例如关闭文件、数据库连接、网络连接等。使用 `try-with-resources` 后，可以将资源的声明放在 `try` 语句后的括号中，`Java` 会在代码块执行完毕后自动关闭这些资源，无论代码块是正常执行完毕还是因为异常而跳出。

`try-with-resources` 使用 `AutoCloseable` 接口来标识需要自动关闭的资源。`AutoCloseable` 接口中只有一个方法 `close()`，用于执行资源的关闭操作。常见的资源类如 `java.io.Closeable` 和 `java.sql.Connection` 都实现了 `AutoCloseable` 接口，因此可以直接在 `try-with-resources` 中使用

以下是使用 `try-with-resources` 的示例：

```java
import java.io.*;

public class TryWithResourcesExample {
    public static void main(String[] args) {
        // 使用 try-with-resources 来自动关闭资源
        try (FileReader fileReader = new FileReader("example.txt");
             BufferedReader bufferedReader = new BufferedReader(fileReader)) {

            // 读取文件内容
            String line;
            while ((line = bufferedReader.readLine()) != null) {
                System.out.println(line);
            }

        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
```





## Java反射机制与代理模式

### 反射

反射是在程序**运行**时检查、访问和修改类、方法、属性等信息。通过反射，你可以**在运行时获取类对象的实例、方法和属性，而不需要在编译时就确定这些信息**

为了获取一个类的方法、方法参数、属性等信息，首先需获取该类的class对象，Java提供了四种方式获取 `Class` 对象:

假设需要获取的目标类为下：

```java
public class TargetObject {
    private String value;
    public TargetObject() {
        value = "JavaGuide";
    }
    public void publicMethod(String s ,Integer times) {
        System.out.println("I hate" + s+" "+times+" 次");
    }
    
    private void privateMethod() {
        System.out.println("value is " + value);
    }
    private void privateMethod2() {
        System.out.println("第二个私有方法");
    }
}
```





**1. 知道具体类的情况下可以使用：**

```java
Class alunbarClass = TargetObject.class;
```

但是我们一般是不知道具体类的，基本都是通过**遍历包下面的类来获取 Class 对象**，通过此方式获取 Class 对象不会进行初始化

**2. 通过 `Class.forName()`传入类的全路径获取：**

```java
Class alunbarClass1 = Class.forName("cn.javaguide.TargetObject");
```

**3. 通过对象实例`instance.getClass()`获取(会初始化)：**

```java
TargetObject o = new TargetObject();
Class alunbarClass2 = o.getClass();
```

**4. 通过类加载器`xxxClassLoader.loadClass()`传入类路径获取:**

```java
ClassLoader.getSystemClassLoader().loadClass("cn.javaguide.TargetObject");
```

通过类加载器获取 Class 对象不会进行初始化，意味着不进行包括初始化等一系列步骤，静态代码块和静态对象不会得到执行



反射调用原类的`public/private`方法：

```java
class TestReflect {
//反射获取某个类的所以方法+属性
public static void main(String[] args) throws NoSuchMethodException, InvocationTargetException, IllegalAccessException {
    //已知对应类的情况下(初始化对象)：
    TargetObject targetObject = new TargetObject();
    Class alunbarClass2 = targetObject.getClass();
    
    //未知对应类的情况下（不做初始化）：
    Class<?> targetClass = Class.forName("cn.javaguide.TargetObject"); 
    //声明一个可以是任何types的Class对象(?是通配符)
    TargetObject targetObject = (TargetObject) targetClass.newInstance();

    
    Method[] methods = alunbarClass2.getDeclaredMethods(); //反射获取类的所有方法
    for (Method method : methods) {
        System.out.println(method.getName());
    }
    //获取私有方法并调用
    Method privateMethod2= alunbarClass2.getDeclaredMethod("privateMethod2");//该函数无入参 
    privateMethod2.setAccessible(true); //设置私有方法的访问权限
    privateMethod2.invoke(targetObject); //privateMethod2无形参

    //获取公有方法并调用
    Method publicMethod = alunbarClass2.getDeclaredMethod("publicMethod",
            String.class,Integer.class); //传入所要调用的方法名，以及该方法所需要的参数类型
    publicMethod.invoke(targetObject,"harry",50); //传入实参,第一个参数一定是对应类的实例
}
}
```

控制台输出为：

```java
//获取到的类中所有方法
privateMethod2
publicMethod
privateMethod
    
//invoke()调用被代理类中的privateMethod2()方法
第二个私有方法

//invoke()调用被代理类中的publicMethod()方法
I hateharry 50 次
```



反射的缺点主要有两个:

- **破坏封装**：由于**反射允许访问私有字段和私有方法**，所以可能会破坏封装而导致安全问题。
- **性能开销**：由于反射涉及到动态解析，因此无法执行 Java 虚拟机优化，再加上反射的写法的确要复杂得多，所以性能要比“正射”差很多，在一些性能敏感的程序中应该避免使用反射。





反射的主要应用场景有：

- **开发通用框架**：像`Spring`为了保持通用性，通过配置文件来加载不同的对象，调用不同的方法。
- **动态代理**：在面向切面编程中，需要拦截特定的方法，就会选择动态代理的方式，而动态代理的底层技术就是反射。
- **注解**：注解本身只是起到一个标记符的作用，它需要利用反射机制，根据标记符去执行特定的行为,例如RPC框架中的`@ScanServices`注解：  

```java
Set<Class<?>> classSet = ReflectUtil.getClasses(basePackage);
        for(Class<?> clazz : classSet) {
            if(clazz.isAnnotationPresent(Service.class)) {
                //在某个类上标注了 @Service 注解，并设置了 name 属性值，
      //可以使用 class.getAnnotation(Service.class).name() 来获取该属性的值
      //该name的值就是Nacos注册中心里的服务名
      String serviceName = clazz.getAnnotation(Service.class).name();
                Object obj;
                try {
                    obj = clazz.newInstance();
                } catch (InstantiationException | IllegalAccessException e) {
                    logger.error("创建 " + clazz + " 时有错误发生");
                    continue;
                }
                if("".equals(serviceName)) {
                    Class<?>[] interfaces = clazz.getInterfaces();
                    for (Class<?> oneInterface: interfaces){
              publishService(obj, oneInterface.getCanonicalName());
                    }
                } else {
             publishService(obj, serviceName); //把扫描到的服务注册到Nacos
                }
            }
        }
```



反射的优点再总结一下：

1. 运行时类型检查和动态加载：通过反射，可以**在运行时动态地获取和加载类，而不需要在编译时就确定类的信息。这对于一些框架、库和插件系统非常有用，可以根据运行时条件加载不同的类**。
2. 动态创建对象：反射**允许在运行时创建对象的实例，即使在编译时没有明确知道类的名称**。这在一些通用的代码和工具中很有用。
3. 动态调用方法：通过反射，可以**在运行时调用类的方法，而不需要提前知道类的结构**。这样可以实现灵活的调用机制，例如根据配置文件来决定调用哪个方法。
4. 动态访问和修改属性：通过反射，可以**在运行时获取和修改类的字段（属性）值，而不需要依赖编译时的硬编码**



其实就是可以在运行期时通过操作字节码文件执行一些自定义逻辑





### JDK动态代理



理解动态代理之前，先来看看什么是静态代理？

静态代理是指**在编译时就已经确定代理类的代码**，并且代理类和被代理类的关系在编译时就已经确定。**代理类和被代理类通常都要实现同一个接口或者继承同一个父类**。在静态代理中，代理类是由程序员编写的，手动实现了接口或者继承了父类，并在代理类中调用被代理类的方法。

假设有一个 `UserService` 接口，其中包含了一个方法 `getUserById(int userId)`，我们需要在调用该方法前后进行一些操作，比如打印日志。以下是使用静态代理实现该功能的代码：

```java
public interface UserService {
    User getUserById(int userId);
}

public class UserServiceImpl implements UserService {
    public User getUserById(int userId) {
        // 实现获取用户信息的逻辑
    }
}

public class UserServiceProxy implements UserService {

    // 目标对象
    private UserService target;

    // 构造函数，传入目标对象
    public UserServiceProxy(UserService target) {
        this.target = target;
    }

    // 重写 getUserById 方法，在方法调用前后进行一些操作
    public User getUserById(int userId) {
        
        System.out.println("调用方法前，打印日志...");  
        //这里的target实际上是UserService的实现类对象UserServiceImpl     
        User result = target.getUserById(userId);
        System.out.println("调用方法后，打印日志...");
        
        return result;
    }
}
```

使用以下代码来测试该静态代理类：

```java
public class Test {
    public static void main(String[] args) {
        UserService userService = new UserServiceImpl();
        UserService proxy = new UserServiceProxy(userService);//静态代理核心
        User user = proxy.getUserById(1); //调用
    }
}
```

上述测试代码中，我们首先创建了一个目标对象 `userService`，然后将其传入 `UserServiceProxy` 中，获取代理对象 `proxy`。当调用 `proxy.getUserById(1)` 方法时，`UserServiceProxy` 中的 `getUserById` 方法会被调用，在方法调用前后打印日志，并调用目标对象的 `getUserById` 方法。通过这种方式，我们实现了对目标对象方法的静态代理，并在方法调用前后进行了一些操作。





>  **动态代理和静态代理的区别**
>
> 
>
> 静态代理的代理对象和被代理对象在代理之前就已经确定，它们都**实现相同的接口或继承相同的抽象类**。静态代理模式一般由业务实现类和业务代理类组成，业务实现类里面实现主要的业务逻辑，业务代理类负责在业务方法调用的前后作一些你需要的处理，以实现业务逻辑与业务方法外的功能解耦，减少了对业务方法的入侵。静态代理又可细分为：基于继承的方式和基于聚合的方式实现
>
> 
>
> 静态代理模式的代理类，只是实现了特定类的代理，代理类对象的方法越多，你就得写越多的重复的代码。动态代理就可以动态的生成代理类，实现对不同类下的不同方法的代理。
>
> JDK 动态代理是利用反射机制生成一个实现代理接口的匿名类，在调用业务方法前调用`InvocationHandler` 处理。代理类必须实现 `InvocationHandler` 接口，并且，JDK 动态代理只能代理实现了接口的类



















**动态代理：**

动态代理通俗点说就是：**无需声明式的创建java代理类**，而是**在运行过程中生成"虚拟"的代理类**，被`ClassLoader`加载。从而避免了静态代理那样需要声明大量的代理类

**在 Java 动态代理机制中 `InvocationHandler` 接口和 `Proxy` 类是核心**

`Proxy` 类中使用频率最高的方法是：`newProxyInstance()` ，这个方法主要用来生成一个代理对象(在java程序运行期生成的代理对象，该代理对象可以拦截并转发对被代理类对象的方法调用)

```java
 public static Object newProxyInstance(ClassLoader loader,
                                          Class<?>[] interfaces,
                                          InvocationHandler h)
     throws IllegalArgumentException
 {
     ............
 }
```

这个方法一共有 3 个参数：

1. **loader** :目标对象的类加载器，用于加载代理对象。
2. **interfaces** : `被代理类`实现的一些接口；
3. **h** : 实现了 `InvocationHandler` 接口的对象；

要实现动态代理的话，还必须需要实现`InvocationHandler` 来自定义处理逻辑。当我们的动态代理对象调用被代理类中的方法时，这个方法的调用就会被转发到实现`InvocationHandler` 接口类中的 `invoke` 方法来调用

```java
public interface InvocationHandler {

    /**
     * 当你使用代理对象调用方法的时候实际会调用到这个方法
     */
    public Object invoke(Object proxy, Method method, Object[] args)
        throws Throwable;
}
```

`invoke()` 方法有下面三个参数：

1. **proxy** :动态生成的代理类对象（看不到）
2. **method** : 与代理类对象调用的方法相对应
3. **args** : 当前 method 方法的参数

也就是说：**你通过`Proxy` 类的 `newProxyInstance()` 创建的代理对象在调用被代理类中的(任何)方法时，实际会调用到实现`InvocationHandler` 接口的类的 `invoke()`方法。** 你可以在 `invoke()` 方法中自定义处理逻辑，比如在方法执行前后做什么事情,例如：

```java
public class DebugInvocationHandler implements InvocationHandler {
    
    public DebugInvocationHandler(Object target) {
        this.target = target;
    }
  
    @Override
    public Object invoke(Object proxy, Method method, Object[] args) throws InvocationTargetException, IllegalAccessException {
        //调用方法之前，我们可以添加自己的操作
        System.out.println("before method " + method.getName());
        Object result = method.invoke(target, args); //通过反射实际调用原方法，第一个参数为对应类的实例，第二个参数为调用方法所需要的入参
        //调用方法之后，我们同样可以添加自己的操作
        System.out.println("after method " + method.getName());
        return result;
    }
}
```



**再来看一个例子：**

首先是接口类:

```java

public interface FoodService {
    public void makeNoodle();
    public void makeChicken();
}

//代理类，实现定义的接口
public class FoodServiceImpl implements FoodService {
    @Override
    public void makeNoodle() {
        System.out.println("make noodle");
    }

    @Override
    public void makeChicken() {
        System.out.println("make Chicken");
    }
}
```

其次是实现了`InvocationHandler`的处理类：

```java
public class JDKProxyFactory implements InvocationHandler {
    private Object target;

    public JDKProxyFactory(Object target) {
        super();
        this.target = target;
    }

    // 创建最终生成的代理对象
    public Object createProxy() {
        // 1.得到目标对象的类加载器
        ClassLoader classLoader = target.getClass().getClassLoader();
        // 2.得到目标对象的实现接口
        Class<?>[] interfaces = target.getClass().getInterfaces();
        // 3.第三个参数需要一个实现invocationHandler接口的对象
        Object newProxyInstance = Proxy.newProxyInstance(classLoader, interfaces, this);//生成代理对象
        return newProxyInstance;
    }


    // 第一个参数:代理对象.一般不使用;第二个参数:需要增强的方法;第三个参数:方法中的参数
    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
        System.out.println("这是增强方法前......");
        Object invoke = method.invoke(target, args);//通过反射实际调用原方法，第一个参数为对应类的实例，第二个参数为调用方法所需要的入参
        System.out.println("这是增强方法后......");
        return invoke;
    }

    public static void main(String[] args) {
        // 1.创建对象
        FoodServiceImpl foodService = new FoodServiceImpl();
        // 2.创建代理对象
        JDKProxyFactory proxy = new JDKProxyFactory(foodService); //传入被代理类对象
        // 3.调用代理对象的增强方法,得到增强后的对象
        FoodService createProxy = (FoodService) proxy.createProxy();
        createProxy.makeChicken();//执行被代理类中的任何方法时，会自动走invoke()
    }

}
```

记住以下几个要点：

1. `Proxy.newInstance(ClassLoader loader,Class<?>[] interfaces, InvocationHandler h)`该方法会返回一个代理对象，并由此代理对象调用被代理类的方法;

>loader: 用哪个类加载器去加载代理对象，一般是获取被代理类(该类必须实现接口)的类加载器
>
>interfaces:被代理类所实现的接口
>
>h:动态代理方法在执行时，会调用h里面的invoke方法去执行

2. 对于`public Object invoke(Object proxy, Method method, Object[] args)`方法，其中proxy为代理过之后的对象(并不是原对象)，`method`为被代理的方法，`args`为方法的参数





如果还是不明白的话再给一个`ChatGPT`的例子：

使用Java中的动态代理时，JDK提供了一个`java.lang.reflect.Proxy`类来帮助我们生成代理对象。动态代理允许我们在运行时创建一个代理对象，该代理对象可以拦截并转发对目标对象的方法调用。下面是JDK自带的动态代理的基本流程：



1、定义接口：首先，我们需要定义一个接口，它包含了我们想要代理的目标对象所具有的方法

```java
public interface Subject {
    void doSomething();
}
```



2、实现目标对象：接下来，我们需要实现这个接口，创建一个**目标对象**(最终被代理的类对象)，即实际执行业务逻辑的对象

```java
public class RealSubject implements Subject {
    @Override
    public void doSomething() {
        System.out.println("RealSubject is doing something.");
    }
}
```



3、编写 `InvocationHandler`：接下来，需要编写一个实现了`java.lang.reflect.InvocationHandler`接口的代理处理器类。该接口中只有一个方法`invoke(Object proxy, Method method, Object[] args)`，**当最终生成的代理对象去调用被代理类所实现的方法时，会执行该`invoke()`方法**：

```java
import java.lang.reflect.InvocationHandler;
import java.lang.reflect.Method;

public class MyInvocationHandler implements InvocationHandler {
    private Object target;

    public MyInvocationHandler(Object target) {
        this.target = target;
    }

    @Override
    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
        // 在目标对象的方法执行前进行一些操作（这里可以加入切面逻辑）
        System.out.println("Before method execution.");

        // 调用目标对象的方法
        Object result = method.invoke(target, args);

        // 在目标对象的方法执行后进行一些操作（这里可以加入切面逻辑）
        System.out.println("After method execution.");

        // 返回方法的执行结果
        return result;
    }
}
```

> `invoke()`方法有三个参数，分别是：
>
> 1. `Object proxy`：代理对象。在`invoke()`方法中，我们可以通过`proxy`参数来调用代理对象的方法，但是在实际情况下，通常很少会用到该参数。
> 2. `Method method`：被代理方法的`Method`对象。`Method`对象表示了被代理方法的信息，如方法名、参数类型等。通过`method`参数，我们可以在`invoke()`方法中获取和调用目标对象的方法。
> 3. `Object[] args`：方法的参数数组。`args`参数是一个对象数组，包含了调用被代理方法时传递的参数。在`invoke()`方法中，我们可以根据需要获取和操作这些参数。





---------

参数`proxy`是什么？

`proxy`参数是动态代理对象的引用。它是一个特殊的对象，代表了代理类的实例。通过这个`proxy`对象，我们可以在`invoke()`方法中调用代理对象自己的方法，但是通常情况下，我们很少直接调用代理对象的方法，而是通过`proxy`来调用目标对象的方法。



这里要注意的是，`proxy`对象是一个动态生成的代理类的实例，它实现了我们在`Proxy.newProxyInstance()`方法的`interfaces`参数中指定的接口列表。因此，`proxy`对象可以强制转换为任何在`interfaces`中指定的接口类型。



例如，在上面的例子中，我们在`Proxy.newProxyInstance()`方法中指定了目标对象实现的接口`Subject`，所以代理对象`proxySubject`实际上是`Subject`接口类型的一个实例，我们可以将其转换为`Subject`接口类型，然后调用`Subject`接口中定义的方法

```java
Subject proxySubject = (Subject) Proxy.newProxyInstance(
        realSubject.getClass().getClassLoader(),
        realSubject.getClass().getInterfaces(),
        handler
);

// 调用代理对象的方法，实际上会调用代理处理器的 invoke() 方法
proxySubject.doSomething(); // 这里调用的是 Subject 接口中的 doSomething() 方法
```







-----------------

4、创建代理对象：在主程序中，我们需要使用`Proxy.newProxyInstance(ClassLoader loader, Class<?>[] interfaces, InvocationHandler h)`方法来创建代理对象。这个方法接受三个参数：

- `ClassLoader loader`：类加载器，用于加载所要代理的类
- `Class<?>[] interfaces`：目标对象实现的接口列表(这里是接口`Subject`)
- `InvocationHandler h`：代理处理器对象

```java
import java.lang.reflect.Proxy;

public class Main {
    public static void main(String[] args) {
        RealSubject realSubject = new RealSubject();  //被代理的类对象

        // 创建代理处理器对象
        MyInvocationHandler handler = new MyInvocationHandler(realSubject);

        // 创建代理对象
        Subject proxySubject = (Subject) Proxy.newProxyInstance(
                realSubject.getClass().getClassLoader(),
                realSubject.getClass().getInterfaces(),
                handler
        );

        // 调用代理对象的方法，实际上会调用代理处理器的 invoke() 方法
        proxySubject.doSomething();
    }
}

```





> 最后一个问题，为什么JDK动态代理要求被代理类必须实现接口呢？

要扩展一个类有常见的两种方式，继承父类或实现接口。这两种方式都允许我们对方法的逻辑进行增强，但现在不是由我们自己来重写方法，而是要想办法让jvm去调用`InvocationHandler`中的`invoke`方法，也就是说代理类需要和两个东西关联在一起：

- 被代理类
- InvocationHandler

而`jdk`处理这个问题的方式是选择代理类继承父类`Proxy`，并把`InvocationHandler`存在父类的对象中，即`JVM`会动态地生成一个代理类，该代理类实现了`interfaces`中指定的接口列表，并在运行时通过`InvocationHandler`来处理方法调用。



最主要的原因是：**因为Java中不支持多继承，而JDK动态生成的代理类在创建代理对象时，默认让代理对象继承了Proxy类，所以JDK只能通过接口去实现动态代理**





### CGlib动态代理

Spring在5.X之前默认的动态代理实现一直是jdk动态代理。但是从5.X开始，spring就开始默认使用Cglib来作为动态代理实现。并且springboot从2.X开始也转向了Cglib动态代理实现。Cglib是一个开源项目，它的底层是字节码处理框架`ASM`，Cglib提供了比jdk更为强大的动态代理。主要相比jdk动态代理的优势有：

- jdk动态代理只能基于接口，代理生成的对象只能赋值给接口变量，而Cglib就不存在这个问题
- Cglib是通过生成子类来实现的，代理对象既可以赋值给实现类，又可以赋值给接口
- Cglib速度比jdk动态代理更快，性能更好





核心要点：在生成代理类时，`CGLIB` 会先通过 `ASM` 库来读取目标类的字节码，然后根据代理需求生成代理类的字节码，并将其加载到虚拟机中。在生成代理类的字节码时，`CGLIB` 会通过字节码技术来修改目标类的字节码，从而实现代理。

> **运行时动态生成字节码**是指在程序运行时，**动态生成新的字节码并将其加载到 JVM 中执行**。这种技术通常被用于实现动态代理、AOP（面向切面编程）等功能。**与程序编译时生成的字节码不同，运行时动态生成的字节码是在程序运行时生成的，因此也称为动态字节码**。
>
> 动态生成字节码的过程通常使用代码生成库（如 CGLIB、ASM 等）来实现。代码生成库可以通过生成类的字节码来实现动态代理、动态生成类等功能。在生成字节码时，代码生成库通常会使用一些代码模板和元数据，然后根据这些模板和元数据生成新的字节码。生成的字节码可以通过类加载器加载到 JVM 中，并在程序运行时执行。
>
> 动态生成字节码的优点在于可以在程序运行时根据需要生成新的类或者代理类，从而实现更加灵活和动态的功能。同时，动态生成字节码也可以避免在程序编译时生成过多的代码，减小程序的体积和复杂度。







接着再来看看`Cglib`具体是怎么实现的动态代理



不同于jdk自带的使用`Proxy.newProxyInstance（）`来创建代理对象的方式，Cglib使用`Enhancer`来创建代理对象（Enhancer是一个非常重要的类，它允许为非接口类型创建一个JAVA代理，`Enhancer`动态的创建给定类的子类并且拦截代理类的所有的方法）：

```java
        //要代理的真实对象
        private Object obj;

        public Object createProxy(Object target) {
		this.obj = target;
		Enhancer enhancer = new Enhancer();
		// 设置父类为目标类
		enhancer.setSuperclass(this.obj.getClass());
            
            
		//设置单一回调对象，在调用中拦截对目标方法的调用 ，拦截后才会执行intercept()的方法
		enhancer.setCallback(this);
		//设置类加载器
		enhancer.setClassLoader(this.obj.getClass().getClassLoader());
            
            
		//通过字节码技术动态创建一个子类实例
		return enhancer.create();
	}
```



同时需要自定义 `MethodInterceptor` 并重写 `intercept()` 方法，`intercept()` 用于拦截增强被代理类的方法，和 JDK 动态代理中的 `invoke` 方法类似:

```java
/*
     * @param o           被代理的对象（需要增强的对象）
     * @param method      被拦截的方法（需要增强的方法）
     * @param args        方法入参
     * @param methodProxy 用于调用原始方法
     */
    @Override
    public Object intercept(Object obj, Method method, Object[] args, MethodProxy methodProxy) throws Throwable {
        //调用方法之前，我们可以添加自己的操作
        System.out.println("before method " + method.getName());
        Object object = methodProxy.invokeSuper(obj, args);
        //调用方法之后，我们同样可以添加自己的操作
        System.out.println("after method " + method.getName());
        return object;
    }
```

以下为使用cglib实现动态代理的例子1：

```java
public class CglibProxyFactory implements MethodInterceptor {
    //得到目标对象
    private Object target;

    //使用构造方法传递目标对象
    public CglibProxyFactory(Object target) {
        super();
        this.target = target;
    }

    //创建代理对象    类似jdk自带动态代理中的Proxy.newProxyInstance()方法
    public Object createProxy(){
        //1.创建Enhancer
        Enhancer enhancer = new Enhancer();
        //2.传递目标对象的class
        enhancer.setSuperclass(target.getClass());
        //3.设置回调操作
        enhancer.setCallback(this);

        return enhancer.create();
    }


    //参数一:代理过后的对象;参数二:需要拦截增强的方法;参数三:需要增强方法的参数;参数四:需要增强的方法的代理
    public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable {
        System.out.println("这是增强方法前......");
        Object invoke = methodProxy.invoke(target, args); //  这里选用invoke还是invokeSuper()有所商榷
        System.out.println("这是增强方法后......");
        return invoke;
    }

    public static void main(String[] args) {
        // 1.创建对象
        FoodServiceImpl foodService = new FoodServiceImpl();
        // 2.创建代理对象
        CglibProxyFactory proxy = new CglibProxyFactory(foodService); //传入的foodService对应Object
        // 3.调用代理对象的增强方法,得到增强后的对象
        FoodService createProxy = (FoodService) proxy.createProxy();
        createProxy.makeChicken();  //走intercept()
    }
}
```



例子2：

```java
import net.sf.cglib.proxy.Enhancer;
import net.sf.cglib.proxy.MethodInterceptor;
import net.sf.cglib.proxy.MethodProxy;

import java.lang.reflect.Method;

// 目标类，即被代理类
class RealSubject {
    public void doSomething() {
        System.out.println("RealSubject: Doing something.");
    }
}

// 拦截器类
class ProxySubject implements MethodInterceptor {
    
    private Object target; // 被代理的目标对象

    public ProxySubject(Object target) {
        this.target = target;
    }

    // 拦截器方法，代理对象的所有方法调用都会经过这个方法
    @Override
    public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable {
        System.out.println("Before method: " + method.getName());
        Object result = method.invoke(target, args); // 调用目标对象的方法
        System.out.println("After method: " + method.getName());
        return result;
    }
}

public class CglibDynamicProxyExample {
    public static void main(String[] args) {
        RealSubject realSubject = new RealSubject();

        // 设置被代理的类 对应的拦截器
        ProxySubject proxy = new ProxySubject(realSubject);

        // 创建Enhancer对象，用于创建代理类
        Enhancer enhancer = new Enhancer();
        enhancer.setSuperclass(realSubject.getClass()); // 设置父类为目标类
        enhancer.setCallback(proxy); // 为代理对象设置回调拦截器

        // 创建代理类实例
        RealSubject proxySubject = (RealSubject) enhancer.create();

        // 调用代理类的方法
        proxySubject.doSomething();
    }
}

```

上述例子中，我们有一个目标类`RealSubject`和一个代理类`ProxySubject`。通过CGLIB的`Enhancer`类，我们可以创建一个代理类，并将目标类作为其父类，然后设置代理拦截器为`ProxySubject`对象。当调用代理类的方法时，拦截器的`intercept`方法会被调用，从而实现对目标类方法的拦截和增强



流程如下：

- 先通过`enhancer`对象设置被代理的类为父类
- 考虑到以后生成的代理对象要执行被代理类中方法，要设置拦截器类拦截方法调用(`implements MethodInterceptor`)
- 通过`enhancer.create()`创建真正的代理对象
- 生成的代理对象在执行被代理类中的方法时会默认走拦截器类中的`intercept()`方法



总结：CGLIB的原理主要涉及两个核心技术

1. **字节码生成：** **CGLIB通过生成新的Java类的字节码来实现代理**。它使用了`ASM`（一个Java字节码操作框架）来动态生成新的类的字节码。在运行时，CGLIB会根据目标类或接口创建一个新的代理类，并将其字节码加载到JVM中。
2. **方法拦截：** CGLIB通过继承目标类，并覆盖目标类中的方法来实现代理。生成的代理类会继承目标类，并重写其中的方法。在代理类的重写方法中，可以通过调用方法拦截器（`MethodInterceptor`）的回调方法，实现对目标方法的拦截和增强。





两者比较：

- `JDK` 动态代理只需要实现 `InvocationHandler` 接口，重写 `invoke()` 方法便可以完成代理的实现，

- `jdk`的代理是利用反射**运行时**生成代理类 `Proxyxx.class` 代理类字节码，并生成对象

- `jdk`动态代理之所以**只能代理接口**是因为**代理类本身已经`extends`了`Proxy`，而java是不允许多重继承的**，但是允许实现多个接口

- CGLib 采用了非常底层的字节码技术，其原理是通过字节码增强技术(`ASM类库`)为一个类创建子类，并在子类中采用方法拦截的技术拦截所有父类方法的调用，顺势织入横切逻辑，来完成动态代理的实现。

- 实现方式上cglib需要实现 `MethodInterceptor` 接口，重写 `intercept()` 方法，通过 `Enhancer` 类的回调方法来创建代理

- 但是CGLib在创建代理对象时所花费的时间却比JDK多得多，所以对于单例的对象，因为无需频繁创建对象，用CGLib合适

  


 [Spring Boot2 为啥默认CGlib不再使用JDK代理?](https://www.bilibili.com/video/BV1Tz4y1t7DV/?spm_id_from=333.1007.top_right_bar_window_custom_collection.content.click&vd_source=b14e177936642415d7e4c5110d4d4bb7)







### Javassist代理

当使用`Javassist`直接操作字节码实现动态代理时，我们需要创建一个新的类并在该类中动态生成方法的字节码。下面是一个使用`Javassist`直接操作字节码实现动态代理的例子：

```java
import javassist.*;
import java.lang.reflect.Method;

interface Subject {
    void doSomething();
}

public class JavassistBytecodeProxyExample {
    public static void main(String[] args) throws Exception {
        // 创建ClassPool对象，用于管理生成的类
        ClassPool classPool = ClassPool.getDefault();

        
        CtClass proxyClass = classPool.makeClass("DynamicProxy");

        // 设置类的接口
        proxyClass.addInterface(classPool.get(Subject.class.getName()));

        // 添加MethodHandler字段
        CtField handlerField = new CtField(classPool.get(MethodHandler.class.getName()), "handler", proxyClass);
        proxyClass.addField(handlerField);

        // 添加doSomething()方法，并在方法体中实现代理逻辑
        CtMethod method = CtNewMethod.make(
                "public void doSomething() { " +
                        "try { " +
                        "handler.invoke(this, this.getClass().getMethod(\"doSomething\"), null); " +
                        "} catch (Throwable e) { " +
                        "e.printStackTrace(); " +
                        "}" +
                        "}", proxyClass);
        proxyClass.addMethod(method);

        // 创建代理类的Class对象
        Class<?> proxyClassObject = proxyClass.toClass();

        // 创建代理实例
        Subject proxySubject = (Subject) proxyClassObject.getDeclaredConstructor().newInstance();

        // 设置MethodHandler
        MethodHandler handler = (self, thisMethod, proceed, args1) -> {
            System.out.println("Before method: " + thisMethod.getName());
            self.doSomething(); // 调用目标对象的方法
            System.out.println("After method: " + thisMethod.getName());
            return null;
        };
        proxySubject.getClass().getField("handler").set(proxySubject, handler);

        // 调用代理对象的方法
        proxySubject.doSomething();
    }
}
```



> 几种字节码生成库的比较

在 Java 中，常用的代码生成库包括 CGLIB、ASM、Javassist 等，它们都可以用来生成字节码，实现动态代理、动态生成类等功能。它们之间的区别主要体现在以下几个方面：

1. 生成方式：**CGLIB 和 Javassist 采用的是基于子类的方式，即生成目标类的子类来实现代理或者动态生成类**；而 **ASM 采用的是基于修改字节码的方式，即直接修改目标类的字节码来实现代理或者动态生成类**。

2. 性能：ASM 通常被认为是最快的代码生成库，因为它直接修改字节码，避免了创建中间对象的开销；而 CGLIB 和 Javassist 的性能相对较差，因为它们需要创建中间对象来生成字节码。

3. 简洁性：CGLIB 和 Javassist 的编程接口相对较为简单，易于上手和使用；而 ASM 的编程接口相对较为复杂，需要对字节码有一定的了解。

   















## Object类常见问题



Object类的内部方法如下(要求全部掌握)：

```java
/**
 * native 方法，用于返回当前运行时对象的 Class 对象，使用了 final 关键字修饰，故不允许子类重写。
 */
public final native Class<?> getClass();


/**
 * native 方法，用于返回对象的哈希码，主要使用在哈希表中，比如 JDK 中的HashMap。
 * hashCode() 方法的实现通常是基于对象的内存地址计算出一个值，这个值可以作为对象的哈希码
 * hashCode() 方法返回的是一个 32 位的整数（int 类型）
 */
public native int hashCode();



/**
 * 用于比较 2 个对象的内存地址是否相等(即比较两个引用变量指向的内存地址是否相等)
 * String 类对该方法进行了重写以用于比较字符串的值是否相等。
 */
public boolean equals(Object obj){
return (this == obj);  //默认比较的是两个引用类型指向的内存地址一不一致
}


/**
 * native 方法，用于创建并返回当前对象的一份拷贝。
 */
protected native Object clone() throws CloneNotSupportedException;



/**
 * 返回对象的字符串表示形式，建议 Object 所有的子类都重写这个方法
默认返回格式为：对象的 class 名称 + @ + hashCode 的十六进制字符串。
 */
public String toString()
{
  return getClass().getName() + "@" + Integer.toHexString(hashCode());  
}


/**
 * native 方法，并且不能重写。唤醒一个在此对象监视器上等待的线程(监视器相当于就是锁的概念)。如果有多个线程在等待只会任意唤醒一个。
 * 很明显该方法需要依赖于特定的Object对象
 */
public final native void notify();



/**
 * native 方法，并且不能重写。跟 notify 一样，唯一的区别就是会唤醒在此对象监视器上等待的所有线程，而不是一个线程。
 */
public final native void notifyAll();


/**
 * native方法，并且不能重写。暂停线程的执行。注意：sleep 方法没有释放锁，而 wait 方法释放了锁 ，timeout 是等待时间。
 */
public final native void wait(long timeout) throws InterruptedException;


/**
 * 多了 nanos 参数，这个参数表示额外时间（以毫微秒为单位，范围是 0-999999）。 所以超时的时间还需要加上 nanos 毫秒。。
 */
public final void wait(long timeout, int nanos) throws InterruptedException;


/**
 * 跟之前的2个wait方法一样，只不过该方法一直等待，没有超时时间这个概念
 */
public final void wait() throws InterruptedException;



/**
 * 实例被垃圾回收器回收的时候触发的操作
 */
protected void finalize() throws Throwable { };

```



对于`toString()`,其返回一个对象对应的字符串表现形式，例如：

```java
Review review1=new Review();
Review review2=new Review();
System.out.println(review1);
System.out.println(review1.toString());
System.out.println(review2.toString());
```

输出结果如下：

```
test.Review@6576fe71
test.Review@6576fe71
test.Review@76fb509a
```

可以看出打印一个对象时会默认调用该对象的`toString()`方法





### 为什么要有hashcode()方法？



当把一个对象加入 `HashSet` 时，`HashSet` 会先计算对象的 `hashCode` 值来判断对象加入的位置，同时也会与其他已经加入的对象的 `hashCode` 值作比较，**如果没有相符的 `hashCode`，`HashSet` 会假设对象没有重复出现。**但是如果发现有相同 `hashCode` 值的对象，这时会调用 `equals()` 方法来检查 `hashCode` 相等的对象是否真的相同。如果两者相同，`HashSet` 就不会让其加入操作成功。如果不同的话，就会重新散列到其他位置。这样我们就大大减少了 `equals` 的次数，相应就大大提高了执行速度，总结下来就是：

- 如果两个对象的`hashCode` 值相等，那这两个对象不一定相等（哈希碰撞）
- 如果两个对象的`hashCode` 值相等并且`equals()`方法也返回 `true`，才认为这两个对象相等
- 如果两个对象的`hashCode` 值不相等，就可以直接认为这两个对象不相等



(哈希码是一个 int 类型的值，它的取值范围是 -2147483648 到 2147483647)





> 为什么一旦重写了`equals`()必须要重写`hashcode`()方法？

那么不重写的后果是什么呢？

举一个例子：

如果一个只重写了**equals(比较所有属性是否相等)**的类 `new` 出了两个**属性相同的对象**。这时可以得到的信息是这两个属性相同的对象地址肯定不同，但是`equals`是`true`，`hashCode`返回的是不相等的(一般不会出现hash碰撞)。这样就违背了`equals`相等则`hashcode`值一定相等的约定！

总结来说：

- equals 为 true ， hashCode 必须相等(默认设计原则)
- hashCode 相等时 ， equals 可以不用为 true （也就是hash碰撞的时候）













## String类常见问题



### String对象为什么是不可变的？



> 前言：final关键字的作用？
>
> 
>
> 在 Java 中，`final` 关键字可以用于修饰类、方法和变量，用于表示不可继承性、不可重写性、**(引用指向 )不可变性**
>
> 1. 对于引用类型，final 使引用指向不变，也就不能引用其它对象，但是被引用的对象本身是可以修改的
> 2. 对于基本数据类型，被final修饰的变量就变成了常量，一旦被赋值则无法再次被修改

`final`并不能保证对象的不可变性，只能保证该引用不能指向一个新的对象：

```java
final char[] name = new char[]{'s', 'o', 'n', 'n', 'y'};
System.out.println(name);  //sonny
name[0] = 'h';
System.out.println(name);  //honny
name=new char[]{'h','a','r','r','y'}; // is not allowed!
```





> 什么叫String不可变？

来看一个简单的例子：

```java
public void testString(){
String name="harry";
name="kane";
}

```

对于以上代码，`jvm`会先在堆中创建一个实例对象"`harry`"，同时在栈中创建一个引用`name`指向堆中实例，而如果想要修改`name`指向的堆中`String`对象实例，这是不可行的，`jvm`只会另外在堆中重新创建一个`String`类对象"`kane`"，然后让引用变量`name`指向新的堆中字符串常量"`kane`"

**所以说的`String`不可变实际上指的是字符串常量池中的"harry"是不能被修改的了**



但是如果这样声明，就是非法的了：

```java
final String name="harry";
name="kane"; //error   被final修饰的String类型的引用 无法改变其指向
```

也就是说：如果在`String`类型引用前不用`final`修饰，那么该引用还是可以改变指向的







> 回到问题上来，`String`为什么不可变？

`String` 类中使用 `final` 关键字修饰字符数组 `value` 来保存字符串：

```java
public final class String
    implements java.io.Serializable, Comparable<String>, CharSequence,
               Constable, ConstantDesc {
       private final char value[]; //Java 9 之前String、StringBuilder（Buffer）使用char[]数组存放字符串
       private final byte[] value; //Java 9 之后，改用byte[]数组存储字符串            
               }
```



`String` 真正不可变有下面几点原因：

1. 保存字符串的数组(char[]、byte[])被 `final` 修饰且为私有的，该数组被声明为 `final`，这意味着 `value` **数组初始化之后 ，value就不能再指向其它堆中字符串常量了(其实这个是最不重要的原因了！)**，**而且由于 byte数组 被`private`修饰，且没有提供`setXXX()`方法，阻止了外部类修改！！(这个才是主要原因)**	

2. `String` 类被 `final` 修饰导致其不能被继承，进而避免了子类破坏 `String` 不可变（防止子类重写`String`类中方法，将子类设计为可变对象）

3. `String`**类中的方法不会去改动value数组中的元素**，若**需修改都是直接新创建一个String对象**，根本没有在原字符串对象上做改变，例如`subString()`、`replace()`：

   ```java
   public String substring(int beginIndex) {
   //略去异常处理
   int subLen = value.length - beginIndex;
   return (beginIndex == 0) ? this : new String(value, beginIndex, subLen);
   }
   
     public String replace(char oldChar, char newChar) {
           if (oldChar != newChar) {
              //进行字符替换的逻辑
                   }
                   return new String(buf, true); //创建一个新的String对象
               }
           }
           return this;  //oldChar和newChar一致，不用修改，直接返回即可
       }
   ```





那么有没有办法改变`String`呢？当然是有的，通过反射可以实现：

```java
public class Test2 {
    public static void main(String[] args) {
        String str ="张三"
            System.out.println(str);
        try {
            //我们通过反射获取内部的value字符数组
            Field field =String.class.getDeclaredField("value");
            field.setAccessible(true);
            char[] value;
            value = (char[]) field.get(str);
            //把字符串第一个字符变成王
            value[0] ='王';
            System.out.println(str); 
            catch (Exception e) {
                e.printstackTrace();
            }
        }
    }
    //output:
    //张三
    //王三
```







问题来了：**为什么要将`String`设计为不可变的？**

(1) 第一个原因就是可以节省空间--字符串常量池：

```java
String club="chelsa";
String club2="chelsa";
```

**对于以上代码：`club`和`club2`两个引用指向的是字符串常量池中的同一字符串对象**





(2) 其次，由于`String`对象是不可变的，因此可以在多个线程之间共享，而不需要担心线程安全问题。如果`String`对象是可变的，那么在多个线程同时修改同一个`String`对象时，就会导致线程安全问题，可能会出现数据不一致等问题



(3) 且由于`String`对象是不可变的，因此可以被缓存，并且在多个地方重复使用，提高应用程序的性能。例如当一个字符串被创建后，它的哈希值就可以被缓存起来，以便在需要时快速查找。如果`String`对象是可变的，那么每次修改`String`对象时都需要重新计算哈希值，这会导致性能下降



此外，不可变的`String`对象还有其他一些优点，例如可以作为`Map`的`Key`来使用，因为`Key`需要是不可变的对象。同时，`Java`中的字符串连接操作也可以通过使用`StringBuilder`或`StringBuffer`来实现，这些类可以动态地修改字符串，而不需要使用可变的`String`对象







### 相关类的线程安全

**`String` 中的对象是不可变的，也就可以理解为常量，线程安全**。`AbstractStringBuilder` 是 `StringBuilder` 与 `StringBuffer` 的公共父类，定义了一些字符串的基本操作，如 `expandCapacity`、`append`、`insert`、`indexOf` 等公共方法。`StringBuffer` 对方法加了同步锁（`synchronized`）或者对调用的方法加了同步锁，所以是线程安全的,而`StringBuilder` 并没有对方法进行加同步锁，所以是非线程安全的：

```java
//StringBuffer类中一些常用方法:

    @Override
    public synchronized int length() {
        return count;
    }


   @Override
   public synchronized StringBuffer append(Object obj) {
        toStringCache = null;
        super.append(String.valueOf(obj));
        return this;
    }
    

   @Override
   public synchronized char charAt(int index) {
        return super.charAt(index);
    }
```





### String str=new String("abc") 创建了几个对象？



> 这行代码创建了几个对象？

```java
String s = new String("二哥");
```

“使用 new 关键字创建一个字符串对象时，Java 虚拟机会**先在字符串常量池中查找有没有‘二哥’这个字符串对象**，如果有，就不会在字符串常量池中创建‘二哥’这个对象了，**直接在堆中创建一个‘二哥’的字符串对象，然后将堆中这个‘二哥’的对象地址返回赋值给变量 s。”**

“如果没有，先在字符串常量池中创建一个‘二哥’的字符串对象，然后再在堆中创建一个‘二哥’的字符串对象，然后**将堆中这个‘二哥’的字符串对象地址返回赋值给变量 s**。”



可以看的出来无论字符串常量池中有没有字符串对象，只要是`new String()`的话都会返回堆中对象地址



<img src="http://cdn.tobebetterjavaer.com/tobebetterjavaer/images/string//constant-pool-6dee151e-3a13-4f85-b870-3c9d1797557a.png" alt="img" style="zoom:50%;" />



在Java中，栈上存储的是基本数据类型的变量和对象的引用，而对象本身则存储在堆上



对于这行代码 `String s = new String("二哥");`，它创建了两个对象：一个是字符串对象 "二哥"，它被添加到了字符串常量池中，另一个是通过 `new String()` 构造函数创建的字符串对象 "二哥"，它被分配在堆内存中，同时引用变量 s 存储在栈上，它指向堆内存中的字符串对象 "二哥"

“**为什么要先在字符串常量池中创建对象，然后再在堆上创建呢**？这样不就多此一举了？(所以没必要使用new String()来创建字符串对象)

由于字符串的使用频率实在是太高了，所以 Java 虚拟机为了提高性能和减少内存开销，在创建字符串对象的时候进行了一些优化，特意为字符串开辟了一块空间——也就是字符串常量池。

通常情况下，我们会采用双引号的方式来创建字符串对象，而不是通过 new 关键字的方式(**new 的方式始终会创建一个对象，不管字符串的内容是否已经存在，而双引号的方式会重复利用字符串常量池中已经存在的对象**)，就像下面👇🏻这样，这样就不会多此一举：

```java
 String s = "三妹";
```

当执行 `String s = "三妹"` 时，Java 虚拟机会先在字符串常量池中查找有没有“三妹”这个字符串对象，如果有，则不创建任何对象，直接将字符串常量池中这个“三妹”的对象地址返回，赋给变量 s；如果没有，在字符串常量池中创建“三妹”这个对象，然后将其地址返回，赋给变量 s。

<img src="http://cdn.tobebetterjavaer.com/tobebetterjavaer/images/string//constant-pool-80ca8b18-2446-431e-98e3-b194e1c608e3.png" alt="img" style="zoom:50%;" />

例子1：

```java
String s = new String("二哥");
String s1 = new String("二哥");
```

按照我们之前的分析，这两行代码会创建三个对象，字符串常量池中一个，堆上两个



例子2：

```java
String s = "三妹";
String s1 = "三妹";
```

这两行代码只会创建一个对象，就是字符串常量池中的那个



例子3：

```java
String s0="二哥";  //先在字符串常量池中创建"二哥"
String s = new String("二哥"); //字符串常量池中已经有了，只需要在堆中创建new String()
String s1 = new String("二哥"); //字符串常量池中已经有了，同样只需要在堆中创建
```

`s0`、`s` 和 `s1` 这三个引用指向的是不同的对象，即使它们的内容都是 "二哥"。因此，尽管它们的哈希码相同（因为`hashCode()`是基于内容计算的，String类重写了`hashcode()`方法），但它们是不同的对象，而不是指向同一个对象









### String.intern()用法

> 前言：
>
> 第一，使用双引号声明的字符串对象会保存在字符串常量池中
>
> 第二，使用 `new` 关键字创建的字符串对象会先从字符串常量池中找，如果没找到就创建一个放入字符串常量池，然后再在堆中创建字符串对象；如果找到了，就只需要在堆中创建字符串对象即可
>
> 
>
> Java 7 之前，执行 `String.intern()` 方法的时候，不管对象在堆中是否已经创建，字符串常量池中仍然会创建一个内容完全相同的新对象，然后返回常量池中该字符串对象的引用； Java 7 之后呢，由于字符串常量池放在了堆中，执行 `String.intern()` 方法的时候，**如果对象在堆中已经创建了，字符串常量池中就不需要再创建新的对象了，而是直接保存堆中对象的引用**，也就节省了一部分的内存空间
>
> 

`String.intern()` 是一个 native（本地）方法，其作用是**返回指定字符串对象的地址**，具体返回哪个，可以分为两种情况：

- **如果字符串常量池中保存了对应的字符串对象的引用，就直接返回该引用**

- 如果字符串常量池中没有保存了对应的字符串对象的引用，那就在常量池中创建一个指向该字符串对象(**这时的字符串对象上存在于堆中，即常量池中的引用指向堆中String类对象**)的引用并返回



还是以例子来说明吧，例子1：

```java
String s1 = new String("二哥三妹");
String s2 = s1.intern();
System.out.println(s1 == s2);   //false
```

第一行代码，字符串常量池中会先创建一个“二哥三妹”的对象，然后堆中会再创建一个“二哥三妹”的对象，s1 引用的是堆中的对象。

第二行代码，对 s1 执行 `intern()` 方法，该方法会从字符串常量池中查找“二哥三妹”这个字符串是否存在，此时是存在的，所以 s2 引用的是字符串常量池中的对象。

也就意味着 s1 和 s2 的引用地址是不同的，一个来自堆，一个来自字符串常量池，所以输出的结果为 `false`





上面的例子1针对的是**字符串常量池中有相应对象实例**的情况，再来看看例子2：

```java
String s1 = new String("二哥") + new String("三妹");
String s2 = s1.intern();
System.out.println(s1 == s2);  //true
```

第一行代码，会在字符串常量池中创建两个对象，一个是“二哥”，一个是“三妹”，然后在堆中会创建两个匿名对象“二哥”和“三妹”，最后还有一个“二哥三妹”的对象（稍后会解释），s1 引用的是堆中“二哥三妹”这个对象。

第二行代码，对 `s1` 执行 `intern()` 方法，**该方法会从字符串常量池中查找“二哥三妹”这个对象是否存在，此时不存在的，但堆中已经存在了，所以字符串常量池中保存的是堆中这个“二哥三妹”对象的引用**，也就是说，`s2` 和 `s1` 的引用地址是相同的，所以输出的结果为 `true`!!



说的详细点就是：

1. 创建 "二哥" 字符串对象，存储在字符串常量池中。

2. 创建 "三妹" 字符串对象，存储在字符串常量池中。

3. 执行 `new String("二哥")`，在堆上创建一个字符串对象，内容为 "二哥"。

4. 执行 `new String("三妹")`，在堆上创建一个字符串对象，内容为 "三妹"。

5. 执行 `new String("二哥") + new String("三妹")`，会创建一个 `StringBuilder` 对象，并将 "二哥" 和 "三妹" 追加到其中，然后调用 `StringBuilder` 对象的 `toString()` 方法，**将其转换为一个新的字符串对象，内容为 "二哥三妹"。这个新的字符串对象存储在堆上**

   也就是说，当编译器遇到 `+` 号这个操作符的时候，会将 `new String("二哥") + new String("三妹")` 这行代码编译为以下代码：

   ```java
   new StringBuilder().append("二哥").append("三妹").toString();
   ```

   实际执行过程如下：

   - 创建一个 StringBuilder 对象。
   - 在 StringBuilder 对象上调用 append("二哥")，将 "二哥" 追加到 StringBuilder 中。
   - 在 StringBuilder 对象上调用 append("三妹")，将 "三妹" 追加到 StringBuilder 中。
   - 在 StringBuilder 对象上调用 toString() 方法，将 StringBuilder 转换为一个新的字符串对象，内容为 "二哥三妹"。







例子3(实战一下)：


```java
// 在堆中创建字符串对象”Java“
// 将字符串对象”Java“的引用保存在字符串常量池中
String s1 = "Java";
// 直接返回字符串常量池中字符串对象”Java“对应的引用
String s2 = s1.intern();
// 会在堆中在单独创建一个String对象
String s3 = new String("Java");
// 直接返回字符串常量池中字符串对象”Java“对应的引用
String s4 = s3.intern();
// s1 和 s2 指向的是堆中的同一个对象
System.out.println(s1 == s2); // true


/* s3指向的是堆中(非字符串常量池)new String("Java")对象，
*  s3.intern()返回的则是字符串常量池中 "Java" 的引用 ，故不相等
*/
System.out.println(s3 == s4); // false


// s1 和 s4 指向的是堆中的同一个对象
System.out.println(s1 == s4); //true

```

  





```java
场景1：
String s1 = new String("ab")+new String("c");
s1.intern(); //将堆中通过StringBuilder创建的字符串对象"abc"的引用推送到常量池中去
String s2 = "abc";
System.out.println( s1 == s2);// true 因为常量池在被推送引用之前没有存放"abc"对象


场景2：

String s1 = new String("ab")+new String("c");
String s2 = "abc";
s1.intern();
System.out.println( s1 == s2);// false

```

场景1和场景2的代码都是单独执行的，但是因为`s1.intern()`在的位置不一样，执行结果就不一样，当然对于内存中的活动也是不一样的：

(1) 场景1中第一行解析的时候会在堆中创建"ab","c","abc"三个字符串，此时s1指向的是堆中的"abc"，解析到`s1.intern()`时，会将`s1`中的引用推送到字符串常量池中。然后在解析`String s2 = "abc"`时;**JVM会去字符串常量池中检查"abc"的引用，发现存在，直接返回给`s2`**；

(2) 场景2中`String s1 = new String("ab")+new String("c"); String s2 = "abc";`解析完之后s1指向的是堆内存中字符串对象，s2指向的是字符串常量池中"abc"对象，当执行`s1.intern();`的时候发现字符串常量池中已经存在"abc"的引用，故什么都不做。最后比较`s1 == s2`实际是比较两个字符串对象的地址值，所以结果是false。但是如果在场景2中加一句`String s3=s1.intern();`然后比较`s2==s3`，结果会是true，比较`s1==s3`，结果依然会是false，原因就不赘述了





注意事项 :grey_exclamation::grey_exclamation:

不过需要注意的是，尽管 intern 可以确保所有具有相同内容的字符串共享相同的内存空间，但也不要滥用 `intern()`，因为任何的缓存池都是有大小限制的，不能无缘无故就占用相对稀缺的缓存空间，导致其他字符串没有坑位可占。因为字符串常量池本质上是一个固定大小的 `StringTable`，如果放进去的字符串过多，就会造成严重的哈希冲突，从而导致链表变长，链表变长也就意味着字符串常量池的性能会大幅下降。。。











## IO模型(RPC要用 最后再看 :grey_exclamation: )



平常开发过程中接触最多的就是 **磁盘 IO（读写文件）** 和 **网络 IO（网络请求和响应）**

UNIX 系统下io模型共有5种：**同步阻塞 I/O**、**同步非阻塞 I/O**、**I/O 多路复用**、**信号驱动 I/O** 和**异步 I/O**



### 涉及到的设计模式

总体来说设计模式分为三大类：

创建型模式，共五种：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式

结构型模式，共七种：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式

行为型模式，共十一种：策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式


#### 装饰器模式

**装饰器（Decorator）模式** 可以在不改变原有对象的情况下拓展其功能

装饰器模式通过**组合替代继承**来扩展原始类的功能，在一些继承关系比较复杂的场景（`IO` 这一场景各种类的继承关系就比较复杂）更加实用，适合在不想增加很多子类的情况下扩展类

在装饰器模式中的角色有：

- **抽象构件(Component)角色：**给出一个抽象接口，已规范准备接收附加责任的对象。
- **具体构件(ConcreteComponent)角色：**定义一个**将要接收附加责任**的类
- **装饰器(Decorator)角色：**持有一个构件(Component)对象的实例，并定义一个与抽象构件接口一致的接口
- **具体装饰器(ConcreteDecorator)角色：**负责给具体构件对象“贴上”附加的责任

举个例子：比如奶茶店有很多奶茶，我去点一杯波霸奶茶，奶茶里面可以加各种配料，我需要在我的波霸奶茶里面加珍珠、椰果配料，这时候就可以使用装饰器模式，分析一下：

**奶茶属于抽象构件**

**波霸奶茶属于具体构件**

**配料属于装饰器角色**

**珍珠、椰果属于具体装饰器角色**

看下图：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E8%A3%85%E9%A5%B0%E5%99%A8%E6%A8%A1%E5%BC%8F.png)

对于字节流来说， `FilterInputStream` （对应输入流）和`FilterOutputStream`（对应输出流）是装饰器模式的核心，可以被看作为装饰器`Decorator`,该`Decorator`分别被用于增强 `InputStream(抽象构件)` 和`OutputStream`的子类对象(**具体构件**)的功能；

常见的`BufferedInputStream`(字节缓冲输入流)、`DataInputStream` 等等都是`FilterInputStream` 的子类，`BufferedOutputStream`（字节缓冲输出流）、`DataOutputStream`等等都是`FilterOutputStream`的子类

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/DP-Decorator-java.io.png"  />

举个例子，我们可以通过 `BufferedInputStream`（字节缓冲输入流，**此处作为具体装饰角色**）来增强 `FileInputStream`(此处是**具体构件**) 的功能，即：

- `InputStream` 是抽象组件；
- `FileInputStream` 是 `InputStream` 的子类，属于具体组件，**提供了字节流的输入操作**；
- `FilterInputStream` 属于抽象装饰者，装饰者用于装饰组件，为组件提供额外的功能。例如 **`BufferedInputStream` 为 `FileInputStream` 提供缓存的功能**

实例化一个具有缓存功能的字节流对象时，只需要在 `FileInputStream` 对象上再套一层 `BufferedInputStream` 对象即可，

```java
FileInputStream fileInputStream = new FileInputStream(filePath);
BufferedInputStream bufferedInputStream = new BufferedInputStream(fileInputStream);
```



再比如`ZipInputStream` 和`ZipOutputStream` 还可以分别增强 `BufferedInputStream` 和 `BufferedOutputStream` 的能力(需要被增强的具体构件作为参数被传入)：

```java
BufferedInputStream bis = new BufferedInputStream(new FileInputStream(fileName));
ZipInputStream zis = new ZipInputStream(bis);//核心

BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream(fileName));
ZipOutputStream zipOut = new ZipOutputStream(bos);//核心
```







#### 适配器模式(不太会)

**适配器（Adapter Pattern）模式** 主要**用于接口互不兼容**的类的协调工作

适配器模式（Adapter）包含以下主要角色：

- 目标（Target）接口：当前系统业务所期待的接口，它可以是抽象类或接口
- 被适配者（Adaptee）类：它是被访问和适配的现存组件库中的组件接口(被适配的对象)
- 适配器（Adapter）类：它是一个转换器，通过继承或引用适配者的对象，**把适配者接口转换成目标接口，让客户按目标接口的格式访问被适配者**

IO 流中的字符流和字节流的接口不同，它们之间可以协调工作就是基于适配器模式来做的，更准确点来说是对象适配器。通过适配器，我们可以将字节流对象(适配者)通过适配器成一个字符流对象，这样我们可以直接通过字节流对象来读取或者写入字符数据

`InputStreamReader` 和 `OutputStreamWriter` 就是两个适配器(Adapter)， 同时它们两个也是字节流和字符流之间的桥梁。`InputStreamReader` 使用 `StreamDecoder` （流解码器）对字节进行解码，**实现字节流到字符流的转换，**`OutputStreamWriter` 使用`StreamEncoder`（流编码器）对字符进行编码，实现字符流到字节流的转换

`InputStream` 和 `OutputStream` 的**子类**(**FileInputStream**)是被适配者， `InputStreamReader` 和 `OutputStreamWriter`是适配器

```JAVA
// InputStreamReader 是适配器，FileInputStream 是被适配的类
InputStreamReader isr = new InputStreamReader(new FileInputStream(fileName), "UTF-8");
// BufferedReader 增强 InputStreamReader 的功能（装饰器模式）
BufferedReader bufferedReader = new BufferedReader(isr);
```



**适配器模式和装饰器模式有什么区别呢？**

**装饰器模式** 更侧重于动态地增强原始类的功能，**装饰器类**需要跟**具体构件类**继承相同的抽象类或者实现相同的接口。并且，装饰器模式支持对原始类(**具体构件类**)嵌套使用多个装饰器(`Decorator`)

**适配器模式** 更侧重于让接口不兼容而不能交互的类可以一起工作，当我们调用适配器对应的方法时，适配器内部会调用适配者类或者和适配类相关的类的方法，这个过程透明的。就比如说 `StreamDecoder` （流解码器）和`StreamEncoder`（流编码器）就是分别基于 `InputStream` 和 `OutputStream` 来获取 `FileChannel`对象并调用对应的 `read` 方法和 `write` 方法进行字节数据的读取和写入

适配器和适配者两者不需要继承相同的抽象类或者实现相同的接口





#### 观察者模式

观察者模式定义了一种一对多的依赖关系，让多个观察者对象同时监听某一个主题对象，这个主题对象在状态上发生变化时，会通知所有观察者对象，让他们能够自动更新自己，观察者模式主要有以下几类角色:

1. 抽象主题（Subject）角色：也叫抽象目标类，它提供了一个**用于保存观察者对象的聚集类**和增加、删除观察者对象的方法，以及通知所有观察者的抽象方法
2. 具体主题（Concrete Subject）角色：也叫具体目标类，它实现抽象目标中的通知方法，当具体主题的内部状态发生改变时，通知所有注册过的观察者对象
3. 抽象观察者（Observer）角色：它是一个抽象类或接口，它包含了一个更新自己的抽象方法，当接到具体主题的更改通知时被调用
4. 具体观察者（Concrete Observer）角色：实现抽象观察者中定义的抽象方法，以便在得到目标的更改通知时更新自身的状态

在 Java 中，通过 `java.util.Observable` 类和 `java.util.Observer` 接口定义了观察者模式，只要实现它们的子类就可以编写观察者模式实例

`Observable` 类是抽象目标类（被观察者），它有一个 Vector 集合成员变量，用于保存所有要通知的观察者对象下面来介绍它最重要的 3 个方法:

- void `addObserver`(Observer o) 方法：用于将新的观察者对象添加到集合中。
- void `notifyObservers`(Object arg) 方法：**调用集合中的所有观察者对象的 update 方法**，通知它们数据发生改变。通常越晚加入集合的观察者越先得到通知
- void `setChange`() 方法：用来设置一个 boolean 类型的内部标志，注明目标对象发生了变化。**当它为true时，notifyObservers() 才会通知观察者**,即`notifyObservers`()要首先检查该变量是否为true,如果为false就不执行而直接返回了

`Observer` 接口是抽象观察者，它监视目标对象的变化，当目标对象发生变化时，观察者得到通知，并调用 `update` 方法，进行相应的工作

根据上述描述，**如何基于Java内置的观察者模式框架实现一个观察者模式呢？**

1. 写一个类(具体主题角色)继承Observable（抽象主题角色），只需要写一个change方法即可 (该方法作用是通知已注册的具体主题角色更新自己)
2. 写一个类(具体观察者角色)实现Observer（抽象观察者角色），只需要实现方法update(Observable o, Object arg)即可
3. 写一个测试类进行测试



举一个简单的例子，警察监视小偷，警察充当观察者，小偷充当被观察者，代码如下：

小偷是一个被观察者，所以需要继承`Observable`类：

```java
import java.util.Observable;

public class Thief extends Observable {
    private String name;
//省略 get、set，构造方法

    public void steal() {
        System.out.println("小偷：我偷东西，有没有人来抓我！！！");
        super.setChanged();//默认为true
        super.notifyObservers();
    }
}
```

警察是一个观察者，所以需要让其实现Observer接口

```java
import java.util.Observable;
import java.util.Observer;
public class Policemen implements Observer {

    private String name;
    //省略
    @Override
    public void update(Observable o, Object arg) {
        System.out.println("警察：" + ((Thief) o).getName() + "你被我抓到了哈哈哈哈！！！");
    }
}
```



客户端代码：

```java
public class Client {
    public static void main(String[] args) {
        //小偷对象
        Thief thief = new Thief("法外狂徒张三");
        //警察对象
        Policemen policemen = new Policemen("小庄警察");
        //把警察注册为小偷的观察者
        thief.addObserver(policemen);
        //先设置setChanged()的flag为true，随后调用notifyObnservers()，来通知集合中所有观察者对象调用其的update() 方法
        thief.steal();
    }
}
```



### Unix中的IO模型



阻塞和非阻塞的概念描述的是用户线程调用内核IO操作的方式，阻塞时指IO操作需要彻底完成后才能返回用户空间，**非阻塞时指IO操作被调用后立即返回给用户一个状态值，无需等待IO操作彻底完成**





**阻塞式IO：**

应用进程被阻塞，直到操作系统内核把数据拷贝到用户空间，将数据复制到应用进程缓冲区中才返回，注意**在阻塞的过程中，其它程序还可以执行，因此阻塞不意味着整个操作系统都被阻塞。因为其他程序还可以执行，因此不消耗 CPU 时间**，这种模型的执行效率会比较高。

下图中，`recvfrom` 用于接收 `Socket` 传来的数据，并复制到应用进程的缓冲区buf中。这里把 `recvfrom()` 当成系统调用

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/java-io-model-0.png)





**非阻塞式IO：**

应用进程执行系统调用之后，内核会返回一个错误码，应用进程可以继续执行其他代码，**但是需要不断的执行系统调用来获知 I/O 是否完成**，这种方式称为**轮询(polling)**，由于 CPU 要处理更多的系统调用，因此这种模型是比较低效的

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/java-io-model-1.png)





**信号驱动IO**：

应用进程使用 `sigaction` 系统调用，内核立即返回，应用进程可以继续执行，也就是说**等待数据阶段应用进程是非阻塞的**。内核在数据到达时向应用进程发送 SIGIO 信号**，应用进程收到之后在信号处理程序中调用 `recvfrom` 将数据从内核复制到应用进程中**，即应用进程想发送/接收数据前先发个信号表示意愿，等待内核通知可以进行操作时再阻塞自己完成数据传输

相比于非阻塞式 I/O 的轮询方式，信号驱动 I/O 的 CPU 利用率更高

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/java-io-model-3.png" style="zoom:100%;" />



**异步IO：**

应用进程进行 `aio_read` 系统调用会立即返回，应用进程继续执行，不会被阻塞，内核会在所有操作完成之后向应用进程发送信号

异步 I/O 与信号驱动 I/O 的区别在于：**异步 I/O 的信号是通知应用进程 I/O 完成，而信号驱动 I/O 的信号是通知应用进程可以开始 I/O**

异步I/O与同步I/O的区别在于：同步 I/O应用进程在调用 `recvfrom` 操作时(即数据传输的过程)会阻塞，而异步 I/O**不会阻塞**进程，且阻塞式 I/O、非阻塞式 I/O、I/O 复用和信号驱动 I/O 都是同步 I/O，虽然**非阻塞式 I/O 和信号驱动 I/O 在等待数据阶段不会阻塞(阻塞式I/O和 I/O复用在等待数据时就会进入阻塞)，但是在之后的将数据从内核复制到应用进程这个操作会阻塞**





> 再来一个例子加深一下理解：
>
> 同步阻塞模式：这种模式下，我们的工作模式是先来到厨房，开始烧水，并坐在水壶面前一直等着水烧开。
>
> 同步非阻塞模式：这种模式下，我们的工作模式是先来到厨房，开始烧水，但是我们不一直坐在水壶前面等，而是回到客厅看电视，然后每隔几分钟到厨房看一下水有没有烧开。
>
> 异步非阻塞 I/O 模型：这种模式下，我们的工作模式是先来到厨房，开始烧水，我们不一直坐在水壶前面等，也不隔一段时间去看一下，而是在客厅看电视，水壶上面有个开关，水烧开之后他会通知我。
>
> 阻塞 VS 非阻塞：人是否坐在水壶前面一直等。
>
> 同步 VS 异步：水壶是不是在水烧开之后主动通知人。







### **IO多路复用**



IO多路复用实际上属于`NIO`



使用 `select` 、 `poll` 、`epoll`等待数据，并且可以监听多个套接字中的任何一个变为可读，这一过程会被阻塞，**当某一个套接字可读时返回**，之后再使用 `recvfrom` 把数据从内核复制到应用缓冲区中，整个过程期间监听的进程阻塞，**IO多路复用使用两个系统调用**（`select/poll/epoll`和`recvfrom`），`blocking IO`调用了`recvfrom`，`select/poll/epoll`核心是可以同时处理多个`connection`，而不是更快，所以连接数不高的话，性能不一定比多线程+阻塞IO好

**它可以让单个进程具有处理多个 I/O 事件的能力**

如果一个 Web 服务器没有 I/O 复用，那么每一个 `Socket` 连接都需要创建一个线程去处理。如果同时有几万个连接，那么就需要创建相同数量的线程。并且相比于多进程和多线程技术，I/O 复用不需要进程线程创建和切换的开销，系统开销更小

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/java-io-model-2.png)

典型的多路复用IO实现有以下几种：

| IO模型 | 相对性能 | 关键思路         | 操作系统      | JAVA支持情况                                                 |
| ------ | -------- | ---------------- | ------------- | ------------------------------------------------------------ |
| select | 较高     | Reactor          | windows/Linux | 支持,Reactor模式(反应器设计模式)。Linux操作系统的 kernels 2.4内核版本之前，默认使用select；而目前windows下对同步IO的支持，都是select模型 |
| poll   | 较高     | Reactor          | Linux         | Linux下的JAVA NIO框架，Linux kernels 2.6内核版本之前使用poll进行支持。也是使用的Reactor模式 |
| epoll  | 高       | Reactor/Proactor | Linux         | Linux kernels 2.6内核版本及以后使用epoll进行支持；Linux kernels 2.6内核版本之前使用poll进行支持；另外一定注意，由于Linux下没有Windows下的IOCP技术提供真正的 异步IO 支持，所以Linux下使用epoll模拟异步IO |
| kqueue | 高       | Proactor         | Linux         | 目前JAVA的版本不支持                                         |



`select`，`poll`，`epoll`都是IO多路复用的机制。I/O多路复用就是通过一种机制，一个进程可以监视多个描述符（socket），一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。虽说IO多路复用被称为异步阻塞IO，但**select，poll，epoll本质上都是同步IO，因为它们都需要在续写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而真正意义上的异步IO无需自己负责进行读写**





**select**

```c++
int select(int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);
```

`select`函数监视的文件描述符有三类，`readfds，writefds，exceptfds(错误信息)`，调用后函数会阻塞，直到有描述符就绪（有数据读、写、或者有except），或者超时（timeout指定时间，如果立即返回设置null），函数返回。当select函数返回后，可以通过便利fdset，来找到就绪的描述符。

 优点：良好的跨平台性

 缺点：单个进程能够监视的文件描述符的数量存在最大限制，在Linux上为1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但这样会造成效率的降低



**poll**

```c++
int poll(struct poll *fds, unsigned int nfds, int timeout);
struct pollfd{
  int fd;
  short events;
  short revents;
};
```

pollfd结构包含了要监视的event和发生的event，**不再使用select参数传值的方式。同时pollfd并没有最大数量的限制**（但数量过大性能也会下降）。和select一样，poll返回后，需要轮询pollfd来或许就绪的描述符。和epoll的比较：

1. 事件注册：
   - `poll()`使用`pollfd`结构来注册文件描述符和事件，并通过`poll()`系统调用等待事件就绪。
   - `epoll()`使用`epoll_event`结构来注册文件描述符和事件，并通过`epoll_wait()`系统调用等待事件就绪。
2. 数据结构：
   - `poll()`使用线性数组来存储注册的文件描述符和事件，需要遍历整个数组来查找就绪的文件描述符，导致性能下降。
   - `epoll()`使用红黑树来存储文件描述符，并使用双链表来存储就绪的文件描述符，可以快速查找和处理就绪事件。
3. 文件描述符数量限制：
   - `poll()`将所有的文件描述符都存储在一个数组中，因此有一个最大文件描述符数量限制（通常是1024）
   - `epoll()`使用红黑树来存储文件描述符，并没有这个限制，可以支持更多的文件描述符。













**epoll**

`epoll`是select和poll的增强版本，相比于前两者，它更加的灵活，没有描述符的限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需要一次

`epoll()`是一种高性能的I/O多路复用机制，用于处理大量并发连接的情况,`epoll()`系统调用提供了一种非阻塞的I/O模型，可以监视多个文件描述符的状态并且在这些文件描述符就绪时通知应用程序进行相应的读写操作

`epoll()`的用法如下：

1. 创建`epoll`实例：首先，需要通过`epoll_create()`系统调用创建一个`epoll`实例，该实例会返回一个文件描述符，用于标识这个`epoll`实例。
2. 添加文件描述符到`epoll`：使用`epoll_ctl()`系统调用将需要监视的文件描述符添加到`epoll`实例中，可以通过设置事件类型（例如可读事件、可写事件等）来指定监视的事件。
3. 等待事件就绪：**使用`epoll_wait()`系统调用等待文件描述符的事件就绪**。**当有一个或多个文件描述符的事件就绪时，`epoll_wait()`会阻塞，并返回就绪的文件描述符以及对应的事件类型。**
4. 处理事件：一旦`epoll_wait()`返回有就绪的文件描述符，应用程序可以通过读取或写入数据来处理这些事件。

使用`epoll()`的优势在于它避免了传统的阻塞式I/O模型中的大量线程阻塞等待，从而减少了线程的创建和销毁开销。它可以同时监视大量的文件描述符，提高了系统的并发性能和吞吐量。因此，对于高并发的网络编程，`epoll()`是一种高效的I/O多路复用机制





###  Reactor模型



https://pdai.tech/md/java/io/java-io-nio-select-epoll.html#reactor%E6%A8%A1%E5%9E%8B%E5%92%8Cproactor%E6%A8%A1%E5%9E%8B





`Reactor`模式由`Reactor`线程、`Handler` 处理器两大角色组成，两大角色的职责分别如下：

（1）`Reactor`：负责查询IO事件，当检测到一个IO事件时将其件分发给相应的Handler处理器去处理。这里的IO事件就是NIO中选择器查询出来的通道IO事件

（2）多种`Handler`：与IO事件（或者选择键）绑定，负责IO事件的处理，完成真正的连接建立、通道的读取、处理业务逻辑、负责将结果写到通道等





**单线程Reactor：**

Reactor单线程模型，指的是**监听I/O事件+处理所有的I/O操作**都在同一个NIO线程中完成

Reactor对象监听socket请求事件，收到事件后通过Dispatch进行分发；

如果是建立连接请求事件，则由Acceptor通过accept处理连接请求，然后创建Handler对象处理连接完成后的后续业务处理；

如果不是建立连接请求事件，则Reactor则会分发调用连接对应的Handler来响应；

Handler会完成 Read 解码-> 业务处理 -> 编码 Send 的完整业务逻辑 



缺点：

1.性能问题，无法完全发挥多核 CPU 的性能。

2.**而且一旦Handler 在处理某个连接上的业务时，整个进程无法处理其它连接事件，很容易导致性能瓶颈**；

3.可靠性问题，线程意外终止，或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障 





**单Reactor多handler:**

监听socket事件还是一个 Reactor 对象,但是在实际的业务处理的时候，使用了线程池进行业务处理。这样，**业务处理线程与负责新连接监听的`Reactor`反应器线程就能相互隔离**，避免服务器的连接监听受到阻塞

1. Reactor对象监听socket请求事件，当请求事件达到后，通过dispatch分发请求；

2. 若是建立连接的事件，则通过Acceptor的accept处理连接请求，然后创建Handler事件来处理后续逻辑

3. 如果不是建立连接事件，则通过Reactor分发到连接对应的handler来处理；

4. handler只负责响应事件，不做具体的业务处理，通过read读取数据后，分发给worker线程池去处理业务；

5. 对应业务的`worker`线程池会分配独立的线程去完成真正的业务，并将结果返回给handler；

6. handler收到响应后，通过send方法将结果返回给client；



缺点：

多线程会进行数据共享和访问比较复杂，而处理所有的事件监听和响应事件的`Reactor`是在单线程中运行，在高并发场景容易出现性能瓶颈





**主从 Reactor:**

它的主要思想是:

- 将处理事件的任务分解为两个部分:事件接收和事件处理。

- 设计一个主Reactor负责事件的监听和接收。

- 设计一个或多个从Reactor负责事件的真正处理

- 三大组件有：

  Reactor：把IO事件分配给对应的 handler 处理
  Acceptor：处理客户端连接事件
  Handler：处理非阻塞的任务

具体来说，梳理下基于主从Reactor多线程模型的事件处理过程：

    Reactor主线程对象通过select监听连接事件，通过Acceptor处理连接事件
    
    当Acceptor处理连接事件后，主reactor将连接分配给从Reactor
    
    从Reactor将连接加入到连接队列进行监听，并创建handler进行各种事件处理
    
    当有新事件发生时，从reactor就会对用对应的handler处理
    
    handler读取数据后，分发给后面的worker线程处理
    
    worker线程池分配独立的worker线程进行处理并返回结果
    
    handler收到结果后再讲结果返回给客户端



















### IO类型

####  BIO (Blocking I/O)

**应用程序发起 read 调用后，会一直阻塞**，直到内核把数据拷贝到用户空间



####  NIO (Non-blocking/New I/O)

Java 中的 NIO 可以看作是 **I/O 多路复用模型**。也有很多人认为，Java 中的 NIO 属于同步非阻塞 IO 模型,同步非阻塞 IO 模型中，应用程序会一直发起 read 调用，等待数据从内核空间拷贝到用户空间的这段时间里，线程依然是阻塞的，直到内核把数据拷贝到用户空间,即通过轮询操作避免了一直阻塞(类似自旋)，但是，这种 IO 模型同样存在问题：**应用程序不断进行 I/O 系统调用轮询数据是否已经准备好的过程是十分消耗 CPU 资源的**



NIO 实现了 IO 多路复用中的 `Reactor` 模型，一个线程 Thread 使用一个选择器 Selector 通过轮询的方式去监听多个通道 Channel 上的事件，从而让一个线程就可以处理多个事件。

通过**配置监听的通道 `Channel` 为非阻塞**，那么当 Channel 上的 I/O 事件还未到达时，就不会进入阻塞状态一直等待，而是继续轮询其它 `Channel`，找到 IO 事件已经到达的 `Channel` 执行



Java 中的 NIO ，有一个非常重要的**选择器 ( `Selector` )** 的概念，也可以被称为**多路复用器**。通过它，只需要一个线程便可以管理多个客户端连接。当客户端数据到了之后，才会为其服务：

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/channel-buffer-selector.png"  />

NIO 主要包括以下三个核心组件：

- **Buffer（缓冲区）**：NIO 读写数据都是通过缓冲区进行操作的。客户端读操作的时候将 `Channel` 中的数据填充到 `Buffer`中，而客户端写操作时将 Buffer中的数据写入到 `Channel`中

  Java NIO 使用了`ByteBuffer`，而Netty则使用了`ByteBuf`

- **Channel（通道）**：`Channel` 是一个双向的、可读可写的数据传输通道，NIO 通过Channel来实现数据的输入输出。通道是一个抽象的概念，它可以代表文件、套接字或者其他数据源之间的连接,Channel 是一个通道，它建立了与数据源（如文件、网络套接字等）之间的连接,Client读操作的时候将 Channel 中的数据填充到 Buffer中，而进行写操作时将 Buffer中的数据写入到 Channel 中

- **Selector（选择器）**：允许一个线程处理多个 `Channel`，基于事件驱动的 I/O 多路复用模型。所有的 `Channel` 都可以注册到`Selector`上，由`Selector`来分配线程(`Select`)来处理事件,`Selector` 是**基于事件驱动的 I/O 多路复用模型**，主要运作原理是：通过 `Selector` 注册通道的事件，`Selector` 会不断地轮询注册在其上的 `Channel`。当事件发生时，比如：**某个 `Channel`上面有新的 TCP 连接接入、读和写事件，这个 `Channel`就处于就绪状态，会被 `Selector` 轮询出来**。`Selector` 会将相关的 `Channel`加入到就绪集合中。通过 `SelectionKey`可以获取就绪 `Channel`的集合，然后对这些就绪的 `Channel`进行响应的 I/O 操作,**由于 JDK使用了 `epoll()` 代替传统的 `select` 实现，所以它并没有最大连接句柄 `1024/2048` 的限制。这也就意味着只需要一个线程负责 `selector` 的轮询，就可以接入成千上万的客户端**

  



#### AIO (Asynchronous I/O)

AIO 也就是 NIO 2，它是**异步** I/O 模型，异步 I/O 是**基于事件和回调机制实现**的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作







### **零拷贝**

零拷贝是指计算机执行 `I/O` 操作时，**CPU 不需要将数据从一个存储区域复制到另一个存储区域，从而可以减少上下文切换(用户态<—>内核态切换)以及 CPU 的拷贝时间**。也就是说，零拷贝主要解决操作系统在处理 I/O 操作时频繁复制数据的问题。零拷贝的常见实现技术有： `mmap+write`、`sendfile`和 `sendfile + DMA gather copy`

下图展示了各种零拷贝技术的对比图：

|                            | CPU 拷贝 | DMA 拷贝 | 系统调用   | 上下文切换 |
| -------------------------- | -------- | -------- | ---------- | ---------- |
| 传统方法                   | 2        | 2        | read+write | 4          |
| **mmap+write**             | 1        | 2        | mmap+write | 4          |
| **sendfile**               | 1        | 2        | sendfile   | 2          |
| sendfile + DMA gather copy | 0        | 2        | sendfile   | 2          |

可以看出，无论是传统的 I/O 方式，还是引入了零拷贝之后，2 次 DMA(Direct Memory Access) 拷贝是都少不了的。因为两次 DMA 都是依赖硬件完成的。零拷贝主要是减少了 CPU 拷贝及上下文的切换



(1) **mmap+write**：实际上是使用mmap替换了传统操作read+write中的read操作，mmap主要是将读缓冲区中的地址(磁盘文件地址)和用户缓冲区的地址(进程虚拟地址)进行映射，内核缓冲区和用户缓冲区共享，从而减少了读缓冲区到用户缓冲区的一次CPU拷贝(**减少了内核态——用户态的拷贝**)：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%9B%B6%E6%8B%B7%E8%B4%9D/mmap%20%2B%20write%20%E9%9B%B6%E6%8B%B7%E8%B4%9D.png)

具体过程如下：

- 应用进程调用了 `mmap()` 后，DMA 会把磁盘的数据拷贝到内核的缓冲区里。接着，应用进程跟操作系统内核「共享」这个缓冲区；
- 应用进程再调用 `write()`，操作系统直接将内核缓冲区的数据拷贝到 socket 缓冲区中，这一切都发生在内核态，由 CPU 来搬运数据；
- 最后，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程是由 DMA 搬运的。

我们可以得知，通过使用 `mmap()` 来代替 `read()`， 可以减少一次数据拷贝的过程。

但这还不是最理想的零拷贝，因为**仍然需要通过 CPU 把内核缓冲区的数据拷贝到 socket 缓冲区里**，而且仍然需要 4 次上下文切换，因为系统调用还是 2 次







(2) **sendfile**:使用`sendfile`数据可以直接在内核空间进行传输，因此避免了用户空间和内核空间的拷贝，同时由于`sendfile`替代了`read+write`,从而节省了一次系统调用(减少了上下文切换)，`sendfile`操作对用户空间完全不可见(IO数据对用户完全不可见)，在消息队列中，无非就是生产者发送消息到mq,然后将消息持久化到磁盘，然后消费者从mq中读取消息，对于`rocketmq`而言，这两个步骤使用的是`mmap+write`,而`kafka`则是使用`mmap+write`来持久化数据，发送数据则使用的`sendfile`



<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/MMAP2.png" style="zoom:67%;" />



从 Linux 内核 `2.4` 版本开始起，对于支持网卡支持 SG-DMA 技术的情况下， `sendfile()` 系统调用的过程发生了点变化，具体过程如下：

- 第一步，通过 DMA 将磁盘上的数据拷贝到内核缓冲区里；
- 第二步，缓冲区描述符和数据长度传到 socket 缓冲区，这样网卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里，此过程不需要将数据从操作系统内核缓冲区拷贝到 socket 缓冲区中，这样就减少了一次数据拷贝；

所以，这个过程之中，只进行了 2 次数据拷贝，如下图：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%9B%B6%E6%8B%B7%E8%B4%9D/senfile-%E9%9B%B6%E6%8B%B7%E8%B4%9D.png)

这就是所谓的**零拷贝（\*Zero-copy\*）技术，因为我们没有在内存层面去拷贝数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的。**

零拷贝技术的文件传输方式相比传统文件传输的方式，减少了 2 次上下文切换和数据拷贝次数，**只需要 2 次上下文切换和数据拷贝次数，就可以完成文件的传输，而且 2 次的数据拷贝过程，都不需要通过 CPU，2 次都是由 DMA 来搬运。**



在 Linux 内核版本 2.1 中，提供了一个专门发送文件的系统调用函数 `sendfile()`，函数形式如下：

```c
#include <sys/socket.h>
ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);
```

它的前两个参数分别是目的端和源端的文件描述符，后面两个参数是源端的偏移量和复制数据的长度，返回值是实际复制数据的长度。

首先，它可以替代前面的 `read()` 和 `write()` 这两个系统调用，这样就可以减少一次系统调用，也就减少了 2 次上下文切换的开销。

其次，该系统调用，可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态，这样就只有 2 次上下文切换，和 3 次数据拷贝。如下图：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E9%9B%B6%E6%8B%B7%E8%B4%9D/senfile-3%E6%AC%A1%E6%8B%B7%E8%B4%9D.png)





Java 对零拷贝的支持：

- `MappedByteBuffer` 是 NIO 基于**内存映射**（`mmap`：**mmap 是一种内存映射文件的方法，即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系**）这种零拷⻉⽅式的提供的⼀种实现，底层实际是调用了 Linux 内核的 `mmap` 系统调用。它可以将一个文件或者文件的一部分映射到内存中，形成一个虚拟内存文件，这样就可以直接操作内存中的数据，而不需要通过系统调用来读写文件。

- `FileChannel` 的`transferTo()/transferFrom()`是 NIO 基于发送文件（`sendfile`）这种零拷贝方式的提供的一种实现，底层实际是调用了 Linux 内核的 `sendfile`系统调用。它可以直接将文件数据从磁盘发送到网络，而不需要经过用户空间的缓冲区

  在 Linux 中系统调用 sendfile() 可以实现将数据从一个文件描述符传输到另一个文件描述符，从而实现了零拷贝技术。在 Java 中也使用了零拷贝技术，它就是 NIO FileChannel 类中的 transferTo() 方法，`transferTo()` **底层就依赖了操作系统零拷贝的机制，它可以将数据从 `FileChannel` 直接传输到另外一个 `Channel`**



总结一下，在发送数据的时候，传统的实现方式是：

```c++
1.  `File.read(bytes)`
2.  `Socket.send(bytes)`
```

这种方式需要四次数据拷贝和四次上下文切换：

1. 数据从磁盘读取到内核的read buffer(DMA方式)
2. 数据从内核缓冲区拷贝到用户缓冲区(内核态——>用户态的切换)
3. 数据从用户缓冲区拷贝到内核的socket buffer(用户态——>内核态的切换)
4. 数据从内核的socket buffer拷贝到网卡接口的缓冲区(DMA方式)

明显上面的第二步和第三步是没有必要的，通过java的`FileChannel.transferTo`方法，可以避免上面两次多余的拷贝（当然这需要底层操作系统支持）

1. 调用transferTo,数据从文件由DMA引擎拷贝到内核read buffer(内核缓冲区)
2. 接着DMA从内核read buffer将数据拷贝到网卡接口buffer(跳过Socket缓冲区)

上面的两次操作都不需要CPU参与，所以就达到了零拷贝。







### `Netty`中的**零拷贝**



在介绍 Netty 零拷贝特性之前，我们有必要学习下传统 Linux 中零拷贝的工作原理。所谓零拷贝，就是在数据操作时，不需要将数据从一个内存位置拷贝到另外一个内存位置，这样可以减少一次内存拷贝的损耗，从而节省了 CPU 时钟周期和内存带宽。

我们模拟一个场景，从文件中读取数据，然后将数据传输到网络上，那么传统的数据拷贝过程会分为哪几个阶段呢？具体如下图所示：

<img src="https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/Netty%20%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86%E5%89%96%E6%9E%90%E4%B8%8E%20RPC%20%E5%AE%9E%E8%B7%B5-%E5%AE%8C/assets/Ciqc1F_Qbz2AD4uMAARnlgeSFc4993.png" alt="Drawing 0.png" style="zoom:50%;" />

从上图中可以看出，从数据读取到发送一共经历了**四次数据拷贝**，具体流程如下：

1. 当用户进程发起 read() 调用后，上下文从用户态切换至内核态。 DMA 引擎从文件中读取数据，并存储到内核态缓冲区，这里是**第一次数据拷贝**
2. 请求的数据从内核态缓冲区拷贝到用户态缓冲区，然后返回给用户进程。第二次数据拷贝的过程同时，会导致上下文从内核态再次切换到用户态
3. 用户进程调用 send() 方法期望将数据发送到网络中，此时会触发第三次线程切换，用户态会再次切换到内核态，请求的数据从用户态缓冲区被拷贝到 Socket 缓冲区
4. 最终 send() 系统调用结束返回给用户进程，发生了第四次上下文切换。第四次拷贝会异步执行，从 Socket 缓冲区拷贝到协议引擎中

传统的数据拷贝过程为什么不是将数据直接传输到用户缓冲区呢？其实引入内核缓冲区可以充当缓存的作用，这样就可以实现文件数据的预读，提升 I/O 的性能。但是当请求数据量大于内核缓冲区大小时，在完成一次数据的读取到发送可能要经历数倍次数的数据拷贝，这就造成严重的性能损耗。

接下来我们介绍下使用零拷贝技术之后数据传输的流程。重新回顾一遍传统数据拷贝的过程，可以发现第二次和第三次拷贝是可以去除的，**DMA 引擎从文件读取数据后放入到内核缓冲区，然后可以直接从内核缓冲区传输到 Socket 缓冲区(跳过内核缓冲区—用户缓冲区之间的拷贝)**，从而减少内存拷贝的次数。



介绍完传统 Linux 的零拷贝技术之后，我们再来学习下 Netty 中的零拷贝如何实现



前置知识：

**在 JVM 内部执行 I/O 操作时，必须将数据拷贝到堆外内存，才能执行系统调用**。这是所有 VM 语言都会存在的问题。那么为什么操作系统不能直接使用 JVM 堆内存进行 I/O 的读写呢？主要有两点原因：第一，操作系统并不感知 JVM 的堆内存，而且 JVM 的内存布局与操作系统所分配的是不一样的，操作系统并不会按照 JVM 的行为来读写数据。第二，同一个对象的内存地址随着 JVM GC 的执行可能会随时发生变化，例如 JVM GC 的过程中会通过压缩来减少内存碎片，这就涉及对象移动的问题了。

**Netty 在进行 I/O 操作时都是使用的堆外内存，可以避免数据从 JVM 堆内存到堆外内存的拷贝**



Netty的零拷贝体现在三个方面：

1. Netty的接收和发送ByteBuffer采用`DIRECT BUFFERS`，**使用堆外直接内存进行Socket读写**，不需要进行字节缓冲区的二次拷贝。**如果使用传统的堆内存（HEAP BUFFERS）进行Socket读写，JVM会将堆内存Buffer拷贝一份到直接内存(堆外内存)中，然后才写入`Socket`中去。相比于堆外直接内存，消息在发送过程中多了一次缓冲区的内存拷贝。**





2. Netty提供了组合Buffer对象，可以聚合多个ByteBuffer对象，用户可以像操作一个Buffer那样方便的对组合Buffer进行操作，避免了传统通过内存拷贝的方式将几个小Buffer合并成一个大的Buffer。

CompositeByteBuf 是 Netty 中实现零拷贝机制非常重要的一个数据结构，CompositeByteBuf 可以理解为一个虚拟的 Buffer 对象，它是由多个 ByteBuf 组合而成，但是在 CompositeByteBuf 内部保存着每个 ByteBuf 的引用关系，从逻辑上构成一个整体。比较常见的像 HTTP 协议数据可以分为**头部信息 header**和**消息体数据 body**，分别存在两个不同的 ByteBuf 中，通常我们需要将两个 ByteBuf 合并成一个完整的协议数据进行发送，可以使用如下方式完成：

```java
ByteBuf httpBuf = Unpooled.buffer(header.readableBytes() + body.readableBytes());

httpBuf.writeBytes(header);

httpBuf.writeBytes(body);
```

可以看出，如果想实现 header 和 body 这两个 ByteBuf 的合并，需要先初始化一个新的 httpBuf，然后再将 header 和 body 分别拷贝到新的 httpBuf。合并过程中涉及两次 CPU 拷贝，这非常浪费性能。如果使用 CompositeByteBuf 如何实现类似的需求呢？如下所示：

```java
CompositeByteBuf httpBuf = Unpooled.compositeBuffer();

httpBuf.addComponents(true, header, body);
```





3. `Netty` 中使用 `FileRegion` 实现文件传输的零拷贝, 不过在底层 `FileRegion` 是依赖于 Java NIO中的 `FileChannel.transfer` 的零拷贝功能

发送数据的时候，传统的实现方式是：

```c++
1.  `File.read(bytes)`
2.  `Socket.send(bytes)`
```

这种方式需要四次数据拷贝和四次上下文切换：

1. 数据从磁盘读取到内核的read buffer
2. 数据从内核缓冲区拷贝到用户缓冲区
3. 数据从用户缓冲区拷贝到内核的socket buffer
4. 数据从内核的socket buffer拷贝到网卡接口的缓冲区

明显上面的第二步和第三步是没有必要的，通过java的`FileChannel.transferTo`方法，可以避免上面两次多余的拷贝（当然这需要底层操作系统支持）

1. 调用**transferTo**,数据从文件由DMA引擎拷贝到内核read buffer
2. 接着DMA从内核read buffer将数据拷贝到网卡接口buffer

上面的两次操作都不需要CPU参与，所以就达到了零拷贝。

> transferTo方法底层是linux中的sendfile()：一次DMA操作从磁盘读取file到内核缓冲区，然后直接跳过Socket缓冲区发送至网卡接口

Netty 使用 FileRegion 实现文件传输的零拷贝。FileRegion 的默认实现类是 DefaultFileRegion，通过 DefaultFileRegion 将文件内容写入到 `NioSocketChannel`。那么 FileRegion 是如何实现零拷贝的呢？我们通过源码看看 FileRegion 到底使用了什么黑科技:

```java
public class DefaultFileRegion extends AbstractReferenceCounted implements FileRegion {

    private final File f; // 传输的文件

    private final long position; // 文件的起始位置

    private final long count; // 传输的字节数

    private long transferred; // 已经写入的字节数

    private FileChannel file; // 文件对应的 FileChannel
    @Override

    public long transferTo(WritableByteChannel target, long position) throws IOException {

        long count = this.count - position;

        if (count < 0 || position < 0) {

            throw new IllegalArgumentException(

                    "position out of range: " + position +

                    " (expected: 0 - " + (this.count - 1) + ')');

        }

        if (count == 0) {

            return 0L;

        }

        if (refCnt() == 0) {

            throw new IllegalReferenceCountException(0);

        }

        open();

        long written = file.transferTo(this.position + position, count, target);

        if (written > 0) {

            transferred += written;

        } else if (written == 0) {

            validate(this, position);

        }

        return written;

    }
    // 省略其他代码

}
```

从源码可以看出，FileRegion 其实就是对 FileChannel 的包装，并没有什么特殊操作，底层使用的是 JDK NIO 中的 `FileChannel.transferTo()` 方法实现文件传输，所以 FileRegion 是操作系统级别的零拷贝，对于传输大文件会很有帮助











## Java8 新特性



### Default()方法

首先定义一个接口A，然后`Clazz`类实现了接口A

```java
public interface A {
    default void foo(){
       System.out.println("Calling A.foo()");
    }
}

public class Clazz implements A {
    public static void main(String[] args){
       Clazz clazz = new Clazz();
       clazz.foo();//调用A.foo()
    }
}
```

代码是可以编译的，即使`Clazz`类并没有实现`foo()`方法。在接口A中提供了`foo()`方法的默认实现

> 什么是默认方法?

简单说，就是接口**可以有实现方法，而且不需要实现类去实现其方法**。只需在方法名前面加个`default`关键字即可

- `Interface` 的设计初衷是面向抽象，提高扩展性。这也留有一点遗憾，`Interface` 修改的时候，实现它的类也必须跟着改

- 为了解决接口的修改与现有的实现不兼容的问题。新 `Interface` 的方法可以用`default` 或 `static`修饰，这样就可以有方法体，实现类也不必重写此方法

- `default`修饰的方法，**是普通实例方法**，可以用`this`调用，可以被子类继承、重写

- `static`修饰的方法，使用上和一般类静态方法一样。但它不能被子类继承，只能用`Interface`调用

  > 在 Java 中，子类可以继承父类的静态方法，但是它们不能被重写。当子类调用继承自父类的静态方法时，实际上是直接调用父类的静态方法，而不是子类的静态方法。这是因为静态方法是在编译时就确定的，它们的调用是通过类名来实现的，而不是通过对象引用来实现的。



再来看看接口和抽象类的区别：

| 相同点                                                       | 不同点                                                       |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| 都是抽象类型                                                 | 抽象类不可以多重继承，接口可以多实现                         |
| 都可以有实现方法(以前接口不行 java8后加入了default 方法，不需要实现类来实现了) | 抽象类和接口所反映出的**设计理念**不同。其实抽象类表示的是”is-a”关系，接口表示的是”like-a”关系； 例如: Class Cat Extends Animal implement Eat  表示Cat只属Animal这一类物种(单继承)，但是它有Eat的功能，还可以同时具备Run、Sleep这样的功能 (对应接口的多实现！) |
| 都可以不需要实现类或者继承者去实现所有方法，(以前不行，现在接口中默认方法不需要实现者实现) | 接口中定义的变量默认是public static final 型，且必须给其初值，所以实现类中不能改变其值；抽象类中的变量默认是 friendly 型，其值可以在子类中重新定义，也可以重新赋值 |
| 抽象类不能被实例化：抽象类不能直接创建对象，即不能使用`new`关键字来实例化抽象类。**只能通过其子类来实例化**，子类必须实现抽象类中的所有抽象方法；                        接口本身同样不能被实例化，**接口的实现类可以被实例化**。**当一个类实现了一个接口时，它必须提供接口中定义的所有抽象方法的具体实现** | 接口的方法是 `public abstract` 修饰，变量是 `public static final` 修饰。 `abstract class` 可以用其他修饰符 |











###  函数式编程 :crying_cat_face:

很长的一段时间里，Java一直是面向对象的语言，一切皆对象，如果想要调用一个函数，函数必须属于一个类或对象，然后再使用类或对象进行调用。但是在其它的编程语言中，如JS、C++，我们可以直接写一个函数，然后在需要的时候进行调用，既可以说是面向对象编程，也可以说是函数式编程。从功能上来看，面向对象编程没什么不好的地方，但是从开发的角度来看，面向对象编程会多写很多可能是重复的代码行。比如创建一个`Runnable`的匿名类的时候：

```java
Runnable runnable = new Runnable() {
    @Override
    public void run() {
        System.out.println("do something...");
    }
};

```

> 匿名内部类通常用于实现接口、继承抽象类或者作为方法参数，可以在一行代码中定义和实例化一个对象
>
> new 父类构造器/接口() {
>     // 匿名内部类的类体部分
> };  // 返回一个实现了该接口的实例对象，但是该接口的实现类没有定义名字，所以叫匿名内部类



这一段代码中真正有用的只有`run()`方法中的内容，剩余的部分都是属于`Java`编程语言的结构部分，没什么用，但是要写。幸运的是`Java 8`开始，引入了函数式编程接口与`Lambda`表达式，帮助我们写更少更优雅的代码：

```java
// 一行即可
Runnable runnable = () -> System.out.println("do something...");
```

函数式编程认为程序可以用一系列数学函数或表达式的组合来表示。函数式编程是程序面向数学的更底层的抽象，将计算过程描述为表达式





实现面向对象编程不一定非得使用面向对象编程语言，同理，实现函数式编程也不一定非得使用函数式编程语言。现在，很多面向对象编程语言，也提供了相应的语法、类库来支持函数式编程。Java这种面向对象编程语言，对函数式编程的支持可以通过一个例子来描述：

```java
public class Demo {
  public static void main(String[] args) {
    Optional<Integer> result = 
        Stream.of("a", "be", "hello") // of返回Stream<String>对象
            .map(s -> s.length()) // map返回Stream<Integer>对象
            .filter(l -> l <= 3)  // filter返回Stream<Integer>对象
            .max((o1, o2) -> o1-o2);  // max终止操作：返回Optional<Integer>
    System.out.println(result.get()); // 输出2
  }
}
```

这段代码的作用是从一组字符串数组中，过滤出长度小于等于3的字符串，并且求得这其中的最大长度。

Java为函数式编程引入了三个新的语法概念：`Stream`类、`Lambda`表达式和函数式接口（`Functional Inteface`）。`Stream`**类用来支持通过“.”级联多个函数操作的代码编写方式**；引入Lambda表达式的作用是简化代码编写；函数接口的作用是让我们可以把函数包裹成函数接口，来实现把函数当做参数一样来使用（Java 不像C那样支持函数指针，可以把函数直接当参数来使用）



#### **Stream类**

>  这里只是简单讲了下Stream的流式处理特性，`Stream` 类主要还是用于操作集合（Collection）和数组（Array）的，后面再细讲

假设我们要计算这样一个表达式：(3-1)*2+5。如果按照普通的函数调用的方式写出来，就是下面这个样子：

```
add(multiply(subtract(3,1),2),5);
```

不过，这样编写代码看起来会比较难理解，我们换个更易读的写法，如下所示：

```
subtract(3,1).multiply(2).add(5);
```

在Java中，“.”表示调用某个对象的方法。**为了支持上面这种级联调用方式，我们让每个函数都返回一个通用的Stream类对象。在Stream类上的操作有两种：中间操作和终止操作。中间操作返回的仍然是Stream类对象，而终止操作返回的是确定的值结果**

上述例子中的

```java
 Optional<Integer> result = 
     Stream.of("f", "ba", "hello") // of返回Stream<String>对象
            .map(s -> s.length()) // map返回Stream<Integer>对象
            .filter(l -> l <= 3) // filter返回Stream<Integer>对象
            .max((o1, o2) -> o1-o2); // max终止操作：返回Optional<Integer>
    System.out.println(result.get()); // 输出
```

其中`map、filter`是中间操作，返回`Stream`类对象，可以继续级联其他操作；`max`是终止操作，返回的不是`Stream`类对象，无法再继续往下级联处理了



> 在 Java 中，级联调用（chained call）是一种连续调用同一个对象的多个方法的语法形式，通常使用点号（`.`）连接每个方法调用。级联调用可以使代码更加简洁和可读，尤其是在方法链式调用中非常常见。
>
> 补充一个例子，加深对级联调用的理解：
>
> ```java
> StringBuilder sb = new StringBuilder();
> sb.append("Hello").append(" ").append("world").append("!");
> String result = sb.toString();
> System.out.println(result);
> ```
>
> 对于方法链式调用，每个方法都应该返回同一个对象，这样才能使级联调用有效。在上面的示例中，每个 `append()` 方法都返回 `StringBuilder` 对象本身，因此可以进行级联调用。如果有任何一个方法返回了不同的对象，那么级联调用就会失效。









#### **Lambda表达式**

前面提到Java引入Lambda表达式的主要作用是简化代码编写。实际上，我们也可以不用Lambda表达式来书写例子中的代码。我们拿其中的map函数来举例说明。下面三段代码，第一段代码展示了map函数的定义，实际上，map函数接收的参数是一个`Function`接口(该接口是一个函数式接口)。第二段代码展示了map函数的使用方式。第三段代码是针对第二段代码用Lambda表达式简化之后的写法。实际上，Lambda表达式在Java中只是一个语法糖而已，底层是基于函数式接口来实现的，也就是第二段代码展示的写法。

```java
// Stream类中map函数的定义：
public interface Stream<T> extends BaseStream<T, Stream<T>> {
  <R> Stream<R> map(Function<? super T, ? extends R> mapper);
  //...省略其他函数...
}

// Stream类中map的使用方法示例：
Stream.of("fo", "bar", "hello").map(new Function<String, Integer>() {
  @Override
  public Integer apply(String s) {
    return s.length();
  }
});

// 用Lambda表达式简化后的写法：
Stream.of("fo", "bar", "hello").map(s -> s.length()); 
```

Lambda表达式包括三部分：**输入、函数体、输出**。表示出来的话就是下面这个样子：

```
(a, b) -> { 语句1；语句2；...; return 输出; } //a,b是输入参数
```

实际上Lambda表达式的写法非常灵活。比如如果输入参数只有一个，可以省略 ()，直接写成 a->{…}；如果没有入参，可以直接将输入和箭头都省略掉，只保留函数体；如果函数体只有一个语句，那可以将{}省略掉；如果函数没有返回值，return语句就可以不用写了：

```java
Optional<Integer> result = Stream.of("f", "ba", "hello")
        .map(s -> s.length())
        .filter(l -> l <= 3)
        .max((o1, o2) -> o1-o2);
        
// 还原为匿名内部类的实现方式
Optional<Integer> result2 = Stream.of("fo", "bar", "hello")
        .map(new Function<String, Integer>() {
          @Override
          public Integer apply(String s) {
            return s.length();
          }
        })
        .filter(new Predicate<Integer>() {
          @Override
          public boolean test(Integer l) {
            return l <= 3;
          }
        })
        .max(new Comparator<Integer>() {
          @Override
          public int compare(Integer o1, Integer o2) {
            return o1 - o2;
          }
        });
```

`Lambda`表达式与匿名类的异同集中体现在以下三点上：

- `Lambda`就是为了优化匿名内部类而生，`Lambda`要比匿名类简洁的多得多。
- `Lambda`仅适用于函数式接口，匿名类不受限。
- 即匿名类中的this是“匿名类对象”本身；`Lambda`表达式中的this是指“调用`Lambda`表达式的对象”



注意：

1.如果 Lambda 表达式的主体只有一条表达式,那么该表达式的值就是 Lambda 表达式的返回值。

2.如果 Lambda 表达式的主体有多条语句，那么需要使用大括号 `{}` 包含这些语句，并且需要使用 `return` 关键字来指定返回值。在这种情况下，Lambda 表达式的返回类型必须与对应的函数式接口中的抽象方法的返回类型相同或兼容。





#### **函数式接口**

实际上，上面一段代码中的`Function`、`Predicate`、`Comparator`都是函数式接口。

1. **函数接口就是接口。不过它也有自己特别的地方，那就是要求只包含一个未实现的方法。因为只有这样，Lambda表达式才能明确知道匹配的是哪个方法。如果有两个未实现的方法，并且接口入参、返回值都一样，那Java在翻译Lambda表达式的时候，就不知道表达式对应哪个方法了。**
2. **而且换个角度理解，用lambda表达式来创建一个接口的实例，那么该实例必然要实现接口的所有抽象方法，自然抽象方法也就只能有一个了，不然怎么匹配呢？**

函数式接口是`interface`，但还需要满足：

- 一个函数式接口只有一个抽象方法(`single abstract method` 而且必须是非`Object`类下的，第二点也提到了)；
- **Object类中的`public abstract method`不会被视为单一的抽象方法**；
- 函数式接口可以有默认方法和静态方法；
- 函数式接口可以用`@FunctionalInterface`注解进行修饰。

满足这些条件的`interface`，就可以被视为**函数式接口**。例如Java 8中的`Comparator`接口：

```java
@FunctionalInterface
public interface Comparator<T> {
    
    /**
     * single abstract method
     * @since 1.8
     */
    int compare(T o1, T o2);
    
    

    /**
     * Object类中的public abstract method 
     * 重写了超类Object类中任意一个public方法的方法并不算接口中的抽象方法
     * @since 1.8
     */
    boolean equals(Object obj);
    
    

    /**
     * 默认方法
     * @since 1.8
     */
    default Comparator<T> reversed() {
        return Collections.reverseOrder(this);
    }

    
    
    /**
     * 静态方法
     * @since 1.8
     */
    public static <T extends Comparable<? super T>> Comparator<T> reverseOrder() {
        return Collections.reverseOrder();
    }

    //省略...
}
```

函数式接口有什么用呢？一句话，函数式接口带给我们最大的好处就是：可以使用极简的`lambda`表达式实例化接口。为什么这么说呢？我们或多或少使用过一些只有一个抽象方法的接口，比如`Runnable`、`ActionListener`、`Comparator`等等，比如我们要用`Comparator`实现排序算法，我们的处理方式通常无外乎两种：

- 规规矩矩的写一个实现了`Comparator`接口的`Java`类去封装排序逻辑。若业务需要多种排序方式，那就得写多个类提供多种实现，而这些实现往往只需使用一次。

- 另外一种聪明一些的做法无外乎就是在需要的地方搞个匿名内部类，比如:

  ```java
  public class Test { 
      public static void main(String args[]) { 
          List<Person> persons = new ArrayList<Person>();
          Collections.sort(persons, new Comparator<Person>(){
              @Override
              public int compare(Person o1, Person o2) {
                  return Integer.compareTo(o1.getAge(), o2.getAge());
              }
          });
      } 
  }
  ```

- 匿名内部类实现的代码量没有多到哪里去，结构也还算清晰。`Comparator`接口在`Jdk 1.8`的实现增加了`FunctionalInterface`注解，代表`Comparator`是一个函数式接口，使用者可放心的通过`lambda`表达式来实例化。那我们来看看使用`lambda`表达式来快速`new`一个自定义比较器所需要编写的代码：

- ```java
  Comparator<Person> comparator = (p1, p2) -> Integer.compareTo(p1.getAge(), p2.getAge());
  
  //Comparator接口中的唯一抽象方法
  int compare(T o1, T o2);
  ```

  -> 前面的()是`Comparator`接口中`compare`方法的参数列表，-> 后面则是`compare`方法的方法体

  然后直接传入`Collections.sort()`即可：

  ```java
  Collections.sort(persons,comparator)；
  ```

  当然也可以直接合为一步：

  ```java
  Collections.sort(persons,(p1, p2) -> Integer.compareTo(p1.getAge(), p2.getAge()))；
  ```



再来看一个非常经典的**通过lambda表达式创建线程**的例子：

```java
//不声明变量的情况下：
new Thread(() ->{
    System.out.println("子线程启动");
     /*这里其实省略了  return;  
     
     lambda表达式的主体有多条语句时：
     需要使用大括号 {} 包含这些语句，并且需要使用 return 关键字来指定返回值；
     Runnable是一个函数式接口，自动匹配了唯一非Object类的抽象方法run()，且没有返回值；
}    */
     
).start();


//声明引用变量的情况下：
Thread t2=new Thread( ()->{
    System.out.println("子线程2启动");
});
t2.start();
```







#### 函数式编程实战

1、例如，我们自定义一个简单的函数接口 `MathOperation`，其中只有一个抽象方法 `int operate(int a, int b)`，表示两个整数的操作。然后，我们可以使用 `lambda` 表达式来实现这个接口并进行调用:

```java
@FunctionalInterface
interface MathOperation {
    int operate(int a, int b);
}

public class LambdaExample {
    public static void main(String[] args) {
        // 使用 lambda 表达式创建 MathOperation 接口的实例
        
        /*
        如果 Lambda 表达式的主体只有一条表达式，
        那么该表达式的值就是 Lambda 表达式的返回值。
        *下列四条语句创建了四个MathOperation的实例
            */
        MathOperation add = (a, b) -> a + b;
        MathOperation subtract = (a, b) -> a - b;
        MathOperation multiply = (a, b) -> a * b;
        MathOperation divide = (a, b) -> a / b;

        int num1 = 10;
        int num2 = 5;

        // 调用 MathOperation 接口的实现方法
        System.out.println("Addition: " + add.operate(num1, num2));
        System.out.println("Subtraction: " + subtract.operate(num1, num2));
        System.out.println("Multiplication: " + multiply.operate(num1, num2));
        System.out.println("Division: " + divide.operate(num1, num2));
    }
}

```

上述出现的 `Lambda` 表达式都是函数式接口 `MathOperation` 的实例，它们并不是 `MathOperation` 的**具体实现类**。在运行时，Java 编译器会根据 `Lambda` 表达式的结构**自动创建一个匿名类或者一个动态代理类来实现函数式接口的抽象方法**，**并将 `Lambda` 表达式转换为该匿名类或动态代理类的实例**







2、集合迭代查询：

```java
void lamndaFor() {
        List<String> strings = Arrays.asList("1", "2", "3");
        //传统foreach
        for (String s : strings) {
            System.out.println(s);
        }
    
        //Lambda foreach
        strings.forEach((s) -> System.out.println(s));
    
    
        //or
        strings.forEach(System.out::println);
    
    
 		//map
        Map<Integer, String> map = new HashMap<>();
        map.forEach((k,v)->System.out.println(v));
}

```

(1) 对于 `strings.forEach((s) -> System.out.println(s))；`：

`forEach` 方法接受一个 `Consumer` 函数式接口作为参数(即最终要返回一个`Consumer`接口的实例)，该接口中只有一个抽象方法 `void accept(T t)`，表示消费一个指定类型的对象。在这里，我们可以使用 `Lambda` 表达式 `(s) -> System.out.println(s)` 来创建一个 `Consumer` 实例，该实例可以接受一个字符串类型的参数 `s`，并将其打印到控制台上。



(2) 对于 `strings.forEach(System.out::println);`：

`System.out::println` 表示引用了 `System.out` 对象的 `println` 方法，并将该方法作为 `Consumer` 接口的抽象方法 `void accept(T t)` 的实现,即使用了方法引用 `System.out::println` 创建一个 `Consumer` 实例









### Stream

`java.util.Stream` 表示能应用在一组元素上一次执行的操作序列。`Stream` 操作分为中间操作或者最终操作两种，最终操作返回一特定类型的计算结果，而中间操作返回 `Stream` 本身，这样你就可以将多个操作依次串起来。`Stream` 的创建需要指定一个数据源，比如` java.util.Collection` 的子类，List 或者 Set， Map 不支持。`Stream` 的操作可以串行执行或者并行执行



Java 8 引入了 Stream API，它是**用于处理集合数据的一种新的抽象层**。Stream API 提供了一种类似于 SQL 查询语句的方式来操作数据集合，可以轻松地实现对集合数据的过滤、映射、排序、聚合等操作

Stream 是一个数据流，它不是数据结构，也不是集合，而是数据在某个阶段的一个视图。Stream 不会修改原始的数据集合，而是通过管道操作将数据转化为新的 Stream 进行处理

使用 Stream API 的主要优势在于代码更加简洁、易读，可以通过链式调用一系列的操作来实现数据处理，同时可以充分利用多核处理器提高性能

Stream API 主要有以下特点：

1. 延迟执行：Stream 中的操作不会立即执行，而是在终端操作时才进行计算。
2. 流水线：Stream 中的操作可以连接起来形成一个流水线，每个操作都是流水线中的一个环节，可以依次进行处理。
3. 内部迭代：Stream 采用内部迭代的方式，即由 Stream API 来处理迭代过程，开发者只需关注数据的处理逻辑，而无需关注具体的迭代过程。
4. 函数式编程：**Stream API 支持函数式编程的风格**，可以使用 lambda 表达式来实现数据处理逻辑，代码更加简洁。

使用 Stream API 可以大大简化集合数据的处理代码



例1：

```java
List<Integer> numbers = Arrays.asList(1, 2, 3, 4, 5);

// 使用 Stream API 对集合进行过滤、映射和求和操作
int sum = numbers.stream()   //返回一个Stream对象
    .filter(n -> n % 2 == 0) //开始级联流式调用： 1、 过滤偶数  用到了lambda表达式
    .mapToInt(n -> n * 2)    // 2、映射为原值的两倍
    .sum();                  // 退出Stream流 ： 3、求和    返回int类型

System.out.println(sum); // 输出结果：12    2*2+4*2=12

```



例2：

先创建实例代码需要用到的数据 List：

```java
List<String> stringList = new ArrayList<>();
stringList.add("ddd2");
stringList.add("aaa2");
stringList.add("bbb1");
stringList.add("aaa1");
stringList.add("bbb3");
stringList.add("ccc");
stringList.add("bbb2");
stringList.add("ddd1");
```



**Filter(过滤)**:

过滤通过一个 `predicate` 接口来过滤并只保留符合条件的元素，**该操作属于中间操作**，**所以我们可以在过滤后的结果来应用其他 `Stream` 操作（比如 `forEach`）, `forEach` 需要一个函数来对过滤后的元素依次执行。forEach 是一个最终操作，所以我们不能在 forEach 之后来执行其他 `Stream` 操作**

```java
// 测试 Filter(过滤)
stringList
    .stream()
    .filter((s) -> s.startsWith("a"))  //过滤出'a'开头的字符串
    .forEach(System.out::println);//aaa2 aaa1
```

`forEach` 是为 `Lambda` 而设计的，保持了最紧凑的风格。而且 Lambda 表达式本身是可以重用的，非常方便



**Sorted(排序):**

排序是一个 **中间操作**，返回的是排序好后的`Stream`，**如果不指定一个自定义的 `Comparator` 则会使用默认排序方式**

```java
// 测试 Sort (排序)
stringList
    .stream()
    .sorted()
    .filter((s) -> s.startsWith("a"))
    .forEach(System.out::println);// aaa1 aaa2    
```

需要注意的是，排序只创建了一个排列好后的 `Stream`，**而不会影响原有的数据源**，排序之后原数据 `stringList` 是不会被修改的：

```java
System.out.println(stringList);// ddd2, aaa2, bbb1, aaa1, bbb3, ccc, bbb2, ddd1
```





> 这里解释一下`forEach(System.out::println)`
>
> forEach()传入参数是`Consumer<? super E>`;
>
> **Consumer<T>是一个函数式接口**，且唯一抽象方法为**`void accept(T t)`**
>
> ```java
> Consumer<Object> consumer = new Consumer<Object>() 
> {
>     
>     @Override
>     public void accept(Object o) {
>         System.out.println(o);
>     }
> };
> ```
>
> 但是在Java8后，支持Lamdba表达式，所以实现接口的匿名类可以这么写:
>
> ```java
> Consumer<Object> consumer = s-> System.out.println(s);//Lamdba表达式
> list.forEach(consumer);
> ```
>
> `System`类里有个`PrintStream`对象的静态引用out—————>`System.out`
>
> 对象`PrintStream`里面有`println`方法, `System.out::println`
>
> `containingObject::instanceMethodName`表示**引用特定对象的实例方法** 这里是：`java.io.PrintStream::println`
>
> ![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/println.png)





**Map(映射):**

中间操作 `map` 会将元素根据指定的`Function`接口来依次将元素转成另外的对象

下面的示例展示了将字符串转换为大写字符串。你也可以通过 `map` 来将对象转换成其他类型，`map` 返回的 `Stream` 类型是根据你 `map` 传递进去的函数的返回值决定的

```java
// 测试 Map 操作
stringList
    .stream()
    .map(String::toUpperCase)
    .sorted((a, b) -> b.compareTo(a))  //降序排列相当于
    .forEach(System.out::println);// "DDD2", "DDD1", "CCC", "BBB3", "BBB2", "BBB1"
```



**Count(计数)：**

计数是一个 **最终操作**，返回 `Stream` 中元素的个数，**返回值类型是 long**

```java
      //测试 Count (计数)操作
        long startsWithB =
                stringList
                        .stream()
                        .filter((s) -> s.startsWith("b"))
                        .count();
        System.out.println(startsWithB);    // 3
```



















### Optional























# Java集合

## List

### ArrayList

#### 初始化

`ArrayList`底层存储数据使用的是`Object[]`数组：

```java
transient Object[] elementData;
//ArrayList 中存储数据的数组 elementData 是用 transient 修饰的，因为这个数组是动态扩展的，并不是所有的空间都被使用，因此就不需要所有的内容都被序列化。通过重写序列化和反序列化方法，使得可以只序列化数组中有内容的那部分数据

private static final int DEFAULT_CAPACITY = 10;  //定义一个默认容量
```

> 
>
> `transient` 是 Java 中的关键字，用于修饰类的成员变量。当一个变量被 `transient` 修饰时，该变量将**不会被默认的序列化机制序列化**，即对象使用默认序列化机制序列化为字节流时，该变量的值不会被写入到字节流中
>
> 
>
> 如果想要序列化 `ArrayList` 中的 `elementData` 数组中的元素，可以使用自定义的序列化和反序列化机制来实现



**带初始容量参数的数组初始化：**

```java
 public ArrayList(int initialCapacity) {
        if (initialCapacity > 0) {
            //如果传入的参数大于0，创建initialCapacity大小的数组
            this.elementData = new Object[initialCapacity];
        } else if (initialCapacity == 0) {
            this.elementData = EMPTY_ELEMENTDATA;//否则创建空数组
        } else {
            throw new IllegalArgumentException("Illegal Capacity: "+
                                               initialCapacity);
        }
    }

```



**默认构造方法**：

```java
// DEFAULTCAPACITY_EMPTY_ELEMENTDATA 是一个空的数组，因此其长度为 0
//这个空的 Object 数组不占用任何内存空间，只是作为一个占位符存在，用于占据 elementData 数组的引用
public ArrayList() {
    this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;
}


private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {};
```





#### 添加元素操作



1、添加至指定位置上：

```java
public void add(int index, E element) {
    // 检查索引是否越界，用于插入元素的位置
    rangeCheckForAdd(index);  //  0=< index <=size

    //size表示：the number of elements it contains————有效元素的数量
    // 确保容量足够以容纳新元素，不足则需要进行扩容
    ensureCapacityInternal(size + 1); // 会增加 modCount    
    

// 将元素从指定索引位置开始的部分向右移动一个位置，为新元素腾出空间(直接在原数组上进行移动)
    System.arraycopy(elementData, index, elementData, index + 1, size - index);

    
    // 在指定索引位置插入新元素
    elementData[index] = element;

    // 更新集合大小
    size++;
}




private void ensureCapacityInternal(int minCapacity) {
    ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));
}

/*
*判断指定的最小容量 minCapacity 是否大于当前数组 elementData 的长度(非有效元素长度)
如果是，说明当前容量不足以容纳 minCapacity 个元素，需要进行扩容
*/
private void ensureExplicitCapacity(int minCapacity) {
    modCount++;
    //modCount 用于记录对集合进行结构修改的次数。
   //在遍历集合时，如果 modCount 发生了改变，就会抛出 ConcurrentModificationException 异常，用于检测并发修改。
    
    
    //当前所需最小容量是否大于数组的长度,大于则需要进行扩容
    if (minCapacity - elementData.length > 0)
        grow(minCapacity);
}




private void grow(int minCapacity) {
    int oldCapacity = elementData.length;
    int newCapacity = oldCapacity + (oldCapacity >> 1);//计算新数组的容量 1.5倍
    
    //判断计算出的新数组容量能不能满足所需最小容量minCapacity的要求？
    if (newCapacity - minCapacity < 0)
        newCapacity = minCapacity; //不满足则直接将minCapacity赋值给新数组的容量
    if (newCapacity - MAX_ARRAY_SIZE > 0)
        newCapacity = hugeCapacity(minCapacity);
    
    //最终执行数组复制
    /*
    * elementData 表示原始数组，需要复制的数组
    * newCapacity 表示新数组的长度，即要创建的新数组的大小。
    *
    *
    */
    elementData = Arrays.copyOf(elementData, newCapacity);
}
```

> - `elementData.length` 表示数组的容量，它是固定的，创建数组时就确定了(大于下面`size`)
> - `size` 表示集合中实际包含的元素个数，它是动态变化的，随着元素的添加和删除而改变

最后再来看一下 `Arrays.copyOf(elementData,newCapacity)`新数组的复制：

将 `elementData` 数组中的元素拷贝到一个新的数组中，并将新数组的大小设置为 `newCapacity`，即扩容后的大小

这样，`elementData` 变量现在引用的是一个新的数组，它的容量已经增加到了 `newCapacity`，并且原来数组中的元素都被保留在新数组中。原始数组 `elementData` 不再被引用，因此在没有其他引用指向它的情况下，会被垃圾回收机制回收。而新的数组 `elementData` 用于存储集合中的元素，并具有更大的容量，以便继续添加更多的元素





> 一个小问题：如果插入元素时`minCapacity`>`elementData.length`, 即涉及到了数组扩容。那么index索引后的元素在整个插入过程中是不是移动了两次呢？

 (1)第一次移动是在扩容时：通过`Arrays.copyOf(elementData, newCapacity)`从旧`elementData`数组迁移到新的`elementData`数组

 (2)第二次移动是在执行`System.arraycopy(elementData, index, elementData, index + 1, size - index);`时，在原数组上进行元素的移动，让`index`索引处开始的元素移动到`index+1`位置开始，总共涉及到的移动元素数量为`size-index`



> 第二个小问题：如果调用默认构造方法来初始化ArrayList,第一次扩容是什么时候？

默认构造方法会返回一个空`Object[]`数组，此时当插入第一个元素时，会判断`size+1` 和 `elementData.length`的大小，结果是大于，故会触发第一次扩容，第一次扩容会扩到长度为10：

```java
private void ensureCapacityInternal(int minCapacity) {
    // 如果当前数组为空，初始化容量为默认容量（一般为10）
    if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {
        minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);
    }

    // 判断是否需要扩容
    ensureExplicitCapacity(minCapacity);
}
```







2、追加到数组的末尾：(其实分析过程和插入到指定Index索引处很类似，但是第一次插入元素时调用此方法，就会涉及到数组的扩容)

```java
/**
 * 将指定元素添加到 ArrayList 的末尾
 * @param e 要添加的元素
 * @return 添加成功返回 true
 */
public boolean add(E e) {
    ensureCapacityInternal(size + 1);  // 确保 ArrayList 能够容纳新的元素
    elementData[size++] = e;//在 ArrayList 的末尾添加指定元素——容易产生线程安全问题
    return true;
}


/**
 * 确保 ArrayList 能够容纳指定容量的元素
 * @param minCapacity 指定容量的最小值
 * private static final int DEFAULT_CAPACITY = 10;  //定义一个默认容量
 */
private void ensureCapacityInternal(int minCapacity) {
    // 如果 elementData 还是默认的空数组 第一次插入元素时
    if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) { 
        
        minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); 
        // 使用 DEFAULT_CAPACITY 和指定容量的最小值中的较大值 Math.max(10，1)
    }

    ensureExplicitCapacity(minCapacity); // 确保容量能够容纳指定容量的元素
}
```

此时：

- 参数 `minCapacity` 为 1（size+1 传过来的   0+1 ） 
- `elementData` 为存放 `ArrayList` 元素的底层数组，前面声明 `ArrayList` 的时候讲过了，此时为空 `{}`
- `DEFAULTCAPACITY_EMPTY_ELEMENTDATA` 前面也讲过了，为 `{}`



所以，if 条件此时为 true，if 语句`minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity)`要执行。`DEFAULT_CAPACITY` 为 10，所以执行完这行代码后，`minCapacity` 为 10，`Math.max()` 方法的作用是取两个当中最大的那个

```java
/**
 * 检查并确保集合容量足够，如果需要则增加集合容量。
 *
 * @param minCapacity 所需最小容量
 */
private void ensureExplicitCapacity(int minCapacity) {
    // 检查是否超出了数组范围，确保不会溢出
    if (minCapacity - elementData.length > 0)
        // 如果需要增加容量，则调用 grow 方法
        grow(minCapacity);
}

```

此时：

- 参数 `minCapacity` 为 10
- `elementData.length` 为 0（数组为空）

所以 10-0>0，if 条件为 true，进入 if 语句执行 `grow()` 方法，来看源码：

```java
/**
 * 扩容 ArrayList 的方法，确保能够容纳指定容量的元素
 * @param minCapacity 指定容量的最小值
 */
private void grow(int minCapacity) {
    // 检查是否会导致溢出，oldCapacity 为当前数组长度
    int oldCapacity = elementData.length;
    int newCapacity = oldCapacity + (oldCapacity >> 1); // 扩容至原来的1.5倍
    if (newCapacity - minCapacity < 0) // 如果还是小于指定容量的最小值
   newCapacity = minCapacity;//直接扩容至指定容量的最小值(第一次扩容是在这里执行！！)
    if (newCapacity - MAX_ARRAY_SIZE > 0) // 如果超出了数组的最大长度
        newCapacity = hugeCapacity(minCapacity); // 扩容至数组的最大长度
    // 将当前数组复制到一个新数组中，长度为 newCapacity，后面空出来的元素补null值
    elementData = Arrays.copyOf(elementData, newCapacity);
}

```

此时：

- 参数 `minCapacity` 为 10
- 变量 `oldCapacity` 为 0

所以 `newCapacity` 也为 0，于是 `newCapacity - minCapacity` 等于 -10 小于 0，于是第一个 if 条件为 true，执行第一个 if 语句 `newCapacity = minCapacity`，然后 `newCapacity` 为 10

紧接着执行 `elementData = Arrays.copyOf(elementData, newCapacity);`，也就是进行数组的第一次扩容，长度为 10。



`ArrayList` 在第一次执行 add 后会扩容为 10，那 `ArrayList` 第二次扩容发生在什么时候呢？

答案是添加第 11 个元素时，大家可以尝试分析一下这个过程









#### **扩容机制**

首先需要知道数组的默认指定容量为10：

```java
private static final int DEFAULT_CAPACITY = 10;
```

如果最开始调用无参构造初始化`elementdata`数组，实际上初始化了一个空数组，**当真正向数组中添加元素时（即添加第一个元素）**，才会真正的分配容量，**即向数组中添加第一个元素时，数组容量扩为 10**，随后不断往数组里添加元素，当数组元素容量到达10时会再次触发扩容——添加第 11 个元素，`minCapacity`(为 11)比 `elementData.length`（为 10）要大。进入 `grow()` 方法进行扩容:

**`ensureCapacity()方法:`**

```java
public void ensureCapacity(int minCapacity) {
        if (minCapacity > elementData.length
            && !(elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA
                 && minCapacity <= DEFAULT_CAPACITY)) {
            modCount++;
            grow(minCapacity);
        }
    }
```

`grow()方法`：

```java
private Object[] grow(int minCapacity) {
        int oldCapacity = elementData.length;
        if (oldCapacity > 0 || elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {
            int newCapacity = ArraysSupport.newLength(oldCapacity,
                    minCapacity - oldCapacity, /* minimum growth */
                    oldCapacity >> 1           /* preferred growth */);
            return elementData = Arrays.copyOf(elementData, newCapacity);
        } else 
            return elementData = new Object[Math.max(DEFAULT_CAPACITY, minCapacity)];
        }
    }
```

由`grow()`可以看出， 首先定义一个扩容后的容量newCapacity`为`oldCapacity+oldCapacity>>1`,即旧容量的1.5倍，并且比较这个新容量`newCapacity`和预期的最小所需容量`minCapacity`大小，如果小于`minCapacity`，则直接将minCapacity赋值给`newCapacity，最后调用`Arrays.copyOf()`来实现旧数组向新数组的迁移:

```java
  public static <T,U> T[] copyOf(U[] original, int newLength, Class<? extends T[]> newType) {
        @SuppressWarnings("unchecked")
    //    T[] copy = ((Object)newType == (Object)Object[].class)
    //        ? (T[]) new Object[newLength]
    //        : (T[]) Array.newInstance(newType.getComponentType(), newLength);
       
    /*核心*/  System.arraycopy(original, 0, copy, 0,
                         Math.min(original.length, newLength));
        return copy;
    }
```

注意，`Arrays.copyOf()`实际上是调用了`System.arraycopy()`方法，而该方法是一个native方法：

```java
/**
    *   复制数组
    * @param src 源数组
    * @param srcPos 源数组中的起始位置
    * @param dest 目标数组
    * @param destPos 目标数组中的起始位置
    * @param length 要复制的数组元素的数量
    */
public static native void arraycopy(Object src,  int  srcPos,
                                    Object dest, int destPos,
                                    int length);
```



#### 删除元素操作

其实和添加元素就是反着来的，而且实现逻辑相对简单了许多：

(1) 删除指定索引位置元素：

```java
public E remove(int index) {
        rangeCheck(index); //检查索引的合理性

        modCount++;  //修改次数加1
        E oldValue = elementData(index);

        int numMoved = size - index - 1;
       
        //将index位置后的元素前移1位，直接覆盖的
        if (numMoved > 0)
            System.arraycopy(elementData, index+1, elementData, index,
                             numMoved);
        elementData[--size] = null; // 原最大有效元素位置置为null

        return oldValue;
    }
```



注意这一行代码：

```java
elementData[--size] = null;
```

将集合中最后一个元素置为 `null`，就是在告诉垃圾回收机制：这个元素不再被集合引用了，你可以将它回收并释放其占用的内存。这样做的目的是帮助垃圾回收机制更早地回收不再需要的对象，从而提高内存的使用效率。





(2) 从集合中删除指定的元素 `o`：

```java
/**
 * 删除列表中第一次出现的指定元素（如果存在）。
 *
 * @param o 要删除的元素
 * @return 如果列表包含指定元素，则返回 true；否则返回 false
 */
public boolean remove(Object o) {
    if (o == null) { // 如果要删除的元素是 null
        for (int index = 0; index < size; index++) // 遍历列表
            if (elementData[index] == null) { // 如果找到了 null 元素
                fastRemove(index); // 调用 fastRemove 方法快速删除元素
                return true; // 返回 true，表示成功删除元素
            }
    } else { // 如果要删除的元素不是 null
        for (int index = 0; index < size; index++) // 遍历列表
            if (o.equals(elementData[index])) { // 如果找到了要删除的元素
                fastRemove(index); // 调用 fastRemove 方法快速删除元素
                return true; // 返回 true，表示成功删除元素
            }
    }
    return false; // 如果找不到要删除的元素，则返回 false
}

```

通过遍历的方式找到要删除的元素，null 的时候使用 == 操作符判断，非 null 的时候使用 `equals()` 方法，然后调用 `fastRemove()` 方法，注意：

- 有相同元素时，只会删除第一个,因为是从前往后顺序遍历，找到第一个直接return

再来看一下 `fastRemove()` 方法：

```java
/**
 * 快速删除指定位置的元素。
 *
 * @param index 要删除的元素的索引
 */
private void fastRemove(int index) {
    int numMoved = size - index - 1; // 计算需要移动的元素个数
    if (numMoved > 0) // 如果需要移动元素，就用 System.arraycopy 方法实现
        System.arraycopy(elementData, index+1, elementData, index,
                         numMoved);
    elementData[--size] = null; // 将数组末尾的元素置为 null，让 GC 回收该元素占用的空间
}
```

可以看出来`fastRemove()`方法的实现和`remove(int index)`的实现逻辑几乎是一样的，就不赘述了





#### 线程安全问题

情景1：添加元素

```java
elementData[size++] = e;
//可拆分为：
elementData[size] = e; 
size++;
```

在单线程执行这两条代码时没有任何问题，但是当多线程环境下执行时，可能就会发生一个线程的值覆盖另一个线程添加的值，具体逻辑如下：

1. 列表大小为0，即size=0；
2. 线程A开始添加一个元素，值为A。此时它执行第一条操作，将A放在了`elementData`下标为0的位置上，在执行`size++`操作之前让出了时间片；
3. 接着线程B拿到时间片，刚好也要开始添加一个值为B的元素，且走到了第一步操作。此时线程B获取到size的值依然为0，于是它将B也放在了`elementData`下标为0的位置上
4. 线程A开始将size的值增加为1
5. 线程B开始将size的值增加为2

这样线程A B执行完毕后，理想中情况为`size`为2，`elementData`下标0的位置为A，下标1的位置为B。而实际情况变成了`size`为2，`elementData`下标为0的位置变成了B，下标1的位置上什么都没有。并且后续除非使用`set()`方法修改此位置的值，否则将一直为`null`，因为`size`为2，添加元素时会从下标为2的位置上开始



情景2：数组越界

在多个线程进行add操作时可能会导致elementData数组越界。具体逻辑如下：

1. 列表大小为9，即size=9
2. 线程A开始进入add方法，这时它获取到size的值为9，调用`ensureCapacityInternal`方法进行容量判断。
3. **线程B此时也进入add方法**，它获取到size的值也为9，也开始调用`ensureCapacityInternal`方法。
4. 线程A发现需求大小为10，而`elementData`的大小就为10，可以容纳。于是它不再扩容，返回。
5. 线程B也发现需求大小为10，也可以容纳，返回。
6. 线程A开始进行设置值操作， elementData[size++] = e 操作。此时size变为10。
7. 线程B也开始进行设置值操作，它尝试设置`elementData`[10] = e，而`elementData`没有进行过扩容，它的下标最大为9。于是此时会报出一个数组越界的异常`ArrayIndexOutOfBoundsException`

究其原因就是线程A先完成了赋值操作，并将size自增后，线程B才开始进行赋值，这时在`elementData[size]`位置再进行赋值操作就已经越界了。。。。



还有类似的情景就不说了，总之就是`ArrayList`在多线程场景下有线程安全问题，如果为了保证线程安全的话，可以使用`Vector`、`Collections.synchronizedList()`、`CopyOnWriteArrayList`(建议使用)





### LinkedList

底层数据结构使用了双向链表(静态内部类)：

```java
/**
 * 链表中的节点类。
 */
private static class Node<E> {
    E item; // 节点中存储的元素
    Node<E> next; // 指向下一个节点的指针
    Node<E> prev; // 指向上一个节点的指针

    /**
     * 构造一个新的节点。
     *
     * @param prev 前一个节点
     * @param element 节点中要存储的元素
     * @param next 后一个节点
     */
    Node(Node<E> prev, E element, Node<E> next) {
        this.item = element; // 存储元素
        this.next = next; // 设置下一个节点
        this.prev = prev; // 设置上一个节点
    }
}
```





(2)`add` 插入元素(在表尾)：

```java
/**
 * 将指定的元素添加到列表的尾部。
 *
 * @param e 要添加到列表的元素
 * @return 始终为 true（根据 Java 集合框架规范）
 */
public boolean add(E e) {
    linkLast(e); // 在列表的尾部添加元素
    return true; // 添加元素成功，返回 true
}


/**
 * 在列表的尾部添加指定的元素。
 *
 * @param e 要添加到列表的元素
 */
void linkLast(E e) {
    final Node<E> l = last; // 获取链表的最后一个节点
    final Node<E> newNode = new Node<>(l, e, null); // 创建一个新的节点，并将其设置为链表的最后一个节点
    last = newNode; // 将新的节点设置为链表的最后一个节点
    if (l == null) // 如果链表为空，则将新节点设置为头节点
        first = newNode;
    else
        l.next = newNode; // 否则将新节点链接到链表的尾部
    size++; // 增加链表的元素个数
}

```





(3)`add/get/remove` 但是在指定index索引处：

`LinkedList`底层使用的是双向链表，因此在**获取头尾元素/向链表表尾插入元素**时的时间复杂度为`O(1)`

而若要获取指定`index`的元素，则首先需要定位到该位置，这样时间复杂度就是`O(n)`,`get(int index)` 

、`remove(int index)` 等方法内部都调用了 `node(int index)` 这个方法来获取对应的节点：

```Java
Node<E> node(int index) {
        // assert isElementIndex(index);

        if (index < (size >> 1)) {
            Node<E> x = first;
            for (int i = 0; i < index; i++)
                x = x.next;
            return x;
        } else {
            Node<E> x = last;
            for (int i = size - 1; i > index; i--)
                x = x.prev;
            return x;
        }
    }
```

从上看出，该方法通过比较索引值与链表`size`一半的大小，来**确定从链表头还是尾开始遍历**。如果索引值小于 `size` 的一半，就从链表头开始遍历，反之从链表尾开始遍历。这样可以在较短的时间内找到目标节点，充分利用了双向链表的特性来提高效率











### CopyOnWriteArrayList



> 为什么使用它？
>
> Java学习者都清楚`ArrayList`并不是线程安全的，在读线程在读取`ArrayList`的时候如果有写线程在写数据的时候，基于**`fast-fail`**机制，会抛出**`ConcurrentModificationException`**异常，也就是说`ArrayList`并不是一个线程安全的容器，当然可以用`Vector`,或者使用`Collections`的静态方法将`ArrayList`包装成一个线程安全的类，但是这些方式都是采用关键字`synchronzied`对方法进行修饰，利用独占式锁来保证线程安全的。但是，**由于独占式锁在同一时刻只有一个线程能够获取到对象监视器**，很显然这种方式效率并不是太高
>
> 
>
> 在业务场景中，有很多业务往往是读多写少的，如果在这种情况用到上述的方法，使用`Vector`,`Collections`转换的这些方式是不合理的，因为尽管多个读线程从同一个数据容器中读取数据，但是读线程对数据容器的数据并不会发生发生修改，这样搞就变相阻塞了读线程的读操作
>
> 
>
> 很自然而然的我们会联想到`ReenTrantReadWriteLock`，通过**读写分离**的思想，使得读读之间不会阻塞，无疑如果一个list能够做到被多个读线程读取的话，性能会大大提升不少。但是，如果仅仅是将list通过读写锁（`ReentrantReadWriteLock`）进行再一次封装的话，由于读写锁的特性，当写锁被写线程获取后，读写线程都会被阻塞。
>
> 
>
> 如果想list的读效率更高的话，这里就是我们的突破口，如果我们**保证读线程无论什么时候都不被阻塞**，效率岂不是会更高？ 这就引出了`CopyOnWriteArrayList`



`ReenTrantReadWriteLock`，通过**读写分离**的思想，使得读读之间不会阻塞，无疑如果一个list能够做到被多个读线程读取的话，性能会大大提升不少。但是，如果仅仅是将list通过读写锁（`ReentrantReadWriteLock`）进行再一次封装的话，由于读写锁的特性，当写锁被写线程获取后，读写线程都会被阻塞。

(1) 读锁`ReadLock`:

```java
public void lock() {
    sync.acquireShared(1);
}
//AQS下的共享模式
```

(1) 写锁`WriteLock`:

```java
public void lock() {
sync.acquire(1);
}
//AQS下的互斥模式
```



#### COW

回到上面所说的，如果简单的使用读写锁的话，在写锁被获取之后，读写线程被阻塞，只有当写锁被释放后读线程才有机会获取到锁从而读到最新的数据，站在**读线程的角度来看，即读线程任何时候都是获取到最新的数据，满足数据实时性**。

既然我们说到要进行优化，必然有trade-off,我们就可以**牺牲数据实时性满足数据的最终一致性即可**。而`CopyOnWriteArrayList`就是通过Copy-On-Write(COW)，即写入时复制的思想来通过延时更新的策略来实现数据的最终一致性，并且能够保证读线程间不阻塞。

COW通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。

对`CopyOnWrite`容器进行并发的读的时候，不需要加锁，因为当前容器不会添加任何元素。所以`CopyOnWrite`容器也是一种读写分离的思想，延时更新的策略是通过**在写的时候针对的是新创建的数据容器**来实现的，**放弃数据实时性达到数据的最终一致性**



`CopyOnWriteArrayList`的思想与`ReentrantReadWriteLock` 读写锁的设计思想(**读读不互斥、读写互斥、写写互斥**)非常类似，不同之处在于其写入操作也不会阻塞读取操作(读操作永远不会被阻塞，即使读到的旧数据，但是可以保证数据的最终一致性)。

写入时复制非常适合**读多写少**的并发场景，当需要修改（ `add`，`set`、`remove` 等操作） `CopyOnWriteArrayList` 的内容时，线程不会直接修改原数组，而是会先创建底层数组的副本，对副本数组进行修改，修改完之后再将修改后的数组赋值回去，这样就可以保证写操作不会影响读操作









`CopyOnWriteArrayList`底层使用`Object[]`数组来存储元素：

```java
private transient volatile Object[] array;  //volatile保证可见性
```



#### 写入操作  :astonished:

> `CopyOnWriteArrayList` 在插入元素时并不涉及扩容！！
>
> 
>
> 在 `CopyOnWriteArrayList` 中，每当进行写操作（插入、删除、修改等）时，都会创建一个新的数组来代替原始数组，并在新数组上执行写操作。这样做的好处是读操作不会受到写操作的影响，从而实现读写分离的线程安全性。
>
> 
>
> 在插入元素时，`CopyOnWriteArrayList` 会在当前数组的基础上创建一个新的数组，并将要插入的元素添加到新数组的末尾。这种操作不会影响到原始数组，因为读操作仍然在使用原始数组。只有当所有正在进行的读操作完成后，`CopyOnWriteArrayList` 才会将内部数组指向新的数组，从而完成插入操作的更新。



在数组末尾添加元素时调用的`add(E e)`方法(两种版本)：

(1) 使用`synchronized`实现同步(新版本的`synchronized`已不是重量级锁)：

```java
public boolean add(E e) {
        synchronized (lock) {
            Object[] es = getArray();  // 获取当前的内部数组array引用
            int len = es.length;  //获取当前的内部数组array的长度
            
            //每插入元素都涉及到新数组的拷贝，并且让数组引用es指向新的堆中数组实例
            es = Arrays.copyOf(es, len + 1); 
            
            es[len] = e;
            setArray(es);  //将原数组引用array 指向新的堆中数组
            return true;
        }
    }
```





(2) 使用 `ReentrantLock`实现线程同步：

```java
final transient ReentrantLock lock = new ReentrantLock();

// 插入元素到 CopyOnWriteArrayList 的尾部
public boolean add(E e) {
    /*
    获取当前 CopyOnWriteArrayList 对象的锁，
    并且使用 final 关键字来确保在方法执行过程中锁对象的引用不可变
    */
    final ReentrantLock lock = this.lock;
    
    
    // 加锁  保证写线程在同一时刻只有一个(多个写线程需要竞争一个CopyOnWriteArrayList对象的成员变量锁——this.lock，竞争到的才可以修改)
    lock.lock();
    try {
        // 获取原来的数组
        Object[] elements = getArray();
        // 原来数组的长度
        int len = elements.length;
        // 创建一个长度+1的新数组，并将原来数组的元素复制给新数组(不影响其他线程进行读操作~)
        Object[] newElements = Arrays.copyOf(elements, len + 1);
        // 元素放在新数组末尾
        newElements[len] = e;
        // array引用指向新数组
        setArray(newElements);
        return true;
    } finally {
        // 解锁
        lock.unlock();
    }
}

```

从上可以看出，`add`方法内部用到了 `ReentrantLock` 加锁，保证了同步，避免了多线程写的时候会复制出多个副本出来。锁被`final`修饰保证了锁的内存地址肯定不会被修改，并且，释放锁的逻辑放在 `finally` 中，可以保证锁能被释放，需要注意的是：

- 每次写操作都需要通过 `Arrays.copyOf` 复制底层数组，时间复杂度是 O(n) 的，且会占用额外的内存空间。因此，`CopyOnWriteArrayList` 适用于读多写少的场景，在写操作不频繁且内存资源充足的情况下，可以提升系统的性能表现；

- `CopyOnWriteArrayList` 中没有类似于 `ArrayList`的 `grow()` 扩容的操作, 每次添加元素均要创建一个`length+1`的数组；
- 采用`ReentrantLock`，保证同一时刻只有一个写线程正在进行数组的复制，否则的话内存中会有多份被复制的数据；
- 前面说过数组引用是`volatile`修饰的，因此将旧的数组引用指向新的数组，**根据volatile的`happens-before`规则，写线程对数组引用的修改对读线程是可见的**。由于在写数据的时候，是在新的数组中插入数据的，从而保证读写是在两个不同的数据容器中进行操作

> **happen-before原则中的volatile 变量规则**：对一个 volatile 变量的写操作，happen-before 于后续对该变量的读操作。这确保了 volatile 变量的修改对其他线程是可见的





####  读取操作

`get`操作是弱一致性的！！

```java
private transient volatile Object[] array;  //volatile修饰 —— 可见性

public E get(int index) {
        return elementAt(getArray(), index);
}

static <E> E elementAt(Object[] a, int index) {
        return (E) a[index];
}

final Object[] getArray() {
    return array;
}


```

`get(int index)`方法是分两步进行的：

1. 通过`getArray()`获取当前数组的引用
2. 直接从数组中获取下标为 `index` 的元素
3. `get()`是弱一致性的，可能读到旧的元素值，例如线程 1 想要通过调用`get(int index)`方法获取值，内部通过`getArray()`方法获取到了 `array` 属性值；此时线程 2 调用了`CopyOnWriteArrayList`的`add`、`set`、`remove` 等修改方法，内部通过`setArray`方法修改了`array`属性的值，而线程1 依然是从旧的 `array` 数组中读取的值，导致读取到的值不是最新的



 



#### 删除操作

**删除指定索引元素的操作则采用了分段复制的方法：**

```java
public E remove(int index) {
    // 获取可重入锁  
    final ReentrantLock lock = this.lock;
    // 加锁  保证写线程在同一时刻只有一个
    lock.lock();
    try {
    	   //获取当前array数组
        Object[] elements = getArray();
        // 获取当前array长度
        int len = elements.length;
        //获取指定索引的元素(旧值)
        E oldValue = get(elements, index);
        int numMoved = len - index - 1;
        // 判断删除的是否是最后一个元素
        if (numMoved == 0)
        	   // 如果删除的是最后一个元素，直接复制该元素前的所有元素到新的数组
            setArray(Arrays.copyOf(elements, len - 1));
        else {
            // 分段复制，将index前的元素和index+1后的元素复制到新数组
            // 新数组长度为旧数组长度-1
            Object[] newElements = new Object[len - 1];
            System.arraycopy(elements, 0, newElements, 0, index);
            System.arraycopy(elements, index + 1, newElements, index,
                             numMoved);// int numMoved = len - index - 1;
            //将新数组赋值给array引用
            setArray(newElements);
        }
        return oldValue;
    } finally {
       	// 解锁
        lock.unlock();
    }
}

```



当然添加指定索引位置的元素同样使用分段复制的思想，这是为什么呢 :question:





## Map



### HashMap



#### 哈希运算

在向Map集合添加一个`<key,value>`键值对时，首先对该`key`对象进行`hashcode()`得到`hashcode`值，然后通过**扰动函数(不同jdk版本函数不同)**的处理得到 `hash` 值,然后通过 `(n - 1) & hash` (注意这里为什么是 [和桶数组长度-1来进行'位与'运算](https://blog.csdn.net/LLF_1241352445/article/details/81321991) )判断当前元素存放的位置（这里的 n 指的是数组的长度），如果当前位置存在元素的话，就判断该元素与要存入的元素的 `hash` 值以及 `key` 是否相同，**如果hash值相同且key也相同，则直接覆盖**，不相同则说明产生了冲突，随后开始遍历链表插入(**遍历以这个元素为头结点的链表，依次和需要插入的 key 比较，如果 key 相同就直接覆盖当前节点，遍历到最后一个节点依旧没有相同key的话就采用尾插法（java8）插入元素**)

**JDK 1.8 HashMap的hash()方法:**

```java
    static final int hash(Object key) {
      int h;
      // key.hashCode()：返回散列值也就是hashcode
      // ^：按位异或
      // >>>:无符号右移，忽略符号位，空位都以0补齐
      // 将变量 h 与它无符号右移 16 位后的结果进行按位异或运算
      return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
  }

```

> 为什么是 `h = key.hashCode()) ^ (h >>> 16)`？
>
> 
>
> 使用 `h >>> 16` 来将 `h` 变量的高位信息混入低位，以增加哈希值的随机性和降低哈希冲突的概率，
>
> 相当于将原来的哈希码分成 了两个16位的部分。一些哈希码可能在高位有更多的0，而其他哈希码可能在高位有更多的1。使用异或操作可以帮助在低位和高位之间混合信息，从而减少聚集现象，增加哈希码的随机性。
>
> 
>
> 理论上，哈希值（哈希码）是一个 int 类型，范围从-2147483648 到 2147483648。前后加起来大概 40 亿的映射空间，只要哈希值映射得比较均匀松散，一般是不会出现哈希碰撞（哈希冲突会降低 HashMap 的效率）。
>
> 但问题是一个 40 亿长度的数组，内存是放不下的。`HashMap` 扩容之前的数组初始大小只有 16，所以这个哈希值是不能直接拿来用的，用之前要和数组的长度做取模运算（之前提到的 `(n - 1) & hash`），用得到的余数来访问数组下标才行。



**jdk1.7的`hash()`则是经过了四次处理**：

```java
static int hash(int h) {
    // This function ensures that hashCodes that differ only by
    // constant multiples at each bit position have a bounded
    // number of collisions (approximately 8 at default load factor).

    h ^= (h >>> 20) ^ (h >>> 12);
    return h ^ (h >>> 7) ^ (h >>> 4);
}

```



>  为什么`putVal()`方法中用到了： `(n - 1) & hash`而没有用`%`运算？

这是因为`&` 运算比 `%` 更加高效，并且当 b 为 2 的 n 次方时，存在下面这样一个公式：

```java
a % b = a & (b-1)
```

我们来验证一下：

假如 a = 14，b = 8，那么 14%8 取模的结果为 6

14 的二进制为 1110，8 的二进制 1000，8-1 = 7，7 的二进制为 0111，1110&0111=0110，位运算&得到的结果也为6，**这样计算机计算&运算时只需关注hash值的最低N位即可，这才是核心！！**



>  **这也正好解释了为什么 `HashMap` 的数组长度要取 2 的N整次方？**

来看个例子： 假设hash值为20，hashMap的容量为length=16

十进制取余算法：20%16 = 4；所以任何的hash值得取余都在0-15之间，达到了最有可能得平均分配；

二进制算法：20转为二进制位10100，length-1=15 = 01111；所以二进制算法为10100 & 01111 = 0100 = 4，**高位和length-1的0相与后全部舍弃，直接保留了hash值最后N位**，而最后N位刚好就是十进制的取余运算的结果；任何hash值都是这样；



假如不是桶数组长度不是按2的幂次方设置，例如length = 15，hash= 17，则10进制取余运算为2，二进制位运算为10001&01110 =0，不会等于10进制的的运算结果；而**实际上length-1 = 14 = 01110和任何的hash相与，最后的一位的0都会被舍弃，所以任何的hash值和01110相与的结果都不会出现1101（13），1001（9）等数据，所以相当于table的数组中index =13或者9的位置永远不会保存到数据**，造成空间浪费；所以这个时候就不能用位运算来计算key应该放入桶数组中的哪个索引处，就只能采用10进制计算，但是这样速度就远远比不上二进制运算，毕竟如果桶数组长度为2的N次方的话，通过&运算来计算该<Key,Value>的位置时只需要直接读取Key的Hash值的低N位就可以了！





#### put/get 分析

`put` 操作：

```java
public V put(K key, V value) {
    return putVal(hash(key), key, value, false, true);
}

// 第四个参数 onlyIfAbsent 如果是 true，那么只有在不存在该 key 时才会进行 put 操作
// 第五个参数 evict 我们这里不关心
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
               boolean evict) {
    Node<K,V>[] tab; Node<K,V> p; int n, i;
    // 第一次 put 值的时候，会触发下面的 resize()，类似 java7 的第一次 put 也要初始化数组长度
    // 第一次 resize 和后续的扩容有些不一样，因为这次是数组从 null 初始化到默认的 16 或自定义的初始容量
    if ((tab = table) == null || (n = tab.length) == 0)
        n = (tab = resize()).length;
    
    
    // 找到具体的数组下标，如果此位置没有值,第一次放入该索引处
    //，那么直接初始化一下 Node 并放置在这个位置就可以了
    if ((p = tab[i = (n - 1) & hash]) == null)
        tab[i] = newNode(hash, key, value, null);

    else {// 数组该位置有数据 哈希冲突
        Node<K,V> e; K k;
        // 首先，判断该位置的第一个数据和我们要插入的数据，key 是不是"相等"，如果是，取出这个节点
        if (p.hash == hash &&
            ((k = p.key) == key || (key != null && key.equals(k))))
            e = p;
        // 如果该节点是代表红黑树的节点，调用红黑树的插值方法，本文不展开说红黑树
        else if (p instanceof TreeNode)
            e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
        else {
            // 到这里，说明数组该位置上是一个链表
            for (int binCount = 0; ; ++binCount) {
                // 插入到链表的最后面(Java7 是插入到链表的最前面) //尾插法
                if ((e = p.next) == null) {
                    p.next = newNode(hash, key, value, null);
                    // TREEIFY_THRESHOLD 为 8，所以，如果新插入的值是链表中的第 8 个
                    // 会触发下面的 treeifyBin，也就是将链表转换为红黑树
                    if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                        treeifyBin(tab, hash);
                    break;
                }
                // 如果在该链表中找到了"相等"的 key(== 或 equals)
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    // 此时 break，那么 e 为链表中[与要插入的新值的 key "相等"]的 node
                    break;
                p = e;
            }
        }
        // e!=null 说明存在旧值的key与要插入的key"相等"
        // 对于我们分析的put操作，下面这个 if 其实就是进行 "值覆盖"，然后返回旧值
        if (e != null) {
            V oldValue = e.value;
            if (!onlyIfAbsent || oldValue == null)
                e.value = value;
            afterNodeAccess(e);
            return oldValue;
        }
    }
    ++modCount;
    // 如果 HashMap 由于新插入这个值导致 size 已经超过了阈值，需要进行扩容
    if (++size > threshold)
        resize();
    afterNodeInsertion(evict);
    return null;
}
```

需要注意的是：

- jdk7在使用链地址法处理哈希冲突时，采用的是头插法，而jdk8则采用了尾插法

- 链表转换为红黑树的根据由`TREEIFY_THRESHOLD`决定：

  ```java
  static final int TREEIFY_THRESHOLD = 8;   // 链表进化为红黑树阈值
  static final int UNTREEIFY_THRESHOLD = 6; // 红黑树退化为链表阈值
  ```

  

以JDK 8为例，简要流程如下：

1、首先根据 key 的值计算 hash 值，找到该元素在数组中存储的下标；

2、如果数组是空的，则调用 **`resize`** 进行初始化；

3、如果没有哈希冲突直接放在对应的数组下标里；

4、如果冲突了，且 key 已经存在，就覆盖掉 value；

5、如果冲突后，发现该节点是红黑树，就将这个节点挂在树上；

6、如果冲突后是链表，**判断该链表是否大于 8 ，如果大于 8则进入treeifyBin方法，该方法内部需要先判断桶数组长度是否小于64，小于64则优先进行扩容；如果链表节点大于 8 并且数组的容量大于 64，则将这个结构转换为红黑树；**否则，链表插入键值对，若 key 存在，就覆盖掉 value。













`get` 操作：

相对于 put 来说，get 操作简单了许多：

- 计算 key 的 hash 值，根据 hash 值找到对应数组下标: hash & (length-1)
- 判断数组该位置处的元素是否刚好就是我们要找的，如果不是，走第三步
- 判断该元素类型是否是 TreeNode，如果是，用红黑树的方法取数据，如果不是，走第四步
- 遍历链表，直到找到相等(==或equals)的 key

```java
public V get(Object key) {
    Node<K,V> e;
    return (e = getNode(hash(key), key)) == null ? null : e.value;
}
final Node<K,V> getNode(int hash, Object key) {
    Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
    if ((tab = table) != null && (n = tab.length) > 0 &&
        (first = tab[(n - 1) & hash]) != null) {
        // 判断第一个节点是不是就是需要的
        if (first.hash == hash && // always check first node
            ((k = first.key) == key || (key != null && key.equals(k))))
            return first;
        if ((e = first.next) != null) {
            // 判断是否是红黑树
            if (first instanceof TreeNode)
                return ((TreeNode<K,V>)first).getTreeNode(hash, key);

            // 链表遍历
            do {
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    return e;
            } while ((e = e.next) != null);
        }
    }
    return null;
}
```







#### resize 扩容:grey_exclamation:

决定`HashMap`何时扩容的因素有两个：`loadFactor`和`threshold`

```java
static final int DEFAULT_INITIAL_CAPACITY = 1 << 4;// 默认数组的初始容量是16
static final float DEFAULT_LOAD_FACTOR = 0.75f;

final float loadFactor;//负载因子
int threshold; // 设定的阈值(容量*负载因子)   当数组的实际大小超过设定阈值时，就会进行扩容
```

> loadFactor 负载因子是控制数组存放数据的疏密程度，loadFactor 越趋近于 1，那么 数组中存放的数据(entry)也就越多，也就越密，也就是会让链表的长度增加，loadFactor 越小，也就是趋近于 0，数组中存放的数据(entry)也就越少，也就越稀疏。**loadFactor 太大导致查找元素效率低，太小导致数组的利用率低，存放的数据会很分散**

可以看到桶数组默认初始长度为16，`loadFactor`为0.75f,在不断往Map中存放数据的过程中，当桶数组中有效元素数量达到`16*0.75=12`时，就需要对桶数组进行`resize()`扩容(扩容至原来长度的两倍)，由于`resize()`方法实现略微复杂，这里只贴上核心代码：

```java
final Node<K,V>[] resize() {
    Node<K,V>[] oldTab = table;
    int oldCap = (oldTab == null) ? 0 : oldTab.length;
    int oldThr = threshold;
    int newCap, newThr = 0;
    if (oldCap > 0) {
        // 超过最大值就不再扩充了，就只好随你碰撞去吧
        if (oldCap >= MAXIMUM_CAPACITY) {
            threshold = Integer.MAX_VALUE;
            return oldTab;
        }
        // 没超过最大值，就扩充为原来的2倍
        else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY && oldCap >= DEFAULT_INITIAL_CAPACITY)
            newThr = oldThr << 1; // double threshold
    }
    else if (oldThr > 0) // initial capacity was placed in threshold
        // 创建对象时初始化容量大小放在threshold中，此时只需要将其作为新的数组容量
        newCap = oldThr;
    else {
        // signifies using defaults 无参构造函数创建的对象在这里计算容量和阈值
        newCap = DEFAULT_INITIAL_CAPACITY;
        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
    }
    if (newThr == 0) {
        // 创建时指定了初始化容量或者负载因子，在这里进行阈值初始化，
    	// 或者扩容前的旧容量小于16，在这里计算新的resize上限
        float ft = (float)newCap * loadFactor;
        newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE);
    }
    threshold = newThr;
    @SuppressWarnings({"rawtypes","unchecked"})
        Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
    table = newTab;
    if (oldTab != null) {
        // 把每个bucket都移动到新的buckets中
        for (int j = 0; j < oldCap; ++j) {
            Node<K,V> e;
            if ((e = oldTab[j]) != null) {
                oldTab[j] = null;
                if (e.next == null)
                    // 只有一个节点，直接计算元素新的位置即可
                    newTab[e.hash & (newCap - 1)] = e;
                else if (e instanceof TreeNode)
                    // 将红黑树拆分成2棵子树，拆分后的子树节点数小于等于6，则将树转化成链表
                    ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                else {
                    Node<K,V> loHead = null, loTail = null;
                    Node<K,V> hiHead = null, hiTail = null;
                    Node<K,V> next;
                    do {
                        next = e.next;
                        // 原索引
                        if ((e.hash & oldCap) == 0) {
                            if (loTail == null)
                                loHead = e;
                            else
                                loTail.next = e;
                            loTail = e;
                        }
                        // 原索引+oldCap
                        else {
                            if (hiTail == null)
                                hiHead = e;
                            else
                                hiTail.next = e;
                            hiTail = e;
                        }
                    } while ((e = next) != null);
                    // 原索引放到bucket里
                    if (loTail != null) {
                        loTail.next = null;
                        newTab[j] = loHead;
                    }
                    // 原索引+oldCap放到bucket里
                    if (hiTail != null) {
                        hiTail.next = null;
                        newTab[j + oldCap] = hiHead;
                    }
                }
            }
        }
    }
    return newTab;
}
```

流程如下：

1、获取原来的数组 table、数组长度 oldCap 和阈值 oldThr。

**2、如果原来的数组 table 不为空，则根据扩容规则计算新数组长度 newCap 和新阈值 newThr，然后将原数组中的元素复制到新数组中。**

**3、如果原来的数组 table 为空但阈值 oldThr 不为零，则说明是通过带参数构造函数创建的 HashMap，此时将阈值作为新数组长度 newCap。**

**4、如果原来的数组 `table` 和阈值 `oldThr` 都为零，则说明是通过无参数构造函数创建的 HashMap，此时将默认初始容量 DEFAULT_INITIAL_CAPACITY（16）和默认负载因子 DEFAULT_LOAD_FACTOR（0.75）计算出新数组长度 newCap 和新阈值 newThr。**

5、计算新阈值 threshold，并将其赋值给成员变量 threshold。

6、创建新数组 newTab，并将其赋值给成员变量 table。

7、如果旧数组 oldTab 不为空，则遍历旧数组的每个元素，将其复制到新数组中。

8、返回新数组 newTab





扩容过程主要包括以下几个步骤：

1. 计算新的容量：将原始容量乘以 2，得到新的容量
2. 创建新数组：根据新的容量创建一个新的数组，用于存放元素
3. 重新计算哈希值：遍历原数组中的元素，重新计算每个元素的哈希值，并根据新的容量取模，得到新的索引位置
4. 插入到新数组：根据新的索引位置，将元素插入到新的数组中(如果hash冲突，jdk8采用尾插法解决)
5. 更新引用：将 `HashMap` 内部的引用指向新的数组，原数组将被垃圾回收







当然还有另外一种情况，初始化hashmap时，如果调用默认构造函数，即不传入initalCapacity，那么就会在第一次添加元素至Node数组时执行扩容`resize()`方法：
![image-20240403013539935](https://cdn.jsdelivr.net/gh/amonstercat/PicGo@master/202404030135308.png)

再来看一下resize()方法中针对空Node数组执行扩容的核心逻辑：
![image-20240403013746933](https://cdn.jsdelivr.net/gh/amonstercat/PicGo@master/202404030137136.png)


#### rE


#### 处理冲突

jdk1.8在解决哈希冲突时,**当链表长度大于阈值（默认为 8）时**，会首先调用 `treeifyBin()`方法。这个方法会根据 HashMap 数组来决定是否转换为红黑树。只有当数组长度大于或者等于 64 的情况下，才会执行转换红黑树操作以减少搜索时间。否则就只是执行 `resize()` 方法对数组扩容：

```java
static final int MIN_TREEIFY_CAPACITY = 64; //数组长度大于64时才会转换红黑树
static final int TREEIFY_THRESHOLD = 8; //链表长度转换为红黑树的阈值（但也不一定转换！）
static final int UNTREEIFY_THRESHOLD = 6;// 当桶(bucket)上的结点数小于等于这个值时红黑树退化为转链表

 final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict){
     p.next = newNode(hash, key, value, null);
     if (binCount >= TREEIFY_THRESHOLD - 1) //  链表长度大于设定的阈值8时，执行treeiftBin()方法来决定是否转换
       treeifyBin(tab, hash);
       break;
 }


final void treeifyBin(Node<K,V>[] tab, int hash) {
        int n, index; Node<K,V> e;
        if (tab == null || (n = tab.length) < MIN_TREEIFY_CAPACITY)
            resize(); //判断此时的桶数组长度，如果小于64，则优先对数组进行扩容
        else if ((e = tab[index = (n - 1) & hash]) != null) {
            TreeNode<K,V> hd = null, tl = null;
            do {
                TreeNode<K,V> p = replacementTreeNode(e, null);
                if (tl == null)
                    hd = p;
                else {
                    p.prev = tl;
                    tl.next = p;
                }
                tl = p;
            } while ((e = e.next) != null);
            if ((tab[index] = hd) != null)
                hd.treeify(tab);
        }
    }

```



或许有人会疑惑：为什么一开始不使用红黑树来解决链表冲突，为什么treeifybin的阈值为8 而不是其他值？推荐阅读这篇文章：

https://cnblogs.com/liaowenhui/p/15055596.html

https://segmentfault.com/a/1190000023308658





#### 线程安全问题

(1)多线程环境下扩容导致死循环：

JDK1.7 及之前版本的 `HashMap` 在多线程环境下扩容操作可能存在死循环问题，这是由于当一个桶位中有多个元素需要进行扩容时，多个线程同时对链表进行操作，**头插法**可能会导致链表中的节点指向错误的位置，从而形成一个环形链表，进而使得查询元素的操作陷入死循环无法结束。当有数据要插入时，首先会检查容量有没有超过设定的`threshold`，如果超过，需要增大`HashMap`的尺寸，这样一来整个Hash表里的元素都需要被重算一遍 ，这就是`rehash`，而`HashMap`的死循环问题就发生在这里：

正常情况(单线程)下`HashMap`的`rehash`过程如下所示（链表使用头插法）：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/hashmap1.jpg)





而在多线程情况下，线程 T1 和线程 T2 要对 HashMap 进行扩容操作，此时 T1 和 T2 指向的是链表的头结点元素 A，而 T1 和 T2 的下一个节点，也就是 T1.next 和 T2.next 指向的是 B 节点，如下图所示：![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/hashmap2.jpg)



线程 T2 时间片用完进入休眠状态，而线程 T1 开始执行扩容操作（且一直到线程 T1 扩容完成后，线程 T2 才被唤醒），上图可知线程 T1 执行之后，因为是头插法，所以 `HashMap` 冲突链表中元素的顺序已经发生了改变(**(插入顺序是A->B->C,故插入完成后会有B——>A的指针)**)，但线程 T2 对于发生的一切是不可知的，所以它的指向元素依然没变，如下图所示的那样，T2 指向的是 A 元素，T2.next 指向的节点是 B 元素：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/hashmap3.jpg)

这样当线程 T1 执行完，而线程 T2 恢复执行时，死循环就建立了，因为 T1 执行完扩容之后 B 节点的下一个节点是 A，而 T2 线程指向的首节点是 A，第二个节点是 B，这个顺序刚好和 T1 扩完容完之后的节点顺序是相反的。T1 执行完之后的顺序是 B 到 A，而 T2 的顺序是 A 到 B，这样 A 节点和 B 节点就形成死循环了，即 **头插法 + 链表 + 多线程并发 + HashMap 扩容 ** ，这几个点加在一起就形成了 HashMap 的死循环



为了解决这个问题，JDK1.8 版本的 HashMap 采用了尾插法而不是头插法来避免链表倒置，使得插入的节点永远都是放在链表的末尾，避免了链表中的环形结构。但是还是不建议在多线程下使用 `HashMap`，因为多线程下使用 `HashMap` 还是会存在数据覆盖的问题。并发环境下，推荐使用 `ConcurrentHashMap` 





(2)`put`操作造成数据丢失

多线程同时执行 put 操作时，如果计算出来的索引位置是相同的，那会造成前一个 key 被后一个 key 覆盖，从而导致元素的丢失。

在 `HashMap` 中，多个键值对可能会被分配到同一个桶（`bucket`），并以链表或红黑树的形式存储。多个线程对 `HashMap` 的 `put` 操作会导致线程不安全，具体来说会有数据覆盖的风险：

1. 线程 1,2 同时进行 `put` 操作
2. 不同的线程可能在不同的时间片获得 `CPU` 执行的机会，当前线程 1 执行完哈希冲突判断后(发现没有冲突！)，由于时间片耗尽挂起。线程 2开始执行判断冲突(**也发现没有冲突，因为线程1都没有完成插入操作呢**) ，发现无冲突后先完成了插入元素操作
3. 随后，线程 1 获得时间片，由于**之前已经进行过 hash 碰撞的判断，所以此时会直接进行插入**，这就导致线程 2 插入的数据被线程 1 覆盖了（**正常情况下会判断冲突并在链表中新添加一个冲突节点的**）









#### 遍历方式



先定义好一个HashMap集合并采用多种方式对其进行遍历：

```java
//创建并赋值 HashMap
        Map<Integer, String> map = new HashMap();
        map.put(1, "Java");
        map.put(2, "JDK");
        map.put(3, "Spring Framework");
        map.put(4, "MyBatis framework");
        map.put(5, "Java中文社群");
```

（1）迭代器**`EntrySet`**：

```java
//获取到针对键值对Entry的Iterator
Iterator<Map.Entry<Integer, String>> iterator = map.entrySet().iterator();
    while (iterator.hasNext()) {
        Map.Entry<Integer, String> entry = iterator.next();
        System.out.println(entry.getKey());
        System.out.println(entry.getValue());
    }
```

（2）迭代器`KeySet`：

```java
//获取到针对Entry中Key的Iterator
Iterator<Integer> iterator = map.keySet().iterator();
        while (iterator.hasNext()) {
            Integer key = iterator.next();
            System.out.println(key);
            System.out.println(map.get(key));
        }
```

（3）ForEach EntrySet：

```java
 for (Map.Entry<Integer, String> entry : map.entrySet()) {
            System.out.println(entry.getKey());
            System.out.println(entry.getValue());
        }
```

（4）ForEach KeySet：

```java
 for (Integer key : map.keySet()) {
            System.out.println(key);
            System.out.println(map.get(key));
        }
```

（5）Lambda表达式：

```java
 map.forEach((key, value) -> {
            System.out.println(key);
            System.out.println(value);
        });
```

（6）Streams API ：

单线程

```java
 map.entrySet().stream().forEach((entry) -> {
            System.out.println(entry.getKey());
            System.out.println(entry.getValue());
        });
```

多线程

```java
map.entrySet().parallelStream().forEach((entry) -> {
            System.out.println(entry.getKey());
            System.out.println(entry.getValue());
        });
```







### ConcurrentHashMap:face_with_head_bandage:



Java7 中 `ConcurrentHashMap` 使用的分段锁(**每个段内部维护一个 `ReentrantLock` 锁**)，也就是每一个 Segment 上同时只有一个线程可以操作，**每一个 `Segment` 都是一个类似 `HashMap` 数组的结构**，它可以扩容，它的冲突会转化为链表。但是 `Segment` 的个数一但初始化就不能改变。

Java8 中的 `ConcurrentHashMap` 使用的 `Synchronized` 锁加 `CAS` 的机制。结构也由 Java7 中的 **`Segment` 数组 + `HashEntry` 数组 + 链表** 进化成了 **Node 数组 + 链表 / 红黑树**，Node 是类似于一个 `HashEntry` 的结构。它的冲突再达到一定大小时会转化成红黑树，在冲突小于一定数量时又退回链表



`jdk1.8`之前`ConcurrentHashMap`的底层结构如下：![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/java-thread-x-concurrent-hashmap-1.png)

`ConcurrentHashMap` 是由 `Segment` 数组结构（`Segment` 的个数一旦初始化就不能改变，大小默认是 16，也就是说默认可以同时支持**16**个线程并发写）和 `HashEntry` 数组结构组成

其中`Segment` (将数据分为一段一段,这个“段”就是 `Segment`的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据时，其他段的数据也能被其他线程访问) 继承了 `ReentrantLock`,所以 `Segment` 也是一种可重入锁，而`HashEntry` 数组则用于存储键值对数据



**`jdk1.8`后使用了Node数组来存储数据**：

```java
transient volatile Node<K,V>[] table;
```

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/java-thread-x-concurrent-hashmap-2.png)

Java8后`ConcurrentHashMap` 取消了 `Segment` 分段锁，采用 `Node数组 + CAS + synchronized` 来保证并发安全。数据结构跟 `HashMap` 在`jdk1.8` 的实现结构类似，数组+链表/红黑二叉树。Java 8 在链表长度超过一定阈值（8）时将链表（寻址时间复杂度为 O(N)）转换为红黑树，在1.8后，`ConcurrentHashMap`锁的粒度更细，`synchronized` 只锁定当前链表或红黑二叉树的首节点，这样只要 hash 不冲突，就不会产生并发，就不会影响其他 `Node` 的读写





#### 初始化



由于`ConcurrentHashMap`的底层实现在`java8`前后区别比较大，故需要分别进行分析，首先是

**JAVA8之前**:

通过`ConcurrentHashMap`的构造方法来进行数组初始化：

```java
  private static final int DEFAULT_CAPACITY = 16; //初始默认容量 同hashmap
  private static final float LOAD_FACTOR = 0.75f; //默认负载因子 同hashmap
  static final int DEFAULT_CONCURRENCY_LEVEL = 16;//默认并发级别 对应多少个桶
   //无参构造
  public ConcurrentHashMap() {
        this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL);
    }
  

@SuppressWarnings("unchecked")
public ConcurrentHashMap(int initialCapacity,float loadFactor, int concurrencyLevel) {
    // 参数校验
    if (!(loadFactor > 0) || initialCapacity < 0 || concurrencyLevel <= 0)
        throw new IllegalArgumentException();
    // 校验并发级别大小，大于 1<<16，重置为 65536
    if (concurrencyLevel > MAX_SEGMENTS)
        concurrencyLevel = MAX_SEGMENTS;
    // Find power-of-two sizes best matching arguments
    // 2的多少次方
    int sshift = 0;
    int ssize = 1;
    
    while (ssize < concurrencyLevel) { // 这个循环可以找到 concurrencyLevel 之上最近的 2的次方值
        ++sshift;
        ssize <<= 1;
    }
    // 记录段偏移量
    this.segmentShift = 32 - sshift;
    // 记录段掩码
    this.segmentMask = ssize - 1;
    // 设置容量
    if (initialCapacity > MAXIMUM_CAPACITY)
        initialCapacity = MAXIMUM_CAPACITY;
    // c = 容量 / ssize ，默认 16 / 16 = 1，这里是计算每个 Segment 中的类似于 HashMap 的容量
    int c = initialCapacity / ssize;
    if (c * ssize < initialCapacity)
        ++c;
    int cap = MIN_SEGMENT_TABLE_CAPACITY;
    //Segment 中的类似于 HashMap 的容量至少是2或者2的倍数
    while (cap < c)
        cap <<= 1;
    // create segments and segments[0]
    // 创建 Segment 数组，设置 segments[0]
    Segment<K,V> s0 = new Segment<K,V>(loadFactor, (int)(cap * loadFactor),
                         (HashEntry<K,V>[])new HashEntry[cap]);
    Segment<K,V>[] ss = (Segment<K,V>[])new Segment[ssize];
    UNSAFE.putOrderedObject(ss, SBASE, s0); // ordered write of segments[0]
    this.segments = ss;
}

```

即在Java7 中 `ConcurrentHashMap` 的初始化逻辑如下：

1. 必要参数校验

2. 校验并发级别 `concurrencyLevel` 大小，如果大于最大值，重置为最大值。无参构造**默认值是 16.**

3. **寻找给定的并发级别 `concurrencyLevel` 之上最近的 2 的幂次方值**，将该值作为数组初始化容量大小(例如用户输入的`concurrencyLevel`为20，则会初始化`Segment`数组长度为32)

   ```java
   Segment<K,V>[] ss = (Segment<K,V>[])new Segment[ssize];
   //ssize为`concurrencyLevel` 之上最近的 2 的幂次方值
   ```

4. **初始化 `segments[0]`**，**默认大小为 2**，**负载因子 0.75**，**扩容阀值是 2\*0.75=1.5**，插入第二个值时才会对该`segement[0]`对应的`HashMap`进行扩容







**`JAVA8`之后**:

**通过`initTable()`来进行Node数组的初始化**， 初始化中的并发问题是通过对变量`sizeCtl` 进行一个 `CAS` 操作来控制的：

```java
private transient volatile int sizeCtl;  //该属性用来控制table数组的大小，  
/*
该属性用来控制table数组的大小，根据是否初始化和是否正在扩容有几种情况：
当值为负数时： 如果为-1表示正在初始化，如果为-N则表示当前正有N-1个线程进行扩容操作；
当值为正数时： 如果当前数组为null的话表示table在初始化过程中，sizeCtl表示为需要新建数组的长度；
若已经初始化了，表示当前数据容器（table数组）可用容量也可以理解成临界值（插入节点数超过了该临界值就需要扩容），具体指为数组的长度n 乘以 加载因子loadFactor；
当值为0时，即数组长度为默认初始值。

*/


//根据输入的初始容量来找到最接近的  //给定map的大小
  public ConcurrentHashMap(int initialCapacity) {
    if (initialCapacity < 0)
        throw new IllegalArgumentException();
    int cap = ((initialCapacity >= (MAXIMUM_CAPACITY >>> 1)) ?   //  >>>1无符号右移
               MAXIMUM_CAPACITY :
               tableSizeFor(initialCapacity + (initialCapacity >>> 1) + 1));
    this.sizeCtl = cap;
}
 


   //有参构造——————自定义并发级别 
   //给定map大小，加载因子以及并发度（预计同时操作数据的线程）
   public ConcurrentHashMap(int initialCapacity,
                             float loadFactor, int concurrencyLevel) {
        if (!(loadFactor > 0.0f) || initialCapacity < 0 || concurrencyLevel <= 0)
            throw new IllegalArgumentException();
        if (initialCapacity < concurrencyLevel)   // Use at least as many bins
            initialCapacity = concurrencyLevel;   //设置的数组初始容量>=设置的并发级别！
        long size = (long)(1.0 + (long)initialCapacity / loadFactor);
        int cap = (size >= (long)MAXIMUM_CAPACITY) ?
            MAXIMUM_CAPACITY : tableSizeFor((int)size);//找到最接近的2的幂次方数
        this.sizeCtl = cap;
    }



/**
 * Initializes table, using the size recorded in sizeCtl.
 */
private final Node<K,V>[] initTable() {
    Node<K,V>[] tab; int sc;
    while ((tab = table) == null || tab.length == 0) {
        // 初始化的"功劳"被其他线程"抢去"了
        /*
        有可能存在一个情况是多个线程同时走到这个方法中，为了保证能够正确初始化，在第1步中         会先通过if进行判断，若当前已经有一个线程正在初始化即sizeCtl值变为-1，这个时候其         他线程在If判断为true从而调用Thread.yield()让出CPU时间片。
        */
        if ((sc = sizeCtl) < 0)
            Thread.yield(); // lost initialization race; just spin
        // CAS 一下，将 sizeCtl 设置为 -1，代表抢到了锁
        else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
            try {
                if ((tab = table) == null || tab.length == 0) {
                    // DEFAULT_CAPACITY 默认初始容量是 16
                    int n = (sc > 0) ? sc : DEFAULT_CAPACITY;
                    // 初始化数组，长度为 16 或初始化时提供的长度
                    Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];
                    // 将这个数组赋值给 table，table 是 volatile 的
                    table = tab = nt;
                    // 如果 n 为 16 的话，那么这里 sc = 12
                    // 其实就是 0.75 * n
                    sc = n - (n >>> 2);
                }
            } finally {
                // 设置 sizeCtl 为 sc，我们就当是 12 吧
                sizeCtl = sc;
            }
            break;
        }
    }
    return tab;
}
```

可以看到：**`sizeCtl`的大小应该就代表了`ConcurrentHashMap`的大小，即table数组长度**。



`tableSizeFor`做了哪些事情了？直接看源码：

```java
/**
 * Returns a power of two table size for the given desired capacity.
 * See Hackers Delight, sec 3.2
 */
private static final int tableSizeFor(int c) {
    int n = c - 1;
    n |= n >>> 1;
    n |= n >>> 2;
    n |= n >>> 4;
    n |= n >>> 8;
    n |= n >>> 16;
    return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
}
```

该方法会将调用构造器方法时指定的大小转换成一个2的幂次方数，也就是说`ConcurrentHashMap`的大小一定是2的幂次方，比如，当指定大小为18时，为了满足2的幂次方特性，实际上`concurrentHashMapd`的大小为2的5次方（32）

需要注意的是，**调用构造器方法的时候并未构造出`table`数组（可以理解为`ConcurrentHashMap`的数据容器），只是算出`table`数组的长度，当第一次向`ConcurrentHashMap`插入数据的时候才真正的完成初始化创建`table`数组的工作**





注意下列代码：

```java
 if ((sc = sizeCtl) < 0)
            Thread.yield();
```

其中`yield()`方法调用后线程只是暂时的将调度权让给别人，但立刻可以回到竞争线程锁的状态，

从源码中可以发现Java8后`ConcurrentHashMap` 的初始化是通过**自旋和 CAS **操作完成的。里面需要注意的是变量 `sizeCtl` ，它的值决定着当前的初始化状态

1. -1 说明正在初始化
2. -N 说明有 N-1 个线程正在进行扩容
3. 0 表示 table 初始化大小，如果 table 没有初始化
4. \>0 表示 table 扩容的阈值，如果 table 已经初始化



还有这行代码：

```java
U.compareAndSwapInt(this, SIZECTL, sc, -1)
```

典型的`CAS`操作





#### Put/Get操作

```java
//java8public V put(K key, V value) {
    return putVal(key, value, false);
}
final V putVal(K key, V value, boolean onlyIfAbsent) {
    if (key == null || value == null) throw new NullPointerException();
    // 得到 hash 值
    int hash = spread(key.hashCode());
    // 用于记录相应链表的长度
    int binCount = 0;
    for (Node<K,V>[] tab = table;;) {
        Node<K,V> f; int n, i, fh;
        // 如果数组"空"，进行数组初始化
        if (tab == null || (n = tab.length) == 0)
            // 初始化数组，后面会详细介绍
            tab = initTable();

        // 找该 hash 值对应的数组下标，得到第一个节点 f
        else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
            // 如果数组该位置为空，
            //用一次 CAS 操作将这个新值放入其中即可，这个 put 操作差不多就结束了，可以拉到最后面了
            //如果 CAS 失败，那就是有并发操作，进到下一个循环就好了
            if (casTabAt(tab, i, null,
                         new Node<K,V>(hash, key, value, null)))
                break;                   // no lock when adding to empty bin
        }
        // hash 居然可以等于 MOVED，这个需要到后面才能看明白，不过从名字上也能猜到，肯定是因为在扩容
        else if ((fh = f.hash) == MOVED)
            // 帮助数据迁移
            tab = helpTransfer(tab, f);

        else { // 到这里就是说，f 是该位置的头节点，而且不为空

            V oldVal = null;
            // 获取数组该位置的头节点的监视器monitor锁
            synchronized (f) {
                if (tabAt(tab, i) == f) {
                    if (fh >= 0) { // 头节点的 hash 值大于 0，说明是链表
                        // 用于累加，记录链表的长度
                        binCount = 1;
                        // 遍历链表
                        for (Node<K,V> e = f;; ++binCount) {
                            K ek;
                            // 如果发现了"相等"的 key，判断是否要进行值覆盖，然后也就可以 break 了
                            if (e.hash == hash &&
                                ((ek = e.key) == key ||
                                 (ek != null && key.equals(ek)))) {
                                oldVal = e.val;
                                if (!onlyIfAbsent)
                                    e.val = value;
                                break;
                            }
                            // 到了链表的最末端，将这个新值放到链表的最后面
                            Node<K,V> pred = e;
                            if ((e = e.next) == null) {
                                pred.next = new Node<K,V>(hash, key,
                                                          value, null);
                                break;
                            }
                        }
                    }
                    else if (f instanceof TreeBin) { // 红黑树
                        Node<K,V> p;
                        binCount = 2;
                        // 调用红黑树的插值方法插入新节点
                        if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,
                                                       value)) != null) {
                            oldVal = p.val;
                            if (!onlyIfAbsent)
                                p.val = value;
                        }
                    }
                }
            }

            if (binCount != 0) {
                // 判断是否要将链表转换为红黑树，临界值和 HashMap 一样，也是 8
                if (binCount >= TREEIFY_THRESHOLD)
                    // 这个方法和 HashMap 中稍微有一点点不同，那就是它不是一定会进行红黑树转换，
                    // 如果当前数组的长度小于 64，那么会选择进行数组扩容，而不是转换为红黑树
                    treeifyBin(tab, i);
                if (oldVal != null)
                    return oldVal;
                break;
            }
        }
    }
    // 
    addCount(1L, binCount);
    return null;
}

```

1. 根据 key 计算出 hashcode
2. 判断是否需要进行初始化(`ConcurrentHashMap`调用默认构造方法后并没有初始化数组，和`ArrayList`一样第一次插入元素时才初始化)
3. 即为当前 key 定位出的 Node，如果为空表示当前位置可以写入数据，**利用 CAS 尝试写入**，失败则**自旋**保证成功
4. 如果当前位置的 `hashcode == MOVED == -1`,则说明正在执行扩容(通过判断该节点的hash值是不是等于-1（MOVED）,代码为`(fh = f.hash) == MOVED`)
5. 在table[i]不为null并且不为`forwardingNode`(`f.hash==MOVED` 标志扩容ing)时，并且当前Node f的hash值大于`0（f.hash() >= 0）`的话说明当前节点f为当前桶的所有的节点组成的链表的头结点。那么接下来，要想向`ConcurrentHashMap`插入新值的话就是向这个链表插入新值。通过`synchronized(f)` 的方式进行加锁以实现线程安全性，**可以看出来每次加锁锁的是链表头节点**
6. **如果数量大于 `TREEIFY_THRESHOLD` 则要执行树化方法，在 `treeifyBin` 中会首先判断当前数组长度， ≥64时才会将链表转换为红黑树**

比较一下`HashMap`与`ConcurrentHashMap`中树化方法的异同：

```java
//ConcurrentHashMap
private final void treeifyBin(Node<K,V>[] tab, int index) {
        Node<K,V> b; int n;
        if (tab != null) {
            if ((n = tab.length) < MIN_TREEIFY_CAPACITY)
                tryPresize(n << 1);   //Node数组长度小于64时优先扩容Node数组
            else if ((b = tabAt(tab, index)) != null && b.hash >= 0) {
                synchronized (b) {
                    if (tabAt(tab, index) == b) {
                        TreeNode<K,V> hd = null, tl = null;
                        for (Node<K,V> e = b; e != null; e = e.next) {
                            TreeNode<K,V> p =
                                new TreeNode<K,V>(e.hash, e.key, e.val,
                                                  null, null);
                            if ((p.prev = tl) == null)
                                hd = p;
                            else
                                tl.next = p;
                            tl = p;
                        }
                        setTabAt(tab, index, new TreeBin<K,V>(hd));
                    }
                }
            }
        }
    }


// HashMap
 final void treeifyBin(Node<K,V>[] tab, int hash) {
        int n, index; Node<K,V> e;
        if (tab == null || (n = tab.length) < MIN_TREEIFY_CAPACITY)
            resize();
        else if ((e = tab[index = (n - 1) & hash]) != null) {
            TreeNode<K,V> hd = null, tl = null;
            do {
                TreeNode<K,V> p = replacementTreeNode(e, null);
                if (tl == null)
                    hd = p;
                else {
                    p.prev = tl;
                    tl.next = p;
                }
                tl = p;
            } while ((e = e.next) != null);
            if ((tab[index] = hd) != null)
                hd.treeify(tab);
        }
    }
```



总结：

1. `CAS`写入是在当前Node数组中的头节点为null时(`table[i]==null` 没有哈希冲突)使用的策略
2. `synchronized`写入是在判断一个桶内的头节点没有正在扩容,且发生了哈希冲突的前提下，对链表头节点进行加锁synchronized(f)，然后遍历到尾节点执行插入元素 









对于**Get操作**：

```java
public V get(Object key) {
    Node<K,V>[] tab; Node<K,V> e, p; int n, eh; K ek;
    // key 所在的 hash 位置
    int h = spread(key.hashCode());
    if ((tab = table) != null && (n = tab.length) > 0 &&
        (e = tabAt(tab, (n - 1) & h)) != null) {
        // 如果指定位置元素存在，头结点hash值相同
        if ((eh = e.hash) == h) {
            if ((ek = e.key) == key || (ek != null && key.equals(ek)))
                // key hash 值相等，key值相同，直接返回元素 value
                return e.val;
        }
        else if (eh < 0)
            // 头结点hash值小于0，说明正在扩容或者是红黑树，find查找
            return (p = e.find(h, key)) != null ? p.val : null;
        while ((e = e.next) != null) {
            // 是链表，遍历查找
            if (e.hash == h &&
                ((ek = e.key) == key || (ek != null && key.equals(ek))))
                return e.val;
        }
    }
    return null;
}

```

查找的流程分为以下几个步骤：
1. 计算 key 的 hash 值
2. 根据 hash 值找到数组对应位置: `(n - 1) & h`
3. 根据该位置处结点性质进行相应查找 

- 如果该位置为 null，那么直接返回 null 就可以了
- 如果该位置处的节点刚好就是我们需要的，返回该节点的值即可
- **如果该位置节点的 hash 值小于 0，说明正在扩容，或者是红黑树，然后接着调用`find()`查找**
- 如果以上 3 条都不满足，那就是链表，进行遍历比对即可







#### 它一定线程安全吗？

`ConcurrentHashMap` 是线程安全的，意味着它可以保证多个线程同时对它进行读写操作时，不会出现数据不一致的情况，也不会导致 JDK1.7 及之前版本的 `HashMap` 多线程操作导致死循环问题。但是，这并不意味着它可以保证所有的复合操作都是原子性的，一定不要搞混了！

复合操作是指由多个基本操作(如`put`、`get`、`remove`、`containsKey`等)组成的操作，例如先判断某个键是否存在`containsKey(key)`，然后根据结果进行插入或更新`put(key, value)`。这种操作在执行过程中可能会被其他线程打断，导致结果不符合预期。

例如，有两个线程 A 和 B 同时对 `ConcurrentHashMap` 进行复合操作，如下：

```
// 线程 A
if (!map.containsKey(key)) {
map.put(key, value);
}
// 线程 B
if (!map.containsKey(key)) {
map.put(key, anotherValue);
}
```

如果线程 A 和 B 的执行顺序是这样：

1. 线程 A 判断 map 中不存在 key
2. 线程 B 判断 map 中不存在 key
3. 线程 B 将 (key, anotherValue) 插入 map
4. 线程 A 将 (key, value) 插入 map

那么最终的结果是 (key, value)，而不是预期的 (key, anotherValue)。这就是复合操作的非原子性导致的问题。

**那如何保证 `ConcurrentHashMap` 复合操作的原子性呢？**

`ConcurrentHashMap` 提供了一些原子性的复合操作，如 `putIfAbsent`、`compute`、`computeIfAbsent` 、`computeIfPresent`、`merge`等。这些方法都可以接受一个函数作为参数，根据给定的 key 和 value 来计算一个新的 value，并且将其更新到 map 中。

上面的代码可以改写为：

```java
// 线程 A
map.putIfAbsent(key, value);
// 线程 B
map.putIfAbsent(key, anotherValue);
```

或者：

```java
// 线程 A
map.computeIfAbsent(key, k -> value);
// 线程 B
map.computeIfAbsent(key, k -> anotherValue);
```

很多同学可能会说了，这种情况也能加锁同步呀！确实可以，但不建议使用加锁的同步机制，违背了使用 `ConcurrentHashMap` 的初衷。在使用 `ConcurrentHashMap` 的时候，尽量使用这些原子性的复合操作方法来保证原子性。







## BlockingQueue

`BlockingQueue` 通常用于一个线程生产对象，而另外一个线程消费这些对象的场景。

一个线程将会持续生产新对象并将其插入到队列之中，直到队列达到它所能容纳的临界点。也就是说，它是有限的。如果该阻塞队列到达了其临界点，负责生产的线程将会在往里边插入新对象时发生阻塞。它会一直处于阻塞之中，直到负责消费的线程从队列中拿走一个对象。 负责消费的线程将会一直从该阻塞队列中拿出对象。如果消费线程尝试去从一个空的队列中提取对象的话，这个消费线程将会处于阻塞之中，直到一个生产线程把一个对象丢进队列



用一句话来概括阻塞队列就是：**是一个支持阻塞式的插入和移除的FIFO队列**：

1. **插入元素的时候：当队列满了，线程阻塞等待，直到队列中的元素被取出，然后被唤醒继续往队列里面插入元素**。
2. **获取元素的时候：队列为空，线程阻塞等待，直到队列有元素，被唤醒**。

> 如何被唤醒的？ 依赖 `Condition`类中的 `await`()和`signal()`方法

`BlockingDeque` 具有 4 组不同的方法用于插入、移除以及对双端队列中的元素进行检查。如果请求的操作不能得到立即执行的话，每个方法的表现也不同。这些方法如下:

|      | 抛出异常       | 返回特定值    | 一直阻塞     | 超时退出                         |
| ---- | -------------- | ------------- | ------------ | -------------------------------- |
| 插入 | addFirst(o)    | offerFirst(o) | putFirst(o)  | offerFirst(o, timeout, timeunit) |
| 移除 | removeFirst(o) | pollFirst(o)  | takeFirst(o) | pollFirst(timeout, timeunit)     |
| 检查 | getFirst(o)    | peekFirst(o)  |              |                                  |

|      | 抛出异常      | 返回特定值   | 一直阻塞    | 超时退出                        |
| ---- | ------------- | ------------ | ----------- | ------------------------------- |
| 插入 | addLast(o)    | offerLast(o) | putLast(o)  | offerLast(o, timeout, timeunit) |
| 移除 | removeLast(o) | pollLast(o)  | takeLast(o) | pollLast(timeout, timeunit)     |
| 检查 | getLast(o)    | peekLast(o)  |             |                                 |



- **抛出异常**：当插入或者获取元素的时候，此时队列已经满了或者为空，那么阻塞队列就会抛出**new IllegalStateException("Queue full")**的异常信息
- **返回特殊值**：当插入元素的时候，插入成功就返回true，当插入失败就返回false
- **一直阻塞**：当插入元素或者获取元素的时候，队列满了或者为空，线程就会处于阻塞
- **超时退出**：当插入元素或者获取元素的时候，队列满了或者队列为空，线程就会根据传入的超时时间，进行在这个时间内进行等待插入或者等待获取，直到超时退出





### ArrayBlockingQueue



1、数组阻塞队列 `ArrayBlockingQueue`

`ArrayBlockingQueue` 是一个**有界的阻塞队列**，其内部实现是将对象放到一个数组里。有界也就意味着，它不能够存储无限多数量的元素。它有一个同一时间能够存储元素数量的上限。你可以在对其初始化的时候设定这个上限，但之后就无法对这个上限进行修改了(译者注: 因为它是基于数组实现的，也就具有数组的特性: 一旦初始化，大小就无法修改)。 `ArrayBlockingQueue` 内部以 FIFO(先进先出)的顺序对元素进行存储。队列中的头元素在所有元素之中是放入时间最久的那个，而尾元素则是最短的那个



先来看看`ArrayBlockingQueue`的`add`操作，`add`操作是队列满的时候抛出异常，源码实现挺简单的：

![图片](https://mmbiz.qpic.cn/mmbiz_png/IJUXwBNpKlgaIDeMWhv4aZDFicTZY3RR5icNeOGPibXpogj3pmCUicQwXYGhUHxaUKJ5an2Sqe1XwibUShqSWhcibATQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

`ArrayBlockingQueue`的add操作是直接调用父类**`AbstractQueue`**的`add`操作：

![图片](https://mmbiz.qpic.cn/mmbiz_png/IJUXwBNpKlgaIDeMWhv4aZDFicTZY3RR541gWjSEwiaA4j2yV3ybS4e3Nooul0BLUlFh1f7qiaicojqdbU3ic5gEwOQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

`add`操作就是通过调用`offer`操作返回的特殊值进行判断实现，来看看`offer`的实现：

```java
public boolean offer(E e) {
    checkNotNull(e);
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        if (count == items.length)  //队列已满 直接返回false  非阻塞
            return false;
        else { 
            enqueue(e); //向队列中添加元素
            return true;
        }
    } finally {
        lock.unlock();
    }
}
```

`offer()`方法实现主要干了以下四件事：

1. `ReentrantLock`加锁，避免多线程的时候插入操作，出现数据的混乱。
2. 判断若是队列满了就直接返回`false`，表示插入不成功。
3. 最后则进行插入`enqueue(e)`
4. 解锁

`enqueue`方法是真正实现插入元素的动作，具体的源码实现如下：

```java
private void enqueue(E x) {
   
    final Object[] items = this.items;
    items[putIndex] = x;
    if (++putIndex == items.length)
        putIndex = 0;  //队列满了，重新复制putIndex=0 ,即为覆盖
    count++;
    //队列中已经存在元素，唤醒获取元素的线程
    notEmpty.signal();  //Condition必须依赖于外部Lock
}
```

上面我们聊到在**`ArrayBlockingQueue`**的源码实现里面使用**Object[] items**来存储元素，也就是上面源码实现的**this.items**，直接通过**items[putIndex] = x;**的方式将元素插入队列里面。

然后再判断`putIndex`是否已经达到队列的长度，若是已经达到队列长度就重新赋值为0。

最后记录 **count++** 也就是队列中元素的个数。这里有个比较有意思的就是**notEmpty.signal()** 方法，与它对应就是：**notEmpty.await()**



`notEmpty`是一个`Condition`类型的元素，对于`Condition`这里制作大致的介绍，后面的原创会详细的介绍。

```java
/* Condition for waiting takes */
private final Condition notEmpty;

/* Condition for waiting puts */
private final Condition notFull;
```



这两个的作用分别是：

`notEmpty`可以在队列为空时，调用`notEmpty.await()`，阻塞线程——消费者线程进入Condition条件队列：

```java
public E take() throws InterruptedException {
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly();
    try {
        while (count == 0)
           notEmpty.await();  //队列为空时无法再取元素， 但是线程会阻塞，不会立即退出
        return dequeue();
    } finally {
        lock.unlock();
    }
}
```



当向队列里面添加了元素时，则会调用**`notEmpty.signal()`**，通知因为队列为空而等待的消费者线程：

![](https://mmbiz.qpic.cn/mmbiz_png/IJUXwBNpKlgaIDeMWhv4aZDFicTZY3RR5FF0ziaBpxp0ukzTl4eSa4macvI5n3tB3qFia11wc93rRbAYVibQt4aicNw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

而**notFull**则是在队列满的时候，实现线程的通信，当向队列中添加元素的时候，队列满了，实现线程等待；或者从队列中获取了元素，则通知等待的线程往可以向队列中插入元素。

所以**总的一句话来概括`Condition`的作用就是：实现线程之间的等待/通知机制的通信**，其实等待通知机制我们知道在Object方法里面也有对应的`wait/notify`方法实现







我们来看看Condition又是怎么实现等待/通知机制的呢？分别来看看await/signal的源码实现，signal跟踪到底层源码的实现，最终实现的重要方法是：

**`LockSupport.unpark(node.thread)`**：
![图片](https://mmbiz.qpic.cn/mmbiz_png/IJUXwBNpKlgaIDeMWhv4aZDFicTZY3RR5yBiaMdnTFkb2icaU5RcxgUD8wjHsVq7ZLjicaXBbiaS5sa3LfMG0IrULYg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

**LockSupport.unpark(node.thread)** 这个就是真正的实现唤醒线程的操作，那么对应的await的方法，肯定是就是：**LockSupport.park()** 方法。再往下面研究就是native方法了：

![图片](https://mmbiz.qpic.cn/mmbiz_png/IJUXwBNpKlgaIDeMWhv4aZDFicTZY3RR58grLHELCdChvUgXoL4WGbPicwibAnvt7TuTNaFXqGkCzcce1g7a1mtag/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

**所以Condition是通过LockSupport.park与LockSupport.unpark实现线程的等待通知机制。**

研究过AQS的源码的人会知道，**在AQS里面也会有Condition**，因为AQS也有独占式锁，阻塞式的获取锁资源。

所以，到这里大家应该知道Condition的作用了吧，就是实现线程的等待与通知，可以用来实现阻塞式的资源获取。



我们来看看`put`方法，阻塞式的(**`add()`方法是非阻塞式！！即发现队列满后会直接`return false`退出**)：

![图片](https://mmbiz.qpic.cn/mmbiz_png/IJUXwBNpKlgaIDeMWhv4aZDFicTZY3RR57a0hdErKrK05gNlMQSWLyC0pLFDgaPwrKPy1mKvKXQibkh3e6cSwEjQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

从它的源码里面就能够显而易见的发现：**当队列满的时候，调用`notFull.await()`，阻塞等待，直到线程被中断，或者有另外的线程唤醒`notFull.signal()`**这个方法比较简单，不过对于理解线程之间的通信，实现阻塞式的等待还是非常有帮助的

<img src="https://mmbiz.qpic.cn/mmbiz_png/IJUXwBNpKlgaIDeMWhv4aZDFicTZY3RR5icufRZ3BTE1Ca17aj9KwCNWxs2xWpyNkF30lgTiboxk4zbKibo92hTic7A/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:67%;" />



最后来看看offer实现超时退出，具体源码如下：


![图片](https://mmbiz.qpic.cn/mmbiz_png/IJUXwBNpKlgaIDeMWhv4aZDFicTZY3RR59xjnfiaGHnMk2Mqepicia61wwUAiasWPFjLemcNSArL7J1AxJHic2saAwWw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

具体的实现，还是调用**notFull.awaitNanos(nanos)**，进行超时等待，而它的底层是调用**LockSupport.parkNanos(this, nanosTimeout)**，最终还是回到了这个LockSupport类：

![图片](https://mmbiz.qpic.cn/mmbiz_png/IJUXwBNpKlgaIDeMWhv4aZDFicTZY3RR5pibkupXZmdEIauZ8hEnHfMvbMM9QdhHvkgPkXr4l27sPIMGnMLOpiaNg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

在超时退出方法offer里面有个有意思的就是这个**`lock.lockInterruptibly()`**，在`ReentrantLock`获取锁的方法有好几个。

**分别有lock、tryLock、lockInterruptibly等，他们的区别就是lock是是阻塞的，tryLock是非阻塞（返回特殊值）、lockInterruptibly是阻塞可中断的**：

![图片](https://mmbiz.qpic.cn/mmbiz_png/IJUXwBNpKlgaIDeMWhv4aZDFicTZY3RR5iaP4uYAOmmBaOquyiaNyUHJG6Qibvquqd6nK0lF8RaLqLW04AfDfOXz6g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

在lock的源码中作者也有解释到：**如果锁由另一个线程持有，则当前线程出于线程调度目的将被禁用，并处于休眠状态，直到获得锁为止，此时锁持有计数设置为1**

所以**`lockInterruptibly`**方法在跳出，有以下几种可能：

1. 如果获取锁成功，方法结束。

2. 如果锁无法获取，当前线程被阻塞，直到下面情况发生：

3. 1. 当前线程(被唤醒后)成功获取锁( 其他线程调用`signal()`方法唤醒它)
   2. 当前线程被其他线程中断

在**`lockInterruptibly`**底层源码跟踪后也是通过**`LockSupport.park(this)`**方法来实现线程的阻塞：

![图片](https://mmbiz.qpic.cn/mmbiz_png/IJUXwBNpKlgaIDeMWhv4aZDFicTZY3RR5qwkWjoOvqmSzt4lhIrBRBrDb6oylWv8emnSXn1nhSrlhefWOs4JvKw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

所以很多并发的工具类底层实现都基本差不多（Condition、LockSupport），因为这些都是通用的，应用层的工具类都是通过各种已有的工具类堆叠起来的



总结： `ArrayBlockingQueue`对于插入元素的方法，提供了三种：

> 1. 非阻塞式： `add(E e)`——>`offer(E e)`——>队列满即返回false
>
> 2. 阻塞式： `put(E e)`
>
> ```java
>    final ReentrantLock lock = this.lock;
>    lock.lockInterruptibly();
>    try {
>        while (count == items.length)
>            notFull.await();  //队列满时阻塞式等待，直到被从同步队列中取出
>        enqueue(e);
>    } finally {
>        lock.unlock();
>    }
> 
> 
> ```
>
> 3. 半阻塞式(超时退出)： 发现队列满后在`nanos`时间内等待，超时退出  
>
>    `offer(E e, long timeout, TimeUnit unit)`
> ```java
> final ReentrantLock lock = this.lock;
>     lock.lockInterruptibly();
>     try {
>         while (count == items.length) {
>             if (nanos <= 0)
>                 return false;
> 
>             //进行等待nanos纳秒  猜测这里nanos会自减--
>             nanos = notFull.awaitNanos(nanos);
>         }
>         enqueue(e);
>         return true;
>     } finally {
>         lock.unlock();
>     }
> 



而对于移除元素的方法也和插入元素类似，同样提供了阻塞式、非阻塞式的方式来执行

- take()
- poll()
- ....









### LinkedBlockingQueue

1.`LinkedBlockingQueue`和`ArrayBlockingQueue`首先最明显的区别就是元素数量：

- `ArrayBlockingQueue`：使用普通的整数(`int count`)来表示元素数量，因为容量是固定的，不涉及动态扩容。

- `LinkedBlockingQueue`：使用`AtomicInteger`来表示元素数量，以确保在并发环境下对元素数量的增减操作是线程安全的，支持动态扩容和缩容

2.其次`ArrayBlockingQueue`在插入元素和移除元素时用到的是同一把锁(类变量: `final ReentrantLock lock`)，而`LinkedBlockingQueue`则用到了两把不同的锁(`putLock`、`getLock`)！！————对应两个CLH队列



类的主要属性有：

```java
/** Current number of elements */
private final AtomicInteger count = new AtomicInteger();

/**
 * Head of linked list.
 * Invariant: head.item == null
 */
transient Node<E> head;

/**
 * Tail of linked list.
 * Invariant: last.next == null
 */
private transient Node<E> last;

/** Lock held by take, poll, etc */
private final ReentrantLock takeLock = new ReentrantLock();

/** Wait queue for waiting takes */
private final Condition notEmpty = takeLock.newCondition();

/** Lock held by put, offer, etc */
private final ReentrantLock putLock = new ReentrantLock();

/** Wait queue for waiting puts */
private final Condition notFull = putLock.newCondition();

```

可以看出与`ArrayBlockingQueue`主要的区别是，`LinkedBlockingQueue`在插入数据和删除数据时分别是由两个不同的lock（`takeLock`和`putLock`）来控制线程安全的，因此，也由这两个lock生成了两个对应的`condition`（`notEmpty`和`notFull`）来实现可阻塞的插入和删除数据。并且，采用了链表的数据结构来实现队列，Node结点的定义为：

```java
static class Node<E> {
    E item;
    Node<E> next;
    Node(E x) { item = x; }
}
```







然后我们再来看看`LinkedBlockingQueue`：

1、容量`Capacity`设置

`LinkedBlockingQueue`的构造函数可以选择是否指定容量，如果**不指定容量，则队列默认为无界队列**，否则为有界队列。在无界队列中，队列可以无限增长，而**有界队列的容量是固定的**

```java
/**
 * Creates a {@code LinkedBlockingQueue} with a capacity of
 * {@link Integer#MAX_VALUE}.
 */
public LinkedBlockingQueue() {
    this(Integer.MAX_VALUE);
}

/**
 * Creates a {@code LinkedBlockingQueue} with the given (fixed) capacity.
 *
 * @param capacity the capacity of this queue
 * @throws IllegalArgumentException if {@code capacity} is not greater
 *         than zero
 */
public LinkedBlockingQueue(int capacity) {
    if (capacity <= 0) throw new IllegalArgumentException();
    this.capacity = capacity;
    last = head = new Node<E>(null);
}
```





2、插入元素：

`put()`：阻塞式插入元素 

```java
public void put(E e) throws InterruptedException {
    if (e == null) throw new NullPointerException();
    // Note: convention in all put/take/etc is to preset local var
    // holding count negative to indicate failure unless set.
    int c = -1;
    Node<E> node = new Node<E>(e);
    final ReentrantLock putLock = this.putLock;
    final AtomicInteger count = this.count;
    putLock.lockInterruptibly();
    try {
        /*
         * Note that count is used in wait guard even though it is
         * not protected by lock. This works because count can
         * only decrease at this point (all other puts are shut
         * out by lock), and we (or some other waiting put) are
         * signalled if it ever changes from capacity. Similarly
         * for all other uses of count in other wait guards.
         */
		//如果队列已满，则阻塞当前线程，将其移入等待队列
        while (count.get() == capacity) {
            notFull.await();
        }
		//入队操作，插入数据
        enqueue(node);
        c = count.getAndIncrement();
		//若队列满足插入数据的条件，则通知被阻塞的生产者线程可以继续插入
        if (c + 1 < capacity)
            notFull.signal();
    } finally {
        putLock.unlock();
    }
    if (c == 0) 
        signalNotEmpty(); //在添加元素后，如果队列之前为空，则唤醒一个等待的消费者线程，让其可以继续执行取出操作
}

```





`offer()`：半阻塞式插入元素，超时退出

```java
public boolean offer(E e, long timeout, TimeUnit unit)
        throws InterruptedException {

        if (e == null) throw new NullPointerException();
        long nanos = unit.toNanos(timeout);
        int c = -1;
        final ReentrantLock putLock = this.putLock;
        final AtomicInteger count = this.count;
        putLock.lockInterruptibly();
        try {
            while (count.get() == capacity) {
                if (nanos <= 0)
                    return false;
                nanos = notFull.awaitNanos(nanos);
            }
            enqueue(new Node<E>(e));
            c = count.getAndIncrement();
            if (c + 1 < capacity)
                notFull.signal(); //通知生产者线程继续插入元素
        } finally {
            putLock.unlock();
        }
        if (c == 0)
            signalNotEmpty();//通知消费者线程可以获取元素了
        return true;
    }
```



3、移除元素：

`take()`：阻塞式取元素，发现队列为空则进入等待队列等待

```java
public E take() throws InterruptedException {
    E x;
    int c = -1;
    final AtomicInteger count = this.count;
    final ReentrantLock takeLock = this.takeLock;
    takeLock.lockInterruptibly();
    try {
		//当前队列为空，则阻塞当前线程，将其移入到等待队列中，直至满足条件
        while (count.get() == 0) {
            notEmpty.await();
        }
		//移除队头元素，获取数据
        x = dequeue();
        c = count.getAndDecrement();
        //如果当前满足移除元素的条件(队列中还有剩余元素)，则通知被阻塞的消费者线程
		if (c > 1)
            notEmpty.signal();
    } finally {
        takeLock.unlock();
    }
    if (c == capacity)
        //在取出元素后，判断队列是否不再满，如果不再满，
        //则唤醒一个等待的生产者线程，让其继续执行添加操作
        signalNotFull();
    return x;
}

```



`poll()`:非阻塞式取元素，发现队列为空则直接退出，不会等待

```java
public E poll() {
    final AtomicInteger count = this.count;
    if (count.get() == 0)
        return null;
    E x = null;
    int c = -1;
    final ReentrantLock takeLock = this.takeLock;
    takeLock.lock();
    try {
        if (count.get() > 0) {
            x = dequeue();
            c = count.getAndDecrement();
            if (c > 1)
                notEmpty.signal();  //
        }
    } finally {
        takeLock.unlock();
    }
    if (c == capacity)
        signalNotFull();
    return x;
}
```



> ArrayBlockingQueue 和 LinkeBlockingQueue 有什么区别？

`ArrayBlockingQueue` 和 `LinkedBlockingQueue` 是 Java 并发包中常用的两种阻塞队列实现，它们都是线程安全的。不过，不过它们之间也存在下面这些区别：

- 底层实现：`ArrayBlockingQueue` 基于数组实现，而 `LinkedBlockingQueue` 基于链表实现。
- 是否有界：`ArrayBlockingQueue` 是有界队列，必须在创建时指定容量大小。`LinkedBlockingQueue` 创建时可以不指定容量大小，默认是`Integer.MAX_VALUE`，也就是无界的。但也可以指定队列大小，从而成为有界的。
- 锁是否分离： **`ArrayBlockingQueue`中的锁是没有分离的，即生产和消费用的是同一个锁；`LinkedBlockingQueue`中的锁是分离的，即生产用的是`putLock`，消费是`takeLock`，这样可以防止生产者和消费者线程之间的锁争夺**。
- 内存占用：`ArrayBlockingQueue` 需要提前分配数组内存，而 `LinkedBlockingQueue` 则是动态分配链表节点内存。这意味着，`ArrayBlockingQueue` 在创建时就会占用一定的内存空间，且往往申请的内存比实际所用的内存更大，而`LinkedBlockingQueue` 则是根据元素的增加而逐渐占用内存空间



最后再介绍一下线程间的等待和唤醒具体的实现：

- 当队列已满时，生产者线程会调用 `notFull.await()` 方法让生产者进行等待，等待队列非满时插入（非满条件）
- 当队列为空时，消费者线程会调用 `notEmpty.await()`方法让消费者进行等待，等待队列非空时消费（非空条件）
- **当有新的元素被添加时，生产者线程会调用 `notEmpty.signal()`方法唤醒正在等待消费的消费者线程**
- **当队列中有元素被取出时，消费者线程会调用 `notFull.signal()`方法唤醒正在等待插入元素的生产者线程**











# JUC

先从全局角度看看Java并发编程：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/juc%E5%B9%B6%E5%8F%91.jpg)





> 实现线程同步的方式主要有以下几种(持续更新)：
>
> 1. join() 、 notify()、notifyAll()
>
> 2. Synchronized
>
> 3. ReentrantLock
>
> 4. CAS Atomic原子类
>
> 5. ThreadLocal
>
> 6. LockSupport类 park()、unpark()
>
> 7. AQS
>
> 8. Condition类 await()、signal()、signalAll()
>
> 
>
> 不可变(Immutable)的对象一定是线程安全的，不需要再采取任何的线程安全保障措施。只要一个不可变的对象被正确地构建出来，永远也不会看到它在多个线程之中处于不一致的状态，不可变的类型有:
>
> - final 关键字修饰的基本数据类型
> - String
> - 枚举类型
> - Number 部分子类，如 Long 和 Double 等数值包装类型，`BigInteger` 和 `BigDecimal` 等大数据类型。但同为 Number 的原子类 `AtomicInteger` 和 `AtomicLong` 则是可变的
>
> 









## 从Java角度理解进程与线程

1. 在java中，当启动 `main()` 函数时其实就是启动了一个 JVM 的进程，而 main 函数所在的线程就是这个进程中的一个线程，也称主线程
2. 一个进程下的多个线程共享进程的**堆**和**方法区(java8后的元空间)**资源，但每个线程有自己的**程序计数器**、**虚拟机栈**和**本地方法栈 **
3. 多个进程间不能共享资源，每个进程有自己的堆、栈、虚存空间（页表）、文件描述符等信息，而线程可以共享进程资源文件（堆和方法区），且线程上下文切换速度很快（线程状态的切换），而进程的上下文切换速度较慢

> 上下文切换方式有：
>
> 
>
> 该线程主动让出CPU，例如调用sleep() 但是`sleep`不释放锁、wait()
>
> 
>
> 其他线程调用`Thread.join()`插队,导致当前线程被迫让出资源
>
> 
>
> 操作系统为了防止一个线程或者进程长时间占用 CPU 导致其他线程或者进程饿死，故采用**时间片轮转调度**的方式，调用了阻塞类型的系统中断
>

4. Java程序天生就是多线程的，**一个 Java 程序的运行是 main 线程和多个其他线程同时运行**

5. 线程共享代码段、数据段、（地址空间）打开的文件资源；但每个线程各自都有一套独立的寄存器和栈，确保线程控制流相对独立；

6. 同一进程内的多个线程都有自己的工作内存，并通过共享内存(`Java Memory Model`)来实现通信

```java
ThreadMXBean threadMXBean = ManagementFactory.getThreadMXBean();
// 不需要获取同步的 monitor 和 synchronizer 信息，仅获取线程和线程堆栈信息
ThreadInfo[] threadInfo
        s = threadMXBean.dumpAllThreads(false, false);
// 遍历线程信息，仅打印线程 ID 和线程名称信息
for (ThreadInfo threadInfo : threadInfos) {
    System.out.println("[" + threadInfo.getThreadId() + "] " + threadInfo.getThreadName());
}

/****************/
[1] main
[2] Reference Handler
[3] Finalizer
[4] Signal Dispatcher
[5] Attach Listener
[13] Common-Cleaner
[14] Monitor Ctrl-Break
[15] Notification Thread
```









## 线程状态与生命周期



![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/640.png)



需要注意以下几点：

1. 线程被创建出来但没有被调用 `start()`时处于`NEW态` 

2. 线程被调用了 `start()`等待运行时进入`RUNNABLE态`，但是`JVM`不严格区分`RUNNING态`和 `READY态`

3. `TIMED_WAITING`(超时等待)状态 相当于在`WAITING状态`的基础上增加了**超时限制**，比如通过 `sleep（long millis）`方法或 `wait（long millis）`方法可以将线程置于 `TIMED_WAITING` 状态，当超时时间结束后，线程将会返回到 `RUNNABLE` 状态

4. 当线程尝试进入`synchronized`方法/块或者被其他线程`notify()`后 重新进入`synchronized` 方法/块时没有抢占到锁，此时该线程就会进入`Blocking`状态(**阻塞态表示线程在等待获取某个锁而被阻塞，或者说等待I/O操作完成**)

5. **`RUNNING` 状态**： 当线程处于 `RUNNING` 状态时，表示该线程正在执行它的代码，占用了 CPU 资源，并在运行中

   **`READY` 状态**： 当线程处于 `READY` 状态时，表示该线程已经准备好运行，但当前并未执行

6. `WAITING` 状态只表示线程正在等待某个条件的发生，不一定涉及锁的释放，而处于阻塞态的线程一定是没有获取到锁的





## 线程创建方式

- 无论是`Runnable`还是`Callable`，它们和线程创建没太大关系，它们是任务类，只有Thread是线程类

  可以将 `Runnable` 或 `Callable` 任务作为 `Thread` 的构造函数参数，从而将任务封装成线程。例如：`new Thread(myRunnable).start()` 或 `new Thread(myCallable).start()`，来看看源码就知道为什么是这样了：

  ```java
  //传入Runnable实例
  public Thread(Runnable target) {
          init(null, target, "Thread-" + nextThreadNum(), 0);
      }
  
  
  //Callable创建线程
  <T> Future<T> submit(Callable<T> task);  //ExecutorService接口的方法
  
  
  //或者将Callable封装为FutureTask ,FutureTask实现了Runnable接口
  public FutureTask(Callable<V> callable) {
          if (callable == null)
              throw new NullPointerException();
          this.callable = callable;
          this.state = NEW;       // ensure visibility of callable
      }
  
  
  //通过Callable创建线程，底层实际上还是start0()方法
  
  Callable<Integer> callable = new MyCallable();
  FutureTask<Integer> futureTask = new FutureTask<>(callable);
  
  Thread thread = new Thread(futureTask);
  ```

  

- JDK那么多类，有且仅有`Thread`类能通过`start0()`方法向操作系统申请线程资源（本地方法）

1、**继承 Thread 类**

通过继承 `Thread` 类，并重写它的 `run` 方法，我们就可以创建一个线程：

```java
public static void main(String[] args) {
	// 第一种
    MyThread myThread = new MyThread();
}

public static class MyThread extends Thread {
    @Override
    public void run() {
        System.out.println("自己实现的run-1");
    }
}
```





2、**实现Runnable接口**

通过实现 `Runnable`接口 ，并重写 `run` 方法，最后将`Runnable`类对象传递给`Thread`类的构造方法，调用`start()`**开启线程**:

```java
public static void main(String[] args) {
	
	MyRunnable runnable2=new MyRunnable();
    MyThread myThread = new MyThread(runnable2);
    myThread.start();
}

public static class MyRunnable implements Runnable {
    @Override
    public void run() {
        System.out.println("自己实现的run-2");
    }
}

//通过Thread类构造函数创建线程
public Thread(Runnable target) {
        this(null, target, "Thread-" + nextThreadNum(), 0);
    }
```

需要注意的是，使用实现`Runnable`接口的方式创建线程可以更加灵活，因为一个类可以实现多个接口，而Java中的类只能继承一个类。此外，使用实现`Runnable`接口的方式可以将线程的任务逻辑与线程的管理逻辑分离开来，方便进行线程的管理和复用

```java
//直接通过Lambda表达式来创建线程比较方便：

Thread t1=new Thread(
    ()->{
        System.out.println("runnable+lambda表达式 来创建线程");
    }
);
```



3、**实现 Callable 接口，并结合 Future 实现**

**`Callable`**接口可以作为任务被线程执行，其与**`Runnable`**接口的区别在于**`Callable`**任务可以有返回值(通过`FutureTask`获取任务执行的返回值**)，而**`Runnable`任务没有返回值：

由于**`Thread`**对象只能执行**`Runnable`**任务，因此无法直接让**`Thread`**执行**`Callable`**任务，但是可以先将**`Callable`**封装成**`FutureTask`**，而**`FutureTask`**是实现了**`Runnable`**接口的，所以**`Thread`**对象可以执行**`FutureTask`**任务，流程如下：

- 首先定义一个 `Callable` 的实现类，并实现 `call` 方法(`call` 方法是带返回值的)
- 然后通过 `FutureTask` 的构造方法，把这个 `Callable` 实现类传进去
- 把 `FutureTask` 作为 `Thread` 类的 `target` ，创建 `Thread` 线程对象
- 通过 `FutureTask` 的 `get` 方法获取线程的执行结果

```java
public class ThirdThreadIntf implements Callable<Integer> {
    int i = 0;
    @Override
    public Integer call() throws Exception {
        for (; i < 20; i++) {
            try {
                Thread.sleep(new Random().nextInt(100));
                System.out.println(Thread.currentThread().getName() + " 循环变量i的值：" + i);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
        System.out.println(Thread.currentThread().getName() + "执行完成");
        return i;
    }

    public static void main(String[] args) {
        Callable a = new ThirdThreadIntf();
        Callable b = new ThirdThreadIntf();
        FutureTask<Integer> task1 = new FutureTask<>(a);
        FutureTask<Integer> task3 = new FutureTask<>(b);
        new Thread(task1, "线程一").start();
        new Thread(task3, "线程三").start();
    }
}
```

注意上个例子中调用的Thread类中构造函数为：

```java
 public Thread(Runnable target, String name) {
        this(null, target, name, 0);
    }
//FutureTask实现了Runnable接口
```





4、**通过线程池来创建线程**

```java
ExecutorService executorService =Executors.newFixedThreadPool(10);
for(int i=0;i<10;i++)
{
    executorService.execute(new Mythread());
}
executorService.shutdown();
```

在线程池中，我们其实是把创建和管理线程的任务都交给了线程池。而创建线程是通过线程工厂类 `DefaultThreadFactory` 来创建的，来看一下这个工厂类的内部实现：

```java
public Thread newThread(Runnable r) {
            Thread t = new Thread(group, r,
                                  namePrefix + threadNumber.getAndIncrement(),
                                  0);
            if (t.isDaemon())
                t.setDaemon(false);
            if (t.getPriority() != Thread.NORM_PRIORITY)
                t.setPriority(Thread.NORM_PRIORITY);
            return t;
        }
```

它会给线程设置一些默认值，如线程名称，线程的优先级，线程组，是否是守护线程等。最后还是通过 `new Thread()` 的方式来创建线程的







## sleep() wait() park()区别

1. **`sleep()` 方法没有释放锁，而 `wait()` 方法释放当前线程所占有的对象锁** ，死锁的例子就是通过让线程1获取到资源1后调用`sleep()`方法(不释放锁)来让线程2获取到资源2，达到死锁条件

   即：`sleep()`让线程休眠指定时间,该线程依然处于运行状态`Running`。`wait()`让线程进入等待队列便处于`Waiting`/`TIME_WAITING`态,释放对象锁

2. `wait()` 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 `notify()`或者 `notifyAll()` 方法。而`sleep(long millis)`方法执行完成后，线程会自动苏醒，或者也可以使用 `wait(long timeout)` 超时后线程会自动苏醒

3. `sleep()` 是 `Thread` 类的静态本地方法，`wait()` 则是 `Object` 类的本地方法,`park()`是`LockSupport`类中调用`UnSafe`类中的`park()`实现的

   ```java
   Thread.sleep(1000);  // 调用时需要使用Thread类 当前线程休眠，但是不释放锁
   
   /*
   wait()方法通常需要由两个线程进行调用:
        一个线程调用object.wait(),进入等待;
        另一个线程调用object.notify()或object.notifyAll(),唤醒正在等待的线程
   */
   
   
   ```

   

4. 每个对象（`Object`）都拥有**对象锁**，既然要释放当前线程占有的对象锁并让其进入 `WAITING` 状态，自然是要操作对应的对象（`Object`）而非当前的线程（`Thread`）；而`sleep()` 是让当前线程暂停执行，不涉及到对象类，也不需要获得对象锁

5. `Thread.sleep()`到时间了会自动唤醒，然后继续执行(必须传入时间参数)

   `Object.wait()`不带时间的，需要另一个线程使用`Object.notify()`唤醒；

   `Object.wait()`带时间的，假如没有被`notify`，到时间了会自动唤醒，这时又分两种情况，一是立即获取到了锁，线程自然会继续执行；二是没有立即获取锁，线程进入同步队列等待获取锁；

6. `Object.wait()/notify()`方法需要在`synchronized`块中执行；`LockSupport.park()`可以在任意地方执行；

7. `park()/unpark()`底层的原理是“二元信号量”，你可以把它想象成只有一个许可证的`Semaphore`，只不过这个信号量在重复执行`unpark()`的时候也不会再增加许可证，最多只有一个许可证

8. 如果在`wait()`之前执行了`notify()`：

   若当前的线程不是此对象锁的所有者，却调用该对象的notify()或wait()方法时抛出IllegalMonitorStateException异常；若当前线程是此对象锁的所有者，wait()将一直阻塞，因为后续将没有其它notify()唤醒它

   如果在park()之前执行了unpark()：

   线程不会被阻塞，直接跳过park()，继续执行后续内容(相当于为该线程多加了一个许可证，且最多只能有一个)

   








## Synchronized

> 前言：
>
> 在java虚拟机中，每个对象和类在逻辑上都是和一个监视器相关联的。
>
> 
>
> 对于对象来说，相关联的监视器保护对象的实例变量。
>
> 对于类来说，监视器保护类的类变量。
>
> 
>
> 类锁实际上用对象锁来实现。当虚拟机装载一个class文件的时候，它就会创建一个java.lang.Class类的实例。当锁住一个对象的时候，实际上锁住的是那个类的Class对象。
>
> 
>
> 一个线程可以多次对同一个对象上锁。对于每一个对象，java虚拟机维护一个加锁计数器，线程每获得一次该对象，计数器就加1，每释放一次，计数器就减 1，当计数器值为0时，锁就被完全释放了。





> 每个实例都对应有自己的一把锁(this),不同实例之间互不影响；
>
> 锁对象是`**.class`以及`synchronized`修饰的是`static`方法的时候，所有对象公用同一把锁
>
> `synchronized`修饰的方法，无论方法正常执行完毕还是抛出异常，都会释放锁



`synchronized` 关键字最主要有以下 3 种应用方式，下面分别介绍：

- 修饰实例方法，作用于当前实例加锁，进入同步代码前要获得当前实例的锁；
- 修饰静态方法，作用于当前类对象加锁，进入同步代码前要获得当前类对象的锁；
- 修饰代码块，则需要指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。











### 对象锁

1. 手动指定锁的对象(可以是this,可以是自定义Object)



```java
public class SynchronizedObjectLock implements Runnable {
    static SynchronizedObjectLock instance = new SynchronizedObjectLock();

    @Override
    public void run() {
        // 同步代码块形式——锁为this，t1、t2都源自于instance对象，故是同一把锁
        synchronized (this) {
            System.out.println("我是线程" + Thread.currentThread().getName());
            try {
                Thread.sleep(3000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            System.out.println(Thread.currentThread().getName() + "结束");
        }
    }

    public static void main(String[] args) {
        Thread t1 = new Thread(instance);  //传入runnable实例
        Thread t2 = new Thread(instance);
        
        //两个线程都在竞争instance的对象锁
        t1.start();
        t2.start();
    }
}

//输出结果为：
我是线程Thread-0
Thread-0结束
我是线程Thread-1
Thread-1结束
```

可以看出：

1. 两个线程使用的锁是一样的(都在竞争`instance`的对象锁),线程t2必须要等到线程t1释放了该锁后才能继续执行
2. 一个对象只有一把锁，当一个线程获取了该对象的锁之后，其他线程无法获取该对象的锁，所以无法访问该对象的其他 `synchronized` 实例方法，但是其他线程还是可以访问该实例对象的其他非 `synchronized` 方法。



但是一个线程 A 需要访问实例对象 obj1 的 synchronized 方法 f1(当前对象锁是 obj1)，另一个线程 B 需要访问实例对象 obj2 的 synchronized 方法 f2(当前对象锁是 obj2)，这样是允许的：

```java
public class AccountingSyncBad implements Runnable {
    //共享资源(临界资源)
    static int i = 0;
    // synchronized 修饰实例方法
    public synchronized void increase() {
        i ++;
    }
    @Override
    public void run() {
        for(int j=0;j<1000000;j++){
            increase();
        }
    }
    public static void main(String args[]) throws InterruptedException {
        // new 两个AccountingSync新实例
        Thread t1 = new Thread(new AccountingSyncBad());
        Thread t2 = new Thread(new AccountingSyncBad());
        t1.start();
        t2.start();
        t1.join();
        t2.join();
        System.out.println("static, i output:" + i);
    }
}
/**
 * 输出结果:
 * static, i output:1224617
 */
```

上述代码虽然我们使用 `synchronized` 修饰了 `increase` 方法，但却 new 了两个不同的实例对象，这也就意味着存在着两个不同的实例对象锁，因此 t1 和 t2 都会进入各自的对象锁，也就是说 t1 和 t2 线程使用的是不同的锁，因此线程安全是无法保证的

> 每个对象都有一个对象锁，不同的对象，他们的锁不会互相影响。

解决这种困境的的方式是将 `synchronized` 作用于静态的 `increase` 方法，这样的话，对象锁就当前类对象(`AccountingSyncBad`类)，由于无论创建多少个实例对象，但对于的类对象拥有只有一个，所有在这样的情况下对象锁就是唯一的。





例二

```java
public class JUC implements Runnable {
    static JUC instance = new JUC();
    // 创建2把锁
    Object block1 = new Object();
    Object block2 = new Object();

    @Override
    public void run() {
        // 这个代码块使用的是第一把锁，当他释放后，后面的代码块由于使用的是第二把锁，因此可以马上执行
        synchronized (block1) {
            System.out.println("线程 " + Thread.currentThread().getName()+" 获取到了block1的对象锁");
            try {
                Thread.sleep(10000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            System.out.println("线程 "+Thread.currentThread().getName() + "释放了block1对象锁");
        }

        synchronized (block2) {
            System.out.println("线程 " + Thread.currentThread().getName()+" 获取到了block2的对象锁");
            try {
                Thread.sleep(3000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            System.out.println("线程 "+Thread.currentThread().getName() + "释放了block2对象锁");
        }
    }

    public static void main(String[] args) {
        Thread t1 = new Thread(instance);
        Thread t2 = new Thread(instance);
        t1.start();
        t2.start();
    }
}

//输出结果为：
线程 Thread-0 获取到了block1的对象锁
线程 Thread-0释放了block1对象锁
线程 Thread-1 获取到了block1的对象锁
线程 Thread-0 获取到了block2的对象锁
线程 Thread-0释放了block2对象锁
线程 Thread-1释放了block1对象锁
线程 Thread-1 获取到了block2的对象锁
线程 Thread-1释放了block2对象锁
```



首先线程t1获取到`block1`对象锁，然后执行`Thread.sleep(10000);`在线程t1休眠的过程中（`sleep()`不释放锁），线程t2也被创建也要去抢占`block1`的对象锁，所以t2陷入阻塞。**在t1结束休眠并释放`block1`的锁后，t2立马获取到`block1`的对象锁，同时t1也立刻获取到`block2`的对象锁**，两个线程此时在并行执行，后面t1再次进入休眠态，如果此时t2释放掉`block1`对象锁并要立刻获取`block2`的对象锁时则会再次进入阻塞态，最终t1释放block2对象锁，t2获取到该锁后执行之后的逻辑



至于类锁这里就不再赘述：

```java

//锁静态方法
synchronized static void method() {
    //业务代码
}



//锁类的实例对象
public class Task {
 public void method2()
 {
     synchronized (Task.class){
       //业务逻辑
     }
 }
}
```



### Synchronized 禁止指令重排

```java
class MonitorExample {
    int a = 0;
    public synchronized void writer() {  //1
        a++;                             //2
    }                                    //3
    public synchronized void reader() {  //4
        int i = a;                       //5
        //……
    }                                    //6
}
```

假设线程 A 执行 writer()方法，随后线程 B 执行 reader()方法。根据 happens before 规则，这个过程包含的 happens before 关系可以分为两类：

- 根据程序次序规则，1 happens before 2, 2 happens before 3; 4 happens before 5, 5 happens before 6。
- 根据监视器锁规则，3 happens before 4。
- 根据 happens before 的传递性，2 happens before 5。

在线程 A 释放了锁之后，随后线程 B 获取同一个锁。在上图中，2 happens before 5。因此，线程 A 在释放锁之前所有可见的共享变量，在线程 B 获取同一个锁之后，将立刻变得对 B 线程可见





### Monitor

使用`synchronized{}`代码块或者`synchronized()`方法相当于标志了一个监视区域(Monitor)。当每次进入一个监视区域时，java 虚拟机都会自动锁上对象或者类，在HotSpot JVM实现中，**锁有个专门的名字：对象监视器（Object Monitor）**，**Monitor（监视器锁）**本质是依赖于底层的操作系统的 `Mutex Lock`（互斥锁）来实现的。`Mutex Lock` 的切换需要从用户态转换到核心态中，因此状态转换需要耗费很多的处理器时间。所以在早期的JAVA版本里`Synchronized`是一个耗费资源的重量级操作





1、作用在对象上(包括类class和类的对象实例)：

再来分析一下`Synchronized`的底层原理，任何一个对象都有一个`Monitor`与之关联，当一个`Monitor`被持有后，它将处于被锁定状态，给定以下代码：

```java
public class SynchronizedDemo {
    public void method() {
        synchronized (this) {
            System.out.println("synchronized 代码块");
        }
    }
}

```

通过java反编译可以得出：`synchronized` **同步语句块**的实现使用的是 `monitorenter` 和 `monitorexit` 指令，其中 `monitorenter` 指令指向同步代码块的开始位置，`monitorexit` 指令则指明同步代码块的结束位置,当执行至`monitorenter` 指令时，线程试图获取锁也就是获取**对象监视器 `monitor`** 的持有权，**即在执行`monitorenter`时，线程会尝试获取对象的锁**，如果锁的计数器为 0 则表示锁可以被获取，获取后将锁计数器设为 1 也就是加 1，**拥有者该对象锁的线程才可以执行 `monitorexit` 指令来释放锁**。在执行 `monitorexit` 指令后，将锁计数器设为 0，表明锁被释放，其他线程可以尝试获取锁





`monitorenter指令`：当一个线程在尝试获得与这个对象相关联的`Monitor`的所有权时，会触发`monitorenter`指令，此时可能发生以下3种情况

- monitor计数器为0，意味着目前该对象的monitor锁还没有被获得，那这个**线程就会立刻获取该锁然后把锁计数器+1**，一旦+1，别的线程再想获取，就需要等待；
- 如果这个monitor已经拿到了这个锁的所有权，又**重入**了这把锁，那锁计数器就会累加，变成2，并且随着重入的次数，会一直累加；
- 这把锁已经被别的线程获取了，等待锁释放,同时该线程进入同步队列等待，变为阻塞态

`monitorexit指令`：会释放对于该monitor锁的所有权，释放过程很简单，就是将`monitor`的计数器减1，如果减完以后，计数器不是0，则代表刚才是重入进来的，当前线程还继续持有这把锁的所有权，如果计数器变成0，则代表当前线程不再拥有该`monitor`的所有权，就会释放锁



任意线程使用`synchronized`对一个`Object`的访问，首先要获得该`Object`的`monitor`，如果获取失败，该线程就进入同步队列`SynchronizedQueue`，线程状态变为`BLOCKED`阻塞态，当`Object`的`monitor`被占有者线程释放后，在同步队列中的线程就会重新抢占获取该对象的`monitor`锁：

```java
synchronized(Object){
//业务逻辑
}
```

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/synchronized.png)





2、作用在方法上

而如果`synchronized`直接作用在方法而不是`Object`上，例如下面这段代码：

```java
public class SynchronizedDemo2 {
    public synchronized void synMethod() {
        System.out.println("synchronized 方法");
    }
}
```

对应的反汇编指令如下所示:

> Java反汇编是针对Java字节码(.class文件)进行的。它通过分析字节码指令,反编译(Re-compile)出大致等价的Java源码

```java
  public synchronized void synMethod();

    descriptor: ()V

    flags: ACC_PUBLIC, ACC_SYNCHRONIZED

    Code:

      stack=0, locals=1, args_size=1

         0: return

      LineNumberTable:

        line 16: 0
```

可以看出，被`synchronized`修饰的方法会有一个 `ACC_SYNCHRONIZED` 标志,该标识指明了该方法是一个同步方法。JVM 通过该 `ACC_SYNCHRONIZED` 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。如果该方法是实例方法，JVM会尝试获取实例对象的锁。如果是静态方法，JVM则会尝试获取当前`class类`的锁



**锁竞争发生在运行阶段,而与类加载和编译无关。具体来说:**

在使用`synchronized`关键字修饰方法或代码块时,会设置`ACC_SYNCHRONIZED`标志。

但是,设置这个标志本身不会产生任何锁竞争。`ACC_SYNCHRONIZED`仅是一个用于JVM识别的标志。

锁竞争发生在多个线程试图访问同一块`synchronized`代码时。此时,多个线程会竞争同一把锁。

例如：

```java
public class Example {
    public synchronized void method() { ... }
}
```

在编译和类加载阶段,仅仅识别到`Example`类使用了`synchronized`,并会设置`ACC_SYNCHRONIZED`标志。此时还没有锁竞争。

> JVM本身包含了编译器(`Compiler`)和类加载器(`ClassLoader`)两个重要组成部分
>
> - 编译器(`Compiler`):JVM内置了一套Java字节码编译器,用于即时编译(*Just-In-Time,JIT*)
> - 类加载器(`ClassLoader`):类加载器负责读取class文件,并加载到JVM中,以完成类的初始化

但当使用`Example`类的多个线程调用method()方法时,这些线程就会试图获取method()方法的锁。此时才会发生真正的锁竞争。所以,总的来说:

- 加锁发生在使用`synchronized`关键字时。
- 设置`ACC_SYNCHRONIZED`标志仅是为了让JVM识别`synchronized`。
- 真正的锁竞争发生在运行阶段,当多个线程同时试图获取同一把锁时。
- 因此,锁竞争的产生和`ACC_SYNCHRONIZED`标志`setting`本身无关,它完全取决于代码的执行。



**总结：**

`synchronized` 同步语句块的实现使用的是 `monitorenter` 和 `monitorexit` 指令，其中 `monitorenter` 指令指向同步代码块的开始位置，`monitorexit` 指令则指明同步代码块的结束位置

`synchronized` 修饰的方法并没有 `monitorenter` 指令和 `monitorexit` 指令，取得代之的确实是 `ACC_SYNCHRONIZED` 标识，该标识指明了该方法是一个同步方法

**不过两者的本质都是对对象监视器 monitor 的获取**







### 可重入原理

**可重入锁**：又名递归锁，是指在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁（**前提锁对象要是同一个对象或者class**），不会因为之前已经获取过还没释放而阻塞。

**例子：**

```java
public class SynchronizedDemo {

    public static void main(String[] args) {
        SynchronizedDemo demo =  new SynchronizedDemo();
        
        demo.method1();
        //多线程执行时会竞争demo实例的对象锁，竞争到后不断重入，计数器+1
    }

    private synchronized void method1() {
        System.out.println(Thread.currentThread().getId() + ": method1()");
        method2();
    }

    private synchronized void method2() {
        System.out.println(Thread.currentThread().getId()+ ": method2()");
        method3();
    }

    private synchronized void method3() {
        System.out.println(Thread.currentThread().getId()+ ": method3()");
    }
}
```



结合前文中加锁和释放锁的原理，不难理解：

- 执行`monitorenter`获取锁 
  - （monitor计数器=0，可获取锁）
  - 执行method1()方法，monitor计数器+1 -> 1 （获取到锁）
  - 执行method2()方法，monitor计数器+1 -> 2
  - 执行method3()方法，monitor计数器+1 -> 3
- 执行`monitorexit`命令释放锁
  - method3()方法执行完，monitor计数器-1 -> 2
  - method2()方法执行完，monitor计数器-1 -> 1
  - method2()方法执行完，monitor计数器-1 -> 0 （释放了锁）
  - （monitor计数器=0，锁被释放了）

这就是`synchronized`的重入性，即在**同一锁程**中，每个对象拥有一个`monitor`计数器，当线程获取该对象锁（`synchronized`修饰的是**实例方法非静态方法**，故获取的是**对象锁**）后，`monitor`计数器就会加一，释放锁后就会将`monitor`计数器减一，线程不需要再次获取同一把锁







### 锁优化与改进(必看👀)



在JVM中`monitorenter`和`monitorexit`字节码依赖于底层的操作系统的`Mutex Lock`来实现的，但是由于使用`Mutex Lock`需要将当前线程挂起并从用户态切换到内核态来执行，这种切换的代价是非常昂贵的；然而在现实中的大部分情况下，同步方法是运行在单线程环境(无锁竞争环境)如果每次都调用`Mutex Lock`那么将严重的影响程序的性能。**不过在jdk1.6中对锁的实现引入了大量的优化，如锁粗化(Lock Coarsening)、锁消除(Lock Elimination)、轻量级锁(Lightweight Locking)、偏向锁(Biased Locking)、适应性自旋(Adaptive Spinning)等技术来减少锁操作的开销**

- `锁粗化(Lock Coarsening)`：也就是**减少不必要的紧连在一起的unlock，lock操作**，**将多个连续的锁扩展成一个范围更大的锁**
- `锁消除(Lock Elimination)`：通过运行时JIT编译器的**逃逸分析(**当JVM分析到一个`synchronized`方法中不存在共享数据时,它可以消除方法内部对锁的使用。这可以使得该方法即使被多个线程调用,也不需要进行同步,从而提高效率。)来消除锁保护，通过逃逸分析也可以在本线程的`Stack`上进行对象空间的分配，减少Heap上的垃圾收集开销(即判断对象是否逃逸出当前作用域。如果没有逃逸直接在栈上分配)
- `轻量级锁(Lightweight Locking)`：这种锁实现的背后基于这样一种假设，即在真实的情况下我们程序中的大部分同步代码一般都处于无锁竞争状态(即单线程执行环境)，在无锁竞争的情况下完全可以避免调用操作系统层面的重量级互斥锁，取而代之的是在`monitorenter`和`monitorexit`中只需要依靠一条CAS原子指令就可以完成锁的获取及释放。当存在锁竞争的情况下，执行CAS指令失败的线程将调用操作系统互斥锁进入到阻塞状态，当锁被释放的时候被唤醒(具体处理步骤下面详细讨论)。
- `偏向锁(Biased Locking)`：是为了在无锁竞争的情况下避免在锁获取过程中执行不必要的CAS原子指令，因为CAS原子指令虽然相对于重量级锁来说开销比较小但还是存在非常可观的本地延迟。
- `适应性自旋(Adaptive Spinning)`：当线程在获取轻量级锁的过程中执行CAS操作失败时，在进入与monitor相关联的操作系统重量级锁(mutex semaphore)前会进入忙等待(Spinning)然后再次尝试，当尝试一定的次数后如果仍然没有成功则调用与该monitor关联的semaphore(即互斥锁)进入到阻塞状态





#### **自旋锁** 

自旋锁的核心就是让线程不进入`BLOCKED`态，一直处于`Runnable`态不断尝试

共享数据的锁定状态只会持续很短的一段时间，为了这段时间去**挂起和回复阻塞线程**并不值得。在如今多处理器环境下，完全可以让另一个没有获取到锁的线程在门外等待一会(**自旋**)，但**不放弃CPU的执行时间(即线程不进入BLOCKED态)**。为了让线程等待，我们只需要让线程执行一个忙循环(自旋)，这便是自旋锁的由来

自旋锁本质上与阻塞并不相同，先不考虑其对多处理器的要求，如果锁占用的时间非常的短，那么自旋锁的性能会非常的好，如果锁被占用时间较长时，其会带来更多的性能开销(因为**在线程自旋时，始终会占用CPU的时间片，如果锁占用的时间太长，那么自旋的线程会白白消耗掉CPU资源**)。因此自旋等待的时间必须要有一定的限度，如果自旋超过了限定的次数仍然没有成功获取到锁，就应该使用传统的方式去**挂起线程**了，在JDK定义中，自旋锁默认的自旋次数为10次，用户可以使用参数`-XX:PreBlockSpin`来更改



**自适应自旋锁：**

JDK 1.6中引入了自适应自旋锁。这就意味着自旋的时间不再固定了，而是由前一次在同一个锁上的该线程的自旋时间以及锁的拥有者的状态来决定的：

(1)如果在同一个锁对象上，自旋等待次数达到上限，但是该线程刚刚成功通过自旋获取过该对象锁，并且持有锁的线程正在运行中，那么JVM会认为该线程此时继续自旋获取到锁的可能性很大，会自动增加等待时间；比如增加到100次循环。

(2)相反，如果对于某个锁，自旋很少成功获取锁。那再以后要获取这个锁时将可能省略掉自旋过程，以避免浪费处理器资源。有了自适应自旋，JVM对程序的锁的状态预测会越来越准确





#### **锁消除**

锁消除是指虚拟机的JIT即时编译器在运行时，对一些**代码上声明了同步操作，但是被检测到不可能存在共享数据竞争的锁进行消除**

锁消除的主要判定依据来源于**逃逸分析**的数据支持。意思就是：JVM会判断在一段程序中声明的同步操作，**如果该操作明显不会逃逸出去从而被其他线程访问到，那JVM就把它们当作栈上数据对待，认为这些数据是线程独有的，不需要加同步**。此时就会进行锁消除

例如 `StringBuffer`类中的`append()`：

```java
@Override
public synchronized StringBuffer append(String str) {
    toStringCache = null;
    super.append(str);
    return this;
}
```

从源码中可以看出，`append()`方法用了`synchronized`关键字，它是线程安全的，但我们可能仅在线程内部把`StringBuffer`当作局部变量使用：

```java
public class LockClear {

    public static void main(String[] args) {
        LockClear test = new LockClear();
        for (int i = 0; i < 100; i++) {
            test.append("aaa", "bbb");
        }
    }
    public void appendString(String str1, String str2) {
        StringBuffer stringBuffer = new StringBuffer();
        stringBuffer.append(str1).append(str2);
    }
}

```

代码中`stringBuffer`方法中的局部变量`stringBuffer`，就只在该方法内的作用域有效，不同线程同时调用`stringBuffer`方法时，都会创建不同的`stringBuffer`对象放在自己栈内的局部变量表中，因此此时的`append()`方法若使用同步操作，就是白白浪费的系统资源，JVM判断该段代码并不会逃逸(`逃逸分析`)，则将该代码带默认为线程独有的资源，并不需要同步，所以执行了锁消除操作，上述代码使用`javap -v LockClear.class ` 反解析字节码文件的结果如下：











#### 锁粗化

如果存在连串的一系列操作都对同一个对象反复加锁和解锁，甚至加锁操作时出现在循环体中，那即使没有线程竞争，频繁的进行互斥同步操作也会导致不必要的性能操作，此时jvm在解析代码后就会自动进行锁消除优化:

```JAVA
public static String test04(String s1, String s2, String s3) {
    StringBuffer sb = new StringBuffer();
    sb.append(s1);
    sb.append(s2);
    sb.append(s3);
    return sb.toString();
}

```

上述的连续`append()`操作中就属于这类情况。JVM会检测到这样一连串的操作都是对同一个对象加锁，那么JVM会将加锁同步的范围扩展(粗化)到整个一系列操作的外部，使整个一连串的`append()`操作只需要加锁一次就可以了:**即在第一次append方法时进行加锁，最后一次append方法结束后进行解锁**









#### 锁状态——MarkWord

Java 6 为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁“。在Java 6 以前，所有的锁都是”重量级“锁。所以在Java 6 及其以后，一个对象其实有四种锁状态，它们级别由低到高依次是：

1. 无锁状态
2. 偏向锁状态
3. 轻量级锁状态
4. 重量级锁状态

无锁就是没有对资源进行锁定，任何线程都可以尝试去修改它，无锁在这里不再细讲。

几种锁会随着竞争情况逐渐升级，锁的升级很容易发生，但是锁降级发生的条件会比较苛刻，锁降级发生在`Stop The World`期间，当JVM进入安全点的时候，会检查是否有闲置的锁，然后进行降级。

> 关于锁降级有两点说明：
>
> 1.不同于大部分文章说锁不能降级，实际上HotSpot JVM 是支持锁降级的，文末有链接。
>
> 2.上面提到的Stop The World期间，以及安全点，这些知识是属于JVM的知识范畴，本文不做细讲。



| 锁       | 优点                                                         | 缺点                                                         | 使用场景                           |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ---------------------------------- |
| 偏向锁   | 加锁和解锁不需要CAS操作，没有额外的性能消耗，和执行非同步方法相比仅存在纳秒级的差距 | 如果线程间存在锁竞争，会带来额外的锁撤销的消耗               | 适用于只有一个线程访问同步块的场景 |
| 轻量级锁 | 竞争的线程不会阻塞，提高了响应速度                           | 如线程始终得不到锁竞争的线程，使用自旋会消耗CPU性能          | 追求响应时间，同步块执行速度非常快 |
| 重量级锁 | 线程竞争不适用自旋，不会消耗CPU                              | 线程阻塞，响应时间缓慢，在多线程下，频繁的获取释放锁，会带来巨大的性能消耗 | 追求吞吐量，同步块执行速度较长     |



JDK 1.6之后引入了轻量级锁，需要注意的是**轻量级锁并不是替代重量级锁**的，而是对在大多数情况下同步块并不会有竞争出现提出的一种优化。它可以减少重量级锁对线程的阻塞带来的线程开销。从而提高并发性能

在JDK 1.6之前,`synchronized`只有传统的锁机制，直接关联到`monitor`对象，存在性能上的瓶颈。在JDK 1.6后，为了提高锁的获取与释放效率，JVM引入了两种锁机制：偏向锁和轻量级锁。它们的引入是为了解决在没有多线程竞争或基本没有竞争的场景下因使用传统锁机制带来的性能开销问题。这几种锁的实现和转换正是依靠对象头中的`Mark Word`:

在 JVM 中，对象在内存中分为三块区域：

- 对象头：由`Mark Word`和`Class Metadata Address`构成

  - **Class Metadata Address**（类型指针）：对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。

  - **Mark Word**（标记字段）：用于存储对象自身的运行时数据，例如存储对象的`HashCode`，分代年龄、**锁标志位**等信息，这个标志位则是`synchronized`实现轻量级锁和偏向锁的关键。 64位JVM的Mark Word组成如下：


![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/markword.png)

- 实例数据：这部分主要是存放类的数据信息，父类的信息。

- 字节对齐：为了内存的IO性能，JVM要求对象起始地址必须是8字节的整数倍。对于不对齐的对象，需要填充数据进行对齐



可以看到，当对象状态为偏向锁时，`Mark Word`存储的是偏向的线程ID；当状态为轻量级锁时，`Mark Word`存储的是指向线程栈中`Lock Record`的指针；当状态为重量级锁时，`Mark Word`为指向堆中的`monitor`对象的指针(此时才升级为老版的`monitor`重量级锁) :imp:







多线程下 `synchronized` 的加锁就是**对同一个对象的对象头中的 `MarkWord` 中的变量进行CAS操作**

在线程执行同步块之前，JVM会先在当前线程的栈帧中创建一个名为锁记录(`Lock Record`)的空间，用于存储锁对象目前的`Mark Word`的拷贝,如果当前对象没有被锁定，那么锁标志位为**01**状态，JVM在执行当前线程时，首先会在当前线程栈帧中创建锁记录`Lock Record`的空间用于存储锁对象目前的`Mark Word`的拷贝, 然后，虚拟机使用`CAS`操作将标记字段`Mark Word`拷贝到锁记录中，并且将`Mark Word`更新为指向当前线程栈帧中`Lock Record`的指针。如果更新成功了，那么这个线程就拥用了该对象的锁，并且对象`Mark Word`的锁标志位更新为(`Mark Word`中最后的2bit)00，即表示此对象处于轻量级锁定状态:

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/java-thread-x-key-schronized-6.png)

如果这个更新操作失败，JVM会检查当前的`Mark Word`中是否存在指向当前线程的栈帧的指针，如果有，说明该锁已经被获取，可以直接调用。如果没有，则说明该锁被其他线程抢占了，如果有两条以上的线程竞争同一个锁，那轻量级锁就不再有效，直接膨胀为重量级锁，没有获得锁的线程会被阻塞。此时，锁的标志位为`10 ， Mark Word`中存储的指向重量级锁的指针

 轻量级解锁时，会使用原子的CAS操作将`Displaced Mark Word`替换回到对象头中，如果成功，则表示没有发生竞争关系。如果失败，表示当前锁存在竞争关系，那么锁就会膨胀成重量级锁。







#### 偏向锁



> Hotspot的作者经过以往的研究发现大多数情况下**锁不仅不存在多线程竞争，而且总是由同一线程多次获得**，于是引入了偏向锁



一个线程在第一次进入同步块时，会在对象头和栈帧中的锁记录`Lock Record`里存储锁的偏向的线程ID。当下次该线程进入这个同步块时，会**去检查该对象的`Mark Word`里面是不是放的自己的线程ID**

如果是，表明该线程已经获得了锁(**说明该对象没有被其他线程所使用过**)，以后该线程在进入和退出同步块时不需要花费CAS操作来加锁和解锁 ；如果不是，就代表有另一个线程来竞争这个偏向锁。这个时候会尝试使用CAS来替换`Mark Word`里面的线程ID为新线程的ID，这个时候要分两种情况：

- 成功，表示之前的线程不存在了，Mark Word里面的线程ID为新线程的ID，锁不会升级，仍然为偏向锁；
- 失败，表示之前的线程仍然存在，那么暂停之前的线程，设置偏向锁标识为0，并设置锁标志位为00，升级为轻量级锁，会按照轻量级锁的方式进行竞争锁

**偏向锁的加锁：**

1. 偏向锁标志是未偏向状态，线程会使用 `CAS` 将 `MarkWord` 中的线程ID设置为自己的线程ID，
   1. 如果成功，则获取偏向锁成功
   2. 如果失败，说明存在竞争，则进行锁升级
2. 偏向锁标志是已偏向状态：
   1. `MarkWord` 中的线程 ID 是自己的线程 ID，成功获取锁
   2. `MarkWord` 中的线程 ID 不是自己的线程 ID，需要进行锁升级





#### 轻量级锁

多个线程在不同时段获取同一把锁，即不存在锁竞争的情况，也就没有线程阻塞。针对这种情况，JVM采用轻量级锁来避免线程的阻塞与唤醒

JVM会为每个线程在当前线程的栈帧中创建用于存储锁记录的空间，我们称为Displaced Mark Word。如果一个线程获得锁的时候发现是轻量级锁，会把锁的Mark Word复制到自己的Displaced Mark Word里面。

然后线程尝试用CAS**将 Mark Word中的内容 替换为指向自己线程`Lock Record`的指针。**如果成功，当前线程获得锁，如果失败，表示 `Mark Word` 已经被替换成了其他线程的锁记录，说明在与其它线程竞争锁，当前线程就尝试使用自旋来获取锁

> 自旋：不断尝试去获取锁，一般用循环来实现。

自旋是需要消耗CPU的，如果一直获取不到锁的话，那该线程就一直处在自旋状态，白白浪费CPU资源。解决这个问题最简单的办法就是指定自旋的次数，例如让其循环10次，如果还没获取到锁就进入阻塞状态。

但是JDK采用了更聪明的方式——**适应性自旋**，简单来说就是线程如果自旋成功了，则下次自旋的次数会更多，如果自旋失败了，则自旋的次数就会减少。

自旋也不是一直进行下去的，如果自旋到一定程度（和JVM、操作系统相关），依然没有获取到锁，称为自旋失败，那么这个线程会阻塞。同时这个锁就会**升级成重量级锁**



#### 总结

 `synchronized`锁升级的顺序为：偏向锁->轻量级锁->重量级锁(Monitor)，每一步触发锁升级的情况如下：

**偏向锁**

在 JDK1.8 中，`synchronized`默认是轻量级锁，但如果设定了 -XX:BiasedLockingStartupDelay = 0 ，那在对一个 Object 做 `synchronized` 的时候，会立即上一把偏向锁。当处于偏向锁状态时， `markword` 会记录当前线程 ID 

**升级到轻量级锁**

当下一个线程参与到偏向锁竞争时，会先**判断 `markword` 中保存的线程 ID 是否与这个线程 ID 相等**，如果不相等，会立即撤销偏向锁，升级为轻量级锁。每个线程在自己的jvm栈中生成一个 `LockRecord` ( LR )，**然后每个线程通过 CAS (自旋)的操作将锁对象头中的 `markword` 设置为指向自己的 LR 的指针，哪个线程设置成功，就意味着获得锁。**



**升级到重量级锁**

如果锁竞争加剧(如线程自旋次数或者自旋的线程数超过某阈值， JDK1.6 之后，由 JVM 自己控制该规则)，就会升级为重量级锁。此时就会向操作系统申请资源，线程挂起，进入到操作系统内核态的等待队列中，等待操作系统调度，然后映射回用户态。在重量级锁中，由于需要做内核态到用户态的转换，而这个过程中需要消耗较多时间，也就是"重"的原因之一





沉默王二上对锁升级流程的总结：



每一个线程在准备获取共享资源时： 第一步，检查`MarkWord`里面是不是放的自己的`ThreadId` ,如果是，表示当前线程是处于 “偏向锁” 

第二步，如果`MarkWord`不是自己的`ThreadId`，锁升级，这时候，用CAS来执行切换，新的线程根据`MarkWord`里面现有的`ThreadId`，通知之前线程暂停，之前线程将Markword的内容置为空。

第三步，两个线程都把锁对象的`HashCode`复制到自己新建的用于存储锁的记录空间，接着开始通过CAS操作， 把锁对象的`MarKword`的内容修改为自己新建的记录空间LockRecord的地址的方式竞争`MarkWord`

第四步，第三步中成功执行CAS的获得资源，失败的则进入自旋 (成功拿到轻量级锁)

第五步，自旋的线程在自旋过程中，成功获得资源(即之前获的资源的线程执行完成并释放了共享资源)，则整个状态依然处于 轻量级锁的状态，如果自旋失败 。

第六步，进入重量级锁的状态，这个时候，自旋的线程进行阻塞，等待之前线程执行完成并唤醒自己。













## Volatile



 **volatile的实现原理：**

- **通过对OpenJDK中的unsafe.cpp源码的分析，会发现被volatile关键字修饰的变量会存在一个“lock:”的前缀。**

- *Lock前缀，Lock不是一种内存屏障，但是它能完成类似内存屏障的功能。Lock会对CPU总线和高速缓存加锁，可以理解为CPU指令级的一种锁。*

- 在具体的执行上，**它先对总线和缓存加锁**，然后**执行后面的指令**，在**Lock锁住总线**的时候，其他CPU的读写请求都会**被阻塞**，**直到锁释放**。最后**释放锁后**会把高速缓存中的脏数据全部**刷新回主内存**，且这个**写回内存的操作**会使在其他CPU核心里**缓存了该地址的数据无效**，强制从主存中重新读取到各自的高速缓存中。

  

- 用`volatile`关键字修饰变量可以解决上述问题，**那么`volatile`是如何做到这一点的呢？那就是内存屏障**，**内存屏障是硬件层的概念**，不同的硬件平台实现内存屏障的手段并不是一样，java通过屏蔽这些差异，**统一由jvm来生成内存屏障的指令**，**Lock是软件指令。**





### Happens-Before原则

**happens-before 原则** 想表达的意义是前一个操作的结果对于后一个操作是可见的，**无论这两个操作是否在同一个线程里**，例如`操作 1 happens-before 操作 2`，即使操作 1 和操作 2 不在同一个线程内，JMM 也会保证操作 1 的结果对操作 2 **是可见的**，且如果两个操作不满足任意一个 `happens-before` 规则，那么这两个操作就没有顺序的保障，JVM 可以对这两个操作进行重排序,常见的`happens-before`原则有以下几条：

(1) 单一线程原则:在一个线程内，在程序前面的操作先行发生于后面的操作

(2) 管程锁定规则: 一个 `unlock` 操作先行发生于后面对**同一个锁**的 `lock` 操作

(3) volatile 变量规则:对一个 `volatile` 变量的写操作先行发生于后面对这个变量的读操作,就是对 `volatile` 变量的写操作的结果对于发生于其后的任何操作都是可见的

(4) 线程启动规则:Thread 对象的 `start()` 方法调用先行发生于此线程的每一个动作 



```java
//假设线程A执行writer方法，线程B执行reader方法
class VolatileExample {
    int a = 0;
    volatile boolean flag = false;
    
    public void writer() {
        a = 1;              // 1 线程A修改共享变量
        flag = true;        // 2 线程A写volatile变量
    } 
    
    public void reader() {
        if (flag) {         // 3 线程B读同一个volatile变量
        int i = a;          // 4 线程B读共享变量
        ……
        }
    }
}
```

根据 happens-before 规则，上面过程会建立 3 类 happens-before 关系:

- 根据程序次序规则 1 happens-before 2 且 3 happens-before 4
- **根据 volatile 规则 2 happens-before 3**
- 根据 happens-before 的传递性规则 1 happens-before 4





### 可见性

可见性即一个线程对共享变量(**如果是方法内部的局部变量，不存在线程安全问题，因为每个线程位于栈内的局部变量表都是私有的！**)的修改后，另外一个线程能够立刻看到,可见性问题主要是因为CPU高速缓存`cache`与主存中的值不一致，当一个共享变量被`volatile`修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值，而**普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的**，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性

单核CPU不存在可见性问题！

**在单核时代，所有的线程都是在一颗CPU上执行，CPU缓存与内存的数据一致性容易解决**,**所有线程都是操作同一个CPU的缓存，一个线程对缓存的写，对另外一个线程来说一定是可见的**,例如下图中，线程A和线程B都是操作同一个CPU里面的缓存，所以线程A更新了变量V的值，那么线程B之后再访问变量V，得到的一定是V的最新值（线程A写过的值）:

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E5%8F%AF%E8%A7%81%E6%80%A7.jpg" style="zoom: 80%;" />

而在多核时代，每颗CPU都有自己的缓存，这时CPU缓存与内存的数据一致性就没那么容易解决了，当**多个线程在不同的CPU上执行时，这些线程操作的是不同的CPU缓存**。比如下图中，线程A操作的是CPU-1上的缓存，而线程B操作的是CPU-2上的缓存：

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/jike-03-02.jpg" style="zoom: 80%;" />

线程A、B相继(或同时 不影响)先从主存中读取最新的变量值V，然后在各自的CPU高速缓存上(多核CPU)操作数据，然后再放回主存，这样就出现了可见性问题，解决办法是：**如果其中一个cpu修改了数据，会通过总线立即回写到主内存中，其他cpu通过总线嗅探机制感知到缓存中数据的变化后，会立即将工作内存中的数据失效，同时去主内存中读取最新数据**

例如以下代码：

```java
//线程1执行的代码
int i = 0;
i = 10;
 
//线程2执行的代码
j = i;
```

假若执行线程1的是CPU1，执行线程2的是CPU2,当线程1执行 i =10时，会先把i的初始值加载到CPU1的高速缓存中，然后赋值为10，那么在CPU1的高速缓存当中i的值变为10了，却没有立即写入到主存当中,此时线程2执行 j = i，它会先去主存读取i的值并加载到CPU2的缓存当中，注意此时内存当中i的值还是0，那么就会使得j的值为0，而不是10



使用`volatile`实现可见性：

```java
public class TestVolatile {
    
    // 如果不在stop前用volatile修饰，main线程对stop的修改Thread A不能及时看到
    private static volatile  boolean stop = false;  
    public static void main(String[] args) {
        // Thread-A
        new Thread("Thread A") {
            @Override
            public void run() {
                while (!stop) {
                }
                System.out.println(Thread.currentThread() + " stopped");
            }
        }.start();

        // Thread-main
        try {
            TimeUnit.SECONDS.sleep(1);
            System.out.println(Thread.currentThread() + " after 1 seconds");
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        stop = true;
    }
}


```

按照`main`方法的逻辑，如果不在stop前用volatile修饰，即使主线程已经把stop设置为true，从逻辑上讲子线程就应该跳出while死循环，但事实并不是这样，这是因为子线程读取的是副本，没有及时读取到主内存中的最新结果





`volatile` 变量的内存可见性是基于**内存屏障**(Memory Barrier)实现：程序运行时，为了提高执行性能，编译器和处理器会**对指令进行重排序**，`JMM` 为了保证在不同的编译器和 CPU 上有相同的结果，会通过插入特定类型的内存屏障来禁止编译器和处理器重排序，如果对声明了 `volatile` 的变量进行写操作，JVM 就会向处理器发送一条 `lock` 前缀的指令，将这个变量所在缓存行的数据写回到系统内存：

`lock` 前缀的指令在多核处理器下会引发两件事情:

- **将当前处理器缓存行的数据写回到系统内存**
- **写回内存的操作会使在其他 CPU 里缓存了该内存地址的数据无效**

为了保证各个处理器的缓存是一致的，CPU实现了**缓存一致性协议(MESI)**：每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，然后从内存中重读该变量数据，即可以获取当前最新值(当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里)



> MESI 缓存一致性协议：
>
> MESI表示缓存行的四种状态，分别是：
>
> 1、M(Modify) 表示共享数据只缓存在当前 CPU 缓存中，并且是被修改状态，也就是缓存的数据和主内存中的数据不一致
> 2、E(Exclusive) 表示缓存的独占状态，数据只缓存在当前CPU缓存中，并且没有被修改
> 3、S(Shared) 表示数据可能被多个 CPU 缓存，并且各个缓存中的数据和主内存数据一致
> 4、I(Invalid) 表示缓存已经失效
>
> 在 MESI 协议中，每个缓存的缓存控制器不仅知道自己的读写操作，而且也监听(snoop)其它CPU的读写操作。
>
> 对于 MESI 协议，从 CPU 读写角度来说会遵循以下原则：
>
> **CPU读请求**：缓存处于 M、E、S 状态都可以被读取，I 状态CPU 只能从主存中读取数据
> **CPU写请求**：缓存处于 M、E 状态才可以被写。对于S状态的写，需要将其他CPU中缓存行置为无效才行。







### 原子性 :astonished::astonished:

众所周知 `volatile`不能保证原子性，但需要注意的是：**对`volatile`变量的单次读/写操作可以保证原子性的**，如long和double类型变量，但是并不能保证i++这种操作的原子性，因为本质上i++是读、写两次操作，Java中只有对基本类型变量的赋值和读取是原子操作(如i = 1的赋值操作，但是像j = i或者i++这样的操作都不是原子操作)，如果一个变量被volatile修饰了，那么肯定可以保证每次读取这个变量值的时候得到的值是最新的——单次读/写操作可以保证原子性，而一旦需要对变量进行自增这样的非原子操作，就不会保证这个变量的原子性



**疑问❓❓❓**

网上大多数博客是这样解释的：“假设某一时刻i=5，此时有两个线程同时从主存中读取了i的值，那么此时两个线程保存的i的值都是5， 此时A线程对i进行了自增计算，然后B也对i进行自增计算，此时两条线程最后刷新回主存的i的值都是6（本来两条线程计算完应当是7），所以说`volatile`保证不了原子性”

上述这种解释是有问题的，我的不解之处在于：

既然i是被volatile修饰的变量，那么对于i的操作应该是线程之间是可见的啊，就算A B两个线程都同时读到i的值是5，**但是如果A线程执行完i的操作以后应该会把B线程读到的i的值置为无效并强制B重新读入i的新值**，也就是6然后才会进行自增操作才对，后来参照其他博客终于想通了，因为i++的操作底层实现实际上是这样的：

```
1、线程读取i

2、temp = i + 1

3、i = temp
```

**正确解释为：**

(1) 当 i=5 的时候A,B两个线程同时读入了 i 的值， 然后A线程执行了 `temp = i + 1`的操作，注意此时i 的值还没有变化

(2) 然后 B 线程也执行了 `temp = i + 1`的操作，**此时A，B两个线程保存的 i 的值都是 5，temp 的值都是 6** 

(3) 接着 A 线程拿到CPU使用权，执行了 `i = temp （6）`操作，此时i的值会立即刷新到主存并通知其他线程保存的 i 值失效，此时B线程需要重新读取i的值 那么此时B线程保存的i值为6，同时B线程保存的temp值仍然是6

(4) 然后B线程执行 i=temp（6），所以导致了计算结果比预期少了1

实际上也是相当于A的操作被覆盖掉了，但是这种理解在解释了`volatile`能保证可见性的同时，也验证了不一定能保证原子性！



### 有序性 :computer:

再来分析有序性，在并发环境下的单例实现方式，通常可以采用双重校验检查加锁(DCL)的方式来实现：

```java
public class Singleton {
    public static volatile Singleton singleton;
    /**
     * 构造函数私有，禁止外部实例化
     */
    private Singleton() {};
    public static Singleton getInstance() {
        if (singleton == null) {
            synchronized (singleton.class) {
                if (singleton == null) {
                    singleton = new Singleton();
                }
            }
        }
        return singleton;
    }
}
```

> 补充:
>
> 单例模式分为**非延迟加载（饿汉式）和延迟加载（懒汉式）**，延迟加载可以有效提高系统资源的利用效率，所以通常使用延迟加载来实现,但是延迟加载涉及到线程安全问题(多个线程同时进入`getInstance()`方法内，故需要加同步锁来确保线程安全)



现在分析一下为什么要在引用变量`singleton`之间加上`volatile`关键字 ，要理解这个问题，先要了解对象的构造过程，实例化一个对象其实可以分为三个步骤：

- 分配内存空间
- 初始化对象
- 将内存空间的地址赋值给对应的引用





但是由于操作系统可以`对指令进行重排序`，所以上面的过程也可能会变成如下过程：

- 分配内存空间
- 将内存空间的地址赋值给对应的引用
- 初始化对象

如果是这个流程，多线程环境下就可能将一个未初始化的对象引用暴露出来，因此为了防止这个过程的重排序，需要将变量设置为`volatile`类型的变量



`happens-before` 规则中有一条 `volatile` 变量规则：**对一个 volatile 域的写，happens-before 于任意后续对这个 volatile 域的读**



为了实现 `volatile` 内存语义，编译器在生成字节码时，会在指令序列中**插入内存屏障**来禁止特定类型的处理器重排序：

- 在每个 volatile 写操作的前面插入一个 StoreStore 屏障
- 在每个 volatile 写操作的后面插入一个 StoreLoad 屏障
- 在每个 volatile 读操作的后面插入一个 LoadLoad 屏障
- 在每个 volatile 读操作的后面插入一个 LoadStore 屏障

volatile 写操作是在前面和后面分别插入内存屏障，而 volatile 读操作是在后面插入两个内存屏障

| 内存屏障        | 说明                                                        |
| --------------- | ----------------------------------------------------------- |
| StoreStore 屏障 | 禁止前面的普通写和后面的 volatile 写重排序。                |
| StoreLoad 屏障  | 防止前面的 volatile 写与后面可能有的 volatile 读/写重排序。 |
| LoadLoad 屏障   | 禁止前面所有的普通读操作和后面的 volatile 读重排序。        |
| LoadStore 屏障  | 禁止后面所有的普通写操作和前面的 volatile 读重排序。        |









### 与synchronized区别？

> 单例模式的双重检验锁中，`synchronized`已经具备了原子性、有序性和可见性，为什么还需要`volatile`？

首先明确一点：`synchronized`是无法禁止指令重排和处理器优化的。那么`synchronized`如何保证有序性呢？

这里需要扩展一下有序性的概念，Java程序中天然的有序性可以总结成一句话：如果在本线程内观察，所有的操作都是天然有序的。如果在一个线程中观察另一个线程，所有的操作都是无序的。以上这句话是《深入理解Java虚拟机》中的原句，但是怎么理解呢？这里其实和 `as-if-serial`的语义有关

`as-if-serial`的语义是：不管怎么重排序，单线程程序的执行结果都不能被改变。也就是说，`as-if-serial`保证了在单线程中，不管指令怎么重排，最终的执行结果是不能被改变的。因此，`synchronized`保证的有序性实际上是多个线程之间的有序性，即被加锁的内容要按照顺序被多个线程执行，但是其内部的同步代码还是会发生重排序，因此还是需要`volatile`



https://blog.csdn.net/bochuangli/article/details/122862651











## ThreadLocal

实现线程安全的方法主要有以下几种：

- 互斥同步: `synchronized` 和 `ReentrantLock`
- 非阻塞同步: `CAS`、 `AtomicXXXX`
- 无同步方案: 栈封闭，**本地存储**(Thread Local)，可重入代码

而`ThreadLocal`类在多线程中会为每一个线程创建单独的变量副本; 当使用`ThreadLocal`来维护变量时, `ThreadLocal`会为每个线程创建单独的变量副本, 避免因多线程操作共享变量而导致的数据不一致的情况。即`ThreadLocal`类可以存储每个线程的私有数据，每个线程可以通过`get()`和`set()`来获取默认值或将其值更改为当前线程所存的副本的值



### 用法

例如管理数据库连接时，如果一直是单线程操作，下列代码是没有问题的：

```java
class ConnectionManager {
    private static Connection connect = null; 

    public static Connection openConnection() {
        if (connect == null) {
            connect = DriverManager.getConnection(); //建立数据库连接
        }
        return connect;
    }

    public static void closeConnection() {
        if (connect != null)
            connect.close();
    }
}

```

而在多线程中使用会存在线程安全问题：

第一，这里面的2个方法都没有进行同步，很可能在`openConnection()`方法中会多次创建`connect`

第二，由于`connect`是共享变量(实际上也不需要设计为共享变量,因为各个线程之间对connect变量的访问实际上是没有依赖关系的，即一个线程不需要关心其他线程是否对这个`connect`进行了修改)，那么必然在调用`connect`的地方需要使用到同步来保障线程安全，因为很可能一个线程在使用`connect`进行数据库操作，而另外一个线程调用`closeConnection()`关闭连接

这时候就可以使用`ThreaLocal`，为每个线程创建一个该连接变量的副本，线程之间互不影响：

```java
public class ConnectionManager {

    //类似hashmap 
    private static final ThreadLocal<Connection> dbConnectionLocal = new ThreadLocal<Connection>()
    {
        @Override
        protected Connection initialValue() {
            try {
                return DriverManager.getConnection("", "", ""); //创建线程局部变量
            } catch (SQLException e) {
                e.printStackTrace();
            }
            return null;
        }
    };

    public Connection getConnection() {
        return dbConnectionLocal.get();
    }
}
```

上述代码里`dbConnectionLocal` 这个变量为Key, 以新建的`Connection对象`为`Value`; ，`ThreadLocal`类提供了一个`initialValue()`方法，用于在每个线程第一次访问该变量时提供一个初始值。该方法是`ThreadLocal`类的方法，它返回一个初始值，用于初始化调用线程的局部变量。当第一次访问`ThreadLocal`对象的`get()`或`set()`方法时，**如果该线程尚未使用set()方法设置过初始值，那么`initialValue()`方法就会被调用**

```java
protected T initialValue() {
        return null;
    }
```



### ThreadLocalMap

`Thread` 类中有一个 `threadLocals` 和 一个 `inheritableThreadLocals` 变量，它们都是 `ThreadLocalMap` 类型的变量,可以把 `ThreadLocalMap` 理解为`ThreadLocal` 类实现的定制化的 `HashMap`:

```java
  //Thread类中有两个ThreadLocalMap类型的变量
  ThreadLocal.ThreadLocalMap threadLocals = null;
  ThreadLocal.ThreadLocalMap inheritableThreadLocals = null;
```

默认情况下这两个变量都是 null，只有当前线程调用 `ThreadLocal` 类的 `set`或`get`方法时才创建它们，当当前线程调用这两个方法的时候，实际上调用的是`ThreadLocalMap`类对应的 `get()`、`set()`方法：

`ThreadLocal`类中的`set()`方法，注意[ThreadLocalMap线性探测法解决hash冲突](https://blog.csdn.net/xiaoxiaodaxiake/article/details/107732928)：

```java
public void set(T value) {
        Thread t = Thread.currentThread();
        ThreadLocalMap map = getMap(t); //获取到当前线程的threadlocalmap变量
        if (map != null) {
            map.set(this, value);   //调用ThreadLocal的静态内部类ThreadLocalMap中的set()方法
        } else {
            createMap(t, value);
        }
    }


ThreadLocalMap getMap(Thread t) {
        return t.threadLocals;
    }

  
private void set(ThreadLocal<?> key, Object value) {
            Entry[] tab = table;
            int len = tab.length;
            int i = key.threadLocalHashCode & (len-1); //根据ThreadLocal对象的hash值，定位到table中的位置i

            for (Entry e = tab[i];
                 e != null;
                 e = tab[i = nextIndex(i, len)]) {
                if (e.refersTo(key)) {
                    //如果位置i不为空，且这个Entry对象的key正好是即将设置的key，那么就刷新Entry中的value
                    e.value = value;
                    return;
                }

                if (e.refersTo(null)) {//如果当前位置是空的，就初始化一个Entry对象放在位置i上；
                    replaceStaleEntry(key, value, i);
                    return;
                }
            }

            tab[i] = new Entry(key, value);
            int sz = ++size;
            if (!cleanSomeSlots(i, sz) && sz >= threshold)
                rehash();
        }   
```

`ThreadLocal`类中的`get()`方法同理：

```java
public T get() {
        Thread t = Thread.currentThread();
        ThreadLocalMap map = getMap(t);
        if (map != null) {
            ThreadLocalMap.Entry e = map.getEntry(this);
            if (e != null) {
                @SuppressWarnings("unchecked")
                T result = (T)e.value;
                return result;
            }
        }
        return setInitialValue();//如果线程没有调用set()方法对threadlocal变量赋值，则返回默认值
    }


ThreadLocalMap getMap(Thread t) {
        return t.threadLocals;
    }


private Entry getEntry(ThreadLocal<?> key) {
            int i = key.threadLocalHashCode & (table.length - 1);
            Entry e = table[i];
            if (e != null && e.refersTo(key))
                return e;
            else
                return getEntryAfterMiss(key, i, e);
        }
```



再来看一个声明了多个`ThreadLocal`变量的例子：

```java
public class ThreadLocalExample {
    private static ThreadLocal<String> threadLocal1 = new ThreadLocal<>();
    private static ThreadLocal<Integer> threadLocal2 = new ThreadLocal<>();

    public static void main(String[] args) {
        threadLocal1.set("Hello");
        threadLocal2.set(42);

        Thread thread1 = new Thread(() -> {
            threadLocal1.set("Thread 1");
            threadLocal2.set(10);

            System.out.println("Thread 1 - ThreadLocal1: " + threadLocal1.get());
            System.out.println("Thread 1 - ThreadLocal2: " + threadLocal2.get());
        });

        Thread thread2 = new Thread(() -> {
            threadLocal1.set("Thread 2");
            threadLocal2.set(20);

            System.out.println("Thread 2 - ThreadLocal1: " + threadLocal1.get());
            System.out.println("Thread 2 - ThreadLocal2: " + threadLocal2.get());
        });

        thread1.start();
        thread2.start();

        System.out.println("Main Thread - ThreadLocal1: " + threadLocal1.get());
        System.out.println("Main Thread - ThreadLocal2: " + threadLocal2.get());
    }
}

```

在这个例子中，我们声明了两个`ThreadLocal`变量(属于类)：`threadLocal1`和`threadLocal2`，每个`ThreadLocal`变量都与当前线程的`ThreadLocalMap`实例相关联

首先，我们来分析主线程的`ThreadLocalMap`情况：

```java
Main Thread:
ThreadLocal1 -> "Hello"
ThreadLocal2 -> 42
```

主线程的`ThreadLocalMap`中存储了两个键值对，分别是`ThreadLocal1 -> "Hello"`和`ThreadLocal2 -> 42`。这些值是在`main`方法中通过`threadLocal1.set("Hello")`和`threadLocal2.set(42)`设置的

接下来，我们分析`thread1`线程的`ThreadLocalMap`情况：

```java
Thread 1:
ThreadLocal1 -> "Thread 1"
ThreadLocal2 -> 10
```

`thread1`线程的`ThreadLocalMap`中存储了两个键值对，分别是`ThreadLocal1 -> "Thread 1"`和`ThreadLocal2 -> 10`。这些值是在`thread1`的线程体内通过`threadLocal1.set("Thread 1")`和`threadLocal2.set(10)`设置的



最后，我们分析thread2线程的ThreadLocalMap情况：

```java
Thread 2:
ThreadLocal1 -> "Thread 2"
ThreadLocal2 -> 20

```

thread2线程的`ThreadLocalMap`中也存储了两个键值对，分别是`ThreadLocal1 -> "Thread 2"`和`ThreadLocal2 -> 20`。这些值是在`thread2`的线程体内通过`threadLocal1.set("Thread 2")`和`threadLocal2.set(20)`设置的。

每个线程独立地管理其自己的`ThreadLocalMap`，因此每个线程对`ThreadLocal`变量的更改不会影响其他线程的`ThreadLocal`变量。这样可以确保在多线程环境下，每个线程都具有独立的上下文信息

```java
private static ThreadLocal<String> ThreadLocal1 = new ThreadLocal<>();
private static ThreadLocal<Integer> ThreadLocal2 = new ThreadLocal<>();
private static ThreadLocal<Character> ThreadLocal3 = new ThreadLocal<>();

/*开启三个线程并调用set()方法*/
 Thread thread1 = new Thread(() -> {
            ThreadLocal1.set(value1);
            ThreadLocal2.set(value4);
            ThreadLocal2.set(value7);
        });

//后面省略
```

例如执行以上代码后，`threadlocalmap`的变化如下图所示：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/threadlocalmap.webp)



### Java引用

Java数据类型只有两种：基本类型和引用类型，例如：

```java
Object obj=new Object();
```

`obj`就是引用类型，指向堆中的实例对象

而Java为了避免出现`OutOfMemoryError`错误，会执行`Garbage Collection`来不定时回收**无任何对象引用**的对象占据的内存空间，JVM如何找到需要回收的对象，方式有两种：

- 引用计数法：每个对象有一个引用计数属性，新增一个对该对象的引用时计数器加1，引用释放时计数减1，计数为0时则可以进行垃圾回收
- 可达性分析法：从 `GC Roots` 开始向下搜索，搜索所走过的路径称为引用链。当一个对象到 `GC Roots` 没有任何引用链相连时，则证明此对象是不可用的，那么虚拟机就判断是可回收对象



从`JDK 1.2`版本开始，对象的引用被划分为`4`种级别，从而使程序能更加灵活地控制**对象的生命周期**。这`4`种级别**由高到低**依次为：**强引用**、**软引用**、**弱引用**和**虚引用**：

1. **强引用 ** 是使用最普遍的引用。如果一个对象具有强引用，那**垃圾回收器**绝不会回收它。如下：

```java
   Object strongReference = new Object();
```

 如果强引用对象**不使用时**，需要弱化从而使`GC`能够回收，显式地设置`strongReference`指向为`null`，则JVM认为该对象**不存在引用**，这时就可以回收这个对象：

```java
strongReference = null;
```



如果在一个**方法的内部**有一个**强引用**，这个引用保存在`Java`**栈**中，而真正的实例(`Object`)保存在`Java`**堆**中。 当这个**方法运行完成**后，就会退出**方法栈**，则引用对象的**引用数**为`0`，这个对象会被回收

```java
public void test() {
        Object strongReference = new Object();
        // 省略其他操作
    }
```

但是如果这个`strongReference`是**全局变量**时，就需要在不用这个对象时赋值为`null`，因为**强引用**不会被垃圾回收！



2. **软引用** 如果一个对象只具有**软引用**，则**内存空间充足**时，**垃圾回收器**就**不会**回收它；如果**内存空间不足**了，就会**回收**这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用，对比一下强引用和软引用，软引用需要借助`SoftReference`：

```
// 强引用
String strongReference = new String("abc");
// 软引用
String str = new String("abc");
SoftReference<String> softReference = new SoftReference<String>(str);

```

**软引用**可以和一个**引用队列**(`ReferenceQueue`)联合使用。如果**软引用**所引用对象被**垃圾回收**，`JAVA`虚拟机就会把这个**软引用**加入到与之关联的**引用队列**：

```java
ReferenceQueue<String> referenceQueue = new ReferenceQueue<>();//引用队列
String str = new String("abc");
SoftReference<String> softReference = new SoftReference<>(str, referenceQueue);
str = null;
// Notify GC
/*
下面调用System.gc()方法只是起通知作用，JVM什么时候扫描回收对象是JVM自己的状态决定的，即使扫描到软引用对象也不一定会回收它，只有内存不够的时候才会回收
*/
System.gc();
System.out.println(softReference.get()); // abc
Reference<? extends String> reference = referenceQueue.poll();//弹出队列元素
System.out.println(reference); //null
```

即当内存不足时，`JVM`首先将**软引用**中的**对象**引用置为`null`，然后通知**垃圾回收器**进行回收，且**垃圾收集线程**会在`JVM`抛出`OutOfMemoryError`之前回**收软引用对象**，而且**虚拟机**会尽可能优先回收**长时间闲置不用**的**软引用对象**（引入引用队列的原因）



3. **弱引用**  **弱引用**与**软引用**的区别在于：只具有**弱引用**的对象拥有**更短暂**的**生命周期**。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有**弱引用**的对象，不管当前**内存空间足够与否**，都会**回收**它的内存

```java
String str = new String("abc");
WeakReference<String> weakReference = new WeakReference<>(str);
```

弱引用同样会关联一个引用队列,如果**弱引用**所引用的**对象**被**垃圾回收**，`Java`虚拟机就会把这个**弱引用**加入到与之关联的**引用队列**中,`WeakReference`对象的生命周期基本由**垃圾回收器**决定，一旦垃圾回收线程发现了**具有弱引用的对象**，在下一次`GC`过程中就会对其进行回收，本文所要讨论的`ThreadLocalMap`中`Entry`的`Key`就是弱引用：



![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/ThreadLocal.jpg)



### 子线程变量传递问题

https://blog.csdn.net/hbtj_1216/article/details/100511851



###  内存泄漏

不再会被使用的对象或者变量占用的内存**不能被有效垃圾回收**，就是内存泄露

```java
private static ThreadLocal<String> threadLocal1 = new ThreadLocal<>();
threadLocal1.set("Hello");
```

观察以上代码：`ThreadLocalMap`在保存时，``key—threadlocal1`是一个**弱引用**，指向真正的堆中`ThreadLocal`实例，而`value`—`"hello"`为当前线程变量的副本，是强引用。`key`被设计成`WeakReference`**弱引用**，这就导致了一个问题：`Entry`中的`value`是**强引用**、而`key`是弱引用，在`JVM`发生`GC`时`key`会被回收，而`value`由于是强引用不会，这样一来，`ThreadLocalMap` 中就会出现 `key` 为 `null` 的 `Entry`，只有**当前Thread线程退出以后,value的强引用链条才会断掉**。假如我们不做任何措施的话，**value** 永远无法被 `GC` 回收，这个时候就产生了内存泄露

在`TheadLocal`中内存泄漏是指`TheadLocalMap`中的`Entry`中的`key`为`null`，而`value`不为null。因为key为null导致value一直访问不到，而根据可达性分析，始终有`threadRef`->`currentThread`->`threadLocalMap`->`entry`->`valueRef`->`valueMemory`,导致垃圾回收在进行可达性分析时,value可达从而不会被回收掉，但是该`value`永远不能被访问到，这样就存在了内存泄漏

说一下自己的缺点



JVM如何找到需要回收的对象，方式有两种：

- 引用计数法：每个对象有一个引用计数属性，新增一个引用时计数加1，引用释放时计数减1，计数为0时可以回收
- 可达性分析法：从 `GC Roots` 开始向下搜索，搜索所走过的路径称为引用链。当一个对象到 GC Roots 没有任何引用链相连时，则证明此对象是不可用的，那么虚拟机就判断是可回收对象

> 引用计数法，可能会出现A 引用了 B，B 又引用了 A，这时候就算他们都不再使用了，但因为相互引用 ，计数器=1 永远无法被回收

`ThreadLocal`在保存的时候`key`为使用**弱引用**的`ThreadLocal`实例，value为线程变量的副本，存在`ThreadLocalMap`中，`key`被设计成`WeakReference`**弱引用**，这就导致了一个问题：Entry中的value是**强引用**、而key是弱引用，在JVM发生GC(`Garbage Collection`)时key会被回收，而value由于是强引用不会，这样一来，`ThreadLocalMap` 中就会出现 key 为 null 的 Entry，只有**Thread线程退出以后,value的强引用链条才会断掉**。假如我们不做任何措施的话，**value** 永远无法被 GC 回收，这个时候就可能会产生内存泄露(相当于白占了`jvm`内存而无法被释放)

`ThreadLocalMap` 的实现中已经考虑了这种情况，**在调用 `set()`、`get()`、`remove()` 方法的时候，会清理掉 key 为 null 的记录**。使用完 `ThreadLocal`方法后最好手动调用`remove()`方法，`ThreadLocal`在`remove()`的时候，会调用弱引用中的`clear()`方法:

```java
//ThreaLocal中的remove方法
public void remove() {
         ThreadLocalMap m = getMap(Thread.currentThread());
         if (m != null) {
             m.remove(this);
         }
     }

//ThreaLocalMap中定义的remove方法
private void remove(ThreadLocal<?> key) {
            Entry[] tab = table;
            int len = tab.length;
            int i = key.threadLocalHashCode & (len-1);
            for (Entry e = tab[i];
                 e != null;  //这个for循环其实就是为了找到key为null的entry
                 e = tab[i = nextIndex(i, len)]) {
                if (e.refersTo(key)) {
                    e.clear(); //如果key为null,而对应的entry还未被回收，调用Reference中的clear()方法
                    expungeStaleEntry(i)；
                    return;
                }
            }
        }

//Reference中的clear方法 
public void clear() {
        clear0();
    }

private native void clear0();
```

**总结：**

由于`Thread`类中包含变量`ThreadLocalMap`，因此`ThreadLocalMap`与`Thread`的生命周期是一样长，如果没有手动删除`key`为`null`，`value`不为`null`的`Entry`,都会导致内存泄漏

使用**弱引用**可以多一层保障：弱引用`ThreadLocal`不会内存泄漏，对应的`value`在下一次`ThreadLocalMap`调用`set(),get(),remove()`的时候会被清除

因此，`ThreadLocal`内存泄漏的根源是：由于`ThreadLocalMap`的生命周期跟Thread一样长，在当前线程未消亡前如果没有手动删除对应`key`为`null`的`Entry`就会导致内存泄漏，而不是因为key为弱引用！





## ThreadPool



### 为什么引入线程池呢？

如果在生产环境使用new Thread();这种方式去进行显式创建线程会带来什么后果？

- - **OOM：** 如果当前方法突遇高并发情况，假设此时来了1000个请求，而按传统的网络模型是BIO，此时服务器会开1000个线程来处理这1000个请求（不考虑WEB容器的最大线程数配置），当1000个请求执行时又会发现此方法中存在`new Thread();`创建线程，此时每个执行请求的线程又会创建一个线程，此时就会出现1000*2=2000个线程的情况出现，而**在一个程序中创建线程是需要向JVM申请内存分配的，但是此时大量线程在同一瞬间向JVM申请分配内存，此时会很容易造成内存溢出（OOM）的情况发生**
  - **资源开销与耗时：**Java对象的生命周期大致包括三个阶段：对象的创建，对象的使用，对象的清除。因此，对象的生命周期长度可用如下的表达式表示：Object = O1 + O2 +O3。其中O1表示对象的创建时间，O2表示对象的使用时间，而O3则表示其清除（垃圾回收）时间。由此，我们可以看出，只有O2是真正有效的时间，而O1、O3则是对象本身的开销。当我们去创建一个线程时也是一样，因为线程在Java中其实也是一个Thread类的实例，所以对于线程而言，其实它的创建（申请内存分配、JVM向OS提交线程映射进程申请、OS真实线程映射）和销毁对资源是开销非常大的并且非常耗时的。
  - **不可管理性：** 对于`new Thread();`的显示创建出来的线程是无法管理的，一旦CPU调度成功，此线程的可管理性几乎为零。





### 创建方式

1. 如何创建线程池？

   - **通过`ThreadPoolExecutor`构造函数来创建**

   ```java
    public ThreadPoolExecutor(int corePoolSize,//线程池的核心线程数量
                                 int maximumPoolSize,//线程池的最大线程数
                                 long keepAliveTime,//当线程数大于核心线程数时，多余的空闲线程存活的最长时间
                                 TimeUnit unit,//时间单位
                                 BlockingQueue<Runnable> workQueue,//任务队列，用来储存等待执行任务的队列
                                 ThreadFactory threadFactory,//线程工厂，用来创建线程，一般默认即可
                                 RejectedExecutionHandler handler//拒绝策略，当提交的任务过多而不能及时处理时，我们可以定制策略来处理任务
                     )  
   ```

   

   - **通过`Executor` 框架的工具类 `Executors` 创建**

   `Executors` 是一个工具类，提供了用于创建和管理线程池的静态方法，用于简化线程池的创建和配置，`Executors` 还提供了其他一些用于创建特定类型线程池的方法。这些方法都返回实现了 `ExecutorService` 接口的线程池对象，可以用于提交任务和管理线程池的执行

   `ExecutorService` 是 Java 并发编程中的一个接口，它扩展了 `Executor` 接口，提供了更丰富的功能和更灵活的任务管理。

   `ExecutorService` 接口的主要作用如下：

   1. 提供线程池：`ExecutorService` 可以通过工厂方法创建线程池，如 `newFixedThreadPool()`、`newCachedThreadPool()` 等。线程池可以重用线程，避免线程的频繁创建和销毁，提高线程的利用率和性能。
   2. 提交任务：`ExecutorService` 可以接收任务（`Runnable` 或 `Callable` 对象）的提交，并安排线程池中的线程执行这些任务。任务的提交可以通过 `submit()` 或 `execute()` 方法进行。
   3. 异步执行：`ExecutorService` 提交的任务可以在后台线程中异步执行，不会阻塞主线程的执行。这使得主线程可以继续执行其他操作，而不必等待任务完成。
   4. 任务管理：`ExecutorService` 提供了一系列方法来管理和控制任务的执行，如 `shutdown()`、`shutdownNow()`、`isShutdown()`、`isTerminated()` 等。可以控制线程池的启动、关闭、监控任务的执行状态等。
   5. 获取任务结果：`ExecutorService` 提交任务后，可以返回一个 `Future` 对象，表示任务的执行结果。通过 `Future` 对象，可以获取任务的返回值、判断任务是否完成、取消任务的执行等。
   6. 批量提交任务：`ExecutorService` 提供了批量提交任务的方法，如 `invokeAll()` 和 `invokeAny()`。`invokeAll()` 提交一批任务，并等待所有任务完成；`invokeAny()` 提交一批任务，并返回最先完成的任务的结果。

   

2. `ThreadPoolExecutor`的类型有哪些（`Executors`中自带的线程池）？

   - `FixThreadPool`:该方法返回一个**固定线程数量的线程池**。该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务  

   ```java
   public static ExecutorService newFixedThreadPool(int nThreads) {  //nThreads表示线程数量
           return new ThreadPoolExecutor(nThreads, nThreads,
                                         0L, TimeUnit.MILLISECONDS,
                                         new LinkedBlockingQueue<Runnable>());
       }
   ```

   

   - `SingleThreadExecutor`:该方法返回一个只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务

   ```java
    public static ExecutorService newSingleThreadExecutor() {
           return new FinalizableDelegatedExecutorService
     (new ThreadPoolExecutor(1, 1,0L, TimeUnit.MILLISECONDS,new LinkedBlockingQueue<Runnable>()));
      // corePoolSize核心线程数为1    maximumPoolSize为1  keepAliveTime为OL   时间单位   传入阻塞任务队列(无界)
       }
   ```

   

   - `CachedThreadPool`:该方法返回一个**可根据实际情况调整线程数量的线程池**。线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用线程池中已有的线程；若所有线程均在工作，而又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用

   ```JAVA
   public static ExecutorService newCachedThreadPool() {
       return new ThreadPoolExecutor(0, Integer.MAX_VALUE, //不限制线程池中最大线程数量，动态调整
                                     60L, TimeUnit.SECONDS,
                                     new SynchronousQueue<Runnable>());
   }
   ```

   

   - **`ScheduledThreadPool`** ：该返回一个用来在给定的延迟后运行任务或者定期执行任务的线程池

   ```java
   public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) {
           return new ScheduledThreadPoolExecutor(corePoolSize);
       }
   
   // ScheduledThreadPoolExecutor()
   public ScheduledThreadPoolExecutor(int corePoolSize) {
           super(corePoolSize, Integer.MAX_VALUE,
                 DEFAULT_KEEPALIVE_MILLIS, MILLISECONDS,
                 new DelayedWorkQueue());//引入了延迟工作队列
       }
   ```



**注意事项：**建议通过 `ThreadPoolExecutor` 构造函数的方式来创建线程池，规避资源耗尽的风险

`Executors` 返回线程池对象的弊端如下：

- **`FixedThreadPool` 和 `SingleThreadExecutor`**：使用的是无界的 `LinkedBlockingQueue`，任务队列最大长度为 `Integer.MAX_VALUE`（由于队列永远不会被放满，因此`FixedThreadPool`最多只能创建核心线程数的线程）。故可能堆积大量的请求，从而导致 `OOM`
- **`CachedThreadPool`**：使用的是同步队列 `SynchronousQueue`, 允许创建的线程数量为 `Integer.MAX_VALUE` ，可能会创建大量线程，从而导致 `OOM`
- **`ScheduledThreadPool` 和 `SingleThreadScheduledExecutor`** : 使用的无界的延迟阻塞队列`DelayedWorkQueue`，`DelayedWorkQueue` 添加元素满了之后会自动扩容原来容量的 1/2，即永远不会阻塞，最大扩容可达 `Integer.MAX_VALUE`，所以最多只能创建核心线程数的线程





> 为什么阿里不建议使用`Executors`内置的线程池

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E9%98%BF%E9%87%8C.png)





### 线程池源码分析:expressionless:

ThreadPoolExecutor线程池有5个状态，分别是：

1. RUNNING：可以接受新的任务，也可以处理阻塞队列里的任务
2. SHUTDOWN：不接受新的任务，**但是可以处理阻塞队列里的任务**
3. STOP：不接受新的任务，不处理阻塞队列里的任务，中断正在处理的任务
4. TIDYING：**过渡状态**，也就是说所有的任务都执行完了，当前线程池已经没有有效的线程，这个时候线程池的状态将会TIDYING，**并且将要调用terminated方法**
5. TERMINATED：终止状态，terminated方法调用完成以后的状态



状态之间可以进行转换：

RUNNING -> SHUTDOWN：手动调用shutdown方法，或者ThreadPoolExecutor要被GC回收的时候调用finalize方法，finalize方法内部也会调用shutdown方法

(RUNNING or SHUTDOWN) -> STOP：调用shutdownNow方法

SHUTDOWN -> TIDYING：当队列和线程池都为空的时候

STOP -> TIDYING：当线程池为空的时候

TIDYING -> TERMINATED：terminated方法调用完成之后

ThreadPoolExecutor内部还保存着线程池的有效线程个数。

状态和线程数在`ThreadPoolExecutor`内部使用一个**整型变量**保存，没错，一个变量表示两种含义。



为什么一个整型变量既可以保存状态，又可以保存数量？ 分析一下：

首先，我们知道java中1个整型占4个字节，也就是32位，所以1个整型有32位。

所以整型1用二进制表示就是：00000000000000000000000000000001

整型-1用二进制表示就是：11111111111111111111111111111111(这个是补码，不懂的同学可以看下原码，反码，补码的知识)

在`ThreadPoolExecutor`中，整型中32位的前3位用来表示线程池状态，后3位表示线程池中有效的线程数。

```
// 前3位表示状态，所有线程数占29位
private static final int COUNT_BITS = Integer.SIZE - 3;
```



线程池的**初始容量**大小为 1 << 29 - 1 = 00011111111111111111111111111111(二进制)，代码如下

```
private static final int CAPACITY   = (1 << COUNT_BITS) - 1;
```



`RUNNING`状态为： -1 << 29 = 11111111111111111111111111111111 << 29 = 11100000000000000000000000000000(前3位为111)：

```
private static final int RUNNING    = -1 << COUNT_BITS;
```

`SHUTDOWN`状态为： 0 << 29 = 00000000000000000000000000000000 << 29 = 00000000000000000000000000000000(前3位为000)

```
private static final int SHUTDOWN   =  0 << COUNT_BITS;
```

`STOP`状态为： 1 << 29 = 00000000000000000000000000000001 << 29 = 00100000000000000000000000000000(前3位为001)：

```
private static final int STOP       =  1 << COUNT_BITS;
```

`TIDYING`状态为： 2 << 29 = 00000000000000000000000000000010 << 29 = 01000000000000000000000000000000(前3位为010)：

```
private static final int TIDYING    =  2 << COUNT_BITS;
```

TERMINATED状态为： 3 << 29 = 00000000000000000000000000000011 << 29 = 01100000000000000000000000000000(前3位为011)：

```
private static final int TERMINATED =  3 << COUNT_BITS;    
```





清楚状态位之后，下面是获得状态和线程数的内部方法：

```java
// 得到线程数，也就是后29位的数字。 直接跟CAPACITY做一个与操作即可，CAPACITY就是的值就 1 << 29 - 1 = 00011111111111111111111111111111。 与操作的话前面3位肯定为0，相当于直接取后29位的值
private static int workerCountOf(int c)  { return c & CAPACITY; }

// 得到状态，CAPACITY的非操作得到的二进制位11100000000000000000000000000000，然后做在一个与操作，相当于直接取前3位的的值
private static int runStateOf(int c)     { return c & ~CAPACITY; }

// 或操作。相当于更新数量和状态两个操作
private static int ctlOf(int rs, int wc) { return rs | wc; }
```



线程池初始化状态线程数变量：

```java
// 初始化状态和数量，状态为RUNNING，线程数为0
private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));
```





至于如何为线程池创建线程，需要来看看`addWorker()`方法：

```java
// 两个参数，firstTask表示需要跑的任务。boolean类型的core参数为true的话表示使用线程池的基本大小，为false使用线程池最大大小
// 返回值是boolean类型，true表示新任务被接收了，并且执行了。否则是false
private boolean addWorker(Runnable firstTask, boolean core) {
    retry:
    for (;;) {
        int c = ctl.get();  // 获取原子属性ctl（包含线程数量与线程池状态）
        int rs = runStateOf(c); // 线程池当前状态

        // 这个判断转换成 rs >= SHUTDOWN && (rs != SHUTDOWN || firstTask != null || workQueue.isEmpty)。 
        // 概括为3个条件：
        // 1. 线程池不在RUNNING状态并且状态是STOP、TIDYING或TERMINATED中的任意一种状态

        // 2. 线程池不在RUNNING状态，线程池接受了新的任务 

        // 3. 线程池不在RUNNING状态，阻塞队列为空。  满足这3个条件中的任意一个的话，拒绝执行任务

        if (rs >= SHUTDOWN &&
            ! (rs == SHUTDOWN &&
               firstTask == null &&
               ! workQueue.isEmpty()))
            return false;

        for (;;) {
            int wc = workerCountOf(c); // 线程池线程个数
            if (wc >= CAPACITY ||
                wc >= (core ? corePoolSize : maximumPoolSize)) // 如果线程池线程数量超过线程池最大容量或者线程数量超过了基本大小(core参数为true，core参数为false的话判断超过最大大小)
                return false; // 超过直接返回false
            if (compareAndIncrementWorkerCount(c)) // 没有超过各种大小的话，cas操作线程池线程数量+1，cas成功的话跳出循环
                break retry;
            c = ctl.get();  // 重新检查状态
            if (runStateOf(c) != rs) // 如果状态改变了，重新循环操作
                continue retry;
            // else CAS failed due to workerCount change; retry inner loop
        }
    }
    // 走到这一步说明cas操作成功了，线程池线程数量+1
    boolean workerStarted = false; // 任务是否成功启动标识
    boolean workerAdded = false; // 任务是否添加成功标识
    Worker w = null;
    try {
        final ReentrantLock mainLock = this.mainLock; // 得到线程池的可重入锁
        w = new Worker(firstTask); // 基于任务firstTask构造worker
        final Thread t = w.thread; // 使用Worker的属性thread，这个thread是使用ThreadFactory构造出来的
        if (t != null) { // ThreadFactory构造出的Thread有可能是null，做个判断
            mainLock.lock(); // 锁住，防止并发
            try {
                // 在锁住之后再重新检测一下状态
                int c = ctl.get();
                int rs = runStateOf(c);

                if (rs < SHUTDOWN ||
                    (rs == SHUTDOWN && firstTask == null)) { // 如果线程池在RUNNING状态或者线程池在SHUTDOWN状态并且任务是个null
                    if (t.isAlive()) // 判断线程是否还活着，也就是说线程已经启动并且还没死掉
                        throw new IllegalThreadStateException(); // 如果存在已经启动并且还没死的线程，抛出异常
                    workers.add(w); // worker添加到线程池的workers属性中，是个HashSet
                    int s = workers.size(); // 得到目前线程池中的线程个数
                    if (s > largestPoolSize) // 如果线程池中的线程个数超过了线程池中的最大线程数时，更新一下这个最大线程数
                        largestPoolSize = s;
                    workerAdded = true; // 标识一下任务已经添加成功
                }
            } finally {
                mainLock.unlock(); // 解锁
            }
            if (workerAdded) { // 如果任务添加成功，运行任务，改变一下任务成功启动标识
                t.start(); // 启动线程，这里的t是Worker中的thread属性，所以相当于就是调用了Worker的run方法
                workerStarted = true;
            }
        }
    } finally {
        if (! workerStarted) // 如果任务启动失败，调用addWorkerFailed方法
            addWorkerFailed(w);
    }
    return workerStarted;
}
```

 

通过`addWorker()`方法来创建线程，实际上是通过传入的`ThreadFactory`线程工厂来创建的：

```java
Worker(Runnable firstTask) {
            setState(-1); // inhibit interrupts until runWorker
            this.firstTask = firstTask;
            this.thread = getThreadFactory().newThread(this);
        }
```

**分析：**

- `addWorker()`方法用于创建新的线程并执行任务，分为两个部分**更新线程数量和创建启动线程**。
- **使用CAS更新线程数量**，使用`compareAndIncrementWorkerCount()`即**CAS操作增加线程数量**，循环更新直到成功为止。
- **创建启动线程部分使用全局锁（独占锁）`mainLock`创建并执行线程**，并记录状态，如果创建失败则调用`addWorkerFailed()`移除线程操作。











线程池构造完毕之后，如果用户调用了execute或者submit方法的时候，最后都会使用execute方法执行。

execute方法内部分3种情况处理任务：

1. **如果当前正在执行的Worker数量比corePoolSize(基本大小)要小。直接创建一个新的Worker执行任务，会调用addWorker方法**
2. 如果当前正在执行的Worker数量大于等于corePoolSize(基本大小)。将任务放到阻塞队列里，如果阻塞队列没满并且状态是RUNNING的话，直接丢到阻塞队列，否则执行第3步
3. 丢到阻塞失败的话，会调用addWorker方法尝试起一个新的Worker去阻塞队列拿任务并执行任务，如果这个新的Worker创建失败，调用reject方法

线程池中的这个基本大小指的是Worker的数量。一个Worker是一个Runnable的实现类，会被当做一个线程进行启动。Worker内部带有一个Runnable属性firstTask，这个firstTask可以为null，为null的话Worker会去阻塞队列拿任务执行，否则会先执行这个任务，执行完毕之后再去阻塞队列继续拿任务执行。

所以说如果Worker数量超过了基本大小，那么任务都会在阻塞队列里，当Worker执行完了它的第一个任务之后，就会去阻塞队列里拿其他任务继续执行。

Worker在执行的时候会根据一些参数进行调节，比如Worker数量超过了线程池基本大小或者超时时间到了等因素，这个时候Worker会被线程池回收，线程池会尽量保持内部的Worker数量不超过基本大小。

另外Worker执行任务的时候调用的是Runnable的run方法，而不是start方法，调用了start方法就相当于另外再起一个线程了。

Worker在回收的时候会尝试终止线程池。尝试关闭线程池的时候，会检查是否还有Worker在工作，检查线程池的状态，没问题的话会将状态过度到TIDYING状态，之后调用terminated方法，terminated方法调用完成之后将线程池状态更新到TERMINATED。



`execute`方法源码解析：

```JAVA
public void execute(Runnable command) {
        // 判断入参是否为空
  if (command == null)
    throw new NullPointerException();
        // 获取原子属性ctl（包含线程数量与线程池状态）
  int c = ctl.get();
        // workerCountOf()用于获取线程池的当前线程数量
  if (workerCountOf(c) < corePoolSize) {
                // 小于核心线程数则直接调用addWorker创建新线程执行任务并返回
    if (addWorker(command, true))
      return;
                // 重新获取ctl
    c = ctl.get();
  }
        // 走到这一步说明当前线程数量已经超过核心线程数，需要判断能否加入阻塞队列
        // 判断线程池状态是否为RUNNING并将任务放入阻塞队列
  if (isRunning(c) && workQueue.offer(command)) {
                // 获取ctl
    int recheck = ctl.get();
                // 如果线程池没有RUNNING，成功从阻塞队列中删除任务，执行reject方法处理任务
    if (! isRunning(recheck) && remove(command))
      reject(command);
                // 线程池处于RUNNING状态，但是没有线程，则创建线程
    else if (workerCountOf(recheck) == 0)
      addWorker(null, false);
  }
        // 如果创建新线程失败，则执行拒绝策略
  else if (!addWorker(command, false))
    reject(command);
}

```





### 线程池关闭



1. 关闭方式一：`shutdown()`

将线程池状态设置为SHUTDOWN状态，并且线程池不会再接收新任务，内部会将队列中提交的所有任务执行完毕后，工作线程自动退出



2. 关闭方式二：`shutdownNow()`

将线程池状态设置为STOP状态，并且线程池会将队列中等待的任务全部移除，将正在执行的任务执行完毕后，工作线程自动退出

> 关闭线程池底层源码操作为：遍历线程池的所有线程，然后依次调用线程的`interrput()`方法来终止线程

```java
 private void interruptIdleWorkers(boolean onlyOne) {
        final ReentrantLock mainLock = this.mainLock;
        mainLock.lock();
        try {
            for (Worker w : workers) {
                Thread t = w.thread;
                if (!t.isInterrupted() && w.tryLock()) {
                    try {
                        t.interrupt(); //中止线程
                    } catch (SecurityException ignore) {
                    } finally {
                        w.unlock();
                    }
                }
                if (onlyOne)
                    break;
            }
        } finally {
            mainLock.unlock();
        }
    }
```





### 常用参数

1. 线程池常见参数有哪些？

   ```java
   /* 用给定的初始参数创建一个新的ThreadPoolExecutor */
       public ThreadPoolExecutor(int corePoolSize,//线程池的核心线程数量
                                 int maximumPoolSize,//线程池的最大线程数
                                 long keepAliveTime,//当线程数大于核心线程数时，多余的空闲线程存活的最长时间
                                 TimeUnit unit,//时间单位
                                 BlockingQueue<Runnable> workQueue,//任务队列，用来储存等待执行任务的队列
                                 ThreadFactory threadFactory,//线程工厂，用来创建线程，一般默认即可
                                 RejectedExecutionHandler handler//拒绝策略，当提交的任务过多而不能及时处理时，我们可以定制策略来处理任务
                     )         
   ```

   - **`corePoolSize`: ** **任务队列中的任务未达到队列容量时，最大可以同时运行的线程数量**（核心线程任务结束后不会被销毁，非核心线程在没有执行任务时会被销毁）

   - **`maximumPoolSize`: **线程池的最大工作线程数（代表当前线程池中一共可以有多少个工作线程）

   - **` BlockingQueue<Runnable> workQueue`:** 新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中（`BlockingDeque`）

   - `ThreadFactory threadFactory`: 线程工厂用来创建线程、设置线程信息

     

     `ThreadPoolExecutor`默认使用`DefaultThreadFactory`线程工厂来创建线程：

     ```java
      public interface ThreadFactory {
         Thread newThread(Runnable r);
     }
     
     
     
     
     private static class DefaultThreadFactory implements ThreadFactory {
             private static final AtomicInteger poolNumber = new AtomicInteger(1);
             private final ThreadGroup group;
             private final AtomicInteger threadNumber = new AtomicInteger(1);
             private final String namePrefix;
     
             DefaultThreadFactory() {
                 @SuppressWarnings("removal")
                 SecurityManager s = System.getSecurityManager();
                 group = (s != null) ? s.getThreadGroup() :
                                       Thread.currentThread().getThreadGroup();
                 namePrefix = "pool-" +
                               poolNumber.getAndIncrement() +
                              "-thread-";
             }
     
             //创建线程的核心
             public Thread newThread(Runnable r) {
                 Thread t = new Thread(group, r,
                                       namePrefix + threadNumber.getAndIncrement(),
                                       0);
                 if (t.isDaemon())
                     t.setDaemon(false);
                 if (t.getPriority() != Thread.NORM_PRIORITY)
                     t.setPriority(Thread.NORM_PRIORITY);
                 return t;
             }
         }
     ```
   
     注意：
   
     该工厂类使用了 `AtomicInteger` 来给新建的每个线程赋予一个唯一的编号,区分线程池中的每个线程。
   
     新建的线程都被设置为非守护线程,优先级为默认的 `Thread.NORM_PRIORITY` 级别。
   
   - **`keepAliveTime`**:（针对的非核心线程）当线程池中的线程数量大于 `corePoolSize` 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 `keepAliveTime`才会被回收销毁
   
   - `TimeUnit unit`: 时间单位
   
   - `handler`: 饱和(拒绝)策略——即当前线程池满了后，新来的任务怎么处理？
   
     
     
     



> 比如一次性提交了100个任务(**调用线程池中的`execute() `方法添加一个任务**)，每个任务执行30秒,那么按照下面的这个线程池的参数,100个任务都是如何被执行的呢?
>
> corePoolSize=5                               maximumPoolSize=10 
>
> keepAliveTime=60                             TimeUnit=TimeUnit.seconds
>
> new LinkedBlockingQueue<>(capacity:50)       new ThreadPoolExecutor.AbortPolicy() 


   1.首先线程池会创建5个核心线程去执行前5个任务;

   2.从第6个任务开始来的都会放到任务队列中，即`LinkedBlockingDeque`中（默认容量为50）;

   3.当任务队列的50个任务放满以后，那么当前还剩下45个任务， 因为有5个在执行 + 50个已在阻塞队列中=55个;

   4.**第56-60个任务来了以后才会继续创建非核心线程去执行,这里只能在创建5个线程**，因为最大线程数是10，5+5=10;

   5.第70-100个任务来了以后，则线程池已经处于满了的一个状态，最大线程数 = 10，任务队列也满了，此时第70-第100个任务会去执行拒绝策略

2. **handler**的拒绝策略有哪些？

   **`AbortPolicy`**:抛出 `RejectedExecutionException`来拒绝新任务的处理

   **`CallerRunsPolicy`**::zzz:在线程池无法处理任务时将任务交给调用者（使用调用者的线程来执行任务）处理  

   **`DiscardPolicy`**:不处理新任务，直接丢弃掉:heavy_multiplication_x:

   **`DiscardOldestPolicy`**:将`BlockingQueue`中最早的任务丢弃掉(`LRU`算法)，然后将当前任务再次尝试交给线程池处理

   

3. 线程池中常用的**阻塞队列（BlockingQueue）**有哪些？

​    阻塞队列：如果一个队列为阻塞队列，当一个线程试图对一个已经满了的队列进行入队列操作时，它将会被阻塞，除非有另一个线程做了出队列操作；同样，当一个线程试图对一个空队列进行出队列操作时同样会被阻塞，直到其他的线程往空的队列插入新的元素。常见阻塞队列有（`ArrayBlockingQueue、PriorityBlockingQueue`）

​    非阻塞队列：若队列为空从中获取元素则会返回空，若队列满了插入元素则会直接抛出异常，不等待；常见的阻塞队列有（`PriorityQueue、ConcurrentLinkedQueue`）

​    有界队列：就是有固定大小的队列。比如设定了固定大小的`ArrayBlockingQueue`

​    无界队列：指的是没有设置固定大小的队列（实际上默认值为`Integer.MAX_VALUE`）,无界队列的特点就是可以一直入队，不存在队列满负荷的现象,从使用者的体验上，就相当于 “无界”

注意事项：

1. 容量为 `Integer.MAX_VALUE` 的 `LinkedBlockingQueue`（无界队列）：`FixedThreadPool` 和 `SingleThreadExector` 。由于队列永远不会被放满，因此`FixedThreadPool`最多只能创建核心线程数的线程（**永远不会创建非核心线程**，故`corePoolSize 等于maximumPoolSize`）。
2. `SynchronousQueue`（同步队列）：`CachedThreadPool` 。`SynchronousQueue` 没有容量，不存储元素，目的是保证对于提交的任务，如果有空闲线程，则使用空闲线程来处理；否则新建一个线程来处理任务。也就是说，`CachedThreadPool` 的最大线程数是 `Integer.MAX_VALUE` ，可以理解为线程数是可以无限扩展的，可能会创建大量线程，从而导致 OOM。
3. `DelayedWorkQueue`：`ScheduledThreadPool` 和 `SingleThreadScheduledExecutor`使用该阻塞队列,`DelayedWorkQueue` 的内部元素并不是按照放入的时间排序，而是会按照延迟的时间长短对任务进行排序，内部采用的是“堆”的数据结构，可以保证每次出队的任务都是当前队列中执行时间最靠前的。`DelayedWorkQueue` 添加元素满了之后会自动扩容原来容量的 1/2，即永远不会阻塞，最大扩容可达 `Integer.MAX_VALUE`，所以最多只能创建核心线程数的线程



### 如何配置线程池参数？


根据系统资源：

- 查看系统的CPU核心数和内存情况，以及其他关键资源的使用情况。通常，**线程池的线程数不应超过CPU核心数，这可以防止过多的线程竞争CPU资源，导致上下文切换开销增加**，反而降低性能。
- 确保线程池大小不会消耗过多的内存资源，过多的线程可能会导致内存溢出或系统负载过高。

考虑任务类型：

- **如果系统中存在大量的CPU密集型任务（计算密集型任务），可以配置较小的线程池大小，避免过多的线程竞争CPU资源**————————可以这么理解：CPU已经满负荷工作了还开多线程频繁进行线程上下文切换，这不是白浪费资源
- **如果系统中存在大量的IO密集型任务（如网络请求、数据库操作），可以适当增大线程池大小**，以便线程在IO等待时可以被更充分地利用

考虑任务执行时间：

- 如果任务的执行时间较短，并且有很多并发请求，可以配置较大的线程池大小，以便更快地响应请求
- 如果任务执行时间较长，可以适当减小线程池大小，避免线程过多，导致系统资源耗尽

使用有界队列：

- 在配置线程池时，最好使用有界队列，避免线程池中等待执行的任务过多，导致系统资源耗尽。有界队列可以限制等待执行的任务数量，一旦队列满了，线程池会拒绝新的任务。

监控和调整：

- 在配置线程池后，观察系统的性能指标，如响应时间、吞吐量和系统负载等，根据实际情况进行调整。监控系统的线程数、队列长度和任务执行时间等指标，及时发现问题并做出调整。









## Future 重要 :star2::star2:

在 Java 中，`Future` 是表示异步任务的执行状态和结果的接口。`Future` 对象提供了一种机制，可以**在任务提交后立即返回**, 允许主线程在后台任务执行的同时执行其他操作,这使得任务的执行和主线程的操作可以并行进行。`Future` 对象的异步性体现在以下几个方面：

1. 非阻塞返回：当主线程通过 `submit()` 方法提交任务给 `ExecutorService` 后，它会立即返回一个 `Future` 对象，而不会等待任务执行完成。这意味着主线程可以继续执行其他操作，而不必阻塞等待任务完成。
2. 异步执行：异步任务通常在后台线程中执行，而不是主线程。这样可以将耗时的操作或需要等待的操作（如网络请求、IO 操作等）放在异步任务中，以充分利用多核处理器或避免阻塞主线程。
3. 获取结果的阻塞：通过 `Future` 对象的 `get()` 方法可以获取任务的执行结果。如果任务尚未完成，`get()` 方法会阻塞主线程，直到任务执行完成并返回结果。这种阻塞是由主线程主动触发的，以获取异步任务的最终结果。

通过将耗时操作放在异步任务中，并使用 `Future` 对象获取结果，可以充分利用多线程或并发处理的优势，提高程序的执行效率。主线程可以在后台任务执行的同时继续执行其他操作，而不必等待任务完成。这种异步执行的特性可以在处理并发任务、提高系统吞吐量和响应性等方面发挥作用

### Future类常用方法

在 Java 中，`Future` 类只是一个泛型接口，位于 `java.util.concurrent` 包下，其中定义了 5 个方法，主要包括下面这 4 个功能：

- 取消任务；
- 判断任务是否被取消;
- 判断任务是否已经执行完成;
- 获取任务执行结果。



```java
// V 代表了Future执行的任务返回值的类型
public interface Future<V> {
    // 取消任务执行
    // 成功取消返回 true，否则返回 false
    boolean cancel(boolean mayInterruptIfRunning);
    // 判断任务是否被取消
    boolean isCancelled();
    // 判断任务是否已经执行完成
    boolean isDone();
    // 获取任务执行结果
    V get() throws InterruptedException, ExecutionException;
    // 指定时间内没有返回计算结果就抛出 TimeOutException 异常
    V get(long timeout, TimeUnit unit)

        throws InterruptedException, ExecutionException, TimeoutExceptio

}
```

简单理解就是：我有一个任务，提交给了 `Future` 来处理。任务执行期间我自己可以去做任何想做的事情。并且，在这期间我还可以取消任务以及获取任务的执行状态。一段时间之后，就可以 `Future` 那里直接取出任务执行结果



### FutureTask

`FutureTask` 类实现了 `RunnableFuture` 接口，我们看一下 `RunnableFuture` 接口的实现：

```java
public interface RunnableFuture<V> extends Runnable, Future<V> {
    void run();
}

public class FutureTask<V> implements RunnableFuture<V>{
    
}
```

可以看出 `RunnableFuture` 继承了 `Runnable` 接口和 `Future` 接口，而 `FutureTask` 实现了 `RunnableFuture` 接口。**所以它既可以作为 `Runnable` 被线程执行，又可以作为 `Future` 得到 `Callable` 的返回值**。反映在程序上就是既能传入`Thread`执行，又能通过`futureTask.get()`获取任务执行结果



- FutureTask有以下2个特征：
  - 能包装Runnable和Callable（构造器传入），但本身却又实现了Runnable接口，即本质是Runnable
  - 既然是Runnable，所以FutureTask能作为任务被Thread执行，但诡异的是也可以通过FutureTask.get()获取结果



> `ExecutorService` 是一个接口，它继承自 `Executor` 接口，用于执行异步任务，`ExecutorService` 接口提供了一系列方法来管理和控制异步任务的执行，其中之一就是 `submit()` 方法：**`submit()` 方法用于提交一个可执行的任务（`Runnable` 或 `Callable` 对象）给 `ExecutorService` 进行执行，并返回一个表示该任务的 `Future` 对象**。`Future` 对象可以用来获取异步任务的执行结果或取消任务的执行

```java
import java.util.concurrent.*;

class MyTask implements Callable<Integer> {
    private int value;

    public MyTask(int value) {
        this.value = value;
    }

    @Override
    public Integer call() throws Exception {
        // 执行任务逻辑，这里简单地返回 value 的平方
        return value * value;
    }
}

public class Main {
    public static void main(String[] args) throws InterruptedException, ExecutionException {
        // 创建线程池
        ExecutorService executorService = Executors.newFixedThreadPool(5);

        // 提交任务给线程池
        Future<Integer> future = executorService.submit(new MyTask(5));

        // 获取任务的结果
        int result = future.get();
        System.out.println(result); // 输出: 25

        // 关闭线程池
        executorService.shutdown();
    }
}

```

在上述示例中，我们定义了一个 `MyTask` 类实现了 `Callable` 接口，它接受一个整数值并返回其平方。然后，我们使用 `Executors.newFixedThreadPool(5)` 创建一个固定大小为 5 的线程池，通过 `executorService.submit()` 方法将 `MyTask` 对象提交给线程池执行。返回的 `Future` 对象可以使用 `get()` 方法获取任务的执行结果，最后将结果打印出来

使用 `submit()` 方法，你可以将任务提交给 `ExecutorService` 执行，并通过 `Future` 对象获取任务的结果或进行其他操作，如取消任务的执行







例子：使用`Callable`+`FutureTask`获取执行结果

```java
public class Test {
    public static void main(String[] args) {
        //第一种方式
        ExecutorService executor = Executors.newCachedThreadPool();
        Task task = new Task();
        FutureTask<Integer> futureTask = new FutureTask<Integer>(task);
        executor.submit(futureTask);
        executor.shutdown();
         
        //第二种方式，注意这种方式和第一种方式效果是类似的，
        //只不过一个使用的是ExecutorService，一个使用的是Thread
        /*Task task = new Task();
        FutureTask<Integer> futureTask = new FutureTask<Integer>(task);
        Thread thread = new Thread(futureTask);
        thread.start();*/
         
        try {
            Thread.sleep(1000);
        } catch (InterruptedException e1) {
            e1.printStackTrace();
        }
         
        System.out.println("主线程在执行任务");
         
        try {
            System.out.println("task运行结果"+futureTask.get()); //通过futuretask来获取任务执行结果
        } catch (InterruptedException e) {
            e.printStackTrace();
        } catch (ExecutionException e) {
            e.printStackTrace();
        }
        
        System.out.println("所有任务执行完毕");
    }
}
class Task implements Callable<Integer>{
    @Override
    public Integer call() throws Exception {
        System.out.println("子线程在进行计算");
        Thread.sleep(3000);
        int sum = 0;
        for(int i=0;i<100;i++)
            sum += i;
        return sum;
    }
}

```

输出如下：

```
子线程在进行计算
主线程在执行任务
task运行结果4950
所有任务执行完毕
```



### CompletableFuture

`CompletableFuture`和`FutureTask`的异同点：

- 相同：都实现了Future接口，所以都可以使用诸如 Future.get()、Future.isDone()、Future.cancel() 等方法
- `CompletableFuture`没有实现`Runnable`接口，**无法作为任务被执行，**所以无法把它直接丢给线程池执行
- `FutureTask`和`CompletableFuture`最大的区别在于，`FutureTask`需要调用者线程主动阻塞式获取(即调用`get()`时依旧是阻塞式的)，而`CompletableFuture`支持异步回调



Future依然有一些局限性：

1. 无法将两个异步计算的结果合并为一个。
2. 等待Future集合中所有任务完成。
3. 等待Future集合中最快任务完成（选择最优的执行方案）。
4. 通过编程的方式完成一个Future任务的执行（手工设定异步结果处理）。
5. 应对Future的完成事件，当Future的完成事件发生时会收到通知，并可以使用Future的结果进行下一步操作，不只是简单的阻塞等待。

而CompletableFuture类实现了Future接口，可以将上述的问题全部解决。CompletableFuture与Stream的设计都遵循了类似的设计模式：使用Lambda表达式以及流水线的思想，从这个角度可以说CompletableFuture与Future的关系类似于Stream与Collection的关系











### Fork/Join 框架

`Fork/Join` 框架的核心思想是将大任务划分为小任务，递归地拆分任务直到任务足够小且可以被直接执行。然后，框架利用工作窃取（work-stealing）算法，在线程池内的线程之间动态地分配和执行这些小任务。工作窃取算法允许空闲的线程从其他线程的任务队列中偷取任务执行，从而实现负载均衡和提高并行性。

与 `Future` 相关，`ForkJoinTask` 是一个抽象类，它实现了 `Future` 接口。因此，`ForkJoinTask` 既能表示异步任务的执行状态，又能获取任务的执行结果。

`ForkJoinTask` 提供了 `fork()` 和 `join()` 方法，用于执行任务的拆分和合并：

- `fork()` 方法将任务拆分为更小的子任务，并将子任务提交给线程池的工作队列，以便其他线程执行。
- `join()` 方法用于等待子任务的执行结果，并合并子任务的结果。如果子任务还没有完成，则 `join()` 方法会阻塞当前线程，直到子任务执行完成并返回结果。

`ForkJoinPool` 是一个特殊的线程池，它针对 Fork/Join 框架进行了优化。它提供了管理和执行 `ForkJoinTask` 对象的功能，以实现任务的并行执行。

综上所述，`Fork/Join` 框架和 `Future` 有以下关系：

1. `ForkJoinTask` 实现了 `Future` 接口，因此可以表示异步任务的执行状态和结果。
2. `ForkJoinTask` 的 `fork()` 和 `join()` 方法提供了任务的拆分和合并功能，可以实现任务的并行执行和结果的合并。
3. `ForkJoinPool` 是一个特殊的线程池，用于管理和执行 `ForkJoinTask` 对象，实现任务的并行处理。
4. `ForkJoinTask` 和 `ForkJoinPool` 可以结合使用，通过拆分和合并任务，并利用工作窃取算法，实现任务的并行执行和高效的负载均衡。

总的来说，`Fork/Join` 框架提供了一种高效的并行任务处理方式，利用 `Future` 接口获取任务结果，而 `ForkJoinPool` 则是支持这种框架的特定线程池实现





## UnSafe类 重要✨✨

`Unsafe` 是位于 `sun.misc` 包下的一个类，主要提供一些用于执行低级别、不安全操作的方法，如**直接访问系统内存资源、自主管理内存资源**等，这些方法在**提升 Java 运行效率、增强 Java 语言底层资源操作能力**方面起到了很大的作用。但由于 `Unsafe` 类使 Java 语言拥有了类似 C 语言指针一样操作内存空间的能力，增加了程序发生相关指针问题的风险

同时`Unsafe` 提供的功能实现需要依赖本地方法（`Native Method`）。可以将本地方法看作是 Java 中使用其他编程语言(C++ C)编写的方法。本地方法使用 **`native`** 关键字修饰，Java 代码中只是声明方法头，具体的实现则交给 **本地代码**，使用本地方法的原因在于：

- 程序需要用到Java不具备的依赖于操作系统的特性，Java在实现跨平台的同时要实现对底层的控制，这就需要借助其他语言
- 对于其他语言已经完成的一些现成功能，可以使用Java直接调用
- 程序对时间敏感或对性能要求非常高时，有必要使用更加底层的语言，例如C/C++甚至是汇编





### 操作内存

在 Java 中不允许直接对内存进行操作，对象内存的分配和回收都是由 JVM 自己实现，但是在 `Unsafe` 中，提供的下列接口可以直接进行内存操作：

```java
//分配新的本地空间
public native long allocateMemory(long bytes);
//重新调整内存空间的大小
public native long reallocateMemory(long address, long bytes);
//将内存设置为指定值
public native void setMemory(Object o, long offset, long bytes, byte value);
//内存拷贝
public native void copyMemory(Object srcBase, long srcOffset,Object destBase, long destOffset,long bytes);
//清除内存
public native void freeMemory(long address);
```



需要注意的是经这种方式分配的内存属于 **堆外内存**，无法进行垃圾回收，要把这些内存当做一种资源去手动调用`freeMemory`方法进行释放，否则会产生内存泄漏:-1: ，**使用堆外内存**的好处在于：

- 改善**垃圾回收停顿**：由于堆外内存直接受操作系统管理而不是 JVM，所以使用堆外内存时，可保持较小的堆内内存规模。从而在 GC 时减少回收停顿对于其他应用的影响
- 提升程序 I/O 操作的性能：通常在 I/O 通信过程中，会存在堆内内存到堆外内存的数据拷贝操作，对于需要频繁进行内存间数据拷贝且生命周期较短的暂存数据，都建议存储到堆外内存



### 内存屏障

编译器和 CPU 会在保证程序输出结果一致的情况下，会对代码进行**重排序**，从指令优化角度提升性能，指令重排序可能会带来一个不好的结果：导致 CPU 的高速缓存和内存中数据的不一致。而内存屏障（`Memory Barrier`）就是通过阻止屏障两边的指令重排序从而避免编译器和硬件的不正确优化

在 Java8 中，引入了 3 个内存屏障的函数，来实现内存屏障的功能：

```java
//内存屏障，禁止load操作重排序。屏障前的load操作不能被重排序到屏障后，屏障后的load操作不能被重排序到屏障前
public native void loadFence();
//内存屏障，禁止store操作重排序。屏障前的store操作不能被重排序到屏障后，屏障后的store操作不能被重排序到屏障前
public native void storeFence();
//内存屏障，禁止load、store操作重排序
public native void fullFence();

//load为读操作 store为写操作
```

内存屏障可以看做对内存随机访问的操作中的一个同步点，使得此点之前的所有读写操作都执行后才可以开始执行此点之后的操作。以`loadFence`方法为例，它会禁止读操作重排序，保证在这个屏障之前的所有读操作都已经完成，并且**将线程工作内存中的缓存数据设为无效，强制重新从主内存中进行加载**：

```java
@Getter
class ChangeThread implements Runnable{
    /**volatile**/ boolean flag=false;
    @Override
    public void run() {
        try {
            Thread.sleep(3000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        System.out.println("subThread change flag to:" + flag);
        flag = true;
    }
}



/*在主线程的while循环中，加入内存屏障，测试是否能够感知到flag的修改变化*/
public static void main(String[] args){
    ChangeThread changeThread = new ChangeThread();
    new Thread(changeThread).start();
    while (true) {
        boolean flag = changeThread.isFlag();
        unsafe.loadFence(); //加入读内存屏障
        if (flag){
            System.out.println("detected flag changed");
            break;
        }
    }
    System.out.println("main thread end");
}


//运行结果为：
subThread change flag to:false
detected flag changed
main thread end

```

分析以上代码：在主线程中开启一个新的线程`changeThread`，新线程在执行`run`()方法时立刻进入休眠态，主线程在`while`循环中首先读取到`flag`值为`false`，而由于插入了`loadfence`屏障的原因，子线程在修改flag后会将结果同步给主线程，变相修改了主线程工作空间中flag的值，进而跳出了循环



### 线程调度

`Unsafe` 类中提供了`park`、`unpark`、`monitorEnter`、`monitorExit`、`tryMonitorEnter`方法进行线程调度。



```java
//取消阻塞线程
public native void unpark(Object thread);
//阻塞线程
public native void park(boolean isAbsolute, long time);
//获得对象锁（可重入锁）
@Deprecated
public native void monitorEnter(Object o);
//释放对象锁
@Deprecated
public native void monitorExit(Object o);
//尝试获取对象锁
@Deprecated
public native boolean tryMonitorEnter(Object o);


//获得对象锁
@Deprecated
public native void monitorEnter(Object var1);
//释放对象锁
@Deprecated
public native void monitorExit(Object var1);
//尝试获得对象锁
@Deprecated
public native boolean tryMonitorEnter(Object var1);

```

其中方法`park`、`unpark` 可实现线程的挂起与恢复，将一个线程进行挂起是通过 `park` 方法实现的，调用 `park` 方法后，线程将一直阻塞直到超时或者中断等条件出现；`unpark` 可以终止一个挂起的线程，使其恢复正常

Java 锁和同步器框架的核心类 `AbstractQueuedSynchronizer` (AQS)，就是通过调用`LockSupport.park()`和`LockSupport.unpark()`实现线程的阻塞和唤醒的，而 `LockSupport` 的 `park`、`unpark` 方法实际是调用 `Unsafe` 的 `park`、`unpark` 方式实现的：

```java
private static final Unsafe U = Unsafe.getUnsafe();

public static void park(Object blocker) {
        Thread t = Thread.currentThread();
        setBlocker(t, blocker);
        U.park(false, 0L);
        setBlocker(t, null);
    }

public static void unpark(Thread thread) {
        if (thread != null)
            U.unpark(thread);
    }
```

`LockSupport` 的`park`方法调用了 `Unsafe` 的`park`方法来阻塞当前调用该方法的线程，此方法将线程阻塞后就不会继续往后执行，直到有其他线程调用`unpark`方法唤醒当前线程，下面例子对 `Unsafe` 的这两个方法进行测试：

```java
public static void main(String[] args) {
    Thread mainThread = Thread.currentThread();
    new Thread(()->{
        try {
            TimeUnit.SECONDS.sleep(5);//新线程创建后先进入休眠态，保证主线程先阻塞自己
            System.out.println("subThread try to unpark mainThread");
            unsafe.unpark(mainThread); //子线程unpark()解冻主线程
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }).start();

    System.out.println("park main mainThread");
    unsafe.park(false,0L);//主线程mainThread调用park()来阻塞自己
    System.out.println("unpark mainThread success");
}
```

程序输出为：

```text
park main mainThread
subThread try to unpark mainThread
unpark mainThread success
```





### CAS❗❗❗



CAS 即比较并替换（`Compare And Swap`)，是实现并发算法时常用到的一种技术。

CAS操作包括三个值：预估值（Expected Value）、内存值（Memory Value）和更新值（Update Value）。

预估值是指线程在进行CAS操作之前，对共享数据的一个期望值，即线程认为共享数据的当前值应该是多少。在CAS操作中，**线程会先读取共享数据的当前值作为预估值**；

在进行CAS操作时，系统会比较预估值（Expected Value）和内存值（Memory Value）是否相等。如果相等，则说明共享数据的值没有被其他线程修改，此时线程可以执行更新操作，将预估值更新为新的值（Update Value）；

如果预估值和内存值不相等，则说明有其他线程已经修改了共享数据的值，CAS操作失败。在这种情况下，线程需要重新获取最新的共享数据值，并重新进行CAS操作，直到CAS操作成功；





由于CAS 是一条 CPU 的原子指令（`cmpxchg` 指令），依靠硬件实现，JVM只是封装了汇编调用，因此不会造成所谓的数据不一致问题。`Unsafe` 提供的 CAS 方法（如 `compareAndSwapXXX`）示例：

```java
/**
	*  CAS
  * @param o         包含要修改field的对象
  * @param offset    对象中某field的偏移量
  * @param expected  期望值
  * @param update    更新值
  * @return          true | false
  */
public final native boolean compareAndSwapObject(Object o, long offset,  Object expected, Object update);

public final native boolean compareAndSwapInt(Object o, long offset, int expected,int update);

public final native boolean compareAndSwapLong(Object o, long offset, long expected, long update);


//新版JDK
public final native int compareAndExchangeInt(Object o, long offset,
                                                  int expected,
                                                  int x);

```

分析以上代码：通过`Object o`+偏移量`offset`可以确定该对象在内存中的位置，再将该内存位置的值与预期值`expected`做比较，然后进行后续操作，`compareAndSwapInt`是一个`native`方法，具体的实现在hotspot源代码的/src/share/vm/prims/unsafe.cpp文件中：

```c++
UNSAFE_ENTRY(jboolean, Unsafe_CompareAndSwapInt(JNIEnv *env, jobject unsafe, jobject obj, jlong offset, jint e, jint x))
  UnsafeWrapper("Unsafe_CompareAndSwapInt"); // 1行
  oop p = JNIHandles::resolve(obj); // 2行
  jint* addr = (jint *) index_oop_from_field_offset_long(p, offset); // 3行
  return (jint)(Atomic::cmpxchg(x, addr, e)) == e; // 4行  关键！！！
UNSAFE_END
```

实现逻辑在第2至4行，其中第2、3行主要是根据字段的偏移量计算出字段的地址

关键是第4行代码，主要是调用了`Atomic::cmpxchg`方法，实现字段值的比较交换操作（CAS）





对于`cmpxchg`指令 `linux_x86`底层实现为：

```c++
inline jint     Atomic::cmpxchg    (jint     exchange_value, volatile jint*     dest, jint     compare_value) {
  int mp = os::is_MP();// 用于判断是否有多个处理器，如果是则mp为1，否则mp为0
  __asm__ volatile (LOCK_IF_MP(%4) "cmpxchgl %1,(%3)"
                    : "=a" (exchange_value)
                    : "r" (exchange_value), "a" (compare_value), "r" (dest), "r" (mp)
                    : "cc", "memory");
  return exchange_value;
}


"=a" (exchange_value) // 第1个输出参数。cmpxchgl指令执行结束后，将寄存器eax的值保存到exchange_value，在方法执行结束后返回
"r" (exchange_value) //  第1个输入参数。编译器会选择任意一个可用的寄存器来存储exchange_value，例如使用寄存器ecx。
"a" (compare_value) // 第2个输入参数。使用寄存器eax来存储待比较的值compare_value，执行cmpxchgl指令时会用到寄存器eax。
"r" (dest) // 第3个输入参数。编译器会选择任意一个可用的寄存器来存储目标地址dest，例如使用寄存器edx。
"r" (mp) //  第4个输入参数。编译器会选择任意一个可用的寄存器来存储多处理器标志
```

在这个方法中最关键的是一行代码是：LOCK_IF_MP(%4) "cmpxchgl %1,(%3)，cmpxchgl关键字就是汇编指令原语，这个原语在不同的计算机的实现不一样，在linux_x86就叫做cmpxchgl。

而cmpxchg方法可以理解为linux_x86平台对外提供cas支持的API。

这段代码中我们看到LOCK_IF_MP关键字，看到lock一般我们会想到加锁，这里确实是加锁的意思，或许你会说cas操作为什么还要加锁，如果这样，那直接用加锁的方式实现原子性不就可以了，这段代码的逻辑其实是先判断是否为多核处理器，如果是多核就会加锁，如果单核就不加锁。而这个加锁的实现根据系统平台的不同会有不同的实现方式，大致分为锁总线和锁缓存。

我们说了，一条机器指令（或者说汇编指令）一定能在一个cpu时间片段内完成，如果两个线程占据两个时间片，这个两个时间片段都是要执行同一个指令，当一个时间片段执行完，才能执行下一个时间片段，这样看起来单个指令的执行是串行的，不会有问题，但是现在的处理器一般都会存在多核，甚至多cpu，每个核都会有自己的缓存，所以，多核情况下仅仅靠cas是无法保证原子性的，操作系统内部通过锁来规避。



因此操作系统底层实际上还是会通过lock加锁的方式来保证操作的原子性(**多核CPU下存在cpu cache缓存一致性问题**)







#### Atomic原子类

J.U.C 包里面的整数原子类 `AtomicInteger`，其中的 `compareAndSet`() 和 `getAndIncrement`() 等方法都使用了 Unsafe 类的 CAS 操作,例如**AtomicInteger 类常用方法**如下所示：

```java
public final int get() //获取当前的值
public final int getAndSet(int newValue)//获取当前的值，并设置新的值
public final int getAndIncrement()//获取当前的值，并自增
public final int getAndDecrement() //获取当前的值，并自减
public final int getAndAdd(int delta) //获取当前的值，并加上预期的值
boolean compareAndSet(int expect, int update) //如果输入的数值等于预期值，则以原子方式将该值设置为输入值（update）
public final void lazySet(int newValue)//最终设置为newValue,使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。
```



以下代码使用了 `AtomicInteger` 执行了自增的操作：

```java
private AtomicInteger cnt = new AtomicInteger();

public void add() {
    cnt.incrementAndGet();
}
```

以下代码是 `incrementAndGet`() 的源码，它调用了 `unsafe` 的 `getAndAddInt`() 。

```java
public final int incrementAndGet() {
    return unsafe.getAndAddInt(this, valueOffset, 1) + 1;
}

//新版本jdk
public final int getAndIncrement() {
        return U.getAndAddInt(this, VALUE, 1);
    }
```

以下代码是 `getAndAddInt`() 源码,对于老版本的jdk:

var1 指示对象内存地址，var2 指示该字段相对对象内存地址的偏移，var4 指示操作需要加的数值，这里为 1。通过 `getIntVolatile`(var1, var2) 得到旧的预期值(可以理解为var1为被操作`object`在内存中的首地址，var2为偏移量`offset`)，通过调用 `compareAndSwapInt`() 来进行 CAS 比较，如果该字段内存地址中的值等于 var5，那么就更新内存地址为 var1+var2 的变量为 var5+var4，可以看到 `getAndAddInt`() 在一个循环中进行，发生冲突的做法是不断的进行重试：

```java
public final int getAndAddInt(Object var1, long var2, int var4) {
    int var5;
    do {
        var5 = this.getIntVolatile(var1, var2);
    } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));

    return var5;
}

//新版本jdk  看这个就行
public final int getAndAddInt(Object o, long offset, int delta) {
        int v;
        do {
            v = getIntVolatile(o, offset); 
        } while (!weakCompareAndSetInt(o, offset, v, v + delta));
        return v;
    }
```

而对于新版本jdk来说，`getAndAddInt()`首先通过 `getIntVolatile()`方法获取对象中offset偏移地址对应的整型field的值(*附加了volatile加载语义，也就是强制从主存中获取属性值*),然后通过`weakCompareAndSetInt()`来比较旧值v和当前值`value=func(o,offset)` (**因为第一次读取到的v后到修改该值前存在时间差，可能其他线程在这个时间间隔内提交了对该值的更新，此时如果直接修改将会产生线程安全问题**)，如果value和v相等，则说明可以更新，不相等则自旋再次尝试修改。

再举一个例子加深理解，**假设现在线程A和线程B同时执行getAndAdd操作(CPU采用时间片轮转方式)：**

1. `AtomicInteger`里面的`value`原始值为3，即主内存中`AtomicInteger`的`value`为3，**根据Java内存模型，线程A和线程B各自持有一份value的副本，值为3**
2. 线程A通过`getIntVolatile(var1, var2)`方法获取到value值3，线程切换，线程A挂起
3. 线程B通过`getIntVolatile(var1, var2)`方法获取到value值3，并利用`compareAndSwapInt`方法比较当前相应内存地址的值 也为3，比较成功，故修改内存值为2，**同时由于value被volatile修饰，被某一线程修改后会立即将新值同步到主存**，此时线程切换，线程B挂起
4. **线程A恢复，利用`compareAndSwapInt`方法比较，发现手里的值3和当前主内存中的值2不一致，**因为此时value正在被另外一个线程修改，线程A不能修改value值
5. 线程A的`compareAndSwapInt`无法实现，循环判断，**重新获取value值，因为value是volatile变量，所以线程对它的修改，线程A总是能够看到，线程A继续利用`compareAndSwapInt`进行比较并替换，**直到`compareAndSwapInt`修改成功后返回`true`





同理 `compareAndSwapObject`，`compareAndSwapLong`等其他方法也都大同小异





#### AtomicStampedReference



加入修改时间戳来解决ABA问题  :astonished:



CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效，从 JDK 1.5 开始，提供了`AtomicReference`类来保证引用对象之间的原子性，可以把多个变量放在一个`pair`对象里来进行 CAS 操作

CAS存在如下问题：如果一个变量初次读取的时候是 A 值，它的值被改成了 B，后来又被改回为 A，那 CAS 操作就会误认为它从来没有被改变过，即**`ABA`问题**，JUC提供带有标记的原子引用类 `AtomicStampedReference` 来解决这个问题，它通过控制变量值的版本，原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可以解决使用 CAS 进行原子更新时可能出现的 `ABA` 问题:

`AtomicStampedReference`主要维护包含一个对象引用以及一个可以自动更新的整数"stamp"的pair对象

```java
public class AtomicStampedReference<V> {
    private static class Pair<T> {
        final T reference;  //维护对象引用
        final int stamp;  //用于标志版本
        private Pair(T reference, int stamp) {
            this.reference = reference;
            this.stamp = stamp;
        }
        static <T> Pair<T> of(T reference, int stamp) {
            return new Pair<T>(reference, stamp);
        }
    }
    private volatile Pair<V> pair;
    ....
    
    /**
      * expectedReference ：更新之前的原始值
      * newReference : 将要更新的新值
      * expectedStamp : 期待更新的标志版本
      * newStamp : 将要更新的标志版本
      */
    public boolean compareAndSet(V   expectedReference,
                             V   newReference,
                             int expectedStamp,
                             int newStamp) 
    {
        // 获取当前的(元素值，版本号)对
        Pair<V> current = pair;
        return
            // 引用没变
            expectedReference == current.reference &&
            // 版本号没变
            expectedStamp == current.stamp &&
            // 新引用等于旧引用
            ((newReference == current.reference &&
            // 新版本号等于旧版本号
            newStamp == current.stamp) ||
            // 构造新的Pair对象并CAS更新
            casPair(current, Pair.of(newReference, newStamp)));
    }

    private boolean casPair(Pair<V> cmp, Pair<V> val) {
        // 调用Unsafe的compareAndSwapObject()方法CAS更新pair的引用为新引用
        return UNSAFE.compareAndSwapObject(this, pairOffset, cmp, val);
    }
```

 :100: 分析以上代码：先将所要修改的`object`值与一个`pair`对象相关联起来，这个`pair`包含了一个成员属性`stamp`戳用来标记版本号，然后在修改此`object`时(实际上是修改pair引用)通过CAS原理同时比较引用与`Stamp`时间戳的值，如果都未发生变化，则提交修改

对于ABA问题，假设线程A、B、C操作一个`Object`，线程A率先进入`compareAndSet()`方法，此时让出时间片，线程B、C执行了修改object操作并提交，保证Object在经两次修改后值未变 。这是线程A再次拿到CPU使用权，在CAS比较 `pair.Reference`时没有问题，而CAS比较版本戳`Stamp`时，会发现`expectedStamp != current.stamp`,因为线程B、C提交了对object的修改后会立刻刷新至主存，此时线程A就会自旋再次尝试更新 



同时 `AtomicReference`引用类型原子类、`AtomicMarkableReference`原子更新带有标记的引用类型也是类似的

>  **AtomicStampedReference 如何解决ABA问题** ? 

思路很简单，每次`compareAndSwap`后给数据的版本号加1，下次`compareAndSwap`的时候不仅比较数据，也比较版本号，值相同，版本号不同也不能执行成功。`Java`中提供了`AtomicStampedReference`来解决该问题：

```java
public static void main(String[] args) {
    final AtomicStampedReference<Integer> count = new AtomicStampedReference<>(5, 1);

    for (int i = 0; i < 2; i++) {
        Thread thread = new Thread(() -> {
            try {
                Thread.sleep(10);
            } catch (Exception ignore) {
            }

            boolean re = count.compareAndSet(5, 10, 1, 2);
            System.out.println(Thread.currentThread().getName() + "[recharge] compareAndSet " + re);
        });
        thread.start();
    }

    Thread thread = new Thread(() -> {
        try {
            Thread.sleep(10);
        } catch (Exception ignore) {
        }
        boolean re = count.compareAndSet(10, 5, count.getStamp(), count.getStamp() + 1);
        System.out.println(Thread.currentThread().getName() + "[consume] compareAndSet " + re);
    });
    thread.start();
}
```



解决ABA问题的核心是`AtomicStampedReference`的`compareAndSet`函数，这里面有四个参数：

`compareAndSet(V expectedReference, V newReference, int expectedStamp, int newStamp)`：

（1）第一个参数expectedReference：表示预期值。

（2）第二个参数newReference：表示要更新的值。

（3）第三个参数expectedStamp：表示预期的时间戳。

（4）第四个参数newStamp：表示要更新的时间戳。

其实就是加了时间戳版本号来区分不同时期的修改操作









## AQS 重要✨✨

AQS其实是一个抽象类，它实现了线程挂起的逻辑，实现了线程存储机制，实现了锁的状态逻辑，实现了线程唤醒的逻辑，却只定义了线程抢锁和释放锁的抽象，这样做的目的是将抢锁和释放锁的逻辑交给子类来实现，这样有助于实现各种不同特性的锁，比如共享锁，独占锁，公平锁，非公平锁，可重入等。并且以模板方法模式将上述上锁流程和释放锁流程封装为固定模板方法。所以AQS就是一个多线程访问共享资源的**同步器框架**

AQS实现同步机制有两种模式，一种是独占模式，一种是共享模式。两种模式分别提供提供两个模板方法实现。四个模板方法为`acquire`，`release`，`acquireShared`，`releaseShared`

独占模式的锁是只允许一个线程持有锁

共享模式的锁是允许多余一个的线程持有锁



AQS框架借助于两个类：`Unsafe`(提供`CAS`操作)和`LockSupport`(提供`park`/`unpark`操作)

`AQS` 核心思想是：如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态;如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 `AQS` 是用`CLH`队列锁实现的，即将暂时获取不到锁的线程加入到队列中



### LockSupport

由于AQS中队列元素操作涉及到`park`()、`unpark`()方法，故需要先来学习下`LockSupport`类

`LockSupport`的核心函数都是基于`Unsafe`类中定义的`park`和`unpark`函数，下面给出`Unsafe`类中两个函数的定义:

```java
public native void park(boolean isAbsolute, long time);
public native void unpark(Thread thread);
```



#### wait/notify

`wait`() 与 `notify/notifyAll()` 是`Object`类的方法，在执行两个方法时，要先获得锁， 经常与`synchronized`搭配使用，即在`synchronized`修饰的同步代码块或方法里面调用`wait()` 与 `notify/notifyAll()`方法:

- 当线程执行wait()时，会把当前的锁释放，然后让出CPU，进入等待状态
- 当执行notify/notifyAll方法时，会唤醒一个处于等待该对象锁的线程，**然后继续往下执行，直到执行完退出对象锁锁住的区域（`synchronized`修饰的代码块）后再释放锁**
- 无论是执行对象的 wait、notify 还是 notifyAll 方法，**必须保证当前运行的线程取得了该对象的监视器控制权（monitor）**,即前提是当前线程已经获取到对象的锁，**也就是`wait/notify`方法必须在`synchronized`修饰的代码块或者方法中使用**



**使用wait/notify实现线程同步:**

例1：

```java
    public static void main(String[] args) throws InterruptedException {
        Object lock1 = new Object();
        Thread t1 = new Thread(new Test().new Tt1(lock1));
        Thread t2 = new Thread(new Test().new Tt2(lock1));
        t1.start();
        Thread.sleep(1000);
        t2.start();
    }
    class Tt1 implements Runnable{

        private Object lock1;
        public Tt1(Object lock1) {
            this.lock1 = lock1;
        }
        @Override
        public void run() {
            try {
                System.out.println(this.getClass()+"-------1");
                synchronized (lock1) {
                    Thread.sleep(2000);
                    System.out.println("waiting start");
                    lock1.wait();
                }
                System.out.println("waiting end");
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }
    
    class Tt2 implements Runnable{

        private Object lock1;
        public Tt2(Object lock1) {
            this.lock1 = lock1;
        }
        @Override
        public void run() {
            System.out.println(this.getClass()+"-------1");
            synchronized (lock1) {
                try {
                    System.out.println(this.getClass()+"-------2");
                    lock1.notify(); //对象锁调用notify()
                    Thread.sleep(1000);
                    System.out.println(this.getClass()+"-------3");
                } catch (Exception e) {
                    e.printStackTrace();
                }
            }
            
        }
    }
```

简单分析一下

(1) t1和t2先后启动(t1启动后主线程睡眠)，t1先获取到lock1锁,然后t1调用`sleep`()方法，但是sleep并不会释放锁，所以t2启动后暂时无法获取到lock1锁导致一直被阻塞住；
(2) t1中执行了`wait()`导致锁lock1被释放，所以t2获取到锁执行下去；
(3) t2中调用了`notify()`但是并不会马上释放锁(待同步代码执行完后才释放)，t1没有马上执行等t2执行完成释放锁后，t1继续执行 `System.out.println("waiting end");`



例2:

```java
class MyThread extends Thread {
    
    public void run() {
        synchronized (this) {
            System.out.println("before notify");   //sout2         
            notify();
            System.out.println("after notify");    //sout3
        }
    }
}

public class WaitAndNotifyDemo {
    public static void main(String[] args) throws InterruptedException {
        MyThread myThread = new MyThread();            
        synchronized (myThread) {
            try { //进入该同步代码块时主线程拿到了myThread对象锁
                myThread.start();//	开启子线程
                Thread.sleep(3000);// 主线程睡眠3s,并不释放锁
                System.out.println("before wait"); //sout1
                myThread.wait();// 阻塞主线程
                System.out.println("after wait");  //sout4
            } catch (InterruptedException e) {
                e.printStackTrace();
            }            
        }        
    }
}
```

运行结果如下：

```
before wait
before notify
after notify
after wait
```



#### park/unpark

park方法是线程阻塞的方法，可以使当前线程进入等待状态，直到被其他线程唤醒。park方法有多个重载方法，其中最常用的是park()方法，该方法会使当前线程进入等待状态，直到被其他线程使用unpark方法唤醒。park方法还可以传入一个Object类型的参数，用于标识当前线程等待的条件，当该条件满足时，线程会被唤醒。

unpark方法是线程唤醒的方法，可以唤醒指定的线程。unpark方法也有多个重载方法，其中最常用的是unpark(Thread thread)方法，该方法可以唤醒指定的线程。**如果该线程之前调用了park方法进入等待状态，那么它会被唤醒；如果该线程还没有调用park方法，那么它在调用park方法之后会立即返回**

unpark函数为线程提供“许可(permit)”，线程调用park函数则等待“许可”。这个有点像信号量，但是这个“许可”是不能叠加的，“许可”是一次性的,比如线程B连续调用了三次unpark函数，此时线程A调用park函数就使用掉这个“许可”，如果线程A再次调用park，则进入等待状态，这是`park/unpark`不同于`wait/notify`之处

**注意，unpark函数可以先于park调用。比如线程B调用unpark函数，给线程A发了一个“许可”，那么当线程A调用park时，它发现已经有“许可”了，那么它会马上再继续运行**



**`park/unpark`实现线程同步**



例子1：

```java
import java.util.concurrent.locks.LockSupport;

public class ParkDemo {

    public static void main(String[] args) {
        Thread thread1 = new Thread(() -> {
            System.out.println("Thread 1 is waiting...");
            LockSupport.park(); // 线程1等待
            System.out.println("Thread 1 is awakened.");
        });

        Thread thread2 = new Thread(() -> {
            System.out.println("Thread 2 is waiting...");
            LockSupport.park(); // 线程2等待
            System.out.println("Thread 2 is awakened.");
        });

        thread1.start();
        thread2.start();

        try {
            System.out.println("wait 2 s.");
            Thread.sleep(2000); // 等待2秒钟
        } catch (InterruptedException e) {
            e.printStackTrace();
        }

        LockSupport.unpark(thread1); // 唤醒线程1
        LockSupport.unpark(thread2); // 唤醒线程2
    }
}
```

在上面的代码中，我们创建了两个线程thread1和thread2，它们都调用了LockSupport.park()方法进入等待状态。然后我们等待了2秒钟，之后在主线程调用`LockSupport.unpark()`方法来分别唤醒线程1和线程2,当线程被唤醒时，它们会继续执行各自后面的代码，结果如下：

```
Thread 1 is waiting...
Thread 2 is waiting...
wait 2 s.
Thread 1 is awakened.
Thread 2 is awakened.
```



例子2：

```java
import java.util.concurrent.locks.LockSupport;

class MyThread extends Thread {
    private Object object;

    public MyThread(Object object) {
        this.object = object;
    }

    public void run() {
        System.out.println("before unpark");
        try {
            Thread.sleep(1000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        // 获取blocker
        System.out.println("Blocker info " + LockSupport.getBlocker((Thread) object));
        // 释放许可
        LockSupport.unpark((Thread) object);
        // 休眠500ms，保证先执行park中的setBlocker(t, null);
        try {
            Thread.sleep(500);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        // 再次获取blocker
        System.out.println("Blocker info " + LockSupport.getBlocker((Thread) object));

        System.out.println("after unpark");
    }
}

public class test {
    public static void main(String[] args) {
        MyThread myThread = new MyThread(Thread.currentThread());
        myThread.start();
        System.out.println("before park");
        // 获取许可
        LockSupport.park("ParkAndUnparkDemo");
        System.out.println("after park");
    }
}
```

结果如下：

```
before park
before unpark
Blocker info ParkAndUnparkDemo
after park
Blocker info null
after unpark
```





###  资源共享方式 :1234:

AQS内部使用了一个`volatile`的变量`state`来作为资源的标识。同时定义了几个获取和改变state的protected方法，子类可以覆盖这些方法来实现自己的逻辑：

```java
getState()
setState()
compareAndSetState()
```

这三种操作均是原子操作，其中`compareAndSetState`的实现依赖于Unsafe的`compareAndSwapInt`()方法。

而AQS类本身实现的是一些排队和阻塞的机制，比如具体线程等待队列的维护（如获取资源失败入队/唤醒出队等）。它内部使用了一个先进先出（FIFO）的双端队列，并使用了两个指针head和tail用于标识队列的头部和尾部。其数据结构如图：

<img src="https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/thread/aqs-c294b5e3-69ef-49bb-ac56-f825894746ab.png" alt="img" style="zoom:67%;" />



但它并不是直接储存线程，而是储存拥有线程的Node节点





`AQS` 定义了两种资源共享方式：

`Exclusive`（独占，一次只有一个线程能执行，如`ReentrantLock`）

`Share`（共享，多个线程可同时执行，如`Semaphore`/`CountDownLatch`,具体的资源个数可以通过参数指定）



一般情况下，子类只需要根据需求实现其中一种模式，当然也有同时实现两种模式的同步类，如`ReadWriteLock`



`AQS`中关于这两种资源共享模式的定义源码（均在内部类Node中）。我们来看看`Node`的结构：

```java
static final class Node {
    // 标记一个结点（对应的线程）在共享模式下等待
    static final Node SHARED = new Node();
    // 标记一个结点（对应的线程）在独占模式下等待
    static final Node EXCLUSIVE = null; 

    // waitStatus的值，表示该结点（对应的线程）已被取消
    static final int CANCELLED = 1; 
    // waitStatus的值，表示后继结点（对应的线程）需要被唤醒
    static final int SIGNAL = -1;
    // waitStatus的值，表示该结点（对应的线程）在等待某一条件
    static final int CONDITION = -2;
    /*waitStatus的值，表示有资源可用，新head结点需要继续唤醒后继结点（共享模式下，多线程并发释放资源，而head唤醒其后继结点后，需要把多出来的资源留给后面的结点；设置新的head结点时，会继续唤醒其后继结点）*/
    static final int PROPAGATE = -3;

    // 等待状态，取值范围，-3，-2，-1，0，1
    volatile int waitStatus;
    volatile Node prev; // 前驱结点
    volatile Node next; // 后继结点
    volatile Thread thread; // 结点对应的线程
    Node nextWaiter; // 等待队列里下一个等待条件的结点

    
    // 判断共享模式的方法
    final boolean isShared() {
        return nextWaiter == SHARED;
    }
    
    Node(Thread thread, Node mode) {     // Used by addWaiter
        this.nextWaiter = mode;
        this.thread = thread;
    }
    
    // 其它方法忽略，可以参考具体的源码
}

// AQS里面的addWaiter私有方法
private Node addWaiter(Node mode) {
    // 使用了Node的这个构造函数
    Node node = new Node(Thread.currentThread(), mode);
    // 其它代码省略
}
```



> 注意：通过Node我们可以实现两个队列，一是通过prev和next实现CLH队列(线程同步队列,双向队列)，**二是nextWaiter实现Condition条件上的等待线程队列(单向队列)，这个Condition主要用在ReentrantLock类中(这里我们先不重点关注它)**





不同的自定义同步器争用共享资源的方式也不同，**自定义同步器在实现时只需要实现共享资源state的获取与释放方式即可**，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS的设计是基于**模板方法模式**的，它有一些方法必须要子类去实现的，主要有：

- `isHeldExclusively()`：该线程是否正在独占资源 。用到`condition`才需要实现
- `tryAcquire(int)`：独占方式。尝试获取资源，成功则返回true，失败则返回false
- `tryRelease(int)`：独占方式。尝试释放资源，成功则返回true，失败则返回false
- `tryAcquireShared(int)`：共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源
- `tryReleaseShared(int)`：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false





`AQS` 使用 **int 成员变量 `state` 表示同步状态**:(有些地方是`status`，一个概念)

```java
private volatile int state; //volatile修饰保证线程可见性
```





:exclamation: :grey_exclamation: :heavy_exclamation_mark:  **一定注意： State在不同的同步器实现下所代表的含义是不同的**

> AQS中的state是表示同步状态的一个整数值，用于管理和控制同步器的状态和线程的访问。
>
> 在AQS中，state的含义和用途取决于具体的同步器的实现。通常情况下，state可以有以下几种用途：
>
> 1. **代表资源的可用数量**：在一些同步器中，state可以表示某种资源的可用数量，例如Semaphore（信号量）同步器中的state表示可用的许可数。线程在获取资源时，会尝试将state减少，当state为0时，表示资源已经耗尽。
> 2. **代表锁的状态**：**在独占锁（如ReentrantLock）的同步器中，state通常表示锁的状态，比如0表示未锁定，1表示锁定**。线程在获取锁时，会尝试将state从0修改为1，获取锁成功后再将state设置回0以释放锁。
> 3. 记录线程数量：在某些同步器中，state可以用于记录当前在同步器上等待的线程数量。线程进入同步器等待时，会将state增加，退出等待时会将state减少。







另外，状态信息 `state` 可以通过 `protected` 类型的`getState()`、`setState()`和`compareAndSetState()` 进行操作,并且这几个方法都是 `final` 修饰的，在子类中无法被重写

```java
//返回同步状态的当前值
protected final int getState() {
     return state;
}
 // 设置同步状态的值
protected final void setState(int newState) {
     state = newState;
}
//原子地（CAS操作）将同步状态值设置为给定值update如果当前同步状态的值等于expect（期望值）
protected final boolean compareAndSetState(int expect, int update) {
      return unsafe.compareAndSwapInt(this, stateOffset, expect, update);
}
```

以 `ReentrantLock` 为例，`state` 初始值为 0，表示未锁定状态。A 线程 `lock()` 时，会调用 `tryAcquire()` 独占该锁并将 `state+1` 。此后，其他线程再 `tryAcquire()` 时就会失败，直到 A 线程 `unlock()` 到 `state=0`（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A 线程自己是可以重复获取此锁的（`state` 会累加），这就是可重入的概念。但要注意，获取多少次就要释放多少次，这样才能保证 state 是能回到零态的

再以 `CountDownLatch` 以例，任务分为 N 个子线程去执行，`state` 也初始化为 N（注意 N 要与线程个数一致）且这 N 个子线程是并行执行的，每个子线程执行完后`countDown()` 一次，state 会经`CAS`操作 减1 ； 等到所有子线程都执行完后(即 `state=0` )，会 `unpark()` 解锁主调用线程，然后主调用线程就会从 `await()` 函数返回，继续后余动作







#### Exclusive



`Exclusive`模式下获取共享资源的流程如下：



1、 `acquire(int)`方法是独占模式下线程获取共享资源的顶层入口(相当于lock())。如果获取到资源，线程直接返回，否则进入等待队列，直到获取到资源为止:

```java
public final void acquire(int arg) {
2     if (!tryAcquire(arg) &&// tryAcuire()为1，即新线程抢占到资源后就直接退出了
3         acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
4         selfInterrupt();
5 }

```

1. `tryAcquire()`尝试**直接去获取资源，如果成功则直接返回(这里体现了非公平锁，每个线程获取锁时会尝试直接抢占加塞一次，而CLH队列中可能还有别的线程在等待)**；
2. **`addWaiter`()将该获取资源失败的线程加入等待队列的尾部，并标记为独占模式**；
3. `acquireQueued`()使线程阻塞在等待队列中获取资源，一直获取到资源后才返回。如果在整个等待过程中被中断过，则返回`true`，否则返回`false`
4. 如果线程在等待过程中被中断过，它是不响应的。只是获取资源后才再进行自我中断`selfInterrupt()`，将中断补上

2、`tryAcquire(int)` 此方法尝试去获取独占资源。如果获取成功，则直接返回`true`，否则直接返回`false`

```java
protected boolean tryAcquire(int arg) {
2         throw new UnsupportedOperationException();
3     }
```

3、`addWaiter(Node)`

```JAVA
private Node addWaiter(Node mode) {
    // 生成该线程对应的Node节点
    Node node = new Node(Thread.currentThread(), mode);
    // 将Node插入队列中
    Node pred = tail;
    if (pred != null) {
        node.prev = pred;
        // 使用CAS尝试，如果成功就返回
        if (compareAndSetTail(pred, node)) {
            pred.next = node;
            return node;
        }
    }
    // 如果等待队列为空或者上述CAS失败，再自旋CAS插入
    enq(node);
    return node;
}

// 自旋CAS插入等待队列
private Node enq(final Node node) {
    for (;;) {
        Node t = tail;
        if (t == null) { // Must initialize
            if (compareAndSetHead(new Node()))
                tail = head;
        } else {
            node.prev = t;
            if (compareAndSetTail(t, node)) {
                t.next = node;
                return t;
            }
        }
    }
}

```

> 上面的两个函数比较好理解，就是在等待队列的尾部插入新的Node节点，但是需要注意的是由于AQS中会存在多个线程同时争夺资源的情况，因此肯定会出现多个线程同时插入节点的操作，在这里是通过CAS自旋的方式保证了操作的线程安全性，且保证了该线程对应节点一定能够入队成功





4、`acquireQueued(Node, int)`

通过`tryAcquire`()和`addWaiter`()，该线程获取资源失败，已经被放入等待队列尾部了,**进入等待状态休息，直到其他线程彻底释放资源后唤醒自己**

```java
final boolean acquireQueued(final Node node, int arg) {
    boolean failed = true;//标记是否成功拿到资源
    try {
        boolean interrupted = false;//标记等待过程中是否被中断过

        //又是一个“自旋”！
        for (;;) {
            final Node p = node.predecessor();//拿到前驱
            //如果前驱是head，即该结点已成老二，那么便有资格去尝试获取资源（可能是老大释放完资源唤醒自己的，当然也可能被interrupt了）。
            if (p == head && tryAcquire(arg)) {
                setHead(node);//拿到资源后，将head指向该结点。所以head所指的标杆结点，就是当前获取到资源的那个结点或null。
                p.next = null; // setHead中node.prev已置为null，此处再将head.next置为null，就是为了方便GC回收以前的head结点。也就意味着之前拿完资源的结点出队了！
                failed = false; // 成功获取资源
                return interrupted;//返回等待过程中是否被中断过
            }

            //如果自己可以休息了，就通过park()进入waiting状态，直到被unpark()。如果不可中断的情况下被中断了，那么会从park()中醒过来，发现拿不到资源，从而继续进入park()等待。
            if (shouldParkAfterFailedAcquire(p, node) &&
                parkAndCheckInterrupt())
                interrupted = true;//如果等待过程中被中断过，哪怕只有那么一次，就将interrupted标记为true
        }
    } finally {
        if (failed) // 如果等待过程中没有成功获取资源（如timeout，或者可中断的情况下被中断了），那么取消结点在队列中的等待。
            cancelAcquire(node);
    }
}
```

所以**结点进入等待队列后，是调用park使它进入阻塞状态的。只有头结点的线程是处于活跃状态的**。



总结下流程：

1. 调用自定义同步器的`tryAcquire()`尝试直接去获取资源，如果成功则直接返回；
2. 没成功，则`addWaiter()`将该线程加入等待队列的尾部，并标记为独占模式；
3. `acquireQueued()`使线程在等待队列中休息，有**机会时（轮到自己，会被unpark()）会去尝试获取资源**,获取到资源后才返回。如果在整个等待过程中被中断过，则返回true，否则返回false
4. 如果线程在等待过程中被中断过，它是不响应的,只是获取资源后才再进行自我中断`selfInterrupt()`，将中断补上

`acquire()`的流程也是`ReentrantLock.lock()`的流程，整个函数就是``acquire(1)`!!!

<img src="https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/thread/aqs-a0689bb2-9b18-419d-9617-6d292fbd439d.jpg" alt="acquire流程" style="zoom: 67%;" />













**`Exclusive`模式下释放共享资源的流程如下：**

1、`release(int)`： 此方法是独占模式下线程释放共享资源的顶层入口。它会释放指定量的资源，如果彻底释放了（即state=0）,它会唤醒等待队列里的其他线程来获取资源。这也正是`unlock()`的语义

```java
public final boolean release(int arg) {
    if (tryRelease(arg)) {//调用tryRelease()来释放资源
        Node h = head;//找到头结点
        if (h != null && h.waitStatus != 0)
            unparkSuccessor(h);//唤醒等待队列里的下一个线程!
        return true;
    }
    return false;
}
```



2、 `tryRelease(int)`:

跟`tryAcquire()`一样，这个方法是**需要独占模式的自定义同步器**去实现的。正常来说，tryRelease()都会成功的，因为这是独占模式，该线程来释放资源，那么它肯定已经拿到独占资源了，直接减掉相应量的资源即可(state-=arg)，也不需要考虑线程安全的问题。但要注意它的返回值，上面已经提到了，**release()是根据tryRelease()的返回值来判断该线程是否已经完成释放掉资源了！**所以自义定同步器在实现时，如果已经彻底释放资源(state=0)，要返回true，否则返回false

```java
1 protected boolean tryRelease(int arg) {
2     throw new UnsupportedOperationException();
3 }
```

3、`unparkSuccessor(Node node)`:此方法用于唤醒等待队列中下一个线程

```java
private void unparkSuccessor(Node node) {
    //这里，node一般为当前线程所在的结点。
    int ws = node.waitStatus;
    if (ws < 0)//置零当前线程所在的结点状态，允许失败。
        compareAndSetWaitStatus(node, ws, 0);

    Node s = node.next;//找到下一个需要唤醒的结点s
    if (s == null || s.waitStatus > 0) {//如果为空或已取消
        s = null;
        for (Node t = tail; t != null && t != node; t = t.prev) // 从后向前找。
            if (t.waitStatus <= 0)//从这里可以看出，<=0的结点，都是还有效的结点。
                s = t;
    }
    if (s != null)
        LockSupport.unpark(s.thread);//// 如果后继结点不为空，唤醒线程
}
```

`release()`是**独占模式**下线程释放共享资源的顶层入口,它会释放指定量的资源，如果彻底释放了（即state=0）,它会唤醒等待队列里的其他线程来获取资源







#### Share

获取共享资源：

1、 `acquireShared()`:此方法是共享模式下线程获取共享资源的顶层入口。它会获取指定量的资源，获取成功则直接返回，获取失败则进入等待队列，直到获取到资源为止，整个过程忽略中断。下面是`acquireShared()`的源码：

```java
 public final void acquireShared(int arg) {
     if (tryAcquireShared(arg) < 0)
         doAcquireShared(arg);
 }

//这里acquireShared()的流程就是：
//tryAcquireShared()尝试获取资源，成功则直接返回；
//失败则通过doAcquireShared()进入等待队列，直到获取到资源为止才返回
    
    
 public final boolean tryAcquireSharedNanos(int arg, long nanosTimeout)
            throws InterruptedException {
        if (!Thread.interrupted()) {
            if (tryAcquireShared(arg) >= 0)
                return true;
            if (nanosTimeout <= 0L)
                return false;
            int stat = acquire(null, arg, true, true, true,
                               System.nanoTime() + nanosTimeout);
            if (stat > 0)
                return true;
            if (stat == 0)
                return false;
        }
        throw new InterruptedException();
    }
```



2、`doAcquireShared()`:此方法用于将当前线程加入等待队列尾部休息，直到其他线程释放资源唤醒自己，自己成功拿到相应量的资源后才返回。下面是`doAcquireShared()`的源码：

```java
private void doAcquireShared(int arg) {
    final Node node = addWaiter(Node.SHARED);//加入队列尾部
    boolean failed = true;//是否成功标志
    try {
        boolean interrupted = false;//等待过程中是否被中断过的标志
        for (;;) {
            final Node p = node.predecessor();//前驱
            if (p == head) {//如果到head的下一个，因为head是拿到资源的线程，此时node被唤醒，很可能是head用完资源来唤醒自己的
                int r = tryAcquireShared(arg);//尝试获取资源
                if (r >= 0) {//成功
                    setHeadAndPropagate(node, r);//将head指向自己，还有剩余资源可以再唤醒之后的线程
                    p.next = null; // help GC
                    if (interrupted)//如果等待过程中被打断过，此时将中断补上。
                        selfInterrupt();
                    failed = false;
                    return;
                }
            }

            //判断状态，寻找安全点，进入waiting状态，等着被unpark()或interrupt()
            if (shouldParkAfterFailedAcquire(p, node) &&
                parkAndCheckInterrupt())
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
```

再梳理一下`acquireShared`的流程：

`tryAcquireShared`()尝试获取资源，成功则直接返回；

失败则通过`doAcquireShared`()进入等待队列`park`()，直到被`unpark`()/`interrupt`()并成功获取到资源才返回,整个等待过程也忽略中断





释放共享资源：

`releaseShared`()：方法是共享模式下线程释放共享资源的顶层入口。它会释放指定量的资源，如果成功释放且允许唤醒等待线程，它会唤醒等待队列里的其他线程来获取资源。下面是`releaseShared`()的源码：

```java
public final boolean releaseShared(int arg) {
    if (tryReleaseShared(arg)) {//尝试释放资源
        doReleaseShared();//唤醒后继结点
        return true;
    }
    return false;
}
```







### CLH队列

`AQS`通过内置的 **FIFO线程等待队列** 来完成获取资源线程的排队工作

CLH 锁是对自旋锁的一种改进，是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系），暂时获取不到锁的线程将被加入到该队列中。AQS 将每条请求共享资源的线程封装成一个 CLH 队列锁的一个结点（Node）来实现锁的分配：

- 内部通过节点`head`(实际上是虚拟节点，**真正的第一个线程在head.next的位置**)和`tail`记录队首和队尾元素，队列元素类型为`Node`;

- 在 CLH 队列锁中，一个节点表示一个线程，它保存着线程的引用（`thread`）、 当前节点在队列中的状态（`waitStatus`）、前驱节点（`prev`）、后继节点（`next`）;

- 如果当前线程获取同步状态失败（锁）时，`AQS` 则会将当前线程以及等待状态等信息构造成一个节点（`Node`）并将其加入等待队列，同时会阻塞当前线程



```java
static final class Node {
/** 等待线程超时或者被中断、需要从同步队列中取消等待（也就是放弃资源的竞争），此状态不会在改变 */
        static final int CANCELLED =  1;
        /** 后继节点会处于等待状态，当前节点线程如果释放同步状态或者被取消则会通知后继节点线程，使后继节点线程的得以运行 */
        static final int SIGNAL    = -1;
        /** 节点在等待队列中，线程在等待在Condition 上，其他线程对Condition调用singnal()方法后，该节点加入到同步队列中。 */
        static final int CONDITION = -2;
        /**
         * 表示下一次共享式获取同步状态的时会被无条件的传播下去。
         */
        static final int PROPAGATE = -3;

        /**等待状态*/
        volatile int waitStatus;

        /**前驱节点 */
        volatile Node prev;

        /**后继节点*/
        volatile Node next;

        /**获取同步状态的线程 */
        volatile Thread thread;

        /**链接下一个等待状态 */
        Node nextWaiter
}
```



#### 入队/出队

入队操作可分解成三步：

1. 将tail（使用CAS保证原子操作）指向新节点

2. 新节点的`prev`指向队列中最后一个节点（**旧的尾节点非tail节点**)
3. 原队列中最后一节点的`next`指针指向新节点以此来建立联系

先通过`addWaiter(Node mode)`方法尝试快速将该节点设置尾成尾节点，设置失败走`enq(final Node node)`方法

```JAVA
private Node addWaiter(Node mode) {
// 以给定的模式来构建节点， mode有两种模式 
//  共享式SHARED， 独占式EXCLUSIVE;
  Node node = new Node(Thread.currentThread(), mode);
    // 尝试快速将该节点加入到队列的尾部
    Node pred = tail;
     if (pred != null) {
        node.prev = pred;
            if (compareAndSetTail(pred, node)) {
                pred.next = node;
                return node;
            }
        }
        // 如果快速加入失败，则通过 enq方式入列
        enq(node);
        return node;
    }

private Node enq(final Node node) {
// CAS自旋，直到加入队尾成功        
for (;;) {
    Node t = tail;
        if (t == null) { // 如果队列为空，则必须先初始化CLH队列，新建一个空节点标识作为Hader节点,并将tail 指向它
            if (compareAndSetHead(new Node()))
                tail = head;
            } else {// 正常流程，加入队列尾部
                node.prev = t;
                    if (compareAndSetTail(t, node)) {
                        t.next = node;
                        return t;
                }
            }
        }
    }

```

通过“自旋”也就是死循环的方式来保证该节点能顺利的加入到队列尾部，只有加入成功才会退出循环，否则会一直循序直到成功

上述两个方法都是通过`compareAndSetHead(new Node())`方法来设置尾节点，以保证节点添加的线程安全



出队操作：同步队列（CLH）遵循FIFO，首节点是获取同步状态的节点，因此首节点的线程释放同步状态后，将会唤醒它的后继节点`next`，而后继节点将会在获取同步状态成功时将自己设置为首节点，在实现上直接将head指向新首节点(通过原首节点的`next`指针)并断开旧首节点与新首节点之前的连接就可以了







## 基于AQS实现的工具类 :computer:



AQS作为并发编程的框架，为很多其他同步工具提供了良好的解决方案。下面列出了JUC中的几种同步工具，大体介绍一下AQS的应用场景：

| 同步工具               | 同步工具与AQS的关联                                          |
| :--------------------- | :----------------------------------------------------------- |
| ReentrantLock          | 使用AQS保存锁重复持有的次数。当一个线程获取锁时，ReentrantLock记录当前获得锁的线程标识，用于检测是否重复获取，以及错误线程试图解锁操作时异常情况的处理。 |
| Semaphore              | 使用AQS同步状态来保存信号量的当前计数。tryRelease会增加计数，acquireShared会减少计数。 |
| CountDownLatch         | 使用AQS同步状态来表示计数。计数为0时，所有的Acquire操作（CountDownLatch的await方法）才可以通过。 |
| ReentrantReadWriteLock | 使用AQS同步状态中的16位保存写锁持有的次数，剩下的16位用于保存读锁的持有次数。 |
| ThreadPoolExecutor     | Worker利用AQS同步状态实现对独占线程变量的设置（tryAcquire和tryRelease）。 |





### ReentrantLock  (结合AQS看)



#### 可重入特性



> 如何实现的可重入性？

`ReentrantLock`重入锁，是实现Lock接口的一个类，**支持重入性，表示能够对共享资源能够重复加锁，即当前线程获取该锁再次获取不会被阻塞**。要想支持重入性，就要解决两个问题：

1. 在线程获取锁的时候，如果已经获取锁的线程是当前线程的话则直接再次获取成功；
2. 由于锁会被获取n次，那么只有锁在被释放同样的n次之后，该锁才算是完全释放成功。



我们知道，同步组件主要是通过重写AQS的几个protected方法来表达自己的同步语义。针对第一个问题，我们来看看`ReentrantLock`是怎样实现的，**以非公平锁为例(这里只是为了分析如何实现锁的可重入，至于公平/非公平如何实现下面再提及)**，判断当前线程能否获得锁为例，核心方法为`nonfairTryAcquire`：

```java
final boolean nonfairTryAcquire(int acquires) {
    final Thread current = Thread.currentThread();
    int c = getState();  //这里的state为0时，表示锁未被占用
    //1. 如果该锁未被任何线程占有，该锁能被当前线程获取
	if (c == 0) {
        if (compareAndSetState(0, acquires)) {
            setExclusiveOwnerThread(current);
            return true;
        }
    }
	//2.若被占有，检查占有线程是否是当前线程
    else if (current == getExclusiveOwnerThread()) {
		// 3. 再次获取，计数加一
        int nextc = c + acquires;
        if (nextc < 0) // overflow
            throw new Error("Maximum lock count exceeded");
        setState(nextc);
        return true;
    }
    return false;
}
```

> 对于 `c == 0` 的判断，它表示当前同步器的状态为0，即当前锁未被任何线程占有(**相当于锁的计数器**)。在这种情况下，可以尝试获取锁，即将锁状态从0修改为acquires（表示获得锁的计数）。如果 `compareAndSetState(0, acquires)` 成功，则表示当前线程成功获取了锁，然后会将锁的拥有者设置为当前线程（`setExclusiveOwnerThread(current)`），最后返回 true 表示获取成功。

为了支持重入性，在第二步增加了处理逻辑，如果该锁已经被线程所占有了，会继续检查占有线程是否为当前线程，如果是的话，同步状态加1返回true，表示可以再次获取成功。每次重新获取都会对同步状态进行加一的操作，那么释放的时候处理思路是怎样的了？（依然还是以非公平锁为例）核心方法为`tryRelease`：

```java
protected final boolean tryRelease(int releases) {
	//1. 同步状态减1
    int c = getState() - releases;
    if (Thread.currentThread() != getExclusiveOwnerThread())
        throw new IllegalMonitorStateException();
    boolean free = false;
    if (c == 0) {
		//2. 只有当同步状态为0时，锁成功被释放，返回true
        free = true;
        setExclusiveOwnerThread(null);
    }
	// 3. 锁未被完全释放，返回false
    setState(c);
    return free;
}

```

代码的逻辑请看注释，需要注意的是，重入锁的释放必须得等到同步状态为0时锁才算成功释放，否则锁仍未释放。如果锁被获取n次，释放了n-1次，该锁未完全释放返回false，只有被释放n次才算成功释放，返回true。到现在我们可以理清`ReentrantLock`重入性的实现了，也就是理解了同步语义的第一条。





####  Fair/NonFair



> 如何实现的公平/非公平？

`ReentrantLock`支持两种锁：**公平锁**和**非公平锁**。**何谓公平性，是针对获取锁而言的，如果一个锁是公平的，那么锁的获取顺序就应该符合请求上的绝对时间顺序，满足FIFO**。`ReentrantLock`的构造方法无参时是构造非公平锁，源码为：

```java
public ReentrantLock() {
    sync = new NonfairSync();
}
```

另外还提供了另外一种方式，可传入一个boolean值，true时为公平锁，false时为非公平锁，源码为：

```java
public ReentrantLock(boolean fair) {
    sync = fair ? new FairSync() : new NonfairSync();
}
```

可以看出来实现非公平/公平需要借助`FairSync`类和`NonfairSync`类来实现：



(1)我们来看看公平锁`FairSync`类中的处理逻辑是怎样的，核心方法为：

```java
protected final boolean tryAcquire(int acquires) {
    final Thread current = Thread.currentThread();
    int c = getState();
    if (c == 0) {
        if (!hasQueuedPredecessors() &&
            compareAndSetState(0, acquires)) {
            setExclusiveOwnerThread(current);
            return true;
        }
    }
    else if (current == getExclusiveOwnerThread()) {
        int nextc = c + acquires;
        if (nextc < 0)
            throw new Error("Maximum lock count exceeded");
        setState(nextc);
        return true;
    }
    return false;
}
```

这段代码的逻辑与`nonfairTryAcquire`基本上一直，唯一的不同在于增加了`hasQueuedPredecessors`的逻辑判断，方法名就可知道该方法用来判断当前节点在同步队列中是否有前驱节点的判断，如果有前驱节点说明有线程比当前线程更早的请求资源，根据公平性，当前线程请求资源失败。如果当前节点没有前驱节点的话，再才有做后面的逻辑判断的必要性。

即**公平锁每次都是从同步队列中的第一个节点获取到锁，而非公平性锁则不一定，有可能刚释放锁的线程能再次获取到锁**。



再来看看新版本jdk中如何实现锁获取的公平/非公平

1. `FairSync`

```java
protected final boolean tryAcquire(int acquires) {
            if (getState() == 0 && !hasQueuedPredecessors() &&
                compareAndSetState(0, acquires)) {
                setExclusiveOwnerThread(Thread.currentThread());
                return true;
            }
            return false;
        }
```



2. `NonfairSync`

```java
 protected final boolean tryAcquire(int acquires) {
            if (getState() == 0 && compareAndSetState(0, acquires)) {
                setExclusiveOwnerThread(Thread.currentThread());
                return true;
            }
            return false;
        }
```

  





#### 加锁/解锁

先来看看`NonFair`类中如何实现加锁的：

```java
// java.util.concurrent.locks.ReentrantLock#NonfairSync

// 非公平锁
static final class NonfairSync extends Sync {
	...
	final void lock() {
		if (compareAndSetState(0, 1))
			setExclusiveOwnerThread(Thread.currentThread());
		else
			acquire(1);
		}
  ...
}
```

这块代码的含义为：

- 若通过CAS设置变量State（同步状态）成功，也就是获取锁成功，则将当前线程设置为独占线程。
- 若通过CAS设置变量State（同步状态）失败，也就是获取锁失败，则进入Acquire方法进行后续处理。

第一步很好理解，但第二步获取锁失败后，后续的处理策略是怎么样的呢？这块可能会有以下思考：

- 某个线程获取锁失败的后续流程是什么呢？有以下两种可能：

(1) 将当前线程获锁结果设置为失败，获取锁流程结束。这种设计会极大降低系统的并发度，并不满足我们实际的需求。所以就需要下面这种流程，也就是AQS框架的处理流程。

(2) 存在某种排队等候机制，线程继续等待，仍然保留获取锁的可能，获取锁流程仍在继续。

- 对于问题1的第二种情况，既然说到了排队等候机制，那么就一定会有某种队列形成，这样的队列是什么数据结构呢？
- 处于排队等候机制中的线程，什么时候可以有机会获取锁呢？
- 如果处于排队等候机制中的线程一直无法获取锁，还是需要一直等待吗，还是有别的策略来解决这一问题?

着非公平锁的这些问题，再看下公平锁源码中获锁的方式：

```java
// java.util.concurrent.locks.ReentrantLock#FairSync

static final class FairSync extends Sync {
  ...  
	final void lock() {
		acquire(1);
	}
  ...
}
```

看到这块代码，我们可能会存在这种疑问：Lock函数通过Acquire方法进行加锁，但是具体是如何加锁的呢？

结合公平锁和非公平锁的加锁流程，虽然流程上有一定的不同，但是都调用了Acquire方法，而Acquire方法是FairSync和UnfairSync的父类AQS中的核心方法。

对于上边提到的问题，其实在`ReentrantLock`类源码中都无法解答，而这些问题的答案，都是位于Acquire方法所在的类`AbstractQueuedSynchronizer`中



为了帮助大家理解ReentrantLock和AQS之间方法的交互过程，以非公平锁为例，我们将加锁和解锁的交互流程单独拎出来强调一下，以便于对后续内容的理解：

加锁：

- 通过ReentrantLock的加锁方法Lock进行加锁操作。
- 会调用到内部类Sync的Lock方法，由于Sync#lock是抽象方法，根据ReentrantLock初始化选择的公平锁和非公平锁，执行相关内部类的Lock方法，本质上都会执行AQS的Acquire方法。
- AQS的Acquire方法会执行tryAcquire方法，但是由于tryAcquire需要自定义同步器实现，因此执行了ReentrantLock中的tryAcquire方法，由于ReentrantLock是通过公平锁和非公平锁内部类实现的tryAcquire方法，因此会根据锁类型不同，执行不同的tryAcquire。
- tryAcquire是获取锁逻辑，获取失败后，会执行框架AQS的后续逻辑，跟ReentrantLock自定义同步器无关。

解锁：

- 通过ReentrantLock的解锁方法Unlock进行解锁。
- Unlock会调用内部类Sync的Release方法，该方法继承于AQS。
- Release中会调用tryRelease方法，tryRelease需要自定义同步器实现，tryRelease只在ReentrantLock中的Sync实现，因此可以看出，释放锁的过程，并不区分是否为公平锁。
- 释放成功后，所有处理由AQS框架完成，与自定义同步器无关。







**总结：**

无论是公平or非公平锁，均要先判断state的状态是否为0(为0说明锁可以获取)，不同的是公平锁需要判断**该线程在CLH等待队列中对应的Node节点是否有前驱节点**，如果没有任何前驱节点说明为第一个有效节点，此时可以CAS尝试获取锁，而非公平就没有这个限制了，进入CLH队列的线程无需排队直接通过CAS自旋不断尝试获取锁







#### 与Synchronized异同

`ReentrantLock` 实现了 `Lock` 接口，是一个可重入且独占式的锁，`ReentrantLock` 里面有一个内部类 `Sync`，`Sync` 继承 **AQS**（`AbstractQueuedSynchronizer`），添加锁和释放锁的大部分操作实际上都是在 `Sync` 中实现的。`Sync` 有公平锁 `FairSync` 和非公平锁 `NonfairSync` 两个子类，它与`synchronized`的区别主要有以下几点：

1. `synchronized` 是依赖于 JVM 实现的，JDK1.6为 `synchronized` 关键字进行了很多优化(偏向锁、轻量级锁、适应性自旋锁 锁消除、锁粗化)，但是这些优化都是在虚拟机层面实现的，并没有直接暴露给用户

   `ReentrantLock` 是 JDK 层面实现的（也就是 API 层面，需要 lock() 和 unlock() 方法配合 try/finally 语句块来完成）

2. 加锁顺序不同:对于 Lock 而言如果有多把 Lock 锁，Lock 可以不完全按照加锁的反序解锁，比如我们可以先获取 Lock1 锁，再获取 Lock2 锁，解锁时则先解锁 Lock1，再解锁 Lock2，加解锁有一定的灵活度

   ```java
   lock1.lock();
   
   lock2.lock();
   
   ...
   
   lock1.unlock();
   
   lock2.unlock();
   ```

   而`synchronized` 解锁的顺序和加锁的顺序必须完全相反，例如：

   ```java
   synchronized(obj1){
   
       synchronized(obj2){
   
           ...
   
       }
   
   }
   ```

   顺序就是先对 obj1 加锁，然后对 obj2 加锁，然后对 obj2 解锁，最后解锁 obj1。这是因为 synchronized 加解锁是由 JVM 实现的，在执行完 synchronized 块后会自动解锁，所以会按照 synchronized 的嵌套顺序加解锁，不能自行控制

3. **是否可实现公平锁** : `ReentrantLock`可以指定是公平锁还是非公平锁。而`synchronized`只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。`ReentrantLock`默认情况是非公平的，可通过`ReentrantLock`类的`ReentrantLock(boolean fair)`构造方法来决定是否是公平的

   ```java
     public ReentrantLock(boolean fair) {
           sync = fair ? new FairSync() : new NonfairSync();
       }  
   //传入true则调用公平锁方法、false则调用非公平锁方法
   ```

4. 等待可中断：`ReentrantLock`提供了一种能够中断等待锁的线程的机制，通过 `lock.lockInterruptibly()` 来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情，即`ReentrantLock`是可中断的，而`synchronized` 锁被某个线程获得后，此时其他线程如果还想获得，那它只能被**阻塞**，直到持有锁的线程运行完毕或者发生异常从而释放这个锁















### ReentrantReadWriteLock



使用`ReentrantReadWriteLock`读写锁的方式，会调用`readLock()`和`writeLock()`两个方法，看下他们的源码：



ReadLock:

```java
public static class ReadLock implements Lock, java.io.Serializable {
    private static final long serialVersionUID = -5992448646407690164L;
    private final Sync sync; //继承了AQS类


    public void lock() {
        sync.acquireShared(1);  //AQS中的共享模式
    }
    
        public void unlock() {
        sync.releaseShared(1); //共享
    }
}       
```













WriteLock:

```java
public static class WriteLock implements Lock, java.io.Serializable {
    private static final long serialVersionUID = -4992448646407690164L;
    private final Sync sync;

    public void lock() {
        sync.acquire(1);  //AQS中的互斥模式
    }
    
     public void unlock() {
        sync.release(1); //独占
    }
    
}
```

实现写锁的同步语义是通过重写AQS中的tryAcquire方法实现的。源码为:

```java
protected final boolean tryAcquire(int acquires) {
    Thread current = Thread.currentThread();
	// 1. 获取写锁当前的同步状态
    int c = getState();
	// 2. 获取写锁获取的次数
    int w = exclusiveCount(c);
    if (c != 0) {
        // (Note: if c != 0 and w == 0 then shared count != 0)
		// 3.1 当读锁已被读线程获取或者当前线程不是已经获取写锁的线程的话
		// 当前线程获取写锁失败
        if (w == 0 || current != getExclusiveOwnerThread())
            return false;
        if (w + exclusiveCount(acquires) > MAX_COUNT)
            throw new Error("Maximum lock count exceeded");
        // Reentrant acquire
		// 3.2 当前线程获取写锁，支持可重复加锁
        setState(c + acquires);
        return true;
    }
	// 3.3 写锁未被任何线程获取，当前线程可获取写锁
    if (writerShouldBlock() ||
        !compareAndSetState(c, c + acquires))
        return false;
    setExclusiveOwnerThread(current);
    return true;
}

```

写锁释放通过重写AQS的tryRelease方法，源码为：

```java
protected final boolean tryRelease(int releases) {
    if (!isHeldExclusively())
        throw new IllegalMonitorStateException();
	//1. 同步状态减去写状态
    int nextc = getState() - releases;
	//2. 当前写状态是否为0，为0则释放写锁
    boolean free = exclusiveCount(nextc) == 0;
    if (free)
        setExclusiveOwnerThread(null);
	//3. 不为0则更新同步状态
    setState(nextc);
    return free;
}
```

源码的实现逻辑请看注释，不难理解与ReentrantLock基本一致，这里需要注意的是，减少写状态` int nextc = getState() - releases;`只需要用**当前同步状态直接减去写状态的原因正是我们刚才所说的写状态是由同步状态的低16位表示的**。







看到这里发现了ReentrantReadWriteLock和ReentrantLock的一个相同点和不同点，**相同的是使用了同一个关键实现AbstractQueuedSynchronizer，不同的是ReentrantReadWriteLock使用了两个锁分别实现了AQS，而且WriteLock和ReentrantLock一样，使用了独占锁。而ReadLock和Semaphore一样，使用了共享锁**。再往下的内容估计看过前面几篇文章的都很熟悉了，独占锁通过state变量的0和1两个状态来控制是否有线程占有锁，共享锁通过state变量0或者非0来控制多个线程访问。在上面的代码中，ReadLock和WriteLock使用了同一个AQS，那么在ReentrantReadWriteLock中又是怎么控制读锁和写锁关系的呢？





#### 设计State状态变量

读写锁同样依赖自定义同步器来实现同步功能，而读写状态就是其同步器的同步状态。回想ReentrantLock中自定义同步器的实现，同步状态表示锁被一个线程重复获取的次数，而读写锁的自定义同步器需要在同步状态（一个整型变量）上维护多个读线程和一个写线程的状态，使得该状态的设计成为读写锁实现的关键。如果在一个**整型变量**上维护多种状态，就一定需要“按位切割使用”这个变量，读写锁将变量切分成了两个部分，高16位表示读，低16位表示写，划分方式如下图所示:

<img src="https://img-blog.csdn.net/20170521115701777?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZnV5dXdlaTIwMTU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="读写锁状态" style="zoom:67%;" />

当前同步状态表示一个线程已经获取了写锁，且重进入了两次，同时也连续获取了两次读锁。读写锁是如何迅速确定读和写各自的状态呢？答案是通过位运算。假设当前同步状态值为S，写状态等于S&0x0000FFFF（将高16位全部抹去），读状态等于S>>>16（无符号补0右移16位）。当写状态增加1时，等于S+1，当读状态增加1时，等于S+(1<<16)，也就是S+0x00010000。

根据状态的划分能得出一个推论：**S不等于0时，当写状态（S&0x0000FFFF）等于0时，则读状态（S>>>16）大于0，即读锁已被获取**







#### 锁升级/降级

1、锁降级

锁降级指的是写锁降级成为读锁。如果当前线程拥有写锁，然后将其释放，最后再获取读锁，这种分段完成的过程不能称之为锁降级。**锁降级是指把持住（当前拥有的）写锁，再获取到读锁，随后释放（先前拥有的）写锁的过程。**

> 这样做主要是为了保证数据的可见性，如果当前线程在持有写锁的前提下：不先获取读锁而直接释放写锁，假设此刻另一个线程（T）获取了写锁并修改了数据，那么当前线程是无法感知线程T的数据更新。如果当前线程获取读锁，即遵循锁降级的步骤，则线程T将会被阻塞，知道当前线程使用数据并释放读锁之后，线程T才能获取写锁进行数据更新。

读写锁支持锁降级，**遵循按照获取写锁，获取读锁再释放写锁的次序，写锁能够降级成为读锁**，不支持锁升级，关于锁降级下面的示例代码摘自ReentrantWriteReadLock源码中：

```java
void processCachedData() {
    rwl.readLock().lock();
    if (!cacheValid) {
        // Must release read lock before acquiring write lock
        rwl.readLock().unlock();
        rwl.writeLock().lock();
        try {
            // Recheck state because another thread might have
            // acquired write lock and changed state before we did.
            if (!cacheValid) {
                data = ...
        cacheValid = true;
      }
      // Downgrade by acquiring read lock before releasing write lock
      rwl.readLock().lock();
    } finally {
      rwl.writeLock().unlock(); // Unlock write, still hold read
    }
  }

  try {
    use(data);
  } finally {
    rwl.readLock().unlock();
  }
}
```





2、锁升级

同一个线程中，在没有释放读锁的情况下，就去申请写锁，这属于锁升级，`ReentrantReadWriteLock`是不支持的。例如下述代码会产生死锁:

```java
 ReadWriteLock rtLock = new ReentrantReadWriteLock();
 rtLock.readLock().lock(); //获取读锁
 System.out.println("get readLock.");
 rtLock.writeLock().lock();//未释放读锁的前提下就去获取写锁
 System.out.println("blocking");
```



### StampedLock

https://segmentfault.com/a/1190000024540229



### Semaphore

`Synchronized` 和 `ReentrantLock(独占模式)` 都是一次只允许一个线程访问某个资源，而`Semaphore`(信号量)可以用来控制同时访问特定资源的线程数量(多个线程)，因此`Semaphore`是`AQS`在`Share`共享模式下的实现：

下面代码表示同一时刻 N 个线程中只有 5 个线程能获取到共享资源，其他线程都会阻塞，只有获取到共享资源的线程才能执行，等到有其他线程释放后，阻塞线程才能获取到共享资源：

```java
// 初始访问共享资源的线程数量
final Semaphore semaphore = new Semaphore(5);
// 线程获取1个许可
semaphore.acquire();

//线程获取指定数量的许可
semaphore.acquire(int permits);


// 线程释放1个许可
semaphore.release();
```

当初始的资源个数为 1 的时候，`Semaphore` 退化为排他锁`Synchronized`



`Semaphore` 有两种模式：

- **公平模式：** 调用 `acquire()` 方法的顺序就是获取许可的顺序，遵循 FIFO；
- **非公平模式：** 抢占式调度

`Semaphore` 其对应的两个构造方法(**这两个构造方法，都必须提供许可的数量**)如下：

```java
public Semaphore(int permits) {
  	sync = new NonfairSync(permits);
}

public Semaphore(int permits, boolean fair) {
  	sync = fair ? new FairSync(permits) : new NonfairSync(permits);
}
```



`Semaphore` 是共享锁的一种实现，它默认构造 `AQS` 的 `state` 值为 `permits`，可以将 `permits` 的值理解为许可证的数量，只有拿到许可证的线程才能执行操作，比如下列代码是实现`Fair`公平模式(默认非公平)下的`Semaphore`：

```java
//默认构造
 public Semaphore(int permits) {
        sync = new NonfairSync(permits);
    }
//公平模式
public Semaphore(int permits, boolean fair) {
        sync = fair ? new FairSync(permits) : new NonfairSync(permits);
    }

FairSync(int permits) {
            super(permits);
        }
Sync(int permits) {
            setState(permits);//调用AQS中的setState()
        }
protected final void setState(int newState) {
        state = newState;
    }
```



**获取许可：**

调用`semaphore.acquire()` ，线程尝试获取许可证，如果 `state >= 0` 的话，则表示可以获取成功。如果获取成功的话，使用 CAS 操作去修改 `state` 的值 `state=state-1`。如果 `state<0` 的话，则表示许可证数量不足，此时会创建一个 Node 节点加入阻塞队列，挂起当前线程

```java
/**
 *  获取1个许可证
 */
public void acquire() throws InterruptedException {
 	 sync.acquireSharedInterruptibly(1);
}
/**
 * 共享模式下获取许可证，获取成功则返回，失败则加入阻塞队列，挂起线程
 */
public final void acquireSharedInterruptibly(int arg)
    throws InterruptedException {
    if (Thread.interrupted())
      throw new InterruptedException();
        // 尝试获取许可证，arg为获取许可证个数，当可用许可证数减当前获取的许可证数(此处为1,因为只有1个线程)结果小于0时,则创建一个节点加入阻塞队列，挂起当前线程。
    if (tryAcquireShared(arg) < 0)
      doAcquireSharedInterruptibly(arg);
}

```



**释放许可：**

通过调用`semaphore.release();` 来使线程尝试释放许可证，并使用 CAS 去修改 `state` 的值 `state=state+1`。释放许可证成功之后，同时会唤醒同步队列中的一个线程。被唤醒的线程会重新尝试去CAS修改 `state` 的值 `state=state-1` ，如果 `state>=0` 则获取令牌成功，否则重新进入阻塞队列，挂起线程：

```java
// 释放一个许可证
public void release() {
  	sync.releaseShared(1);
}

// 释放共享锁，同时会唤醒同步队列中的一个线程  
public final boolean releaseShared(int arg) {
    //释放共享锁
    if (tryReleaseShared(arg)) {
      //唤醒同步队列中的一个线程
      doReleaseShared();
      return true;
    }
    return false;
}
//新版本的releaseShared()
public final boolean releaseShared(int arg) {
        if (tryReleaseShared(arg)) {
            signalNext(head);
            return true;
        }
        return false;
    }

//从阻塞队列中唤醒head节点
private static void signalNext(Node h) {
        Node s;
        if (h != null && (s = h.next) != null && s.status != 0) {
            s.getAndUnsetStatus(WAITING);
            LockSupport.unpark(s.waiter);
        }
    }
```



下面是一个`Semaphore`使用的例子:

首先生成一个信号量，该信号量有10个许可，然后，main，t1，t2三个线程获取许可运行

```java
import java.util.concurrent.Semaphore;

class MyThread extends Thread {
    private Semaphore semaphore;
    
    public MyThread(String name, Semaphore semaphore) {
        super(name);
        this.semaphore = semaphore;
    }
    
    public void run() {        
        int count = 3;
        System.out.println(Thread.currentThread().getName() + " trying to acquire");
        try {
            semaphore.acquire(count);
            System.out.println(Thread.currentThread().getName() + " acquire successfully");
            Thread.sleep(1000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        } finally {
            semaphore.release(count);
            System.out.println(Thread.currentThread().getName() + " release successfully");
        }
    }
}

public class SemaphoreDemo {
    public final static int SEM_SIZE = 10;
    
    public static void main(String[] args) {
        Semaphore semaphore = new Semaphore(SEM_SIZE);
        MyThread t1 = new MyThread("t1", semaphore);
        MyThread t2 = new MyThread("t2", semaphore);
        t1.start();
        t2.start();
        int permits = 5;
        System.out.println(Thread.currentThread().getName() + " trying to acquire");
        try {
            semaphore.acquire(permits);
            System.out.println(Thread.currentThread().getName() + " acquire successfully");
            Thread.sleep(1000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        } finally {
            semaphore.release();
            System.out.println(Thread.currentThread().getName() + " release successfully");
        }      
    }
}
```

输出结果为：

```
main trying to acquire
main acquire successfully
t1 trying to acquire
t1 acquire successfully
t2 trying to acquire   //t2在申请许可时数量不够用了
t1 release successfully
main release successfully
t2 acquire successfully
t2 release successfully
```



首先，`main`线程执行`acquire`操作，并且成功获得许可，之后t1线程执行`acquire`操作，成功获得许可，之后t2执行`acquire`操作，由于此时许可数量不够(2<3)，t2线程将会阻塞，直到许可可用。之后t1线程释放许可，main线程释放许可，此时的许可数量可以满足t2线程的要求，所以，此时t2线程会成功获得许可运行，t2运行完成后释放许可:

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/java-thread-x-semaphore-5.png)







使用Semaphore实现三个线程交替打印A、B、C字符：

```java
//使用Semaphore三个线程交替打印A、B、C

class  SemaphoreTest2{

 private static  final  Semaphore semaphoreA =new Semaphore(1);
 private static  final  Semaphore semaphoreB=new Semaphore(0);
 private static  final  Semaphore semaphoreC=new Semaphore(0);

    public static void main(String[] args) {

        new Thread(
                ()->{
                    print("A",semaphoreA,semaphoreB);
                }
        ,"ThreadA").start();

        new Thread(
                ()->{
                    print("B",semaphoreB,semaphoreC);
                }
                ,"ThreadB").start();

        new Thread(
                ()->{
                    print("C",semaphoreC,semaphoreA);
                }
                ,"ThreadC").start();
    }

   public static  void print(String message,Semaphore cur,Semaphore next)
   {

       for (int i = 0; i < 100; i++) {
           try {
               cur.acquire(1); //
           } catch (InterruptedException e) {
               throw new RuntimeException(e);
           }
           System.out.println(Thread.currentThread().getName()+"打印"+message+"第"+i+"次");
           next.release(); //为下一个等待该信号量的线程开绿灯
       }
   }
}
```









### CountDownLatch

`CountDownLatch` 也是共享锁的一种实现,它默认构造 `AQS` 的 `state` 值为 `count`

当线程使用 `countDown()` 方法时,其实使用了`tryReleaseShared`方法以 `CAS` 的操作来减少 `state`,直至 `state` 为 0；

当调用 `await()` 方法的时候，如果 `state` 不为 0，那就证明任务还没有执行完毕，`await()` 方法就会一直阻塞，也就是说 `await()` 方法之后的语句不会被执行。然后，`CountDownLatch` 会自旋 CAS 判断 `state == 0`，如果 `state == 0` 的话，就会释放所有等待的线程，`await()` 方法之后的语句得到执行





源码分析：

现在我们从源码分析一下`CountDownLatch`的工作原理，先来看看它的内部类**Sync**,在 `CountDownLatch` 类内部定义了一个 Sync 内部类，这个内部类就是继承自 `AbstractQueuedSynchronizer` 的。并且重写了方法 `tryAcquireShared`和`tryReleaseShared`：

```java
private static final class Sync extends AbstractQueuedSynchronizer {
    private static final long serialVersionUID = 4982264981922014374L;
    
    // 传入初始次数
    Sync(int count) {
        setState(count);
    }
    // 获取还剩的次数
    int getCount() {
        return getState();
    }
    // 尝试获取共享锁
    protected int tryAcquireShared(int acquires) {
        // 注意，这里state等于0的时候返回的是1，也就是说count减为0的时候获取总是成功
        // state不等于0的时候返回的是-1，也就是count不为0的时候总是要排队
        return (getState() == 0) ? 1 : -1;
    }
    // 尝试释放锁
    protected boolean tryReleaseShared(int releases) {
        for (;;) {
            // state的值
            int c = getState();
            // 等于0了，则无法再释放了
            if (c == 0)
                return false;
            // 将count的值减1
            int nextc = c-1;
            // 原子更新state的值
            if (compareAndSetState(c, nextc))
                // 减为0的时候返回true，这时会唤醒后面排队的线程
                return nextc == 0;
        }
    }
}
```



声明一个`CountDownLatch`对象需要传入**一个count，相当于AQS中的state**

```java
public CountDownLatch(int count) {
    this.sync = new Sync(count);
}

Sync(int count) {
    setState(count);
}

//最终还是调用AQS中的setState()
protected final void setState(int newState) {
    state = newState;
}
```





而当调用 `await()`方法时，`CountDownLatch` 会调用内部类 Sync 的 `acquireSharedInterruptibly() ` 方法，然后在这个方法中会调用 `tryAcquireShared` 方法，这个方法就是 `CountDownLatch` 的内部类 `Sync` 里重写的 `AbstractQueuedSynchronizer` 的方法。

调用 `countDown()` 方法同理会调用Sync类中的`tryReleaseShared`方法



await()方法

```java
// java.util.concurrent.CountDownLatch.await()
public void await() throws InterruptedException {
    // 调用AQS的acquireSharedInterruptibly()方法
    sync.acquireSharedInterruptibly(1);
}
// java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly()
public final void acquireSharedInterruptibly(int arg)
        throws InterruptedException {
    if (Thread.interrupted())
        throw new InterruptedException();
    // 尝试获取锁，如果失败则排队
    if (tryAcquireShared(arg) < 0)
        doAcquireSharedInterruptibly(arg);
}
```

await()方法是等待其它线程完成的方法，它会先尝试获取一下共享锁，如果失败则进入AQS的队列中排队等待被唤醒。

根据上面Sync的源码，我们知道，state不等于0的时候tryAcquireShared()返回的是-1，也就是说count未减到0的时候所有调用await()方法的线程都要排队。

 



countDown()方法

```java
// java.util.concurrent.CountDownLatch.countDown()
public void countDown() {
    // 调用AQS的释放共享锁方法
    sync.releaseShared(1);
}
// java.util.concurrent.locks.AbstractQueuedSynchronizer.releaseShared()
public final boolean releaseShared(int arg) {
    // 尝试释放共享锁，如果成功了，就唤醒排队的线程
    if (tryReleaseShared(arg)) {
        doReleaseShared();
        return true;
    }
    return false;
}
```

countDown()方法，会释放一个共享锁，也就是count的次数会减1。

根据上面Sync的源码，我们知道，tryReleaseShared()每次会把count的次数减1，当其减为0的时候返回true，这时候才会唤醒等待的线程。











来看一下`CountDownLatch`的用法：

假如现在要读取处理 6 个文件，这 6 个任务都是没有执行顺序依赖的任务，但是我们需要返回给用户的时候将这几个文件的处理的结果进行统计整理 。我们可以定义一个线程池和 `count` 为 6 的`CountDownLatch`对象 ，使用线程池处理读取任务，每一个线程处理完之后就将 `count-1`，调用`CountDownLatch`对象的 `await()`方法，直到所有文件读取完之后，才会接着执行后面的逻辑：

```java
public class CountDownLatchExample1 {
    // 处理文件的数量
    private static final int threadCount = 6;

    public static void main(String[] args) throws InterruptedException {
        // 创建一个具有固定线程数量的线程池对象（推荐使用构造方法创建）
        ExecutorService threadPool = Executors.newFixedThreadPool(10);
        final CountDownLatch countDownLatch = new CountDownLatch(threadCount);
        for (int i = 0; i < threadCount; i++) {
            final int threadnum = i;
            threadPool.execute(() -> {
                try {
                    //处理文件的业务操作
                    //......
                } catch (InterruptedException e) {
                    e.printStackTrace();
                } finally {
                    //表示一个文件已经被完成
                    countDownLatch.countDown();
                }

            });
        }
        countDownLatch.await(); //
        threadPool.shutdown();
        System.out.println("finish");
    }
}

```





例子2  在3个前置资源加载完成后，Main线程继续执行：

```java

public class CountDownLatchTest {
    
    private  static  final CountDownLatch count=new CountDownLatch(3);
    public static void main(String[] args) throws InterruptedException {

        System.out.println("主线程开始执行");
        new Thread(
                ()->{
                    count.countDown(); //共享模式下的释放
                    System.out.println(Thread.currentThread().getName()+"加载资源1");
                    System.out.println("还有"+count.getCount()+"个资源未加载完成");
                }
                ,"Thread1").start();

        new Thread(
                ()->{
                    try {
                        Thread.sleep(1000);
                    } catch (InterruptedException e) {
                        throw new RuntimeException(e);
                    }
                    count.countDown(); //共享模式下的释放
                    System.out.println(Thread.currentThread().getName()+"加载资源2");
                    System.out.println("还有"+count.getCount()+"个资源未加载完成");
                }
                ,"Thread2").start();
        new Thread(
                ()->{
                    try {
                        Thread.sleep(2000);
                    } catch (InterruptedException e) {
                        throw new RuntimeException(e);
                    }
                    count.countDown(); //共享模式下的释放
                    System.out.println(Thread.currentThread().getName()+"加载资源3");
                    System.out.println("还有"+count.getCount()+"个资源未加载完成");
                }
                ,"Thread3").start();

        count.await();
        System.out.println("前置资源加载完毕,主线程继续执行");
    }
}
```

控制台输出如下：

```
主线程开始执行
Thread1加载资源1
还有2个资源未加载完成
Thread2加载资源2
还有1个资源未加载完成
前置资源加载完毕,主线程继续执行
Thread3加载资源3
还有0个资源未加载完成
```



疑惑 :question: 

为什么`Thread3`还没有`countDown()`完成，主线程就已经开始继续执行了？

原因是CPU基于时间片轮转调度，





### CyclicBarrier









## Condition类

任何一个java对象都天然继承于Object类，在线程间实现通信的往往会应用到Object的几个方法：

- wait()
- wait(long timeout)
- wait(long timeout, int nanos)
- notify()
- notifyAll()

在java Lock体系下依然会有同样的方法实现等待/通知机制，整体上来看**Object的wait和notify/notify是与对象监视器配合完成线程间的等待/通知机制，而Condition与Lock配合完成等待通知机制，前者是java底层级别的，后者是语言级别的，具有更高的可控制性和扩展性**



`Condition`是在java 1.5中才出现的，它用来替代传统的Object的`wait()`、`notify()`实现线程间的协作，相比使用`Object`的`wait()`、`notify()`，使用`Condition`的`await()`、`signal()`这种方式实现线程间协作更加安全和高效：

- Condition是个接口，基本的方法就是await()和signal()方法；
- Condition依赖于Lock接口，生成一个Condition的基本代码是**lock.newCondition()**
- **调用Condition的await()和signal()方法，都必须在lock保护之内，就是说必须在lock.lock()和lock.unlock之间才可以使用，因为内部会做释放锁的操作，如果不是在lock和unlock之间使用，会报错`java.lang.IllegalMonitorStateException`**
- Conditon中的`await()`对应Object的`wait()`；signal()对应Object的`notify()`；Condition中的`signalAll()`对应Object的`notifyAll()`





### 条件队列



`AQS`内部有一个内部类`ConditionObject`，其内部维护了一个单向链表（先进先出），这个内部类内有两个属性：`firstWaiter`和`lastWaiter`分别指向单向链表的头结点和尾节点，这个单向链表就是条件队列，和等待队列的不同处是它的头节点是绑定线程的,条件队列的结构如下

![图片](https://mmbiz.qpic.cn/mmbiz_png/XpRTa39LHCWzhDXpHDJZ8MTjyzw8VsVTgVCLRmlq73GqwGzydF9CXpqoDFYicCJpOrvmZRPlZokIYhicibDvHJNpw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

前面我们说过，`condition`是要和lock配合使用的也就是condition和Lock是绑定在一起的，而lock的实现原理又依赖于AQS，自然而然`ConditionObject`就成为了AQS的一个内部类。

创建一个`condition`对象是通过`lock.newCondition()`,而这个方法实际上是会new出一个**`ConditionObject`**对象，该类是AQS的一个内部类。







在锁机制的实现上，**AQS内部维护了一个同步等待队列，如果是独占式锁的话，所有获取锁失败的线程的尾插入到同步等待队列，同样的，Condition内部也是使用同样的方式，每个`Condition`内部维护了一个条件队列**，所有调用`condition.await`方法的线程会加入到条件队列中，并且线程状态转换为等待状态。另外注意到`ConditionObject`中有两个成员变量：

```java
/** First node of condition queue. */
private transient Node firstWaiter;
/** Last node of condition queue. */
private transient Node lastWaiter;

```

可以看出来`ConditionObject`通过持有等待队列的`头尾指针`来管理条件队列，Node类有这样一个属性：

```JAVA
static final class ConditionNode extends Node{
ConditionNode nextWaiter;   
}
```

进一步说明，**条件队列是一个单向队列**，而在之前说AQS时知道同步队列是一个双向队列。接下来我们用一个demo，通过debug进去看是不是符合我们的猜想：

```java
public static void main(String[] args) {
    for (int i = 0; i < 10; i++) {
        Thread thread = new Thread(() -> {
            lock.lock();
            try {
                condition.await();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }finally {
                lock.unlock();
            }
        });
        thread.start();
    }
}
```

新建了10个线程，没有线程先获取锁，然后调用`condition.await`方法释放锁将当前线程加入到等待队列中，通过debug控制当走到第10个线程的时候查看`firstWaiter`即等待队列中的头结点，debug模式下情景图如下:

![debug模式下情景图](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/thread/condition-01.png)



从这个图我们可以很清楚的看到这样几点：

1. 调用`condition.await`方法后线程依次尾插入到等待队列中，如图队列中的线程引用依次为Thread-0,Thread-1,Thread-2....Thread-8；
2. 等待队列是一个单向队列。通过我们的猜想然后进行实验验证，我们可以得出等待队列的示意图如下图所示：

![等待队列的示意图](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/thread/condition-02.png)







同时还有一点需要注意的是：我们可以多次调用`lock.newCondition()`方法创建多个`condition`对象，也就是一个lock可以持有多个等待队列。不同于在`Object的监视器模型上`的一个对象拥有一个同步队列和等待队列，**并发包中的Lock实现类拥有一个同步队列和多个等待队列**：

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/1352849-20201223220123984-923368951.png" style="zoom: 80%;" />

- **条件队列是一个单向FIFO队列，队列每个节点都包含了一个线程引用，该线程是在Condition对象上等待的线程；**
- **实际上这里的条件队列和AQS中的同步队列，都是采用AQS.Node静态内部类；**
- **一个ConditionObject拥有首节点(fisrtWaiter)和尾节点(lastWaiter)；**
- **如果一个线程调用了Condition.await()方法，那么该线程将会释放锁（从同步队列中移除），构造成节点加入条件队列，等待被唤醒；**
- **如果一个线程调用了Condition.signal()方法，那么该线程将会被唤醒（从条件队列中移除），构造成节点加入同步队列，尝试重新获取同步状态；**



(最后两条后面会单独进行分析)







### 入队/出队



#### await()

当调用`await()`方法时，相当于同步队列的首节点（获取了锁的节点）移动到了`Condition`的等待队列中 

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/condition-await.png" style="zoom:67%;" />	

更具体来说是**首先调用await()方法之前肯定是能获取到同步状态的线程，也就是同步队列中首节点，之后调用await()方法由将释放锁，进入等待队列**



再来看源码：

**1）调用`await`()方法，通过`addConditionWaiter`()方法加入等待线程，然后释放全部同步状态**

**2）进入while循环，判断是否已经移动到同步队列中，如果已经被移动到同步队列中则说明线程已经被唤醒（signal）；**

**3）接下来尝试获取竞争同步状态，即调用`acquireQueue`方法**

```java
   　　public final void await() throws InterruptedException {
            if (Thread.interrupted())
                throw new InterruptedException();
            // addConditionWaiter()方法当前线程加入等待队列
            Node node = addConditionWaiter();
            // 调用await()方法后释放当前线程所占用的lock，在释放的过程中会唤醒同步队列中的下一个节点
            int savedState = fullyRelease(node);
            int interruptMode = 0;
            // 检查node是否在同步队列中，不是的话说明已经获取到锁
            //  LockSupport.unpark唤醒线程后，从这里返回，此时已经在SyncQueue同步队列中，退出循环
            // 从这里也可以看出，也是经典的等待/通知模式
            while (!isOnSyncQueue(node)) {
                // 阻塞当前线程 ，当前线程进入等待状态
                LockSupport.park(this);
                // 在调用signal前抛出中断异常，或者调用之后中断，都退出循环
                // THROW_IE if interrupted  before signalled, REINTERRUPT if after signalled
                if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
                    break;
            }
            // 被唤醒后的线程重新尝试竞争获取同步状态
            if (acquireQueued(node, savedState) && interruptMode != THROW_IE)
                interruptMode = REINTERRUPT;
            if (node.nextWaiter != null) // clean up if cancelled
                unlinkCancelledWaiters();
            if (interruptMode != 0)
                reportInterruptAfterWait(interruptMode);
        }
```

**当前线程调用`condition.await()`方法后，会使得当前线程释放lock然后加入到等待队列中，直至被`signal/signalAll`后会使得当前线程从等待队列中移至到同步队列中去，直到获得了lock后才会从await方法返回，或者在等待时被中断会做中断处理**

那么关于这个实现过程我们会有这样几个问题：

1. 是怎样将当前线程添加到等待队列中去的？
2. 释放锁的过程？
3. 怎样才能从await方法退出？

而这段代码的逻辑就是告诉我们这三个问题的答案。具体**请看注释**，在第1步中调用`addConditionWaiter`将当前线程添加到等待队列中，该方法源码为：

```
private Node addConditionWaiter() {
    Node t = lastWaiter;
    // If lastWaiter is cancelled, clean out.
    if (t != null && t.waitStatus != Node.CONDITION) {
        unlinkCancelledWaiters();
        t = lastWaiter;
    }
	//将当前线程包装成Node
    Node node = new Node(Thread.currentThread(), Node.CONDITION);
    if (t == null)
        firstWaiter = node;
    else
		//尾插入
        t.nextWaiter = node;
	//更新lastWaiter
    lastWaiter = node;
    return node;
}
```

这段代码就很容易理解了，将当前节点包装成Node，如果等待队列的`firstWaiter`为null的话（等待队列为空队列），则将`firstWaiter`指向当前的Node,否则，更新`lastWaiter`(尾节点)即可。就是**通过尾插入的方式将当前线程封装的Node插入到等待队列中即可**，同时可以看出等待队列是一个**不带头结点的链式队列**，之前我们学习AQS时知道同步队列**是一个带头结点的链式队列**，这是两者的一个区别

将当前节点插入到等待队列之后，会使当前线程释放lock，由fullyRelease方法实现，fullyRelease源码为：

```java
final int fullyRelease(Node node) {
    boolean failed = true;
    try {
        int savedState = getState();
        if (release(savedState)) {
			//成功释放同步状态
            failed = false;
            return savedState;
        } else {
			//不成功释放同步状态抛出异常
            throw new IllegalMonitorStateException();
        }
    } finally {
        if (failed)
            node.waitStatus = Node.CANCELLED;
    }
}
```

这段代码就很容易理解了，**调用AQS的模板方法release方法释放AQS的同步状态并且唤醒在同步队列中头结点的后继节点引用的线程**



那么线程如何退出`await`方法呢？

**当前线程被中断或者调用`condition.signal/condition.signalAll`方法当前节点移动到了同步队列后** ，这是当前线程退出await方法的前提条件

当退出while循环后就会调用`acquireQueued(node, savedState)`，该方法的作用是在**自旋过程中线程不断尝试获取同步状态，直至成功（线程获取到lock）**。这样也说明了**退出await方法必须是已经获得了condition引用（关联）的lock**。









#### signal()

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/condition-signal.png)

调用`signal`方法将会唤醒等待队列中等待时间最长的节点（首节点），在唤醒节点之前，会将节点移动到同步队列中:

```java
　　public final void signal() {
            // 判断当前线程是否持有获得锁
            if (!isHeldExclusively())
                throw new IllegalMonitorStateException();
            Node first = firstWaiter;
            if (first != null)
                // 移动到同步队列中，并且唤醒节点中的线程
                doSignal(first);
        }
　　private void doSignal(Node first) {
            do {
                // 如果等待队列中只有一个节点（即首节点），则唤醒首节点后lastWaiter置空
                if ( (firstWaiter = first.nextWaiter) == null)
                    lastWaiter = null;
                // 否则获取等待队列中的首节点，即next域断开置空
                first.nextWaiter = null;
            } while (!transferForSignal(first) &&
                     (first = firstWaiter) != null);
        }
```

**`doSignal(Node node)`方法中调用`transferForSignal(Node node)`，通过调用`enq(Node node)`方法(这里其实就是同步队列的入队`enq(Node node)`方法)，等待队列中的头结点线程安全地移动到同步队列，当节点移动到同步队列后，当前线程将会被唤醒`（LockSupport.unpark(node.thread)`**

```java
    final boolean transferForSignal(Node node) {
        /*
         * If cannot change waitStatus, the node has been cancelled.
         */
        // 如果没有正确设置等待状态为初始状态准备加入同步队列中，则返回，当前节点状态为Node.CONDITION
        if (!compareAndSetWaitStatus(node, Node.CONDITION, 0))
            return false;
        // 将等待队列中的头结点移动到同步队列中, 返回已经加入的当前node在同步队列中前节点
        Node p = enq(node);
        int ws = p.waitStatus;
        if (ws > 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL))
            // 唤醒当前node线程，返回while(isOnSynQueue(Node node))处，退出循环
            LockSupport.unpark(node.thread);
        return true;
    }
```



流程结构如下图：

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/conditiom-signal2.png" style="zoom:80%;" />

总结：

(1) 通过调用同步器的`enq(Node node)`方法，让等待队列中的头节点线程安全地移动到同步队列。当节点移动到同步队列后，当前线程再使用`LockSupport`唤醒该节点的线程。被唤醒后的线程，将从`await()`方法中的`while`循环中退出(`isOnSyncQueue(Node node)`方法返回`true`，节点已经在同步队列中)，**进而调用同步器的`acquireQueued()`方法加入到获取同步状态的竞争中**。成功获取同步状态（或者说锁）之后，被唤醒的线程将从先前调用的`await()`方法返回，此时该线程已经成功地获取了锁

(2) `Condition`的`signalAll()`方法，相当于对等待队列中的每个节点均执行一次`signal()`方法（**注意是这个`Condition`对应的等待队列**），效果就是将等待队列中所有节点全部移动到同步队列中，并唤醒每个节点的线程











### 一些问题:currency_exchange:



> `question1`:当一个线程调用 await()方法后进入条件队列，其他线程后续调用signal()方法唤醒该线程，请问这里的唤醒是进入了AQS中的CLH同步队列吗？

当一个线程调用 `await()` 方法后进入条件队列，其他线程后续调用 `signal()` 或 `signalAll()` 方法来唤醒等待线程时，被唤醒的线程会从条件队列移动到 AQS（AbstractQueuedSynchronizer）的 CLH（Craig, Landin, and Hagersten）同步队列中。

这是因为 `Condition` 接口的实现通常是基于 `ReentrantLock` 或其他 `AQS` 子类的。当一个线程调用 `await()` 方法时，它会释放当前持有的锁（即 `ReentrantLock` 锁），然后进入条件队列等待。当其他线程调用 `signal()` 或 `signalAll()` 方法来唤醒等待线程时，被唤醒的线程会从条件队列中移动到 AQS 的 CLH 同步队列中，开始参与锁的竞争。

在 AQS 的 CLH 队列中，线程会按照一定的规则排队等待获取锁(**锁的竞争：公平/非公平**)，通过自旋等待来减少线程切换的开销。一旦线程成功获取锁，它会从 CLH 队列中移除，并继续执行  





> `question2`: 既然await/signal方法需要借助于lock (必须声明在`lock.lock()+lock.unlock()`方法块中)，那么为什么一个线程在方法块内部调用`condition.await()`方法时会释放锁，明明该线程还没有调用`lock.unlock()`方法呀

在 `ReentrantLock` 和 `Condition` 的设计中，当一个线程在方法块内部调用 `condition.await()` 方法时，确实会释放锁，尽管此时还没有显式地调用 `lock.unlock()` 方法。这可能会引起一些困惑，但实际上这种设计是为了提供更灵活的线程协调和等待机制。

这里的关键在于 `condition.await()` 方法内部会自动释放当前线程持有的锁，并将当前线程放入条件等待队列中。然后，等待队列中的线程会等待在特定的条件上，直到被其他线程通过 `condition.signal()` 或 `condition.signalAll()` 方法**唤醒，** 这里的唤醒指的是被唤醒的线程会在 CLH 队列中按照一定的顺序等待，然后尝试使用 **CAS**（Compare and Swap）操作获取锁

- 当一个线程被唤醒并进入 AQS 的 CLH 同步队列，它并不是直接通过 CAS 操作获取锁的，而是会按照队列中的顺序逐个尝试获取锁，这个过程与公平锁和非公平锁有关

- 对于公平锁（`Fair` 为 `true`）的情况：

  1. 当被唤醒的线程进入 CLH 队列后，它会按照队列的顺序等待，不会直接通过 CAS 操作获取锁。

  2. 线程只有在轮到它成为队列的头结点时，才会尝试使用 CAS 操作获取锁。此时，它会检查前一个节点是否已经释放锁？

     如果是，则该线程可以通过 CAS 操作获取锁

- 对于非公平锁（`Fair` 为 `false`）的情况：

  1. 当被唤醒的线程进入 CLH 队列后，它会直接尝试使用 CAS 操作获取锁，不会等待前一个节点释放锁。
  2. 如果 CAS 操作成功，线程会成功获取锁。如果 CAS 操作失败，则线程可能会进行自旋等待，或者被阻塞，直到它成功获取锁或者放弃竞争。



这种设计的目的是允许其他线程有机会获得锁并执行一些操作，而不会被当前线程持有锁的代码块所阻塞。如果 `condition.await()` 不释放锁，那么其他线程将无法进入到该代码块，导致效率下降或死锁。当被唤醒的线程重新获取锁时，它会继续执行条件等待之后的代码，此时再次持有锁。所以，虽然在 `condition.await()` 方法内部释放了锁，但在线程被唤醒后，它会继续执行锁保护下的代码。





> question3:当一个线程调用 signalAll()方法时，会唤醒所有在条件队列上的线程吗？

首先要清楚：

- 如果一个线程调用`signalAll`()方法时，该线程此时是处于持有锁准备释放的状态
- 如果一个线程调用 `await()` 方法，同样是在持有锁的状态下调用的，尽管调用 `await()` 方法时会释放锁，但线程在被唤醒后会重新获取锁，所以在 `await()` 之后的代码块中，线程仍然是在持有锁的状态下执行的(即该线程先进入了`Condition`条件队列等待，然后被唤醒后重新进入CLH同步队列来竞争锁)



当一个线程在`lock`代码块内部调用 `signalAll()` 方法时，它会通知所有在该特定条件上等待的线程(每个`Condition`都有一个对应的条件队列)，使它们有机会重新参与竞争锁。被唤醒的线程会从条件队列移动到 `AQS（AbstractQueuedSynchronizer）`的**CLH同步队列**中，然后开始竞争锁。



需要注意的是，尽管 `signalAll()` 会唤醒所有等待线程，但并不是所有被唤醒的线程都会成功获取锁。线程还需要参与锁的竞争，通过 CAS 操作等待其机会，最终获取锁并继续执行。在这个过程中，可能只有一个线程能够成功获取锁并满足条件。



### 示例

1、使用Condition来实现三个线程交替打印A、B、C字符：

```java
public class ConditionTest {
    //Condition依赖外部Lock对象
    private  static  final ReentrantLock lock=new ReentrantLock();
    private  static  final Condition A=lock.newCondition();
    private  static  final Condition B=lock.newCondition();
    private  static  final Condition C=lock.newCondition();
    private  static AtomicInteger state=new AtomicInteger(0);

    public static void main(String[] args) {
        new Thread(
            ()->{
                print("A",0,A,B);
            }
            ,"Thread A").start();

        new Thread(
            ()->{
                print("B",1,B,C);
            }
            ,"Thread B").start();

        new Thread(
            ()->{
                print("C",2,C,A);
            }
            ,"Thread C").start();
    }

    static  void print(String msg,int  target,Condition cur,Condition next)
    {
        for (int i = 0; i < 100; i++) {
            try {
                lock.lock();
                while (state.get() % 3 != target) {
                    cur.await();
                }
                next.signalAll(); //唤醒在下一个condition队列中的所有线程，让该线程加入竞争锁的同步队列
                System.out.println(Thread.currentThread().getName() + "线程打印" + msg + "第" + i + "次");
                state.incrementAndGet();
            } catch (Exception e) {
                e.printStackTrace();
            } finally {
                lock.unlock();
            }
        }
    }
}
```









2、使用Condition实现生产者消费者模型:

```java

//使用Condition实现生产者/消费者模型
//实现一个简易的BlockingQueue
class  MyBlockingQueueTest{

    private  volatile  int maxSize;
    private   final Queue<Object> queue;
    private  static  final  ReentrantLock lock=new ReentrantLock();

    private  Condition notEmpty=lock.newCondition();
    private  Condition notFull=lock.newCondition();
   public MyBlockingQueueTest(int size)
    {
        this.maxSize=size;
        queue=new LinkedList();
    }

    public  void  put(Object obj) throws InterruptedException {
       lock.lock();
       try {
           if(queue.size()==maxSize) //队列到达最大容量—— Full
           {
               notFull.await(); //生产者不能接着put元素了
           }
           queue.add(obj);
           notEmpty.signalAll(); //唤醒等待的消费者
       }
       finally {
           lock.unlock();
       }
    }

    public  Object  get() throws  InterruptedException
    {
        lock.lock();
        try {
            if(queue.size()==0)  //队列中没有元素
            {
                notEmpty.await();// 消费者无法取了,阻塞式等待
            }
            Object item=queue.remove();
            notFull.signalAll() ;//唤醒生产者，可以继续往队列中添加元素
            return  item;
        }finally {
            lock.unlock();
        }
    }


    public static void main(String[] args) throws InterruptedException {
        MyBlockingQueueTest myBlockingQueueTest = new MyBlockingQueueTest(20);
        ExecutorService producerPool = Executors.newFixedThreadPool(5);
        ExecutorService consumerPool = Executors.newFixedThreadPool(5);
        producerPool.execute(
                // 这部分代码将由线程池中的一个线程异步执行
                ()->{
                    for (int i = 0; i < 20; i++) {
                        try {
                            myBlockingQueueTest.put(i);
                            System.out.println("Producer :"+i);
                        } catch (InterruptedException e) {
                            throw new RuntimeException(e);
                        }
                    }
                }
        );
        consumerPool.execute(
                ()->{
                    try {
                        Thread.sleep(2000);
                    } catch (InterruptedException e) {
                        throw new RuntimeException(e);
                    }
                    for (int i = 0; i < 20; i++) {
                        try {
                            Object result = myBlockingQueueTest.get();
                            System.out.println("Consumer"+result);
                        }catch (Exception e)
                        {
                            throw  new RuntimeException(e);
                        }
                    }
                }
        );

        producerPool.shutdown();
        consumerPool.shutdown();
    }
}
```







# JVM





## 一段JAVA代码的执行过程是怎样的？

Java代码的执行分为以下几个阶段：

1. **编写代码：** 首先，开发人员根据需求编写Java源代码。源代码是以文本形式编写的，包含Java的语法规则和逻辑。

2. **编译阶段：** 编译阶段是将Java源代码编译成字节码的过程。Java源代码经过Java编译器（javac）的处理，生成字节码文件（.class文件）。字节码是一种中间代码，它包含了与特定硬件和操作系统无关的指令。

3. **类加载阶段：** 类加载阶段是将字节码文件加载到Java虚拟机的过程。Java虚拟机将字节码文件加载到内存中，并对类进行验证、准备、解析和初始化。类加载阶段是Java虚拟机的一部分，它负责加载类和接口，并将它们存储在方法区。

4. **运行阶段：** 运行阶段是Java代码实际执行的阶段。在运行阶段，Java虚拟机会根据程序的控制流和逻辑执行字节码指令，从而实现Java程序的功能

   > 运行阶段是Java程序实际执行的阶段，也是Java虚拟机（JVM）最核心的部分,该阶段JVM完成了：
   >
   > 1. **解释执行：** JVM使用解释器对字节码指令进行逐条解释执行。解释器将字节码指令翻译成特定平台的机器码，然后执行这些机器码指令。这种方式使得Java程序可以在不同的硬件和操作系统上运行，实现了Java的跨平台特性。然而，解释执行效率相对较低，所以JVM会采用一些优化手段来提高性能。
   > 2. **即时编译（JIT编译）：** 为了提高Java程序的执行效率，JVM会使用即时编译器（Just-In-Time Compiler，JIT）对**热点代码**进行编译优化。**JIT编译器将字节码转换为本地机器码，并生成优化的本地代码**。**这样在后续执行时，热点代码就不再通过解释器执行，而是直接使用本地代码，从而大幅提高执行速度**。
   > 3. **内存管理：** 在运行阶段，JVM负责管理Java程序的内存。它将堆内存划分为新生代和老年代，用于存储不同类型的对象。JVM使用垃圾回收器进行自动的内存回收，回收不再使用的对象，释放内存空间，避免内存泄漏和溢出。
   > 4. **执行异常处理：** 在运行阶段，JVM会捕获和处理Java程序中的异常。当程序执行过程中遇到异常情况时，JVM会根据异常处理机制执行相应的异常处理代码，保证程序的正常运行。





Java 虚拟机虽然是虚拟的，但它的内部是可以划分为：

- 类加载器（Class Loader）
- 运行时数据区（Runtime Data Areas）
- 执行引擎（Excution Engine）

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/seven-06.png" style="zoom: 50%;" />





**1）类加载器**

类加载器是 Java 虚拟机的一个子系统，用于加载类文件。每当我们运行一个 Java 程序，它都会由类加载器首先加载。

一般来说，Java 程序员并不需要直接同类加载器进行交互。JVM 默认的行为就已经足够满足大多数情况的需求了。不过，如果遇到了需要和类加载器进行交互的情况，而对类加载器的机制又不是很了解的话，就不得不花大量的时间去调试 `ClassNotFoundException` 和 `NoClassDefFoundError` 等异常。

对于任意一个类，都需要由它的类加载器和这个类本身一同确定其在 JVM 中的唯一性。也就是说，如果两个类的加载器不同，即使两个类来源于同一个字节码文件，那这两个类就必定不相等（比如两个类的 Class 对象不 `equals`）



来通过一段简单的代码了解下。

```java
public class Test {
    public static void main(String[] args) {
        ClassLoader loader = Test.class.getClassLoader();
        while (loader != null) {
            System.out.println(loader);
            loader = loader.getParent();
        }
    }
}
```

每个 Java 类都维护着一个指向定义它的类加载器的引用，通过 `类名.class.getClassLoader()` 可以获取到此引用；然后通过 `loader.getParent()` 可以获取类加载器的上层类加载器，输出结果如下：

```shell
jdk.internal.loader.ClassLoaders$AppClassLoader@512ddf17
jdk.internal.loader.ClassLoaders$PlatformClassLoader@2d209079
```

第一行输出为 Test 的类加载器，即应用类加载器，它是 `jdk.internal.loader.ClassLoaders$AppClassLoader` 类的实例；第二行输出为平台类加载器，是 `jdk.internal.loader.ClassLoaders$PlatformClassLoader` 类的实例。那启动类加载器呢？按理说，扩展类加载器的上层类加载器是启动类加载器，但启动类加载器是虚拟机的内置类加载器，通常表示为 `null`





**2）运行时数据区**  

jdk1.7和jdk1.8情况不同，这里就不再赘述了







**3）执行引擎**：执行引擎是JVM的核心组件之一，负责解释和执行Java字节码指令。执行引擎可以使用不同的实现方式，包括解释执行和即时编译（JIT）执行

- 解释器执行：读取字节码流，然后翻译成指令并执行。因为它是一行一行地解释和执行指令，所以它可以很快地解释字节码，但是执行起来会比较慢（毕竟要一行执行完再执行下一行）
- 即时（`Just-In-Time，JIT`）编译器执行：即时编译器用来弥补解释器的缺点，提高性能。执行引擎首先按照解释执行的方式来执行，然后在合适的时候，即时编译器把整段字节码编译成本地代码。然后，执行引擎就没有必要再去解释执行方法了，它可以直接通过本地代码去执行。执行本地代码比一条一条进行解释执行的速度快很多。编译后的代码可以执行的很快，因为本地代码是保存在缓存里的





**4) 本地方法接口 Native Interface：**是JVM与底层操作系统和硬件的接口，允许Java代码调用本地代码（如C或C++编写的代码）

**5) 本地方法库 Native Method Libraries**：包含了与平台相关的本地方法的实现，用于支持Java的本地方法调用









## 虚拟机是如何管理对象的？ :star2:



Step1:类加载检查

虚拟机遇到一条 new 指令时，**首先将去检查这个指令的参数是否能在运行时常量池中定位到这个类的符号引用**，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程

> 每个class文件均包含一个常量池,存储着该类使用的Various constants,包括类名、字段名、方法名、字符串字面量等。
>
> 
>
> 在Java程序执行时JVM会将所有涉及到的类对应的符号引用(定义在每个Class文件中)加载到运行时常量池中
>
> 
>
> 这里的“符号引用”指的是类名在常量池中的引用 entry。JVM通过**这个符号引用来定位类,通过检查该符号引用可以判断出是否代表一个已被加载、解析和初始化过的类。**



Step2:分配内存(实际会先分配在每个线程的本地分配缓冲区(位于eden区)内，不够了才分配到全局堆中 :exclamation: )

在**类加载检查**通过后，接下来虚拟机将为新生对象**分配内存**。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。**分配方式**有 **“指针碰撞”** 和 **“空闲列表”** 两种，**选择哪种分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定**

**内存分配的两种方式** （补充内容，需要掌握）：

- 指针碰撞： 
  - 适用场合：**堆内存规整**（即没有内存碎片）的情况下
  - 原理：**用过的内存全部整合到一边，没有用过的内存放在另一边，中间有一个分界指针，只需要向着没用过的内存方向将该指针移动对象内存大小位置即可**
  - 使用该分配方式的 GC 收集器：Serial, ParNew
- 空闲列表： 
  - 适用场合：堆内存不规整的情况下
  - 原理：**虚拟机会维护一个列表，该列表中会记录哪些内存块是可用的，在分配的时候，找一块儿足够大的内存块儿来划分给对象实例，最后更新列表记录**
  - 使用该分配方式的 GC 收集器：CMS

**选择以上两种方式中的哪一种，取决于 Java 堆内存是否规整。而 Java 堆内存是否规整，取决于 GC 收集器的算法是"标记-清除"，还是"标记-整理"（也称作"标记-压缩"）**，值得注意的是，复制算法内存是规整的



**内存分配并发问题（补充内容，需要掌握）**

在创建对象的时候有一个很重要的问题，就是线程安全，因为在实际开发过程中，创建对象是很频繁的事情，作为虚拟机来说，必须要保证线程是安全的，通常来讲，虚拟机采用两种方式来保证线程安全：

- **CAS+失败重试(自旋)：** CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。**虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。**
- **TLAB(堆内存处讲过)：** 为每一个线程预先在 Eden 区分配一块儿内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，**当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配**

> TLAB全称Thread Local Allocation Buffer,即线程本地分配缓冲区。
>
> 它是JVM为每个线程提供的内存空间,用于申请和回收线程私有的短期对象。
>
> 具体来说:
>
> - 每个线程在启动时,JVM会给予它一个TLAB空间。
> - 当线程申请新对象时(比如使用new Operator),JVM首先会从该线程的TLAB中分配内存。
> - 对象在TLAB中分配的内存空间,这些对象的生命周期结束后,对应的内存也会立即释放回TLAB。
> - 如果TLAB剩余空间不足,申请大对象,或者TLAB已空,则JVM才会真正的向堆申请内存。
>
> TLAB的设计主要是为了有效地支持大量短期小对象的高效分配。它有以下优点:
>
> - 减少全局锁的竞争:每个线程有自己的TLAB,**无需竞争全局锁**。
> - 减少内存分配开销:TLAB内部分配比向堆申请更快。
> - 提高局部性:TLAB内对象生命周期短,自然聚集在一起。



Step3:初始化零值

内存分配完成后，虚拟机需要**将分配到的内存空间都初始化为零值**（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，**程序能访问到这些字段的数据类型所对应的零值**



Step4:设置对象头

初始化零值完成之后，**虚拟机要对对象进行必要的设置**，例如这个对象是哪个类的实例(`Klass Pointer`)即如何才能找到类的元数据信息、对象的哈希码、**对象的 GC 分代年龄**，以及锁标志位(`Synchronized`那里讲过)等信息， **这些信息存放在对象头中。**



Step5:执行 init 方法

在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始，`<init>` 方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行 `<init>` 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来



在字节码中，构造函数被表示为`<init>`方法，其中`<init>`是构造函数的标识符。每个构造函数都对应一个`<init>`方法，用于执行对象的初始化工作，例如为对象的成员变量分配内存并初始化它们的初始值。



构造函数（`<init>`方法）的特点：

1. 方法名称为`<init>`，没有返回类型（包括void），也不需要显式声明返回值。
2. 构造函数的参数列表由对象初始化时所需的参数决定。
3. 构造函数在对象被创建时自动调用，不能手动调用，因为它不是普通的方法。

```java
 Student student = new Student("Alice", 20);
```



> 补充1：对象的内存布局

在 Hotspot 虚拟机中，对象在内存中的布局可以分为 3 块区域：**对象头**、**实例数据**和**对齐填充**。

**Hotspot 虚拟机的对象头包括两部分信息**，**第一部分用于存储对象自身的运行时数据**（哈希码、GC 分代年龄、`锁状态标志`等等），**另一部分是类型指针**，即对象指向它的类元数据的指针，**虚拟机通过这个指针来确定这个对象是哪个类的实例**。

**实例数据部分是对象真正存储的有效信息**，也是在程序中所定义的各种类型的字段内容。

**对齐填充部分不是必然存在的，也没有什么特别的含义，仅仅起占位作用。** 因为 Hotspot 虚拟机的自动内存管理系统要求对象起始地址必须是 8 字节的整数倍，换句话说就是**对象的大小必须是 8 字节的整数倍**。而对象头部分正好是 8 字节的倍数（1 倍或 2 倍），因此，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全





> 补充2：对象的访问

建立对象就是为了使用对象，我们的 Java 程序通过栈上的 `reference` 数据来操作堆上的具体对象。对象的访问方式由虚拟机实现而定，目前主流的访问方式有：**使用句柄**、**直接指针**

1、句柄

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/access-location-of-object-handle.png" style="zoom: 80%;" />



2、直接指针



<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/access-location-of-object-handle-direct-pointer.png" style="zoom:80%;" />



这两种对象访问方式各有优势。使用句柄来访问的最大好处是 reference 中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而 reference 本身不需要修改。使用直接指针访问方式最大的好处就是速度快，它节省了一次指针定位的时间开销









## 字节码

JVM 可以理解的代码就叫做`字节码`（即扩展名为 `.class` 的文件），Java 语言通过字节码的方式，在一定程度上解决了传统解释型语言执行效率低的问题，同时又保留了解释型语言可移植的特点。所以 Java 程序运行时比较高效，而且，**由于字节码并不针对一种特定的机器，因此，Java 程序无须重新编译便可在多种不同操作系统的计算机上运行**

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/java-virtual-machine-program-language-os.png" style="zoom: 67%;" />

可以说`.class`文件是不同的语言在 Java 虚拟机之间的重要桥梁，同时也是支持 Java 跨平台很重要的一个原因

根据 Java 虚拟机规范，Class 文件通过 `ClassFile` 定义，有点类似 C 语言的结构体。



可以从十六进制的字节码角度、 `jclasslib` 图形化查看反编译后的字节码的角度、也或者是后面从 `javap` 反编译后的角度都可以分析字节码文件：

`ClassFile` 的结构如下：

```java
ClassFile {
    u4             magic; //Class 文件的标志      0xcafebabe
    u2             minor_version;//Class 的小版本号  次版本号
    
    u2             major_version;//Class 的大版本号  主版本号————每当 Java 发布大版本时（Java 8，Java9）主版本号都会加 1
    
    u2             constant_pool_count;//常量池的数量
    cp_info        constant_pool[constant_pool_count-1];//常量池
    u2             access_flags;//Class 的访问标记
    u2             this_class;//当前类
    u2             super_class;//父类
    u2             interfaces_count;//接口数量
    u2             interfaces[interfaces_count];//一个类可以实现多个接口
    u2             fields_count;//Class 文件的字段属性数量
    field_info     fields[fields_count];//一个类可以有多个字段
    u2             methods_count;//Class 文件的方法数量
    method_info    methods[methods_count];//一个类可以有个多个方法
    u2             attributes_count;//此类的属性表中的属性数
    attribute_info attributes[attributes_count];//属性表集合
}

```

通过分析 `ClassFile` 的内容，我们便可以知道 `class` 文件的组成:

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/classfile.jpeg" style="zoom: 25%;" />



**Magic-Number 魔数:**

```java
    u4             magic; //Class 文件的标志
```

每个 Class 文件的头 4 个字节称为魔数（`Magic Number`）,它的唯一作用是**确定这个文件是否为一个能被虚拟机接收的 Class 文件**(在自定义RPC传输协议时也加入了标记头 `Magic`)





**Constant Pool 常量池(最重要！！):**

Java 虚拟机是在加载字节码文件的时候才进行的动态链接，也就是说，字段和方法的符号引用只有经过运行期转换后才能获得真正的内存地址。**当 Java 虚拟机运行时，需要从常量池获取对应的符号引用，然后在类创建或者运行时解析并翻译到具体的内存地址上**

```java
    u2             constant_pool_count;//常量池的数量
    cp_info        constant_pool[constant_pool_count-1];//常量池
```

常量池主要存放两大常量：字面量和符号引用。字面量比较接近于 Java 语言层面的的常量概念，如**文本字符串、声明为 final 的常量值**等。而符号引用(索引)则属于编译原理方面的概念。包括下面三类常量：

- 类和接口的全限定名
- 字段的名称和描述符
- 方法的名称和描述符

Java 定义了 boolean、byte、short、char 和 int 等基本数据类型，**它们在常量池中都会被当做 int 来处理(0x03)**，我们来通过一段简单的 Java 代码了解下：

```java
public class ConstantTest {
    public final boolean bool = true;
    public final char aChar = 'a';
    public final byte b = 66;
    public final short s = 67;
    public final int i = 68;
}
```

布尔值 true 的十六进制是 0x01、字符 a 的十六进制是 0x61，字节 66 的十六进制是 0x42，短整型 67 的十六进制是 0x43，整型 68 的十六进制是 0x44。所以编译生成的整型常量在 class 文件中的位置如下图所示：

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/class-file-jiegou-bbe4c673-c3a.png" style="zoom:50%;" />

第一个字节 0x03 表示常量的类型为 *CONSTANT_Integer_info*，是 JVM 中定义的 14 种常量类型之一，对应的还有 *CONSTANT_Float_info*、*CONSTANT_Long_info*、*CONSTANT_Double_info*，对应的标识分别是 0x04、0x05、0x06



接下来，我们再来看一段代码:

```java
class Hello {
    public final String s = "hello";
}
```

“hello”是一个字符串，它的十六进制为 `68 65 6c 6c 6f`，我们来看一下它在 class 文件中的位置。

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/class-file-jiegou-801ed589-658c-407e-ac64-81fd525d7324.png" style="zoom:50%;" />

前面还有 3 个字节，第一个字节 0x01 是标识，标识类型为 *CONSTANT_Uft8_info*(UTF-8 编码的字符串)，第二个和第三个自己 0x00 0x05 用来表示第三部分字节数组的长度

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/class-file-jiegou-string.png" style="zoom:50%;" />

与 *`CONSTANT_Uft8_info`* 类型对应的，还有一个 *`CONSTANT_String_info`*，用来表示字符串对象（之前代码中的 s），标识是 0x08。前者存储了字符串真正的值，后者并不包含字符串的内容，仅仅包含了一个指向常量池中 *`CONSTANT_Uft8_info`* 的索引。

*CONSTANT_String_info* 通过索引 19 来找到 *CONSTANT_Uft8_info*:

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/1.png)





**访问标志 `Access Flags`:**

紧跟着常量池之后的区域就是访问标记（`Access flags`），这个标记用于识别类或接口的访问信息，比如说到底是 `class` 还是 `interface`？是 `public` 吗？是 `abstract` 抽象类吗？是 `final` 类吗？等等。总共有 16 个标记位可供使用，但常用的只有其中 7 个

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/class-file-jiegou.png" style="zoom:67%;" />

来看一个简单的枚举代码

```java
public enum Color {
    RED,GREEN,BLUE;
}
```

通过 `jclasslib` 可以看到访问标记的信息有 `0x4031 [public final enum]`:

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/class-file-jiegou-dddd.png" style="zoom: 40%;" />





`this_class、super_class、interfaces:`

Java 类的继承关系由类索引、父类索引和接口索引集合三项确定。

**类索引用于确定这个类的全限定名**，**父类索引用于确定这个类的父类的全限定名**，由于 Java 语言的单继承，所以父类索引只有一个，除了 `java.lang.Object` 之外，所有的 Java 类都有父类，**因此除了 `java.lang.Object` 外，所有 Java 类的父类索引都不为 0**

**接口索引集合用来描述这个类实现了那些接口**，这些被实现的接口将按 `implements` (如果这个类本身是接口的话则是`extends`) 后的接口顺序从左到右排列在接口索引集合中

通过 `jclasslib` 插件可以看到`TeachplanServiceImpl`类的继承关系:

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/jclasslib.png)





**字段表、方法表、属性表：**

```java
u2             fields_count;//Class 文件的字段属性数量
field_info     fields[fields_count];//一个类可以有多个字段
u2             methods_count;//Class 文件的方法数量
method_info    methods[methods_count];//一个类可以有个多个方法
u2             attributes_count;//此类的属性表中的属性数
attribute_info attributes[attributes_count];//属性表集合
```

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/jclass2.png" style="zoom: 67%;" />





## 常量池分析 :grey_question:

观察以下字节码文件：

```java
Classfile /Users/maweiqing/Documents/GitHub/TechSisterLearnJava/codes/TechSister/target/classes/com/itwanger/jvm/Main.class
  Last modified 2021年4月15日; size 385 bytes
  SHA-256 checksum 6688843e4f70ae8d83040dc7c8e2dd3694bf10ba7c518a6ea9b88b318a8967c6
  Compiled from "Main.java"
public class com.itwanger.jvm.Main
  minor version: 0
  major version: 55
  flags: (0x0021) ACC_PUBLIC, ACC_SUPER
  this_class: #3                          // com/itwanger/jvm/Main
  super_class: #4                         // java/lang/Object
  interfaces: 0, fields: 1, methods: 2, attributes: 1
Constant pool:
   #1 = Methodref          #4.#18         // java/lang/Object."<init>":()V
   #2 = Fieldref           #3.#19         // com/itwanger/jvm/Main.age:I
   #3 = Class              #20            // com/itwanger/jvm/Main
   #4 = Class              #21            // java/lang/Object
   #5 = Utf8               age
   #6 = Utf8               I
   #7 = Utf8               <init>
   #8 = Utf8               ()V
   #9 = Utf8               Code
  #10 = Utf8               LineNumberTable
  #11 = Utf8               LocalVariableTable
  #12 = Utf8               this
  #13 = Utf8               Lcom/itwanger/jvm/Main;
  #14 = Utf8               getAge
  #15 = Utf8               ()I
  #16 = Utf8               SourceFile
  #17 = Utf8               Main.java
  #18 = NameAndType        #7:#8          // "<init>":()V
  #19 = NameAndType        #5:#6          // age:I
  #20 = Utf8               com/itwanger/jvm/Main
  #21 = Utf8               java/lang/Object
{
      
   //字段表集合 此例中只有一个int类型的age字段
  private int age;
    descriptor: I
    flags: (0x0002) ACC_PRIVATE  
   
   //方法表集合  
        //main方法
  public com.itwanger.jvm.Main();
    descriptor: ()V
    flags: (0x0001) ACC_PUBLIC
    Code:
      stack=2, locals=1, args_size=1
         0: aload_0
         1: invokespecial #1                  // Method java/lang/Object."<init>":()V
         4: aload_0
         5: bipush        18
         7: putfield      #2                  // Field age:I
        10: return
      LineNumberTable:
        line 6: 0
        line 7: 4
      LocalVariableTable:
        Start  Length  Slot  Name   Signature
            0      11     0  this   Lcom/itwanger/jvm/Main;

      //getAge方法
  public int getAge();
    descriptor: ()I
    flags: (0x0001) ACC_PUBLIC
    Code:
      stack=1, locals=1, args_size=1
         0: aload_0
         1: getfield      #2                  // Field age:I
         4: ireturn
      LineNumberTable:
        line 9: 0
      LocalVariableTable:
        Start  Length  Slot  Name   Signature
            0       5     0  this   Lcom/itwanger/jvm/Main;
}
SourceFile: "Main.java"

```

**Java 虚拟机是在加载字节码文件的时候才进行的动态链接，也就是说，字段和方法的符号引用只有经过运行期转换后才能获得真正的内存地址。当 Java 虚拟机运行时，需要从常量池获取对应的符号引用，然后在类创建或者运行时解析并翻译到具体的内存地址上**

当前字节码文件中一共有 21 个常量，它们之间是有链接的，逐个分析会比较乱，我们采用顺藤摸瓜的方式，从上依次往下看，那些被链接的常量我们就点到为止

*注*：

- `#` 号后面跟的是索引，索引没有从 0 开始而是从 1 开始，是因为设计者考虑到，“如果要表达不引用任何一个常量的含义时，可以将索引值设为 0 来表示”（《深入理解 Java 虚拟机》描述的）
- `=` 号后面跟的是常量的类型，没有包含前缀 `CONSTANT_` 和后缀 `_info`



第 1 个常量：

```text
#1 = Methodref          #4.#18         // java/lang/Object."<init>":()V
```

类型为 Methodref，表明是用来定义方法的，指向常量池中下标为 4 和 18 的常量。

第 4 个常量：

```text
#4 = Class              #21            // java/lang/Object
```

类型为 Class，表明是用来定义类（或者接口）的，指向常量池中下标为 21 的常量。

第 21 个常量：

```text
#21 = Utf8               java/lang/Object
```

类型为 Utf8，UTF-8 编码的字符串，值为 `java/lang/Object`。

第 18 个常量：

```text
#18 = NameAndType        #7:#8          // "<init>":()V
```

类型为 NameAndType，表明是字段或者方法的部分符号引用，指向常量池中下标为 7 和 8 的常量。

第 7 个常量：

```text
#7 = Utf8               <init>
```

类型为 Utf8，UTF-8 编码的字符串，值为 `<init>`，表明为构造方法。

第 8 个常量：

```text
#8 = Utf8               ()V
```

类型为 Utf8，UTF-8 编码的字符串，值为 `()V`，表明方法的返回值为 void。

到此为止，第 1 个常量算是摸完了。组合起来的意思就是，Main 类使用的是默认的构造方法，来源于 Object 类。





第 2 个常量：

```text
#2 = Fieldref           #3.#19         // com/itwanger/jvm/Main.age:I
```

类型为 Fieldref，表明是用来定义字段的，指向常量池中下标为 3 和 19 的常量。

第 3 个常量：

```text
#3 = Class              #20            // com/itwanger/jvm/Main
```

类型为 Class，表明是用来定义类（或者接口）的，指向常量池中下标为 20 的常量。

第 19 个常量：

```text
#19 = NameAndType        #5:#6          // age:I
```

类型为 NameAndType，表明是字段或者方法的部分符号引用，指向常量池中下标为 5 和 6 的常量。

第 5 个常量：

```text
#5 = Utf8               age
```

类型为 Utf8，UTF-8 编码的字符串，值为 `age`，表明字段名为 age。

第 6 个常量：

```text
#6 = Utf8               I
```

类型为 Utf8，UTF-8 编码的字符串，值为 `I`，表明字段的类型为 int













## JVM内存结构



Java 源代码文件经过编译器编译后生成字节码文件，然后交给 JVM 的类加载器，加载完毕后，交给执行引擎执行。在整个执行的过程中，JVM 会用一块空间来存储程序执行期间需要用到的数据，这块空间一般被称为运行时数据区，也就是常说的 JVM 内存区域



jdk1.7之前：







jdk1.7:

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/java-runtime-data-areas-jdk1.7.png" style="zoom: 67%;" />





jdk1.8:

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/java-runtime-data-areas-jdk1.8.png" style="zoom:67%;" />

**线程私有的：**

- 程序计数器
- 虚拟机栈
- 本地方法栈

**线程共享的：**

- 堆
- 方法区
- 直接内存 (非运行时数据区的一部分)

> 什么是**直接内存**？
>
> 
>
> 在Java中，通常使用`java.nio`包中的`ByteBuffer`类来使用直接内存。`ByteBuffer`类提供了一种在JVM中分配直接内存的方法，通过这种方法，可以获得更高效的I/O操作和减少内存拷贝的开销
>
> 直接内存的主要特点包括：
>
> 1. **非堆内存：** **直接内存并不是Java虚拟机的堆内存的一部分，而是在本地内存中分配的**，这使得直接内存在分配和回收时不受Java堆的限制
> 2. **零拷贝：** 直接内存与Java堆内存之间的数据交换可以通过`java.nio`包中的通道（Channel）和缓冲区（Buffer）进行。使用直接内存可以实现**零拷贝**，减少了数据在Java堆和本地内存之间的拷贝次数，提高了I/O操作的效率
> 3. **释放方式：** **直接内存的释放通常由Java虚拟机外的操作系统负责，而不是由Java虚拟机的垃圾回收器来处理**。这意味着直接内存的释放可能不会像Java堆内存一样及时进行，需要注意防止过度使用直接内存
> 4. 直接内存是一种特殊的内存缓冲区，是通过 JNI 的方式在本地内存上分配的，例如`UnSafe`类中分配内存的函数



先从线程私有的部分讨论:



### **程序计数器**

程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。字节码解释器工作时通过改变这个计数器的值来**选取下一条需要执行的字节码指令**，分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完成

另外，为了线程切换后能恢复到正确的执行位置，**每条线程都需要有一个独立的程序计数器，各线程之间计数器互不影响**，独立存储，我们称这类内存区域为“线程私有”的内存

当线程执行一个方法时，程序计数器会记录当前执行的字节码指令的地址或索引。当线程切换到另一个方法执行时，程序计数器会被更新为新方法的开始地址或索引。因此，程序计数器在不同方法之间进行切换时起到了导航的作用

程序计数器的值是一个非负整数，通常以字节码指令的地址或索引表示。字节码指令是一系列用于执行Java程序的基本指令，JVM根据程序计数器中的地址或索引来获取当前要执行的字节码指令，然后进行解释和执行



从上面的介绍中我们知道了程序计数器主要有两个作用：

- 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理
- **在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了**

**注意：**程序计数器是唯一一个不会出现 `OutOfMemoryError` 的内存区域，它的生命周期随着线程的创建而创建，随着线程的结束而死亡

如果线程执行的是非本地（`native`）方法，则程序计数器中保存的是当前需要执行的指令地址；如果线程执行的是本地方法，则程序计数器中的值是 `undefined`

为什么本地方法在程序计数器中的值是 `undefined` 的？因为本地方法大多是通过 C/C++ 实现的，并未编译成需要执行的字节码指令。

由于程序计数器中存储的数据所占的空间不会随程序的执行而发生大小上的改变，因此，程序计数器是不会发生内存溢出现象(`OutOfMemory`)





### **Java虚拟机栈**

与程序计数器一样，Java 虚拟机栈（后文简称栈）也是线程私有的，它的生命周期和线程相同，随着线程的创建而创建，随着线程的死亡而死亡；

栈绝对算的上是 JVM 运行时数据区域的一个核心，除了一些 `Native` 方法调用是通过本地方法栈实现的(后面会提到)，其他所有的 Java 方法调用都是通过栈来实现的（也需要和其他运行时数据区域比如程序计数器配合）；

Java 虚拟机栈中是一个个栈帧，**每个栈帧对应一个被调用的方法**。当线程执行一个方法时，会创建一个对应的栈帧，并将栈帧压入栈中。当方法执行完毕后，将栈帧从栈中移除。栈遵循的是**后进先出**的原则，所以**线程当前执行的方法对应的栈帧必定在 Java 虚拟机栈的顶部**(每个栈帧中都拥有：**局部变量表、操作数栈、动态链接、方法返回地址**)；

- JVM 直接对 Java 栈的操作只有两个，对栈帧的**压栈**和**出栈**，遵循“先进后出/后进先出”原则

- 在一条活动线程中，一个时间点上，只会有一个活动的栈帧。即只有当前正在执行的方法的栈帧（**栈顶栈帧**）是有效的，这个栈帧被称为**当前栈帧**（Current Frame），与当前栈帧对应的方法就是**当前方法**（Current Method），定义这个方法的类就是**当前类**（Current Class）
- 执行引擎运行的所有字节码指令只针对当前栈帧进行操作
- 如果在该方法中调用了其他方法，对应的新的栈帧会被创建出来，放在栈的顶端，称为新的当前栈帧
- 不同线程中所包含的栈帧是不允许存在相互引用的，即不可能在一个栈帧中引用另外一个线程的栈帧
- 如果当前方法调用了其他方法，方法返回之际，当前栈帧会传回此方法的执行结果给前一个栈帧，接着，虚拟机会丢弃当前栈帧，使得前一个栈帧重新成为当前栈帧
- Java 方法有两种返回函数的方式，**一种是正常的函数返回，使用 return 指令，另一种是抛出异常，不管用哪种方式，都会导致栈帧被弹出**

> 栈空间虽然不是无限的，但一般正常调用的情况下是不会出现问题的。不过，如果函数调用陷入无限循环的话，就会导致当前线程的JVM栈中被压入太多栈帧而占用太多空间，导致栈空间过深。那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 `StackOverFlowError`错误
>
> 
>
> 在使用Java命令启动Java程序时，可以使用`-Xss`参数来设置栈的大小 (stack-size)
>
> ```java
> java -Xss1m MyClass
> ```
>
> 除了 `StackOverFlowError` 错误之外，栈还可能会出现`OutOfMemoryError`错误，这是因为如果栈的内存大小可以动态扩展， 如果虚拟机在动态扩展栈时无法申请到足够的内存空间，则抛出`OutOfMemoryError`异常
>
>  
>
>
>
> 简单总结一下程序运行中栈可能会出现两种错误：
>
> - **`StackOverFlowError`：** 若栈的内存大小不允许动态扩展，那么当**线程请求栈的深度超过当前 Java 虚拟机栈的最大深度**的时候，就抛出 `StackOverFlowError` 错误。
> - **`OutOfMemoryError`：** 如果栈的内存大小可以动态扩展， 如果虚拟机在动态扩展栈时无法申请到足够的内存空间，则抛出`OutOfMemoryError`异常
>
> 



<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/neicun-jiegou-1.png" style="zoom:67%;" />





(1) **局部变量表：**

- 局部变量表也被称为局部变量数组或者本地变量表
- 是一组变量值存储空间，**主要用于存储方法参数(包含了方法的输入参数和对于非静态方法的隐含this指针)和定义在方法体内的局部变量**，包括编译器可知的各种 `Java` 虚拟机**基本数据类型**（`boolean、byte、char、short、int、float、long、double`）、**对象引用**(最常见的)
- 不同数据类型的局部变量占据不同的**槽位**（`Slot`），例如`int`类型占用一个槽位，`long`和`double`类型占用两个槽位
- JVM 会为局部变量表中的每一个 `Slot` 都分配一个访问索引，通过这个索引即可成功访问到局部变量表中指定的局部变量值，索引值的范围从 0 开始到局部变量表最大的 `Slot` 数量
- 如果当前帧是由构造方法或实例方法创建的，那么该对象引用 this 将会存放在 index 为 0 的 Slot 处，其余的参数按照参数表顺序继续排列（这里就引出一个问题：**静态方法中为什么不可以引用 this，就是因为this 变量不存在于当前方法的局部变量表中**）
- 由于局部变量表是建立在线程的栈上，是线程的私有数据，因此**不存在数据安全问题**
- **局部变量表中的变量只在当前方法调用中有效**。在方法执行时，虚拟机通过使用局部变量表完成参数值到参数变量列表的传递过程。当方法调用结束后，随着方法栈帧的销毁，局部变量表也会随之销毁
- **局部变量表中的变量也是重要的垃圾回收根节点，只要被局部变量表中直接或间接引用的对象都不会被回收**

当一个方法定义如下时：

```java
public int addNumbers(int a, int b) {
    int sum = a + b;
    int product = a * b;
    return sum + product;
}
```

在JVM的局部变量表中，该方法的局部变量表将包含以下内容：

```shell
Slot 0: this (for non-static method, a reference to the current object)  #this指针
Slot 1: a (method parameter)                   #a是int类型 占一个槽位
Slot 2: b (method parameter)
Slot 3: sum (local variable)
Slot 4: product (local variable)
```





(2) **操作数栈：**

每个独立的栈帧中除了包含局部变量表之外，还包含一个**后进先出**的操作数栈，也可以称为**表达式栈**（`Expression Stack`）

**操作数栈在方法执行过程中，根据字节码指令，往操作数栈中写入数据或提取数据，即入栈（push）、出栈（pop）**

某些字节码指令将值压入操作数栈，其余的字节码指令将操作数取出栈。使用它们后再把结果压入栈。比如，执行复制、交换、求和等操作

其作用如下：

- 操作数栈，**主要用于保存计算过程的中间结果，同时作为计算过程中变量临时的存储空间**

- 操作数栈就是 JVM 执行引擎的一个工作区，当一个方法刚开始执行的时候，一个新的栈帧也会随之被创建出来，**此时这个方法的操作数栈是空的**
- 操作数栈并非采用访问索引的方式来进行数据访问的，而是只能通过标准的入栈和出栈操作来完成一次数据访问
- **如果被调用的方法带有返回值的话，其返回值将会被压入当前栈帧的操作数栈中**，并更新 PC 寄存器中下一条需要执行的字节码指令
- 另外，我们说**Java虚拟机的解释引擎是基于栈的执行引擎**，其中的栈指的就是操作数栈

接着看上述那个例子：

```java
public int addNumbers(int a, int b) {
    int sum = a + b;
    int product = a * b;
    return sum + product;
}
```

1. **方法入栈：** 方法被调用时，参数会被压入操作数栈。在这个例子中，`addNumbers(2, 3)`方法调用时，参数2和3会被依次压入操作数栈，操作数栈变为：`[2, 3]`。
2. **局部变量入栈：** 方法开始执行时，局部变量表中的`a`和`b`会被加载到操作数栈。这里`a`和`b`的值分别是2和3，所以操作数栈变为：`[2, 3, 2, 3]`。
3. **执行`a + b`：** 执行`int sum = a + b;`时，从操作数栈中依次弹出两个操作数，执行加法操作，然后将结果5入栈。此时操作数栈变为：`[5, 2, 3]`。
4. **执行`a \* b`：** 执行`int product = a * b;`时，从操作数栈中依次弹出两个操作数，执行乘法操作，然后将结果6入栈。此时操作数栈变为：`[6, 5]`。
5. **执行`sum + product`：** 执行`return sum + product;`时，从操作数栈中依次弹出两个操作数（分别是6和5），执行加法操作，然后将结果11入栈。此时操作数栈变为：`[11]`。
6. **方法返回：** 方法执行结束后，将最终的结果11从操作数栈中弹出，然后返回给方法调用者





可以这么理解：**局部变量表和操作数栈的关系就相当于形参和实参的关系一样**。。。。



(3) **动态链接：** 针对的是方法调用————**多态**就是这样实现的

动态链接即虚拟方法调用，用到了**指向运行时常量池的方法引用**

主要服务一个方法需要调用其他方法的场景。Class 文件的常量池里保存有大量的符号引用比如方法引用的符号引用。当一个方法要调用其他方法，需要将常量池中指向方法的符号引用转化为其在内存地址中的直接引用。动态链接的作用就是为了将符号引用转换为调用方法的直接引用，这个过程也被称为 **动态链接**

**每一个栈帧内部都包含一个指向运行时常量池中该栈帧所属方法的引用**。包含这个引用的目的就是为了支持当前方法的代码能够实现动态链接(`Dynamic Linking`)。

**在 Java 源文件被编译到字节码文件中时，所有的变量和方法引用都作为符号引用（`Symbolic Reference`）保存在 Class 文件的常量池中**。比如：描述一个方法调用了另外的其他方法时，就是通过常量池中指向方法的符号引用来表示的，那么**动态链接的作用就是为了将这些符号引用转换为调用方法的直接引用(内存地址)**

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E5%8A%A8%E6%80%81%E9%93%BE%E6%8E%A5.jpg" style="zoom:67%;" />



> question1:JVM是如何执行方法调用的?
>

方法调用不同于方法执行，方法调用阶段的唯一任务就是确定被调用方法的版本（即调用哪一个方法），暂时还不涉及方法内部的具体运行过程。Class 文件的编译过程中不包括传统编译器中的连接步骤，**一切方法调用在 Class文件里面存储的都是符号引用，而不是方法在实际运行时内存布局中的入口地址（直接引用）**。也就是需要在类加载阶段，甚至到运行期才能确定目标方法的直接引用

>  question2:在 JVM 中，将符号引用转换为调用方法的直接引用与方法的绑定机制有什么关系？

- **静态链接**：当一个字节码文件被装载进 JVM 内部时，如果被调用的**目标方法在编译期可知**，且运行期保持不变时。这种情况下将调用方法的符号引用转换为直接引用的过程称之为静态链接
- **动态链接**：如果被调用的方法在编译期无法被确定下来，也就是说，**只能在程序运行期将调用方法的符号引用转换为直接引用，由于这种引用转换过程具备动态性，因此也就被称之为动态链接**

对应的方法的绑定机制为：早期绑定（Early Binding）和晚期绑定（Late Binding）。**绑定是一个字段、方法或者类在符号引用被替换为直接引用的过程，这仅仅发生一次**

- 早期绑定：**早期绑定就是指被调用的目标方法如果在编译期可知，且运行期保持不变时**，即可将这个方法与所属的类型进行绑定，这样一来，由于明确了被调用的目标方法究竟是哪一个，因此也就可以使用静态链接的方式将符号引用转换为直接引用。
- 晚期绑定：如果被调用的方法在编译器无法被确定下来，只能够在程序运行期根据实际的类型绑定相关的方法，这种绑定方式就被称为晚期绑定







**(4) 方法返回地址:**

用于记录方法调用结束后的返回地址，以便在方法返回时返回到正确的调用点,即存放了**调用该方法的 PC 寄存器的值**

一个方法的结束，有两种方式

- 正常执行完成
- 出现未处理的异常，非正常退出

无论通过哪种方式退出，在方法退出后都返回到该方法被调用的位置。方法正常退出时，调用者的 PC 计数器的值作为返回地址，**之后调用该方法对应字节码指令后的下一条指令的地址**。而通过异常退出的，返回地址是要通过异常表来确定的，栈帧中一般不会保存这部分信息。





### 本地方法栈

和虚拟机栈所发挥的作用非常相似，区别是：**虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 `Native` 方法服务( `Unsafe` 类就有很多本地方法),** 在 `HotSpot` 虚拟机中和 Java 虚拟机栈合二为一

本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接、出口信息(调用者的PC寄存器值)

方法执行完毕后相应的栈帧也会出栈并释放内存空间，也会出现 `StackOverFlowError` 和 `OutOfMemoryError` 两种错误

> 为什么需要`native method`?
>
> - 与 Java 环境外交互：有时 Java 应用需要与 Java 外面的环境交互，这就是本地方法存在的原因
> - 与操作系统交互：JVM 支持 Java 语言本身和运行时库，但是有时仍需要依赖一些底层系统的支持。通过本地方法，我们可以实现用 Java 与实现了 jre 的底层系统交互， JVM 的一些部分就是 C 语言写的
> - 程序需要用到Java不具备的依赖于操作系统的特性，Java在实现跨平台的同时要实现对底层的控制，这就需要借助其他语言
> - 对于其他语言已经完成的一些现成功能，可以使用Java直接调用
> - 程序对时间敏感或对性能要求非常高时，有必要使用更加底层的语言，例如C/C++甚至是汇编







### 堆内存  :astonished:

> **栈是运行时的单位，而堆是存储的单位**
>
> 栈解决程序的运行问题，即程序如何执行，或者说如何处理数据。堆解决的是数据存储的问题，即数据怎么放、放在哪。
>
> 

Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建，此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存

随着 JIT 编译器的发展与逃逸分析技术逐渐成熟，栈上分配、标量替换优化技术将会导致一些微妙的变化，所有的对象都分配到堆上也渐渐变得不那么“绝对”了。从 JDK 1.7 开始已经默认开启逃逸分析，**如果某些方法中的对象引用没有被返回或者未被外面使用（也就是未逃逸出去），那么对象可以直接在栈上分配内存**

Java 堆是垃圾收集器管理的主要区域，因此也被称作 **GC 堆（Garbage Collected Heap）**。从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以 Java 堆还可以细分为：新生代和老年代；再细致一点有：Eden、Survivor、Old 等空间。进一步划分的目的是更好地回收内存，或者更快地分配内存





**来看一看阿里大神总结的版本：**

Java 堆（Java Heap）是 JVM 所管理的内存中最大的一块，堆又是垃圾收集器管理的主要区域，这里我们主要分析一下 Java 堆的结构

<img src="https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/jvm/tujie-gc-294701a5-1c50-4112-94a1-96a8bab80e34.png" alt="img" style="zoom:67%;" />

Java 堆主要分为 2 个区域-年轻代与老年代，其中年轻代又分 Eden 区和 Survivor 区，其中 Survivor 区又分 From 和 To 2 个区。可能这时候大家会有疑问，

大多数情况下，对象会在新生代 Eden 区中进行分配。当 Eden 区没有足够空间进行分配时，虚拟机会发起一次 Minor GC，Minor GC 相比 Major GC 更频繁，回收速度也更快

**通过 Minor GC 之后，Eden 会被清空，Eden 区中绝大部分对象会被回收，而那些无需回收的存活对象，将会进到 Survivor 的 From 区（若 From 区不够，则直接进入 Old 区——分配担保机制）**



> 为什么需要 `Survivor` 区?

Survivor 区相当于是 Eden 区和 Old 区的一个缓冲，类似于我们交通灯中的黄灯。Survivor 又分为 2 个区，一个是 From 区，一个是 To 区。每次执行 Minor GC，会将 Eden 区和 From 存活的对象放到 Survivor 的 To 区（如果 To 区不够，则直接进入 Old 区）

之所以有 Survivor 区是因为如果没有 Survivor 区，Eden 区每进行一次 Minor GC，存活的对象就会被送到老年代，老年代很快就会被填满。而有很多对象虽然一次 Minor GC 没有消灭，但其实也并不会蹦跶多久，或许第二次，第三次就需要被清除。这时候移入老年区，很明显不是一个明智的决定

所以，Survivor 的存在意义就是减少被送到老年代的对象，进而减少 `Major GC`(针对老年代) 的发生。Survivor 的预筛选保证，只有经历 16 次 Minor GC 还能在新生代中存活的对象，才会被送到老年代





> 为什么 `Survivor` 还要分 2 个区?

设置两个 `Survivor` 区最大的好处就是解决内存碎片化。

我们先假设一下，Survivor 如果只有一个区域会怎样。Minor GC 执行后，Eden 区被清空了，存活的对象放到了 Survivor 区，而之前 Survivor 区中的对象，可能也有一些是需要被清除的。问题来了，这时候我们怎么清除它们？在这种场景下，我们只能标记清除，而我们知道标记清除最大的问题就是内存碎片，在新生代这种经常会消亡的区域，采用标记清除必然会让内存产生严重的碎片化。**因为 Survivor 有 2 个区域，所以每次 Minor GC，会将之前 Eden 区和 From 区中的存活对象复制到 To 区域。第二次 Minor GC 时，From 与 To 职责互换，这时候会将 Eden 区和 To 区中的存活对象再复制到 From 区域**，以此反复。

这种机制最大的好处就是，整个过程中，**永远有一个 Survivor space 是空的，另一个非空的 Survivor space 是无碎片的**。那么，Survivor 为什么不分更多块呢？比方说分成三个、四个、五个?显然，如果 Survivor 区再细分下去，每一块的空间就会比较小，容易导致 Survivor 区满，两块 Survivor 区可能是经过权衡之后的最佳方案。



> 关于老年代

老年代占据着 2/3 的堆内存空间，只有在 Major GC 的时候才会进行清理，每次 GC 都会触发长期的“Stop-The-World”

(Minor GC（年轻代垃圾回收）通常也会触发**短暂**的"Stop-the-World"（停顿）事件)

内存越大，STW 的时间也越长，所以内存也不仅仅是越大就越好。在内存担保机制下，无法安置的对象会直接进到老年代，以下几种情况也会进入老年代。

1）**大对象**，指需要大量连续内存空间的对象，这部分对象不管是不是“朝生夕死”，都会直接进到老年代。这样做主要是为了避免在 Eden 区及 2 个 Survivor 区之间发生大量的内存复制。

2）**长期存活对象**，虚拟机给每个对象定义了一个对象年龄（Age）计数器。正常情况下对象会不断的在 Survivor 的 From 区与 To 区之间移动，对象在 Survivor 区中每经历一次 Minor GC，年龄就增加 1 岁。当年龄增加到 15 岁时，这时候就会被转移到老年代。当然，这里的 15，JVM 也支持进行特殊设置。

3）**动态对象年龄**，虚拟机并不重视要求对象年龄必须到 15 岁，才会放入老年区，如果 Survivor 空间中相同年龄所有对象大小的总合大于 Survivor 空间的一半，年龄大于等于该年龄的对象就可以直接进去老年区，无需等你“成年”。



>  什么是分配担保机制？
>
> 
>
> 分配担保机制的基本思想是，在进行一次 Minor GC 前，首先估计本次 GC 后存活的对象大小（通常使用上一次 GC 后存活的对象大小作为估计），然后检查老年代的剩余空间是否足够容纳这些存活对象。如果足够，就可以放心进行 Minor GC；如果不够，JVM 会尝试先执行一次 Full GC，尽量回收老年代的空间，以保证 Minor GC 的安全性。
>
> 这个机制确保了在进行 Minor GC 时，老年代不会因为空间不足而触发 Full GC，从而降低了应用程序的停顿时间。





#### 内存划分

在 JDK 7 版本及 JDK 7 版本之前，堆内存被通常分为下面三部分：

1. 新生代内存(Young Generation)
2. 老生代(Old Generation)
3. 永久代(Permanent Generation)

**JDK 8 版本之后 PermGen(永久代) 已被 Metaspace(元空间) 取代，元空间使用的是本地内存**

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/hotspot-heap-structure.png" style="zoom: 67%;" />



**新生代：**

大部分情况，对象都会首先在 Eden 区域分配，在一次新生代垃圾回收后，如果对象还存活，则会进入 S0 或者 S1(它们也被称为"`from survivor`"和"`to survivor`")，并且对象的年龄还会加 1(Eden 区->Survivor 区后对象的初始年龄变为 1)，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 `-XX:MaxTenuringThreshold` 来设置

新生代被分为三个部分——伊甸园（**Eden Memory**）和两个幸存区（**Survivor Memory**，被称为from/to或s0/s1），默认比例是`8:1:1`

- 大多数新创建的对象都位于 Eden 内存空间中
- 当 Eden 空间被对象填充满时，执行**Minor GC**，并将所有幸存者对象移动到一个幸存者空间中
- Minor GC 检查幸存者对象，并将它们移动到另一个幸存者空间。**所以每次GC后，总有一个幸存者空间为空**
- 经过多次 GC 循环后存活下来的对象被移动到老年代。通常，这是通过设置年轻一代对象的年龄阈值来实现的，然后他们才有资格提升到老一代

> Minor GC:
>
> 新生代（Young Generation）主要用于存放新创建的对象。当对象经过垃圾回收后，如果仍然存活，它们会被移动到Survivor区中。新生代的垃圾回收通常采用复制算法（Copying Algorithm），其中的"S0"和"S1"是两个用于复制存活对象的Survivor区。
>
> 新创建的对象首先被分配在Eden区，当Eden区满了之后，触发Minor GC（新生代垃圾回收）。在Minor GC中，存活的对象会被复制到"S0"或"S1"中的一个，同时清理Eden区和另一个Survivor区。经过多次Minor GC后，依然存活的对象会被移到老年代中。
>
> "S0"和"S1"的作用是用于两次Minor GC之间的存活对象复制和调整。在第一次Minor GC后，存活的对象会被复制到另一个Survivor区（通常是"S0"到"S1"或者"S1"到"S0"）。在第二次Minor GC时，再将存活的对象复制到未使用的Survivor区。
>
> 这种轮换方式可以保证在一次Minor GC过程中，Survivor区中的一个是空的，以备下次Minor GC使用。同时，经过多次Minor GC后，依然存活的对象会被移到老年代，从而实现了新生代和老年代之间对象的分代管理





**老年代：**

老年代内存包含那些经过许多轮小型`GC`后仍然存活的对象，老年代垃圾收集称为 主GC（`Major GC`），通常需要更长的时间

大对象也会直接进入老年代（大对象是指需要大量连续内存空间的对象）。这样做的目的是避免在 Eden 区和两个 `Survivor` 区之间发生大量的内存拷贝



**永久代(元空间)：**

**不管是 JDK8 之前的永久代，还是 JDK8 及以后的元空间，都可以看作是 Java 虚拟机规范中方法区的实现**

在 Java 虚拟机（JVM）的内存模型中，永久代（Permanent Generation）是一部分堆内存的区域，它主要用于存放类的元数据、常量池、静态变量和一些编译器优化后的代码等。永久代在 JVM 中的作用如下：

1. **存放类的元数据：** 类的元数据是指类的结构信息，包括类的字段、方法、父类、接口等。在运行时，JVM需要快速访问类的元数据，因此将它们存放在永久代中。
2. **存放运行时常量池(对应`Class`文件中的`Constant Pool`)：** 常量池用于存放编译期生成的字面量和符号引用，包括字符串、基本数据类型的值、类和方法的符号引用等。这些常量在编译期就已经确定，因此将它们存放在永久代中，以便在运行时可以快速访问。
3. **存放静态变量：** 静态变量是类级别的变量，它们的生命周期和类的生命周期一致，存放在永久代中可以保证它们在整个应用程序的生命周期内存在。
4. **存放编译器优化后的代码：** 一些经过 JIT 编译器优化后的代码（例如即时编译生成的本地机器码）也可能存放在永久代中。

需要注意的是，在 Java 8 及之后的版本中，永久代被元数据区（Metaspace）所取代。Metaspace 不再是堆内存的一部分，而是在本地内存中分配的。Metaspace 的大小不再受固定的限制，而是可以根据应用程序的需要动态调整。

永久代在 Java 8 之前的版本中存在，但在 Java 8 及之后的版本中被移除。**在 Java 8 之后，类的元数据等信息依然被存放在 Metaspace 中，而静态变量和字符串常量池等信息则被存放在堆中的其他区域**。







####   堆内存分配原则



1、对象优先在 Eden 区分配

大多数情况下，对象在新生代中 Eden 区分配。当 Eden 区没有足够空间进行分配时，虚拟机将发起一次 `Minor GC`

执行 `Minor GC` 后，后面分配的对象如果能够存在 Eden 区的话，还是会在 Eden 区分配内存



2、大对象直接进入老年代

大对象就是需要大量连续内存空间的对象（比如：字符串、数组）。

大对象直接进入老年代主要是为了避免为大对象分配内存时由于**分配担保机制**带来的复制而降低效率。



3、长期存活的对象将进入老年代(如何判断？)

大部分情况，对象都会首先在 Eden 区域分配。如果对象在 Eden 出生并经过第一次 `Minor` `GC` 后仍然能够存活，并且能被 `Survivor` 容纳的话(**无法被容纳则经过分配担保机制直接进入老年代**)，将被移动到 `Survivor` 空间（s0 或者 s1）中，并将对象年龄设为 1(Eden 区->`Survivor` 区后对象的初始年龄变为 1)

> 1. 在进行Minor GC之前，JVM会检查老年代的剩余空间是否大于新生代中所有存活对象的大小之和（即所有存活对象的大小之和要小于老年代的剩余空间）
> 2. 如果老年代的剩余空间足够，JVM会继续执行Minor GC，并将存活对象晋升到老年代中(符合晋升条件的前提下)
> 3. 如果老年代的剩余空间不足以存放所有存活对象，那么JVM将触发一次Full GC（全局垃圾收集），这样就会在老年代腾出足够的空间来容纳从新生代晋升而来的对象

对象在 `Survivor` 中每熬过一次 `MinorGC`,年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 `-XX:MaxTenuringThreshold` 来设置

> 这里说法有误解，是否晋升老年代采用的是动态年龄计算策略：
>
> “Hotspot 遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了 survivor 区的 50% 时（默认值是 50%，可以通过 `-XX:TargetSurvivorRatio=percent` 来设置，**取这个年龄和 `MaxTenuringThreshold` 中更小的一个值，作为新的晋升年龄阈值**”

```
// 定义年龄表计算函数，用于计算对象晋升到老年代的年龄阈值
uint ageTable::compute_tenuring_threshold(size_t survivor_capacity) {
    // survivor_capacity 是survivor空间的大小

    // 计算目标 Survivor 大小，根据目标比例 TargetSurvivorRatio 来确定
    size_t desired_survivor_size = (size_t)((((double)survivor_capacity) * TargetSurvivorRatio) / 100);

    // 初始化 total 变量，用于累积各个年龄段对象的大小之和
    size_t total = 0;

    // 初始化 age 变量，表示当前对象的年龄，默认为 1
    uint age = 1;

    // 开始循环，遍历各个年龄段
    while (age < table_size) {
        // sizes 数组存储了每个年龄段对象的大小，将当前年龄段对象大小累加到 total 中
        total += sizes[age];

        // 如果 total 超过了目标 Survivor 大小(Survior区的一半)，就跳出循环
        if (total > desired_survivor_size) {
            break;
        }

        // 如果 total 还未达到目标 Survivor 大小，继续处理下一个年龄段
        age++;
    }

    // 根据计算得到的年龄，决定最终的年龄阈值，并将结果存储在 result 中
    // 如果计算得到的年龄超过了最大阈值 MaxTenuringThreshold，则取最大阈值
    uint result = age < MaxTenuringThreshold ? age : MaxTenuringThreshold;
    
    // 返回最终计算得到的年龄阈值
    return result;
}

```

















#### 设置堆内存大小

堆的大小在 JVM 启动的时候就确定了，我们可以通过 `-Xmx` 和 `-Xms` 来设定

- `-Xms` 用来表示堆的起始内存，等价于 `-XX:InitialHeapSize`
- `-Xmx` 用来表示堆的最大内存，等价于 `-XX:MaxHeapSize`

如果堆的内存大小超过 `-Xmx` 设定的最大内存， 就会抛出 `OutOfMemoryError` 异常。

我们通常会将 `-Xmx` 和 `-Xms` 两个参数配置为相同的值，其目的是为了能够在垃圾回收机制清理完堆区后不再需要重新分隔计算堆的大小，从而提高性能

- 默认情况下，初始堆内存大小为：电脑内存大小/64
- 默认情况下，最大堆内存大小为：电脑内存大小/4

可以通过代码获取到我们的设置值，当然也可以模拟 OOM：

```java
public static void main(String[] args) {

  //返回 JVM 堆大小
  long initalMemory = Runtime.getRuntime().totalMemory() / 1024 /1024;
  //返回 JVM 堆的最大内存
  long maxMemory = Runtime.getRuntime().maxMemory() / 1024 /1024;

  System.out.println("-Xms : "+initalMemory + "M");
  System.out.println("-Xmx : "+maxMemory + "M");

  System.out.println("系统内存大小：" + initalMemory * 64 / 1024 + "G");
  System.out.println("系统内存大小：" + maxMemory * 4 / 1024 + "G");
}
```

输出结果如下：

```
-Xms : 489M
-Xmx : 7241M
系统内存大小：30G
系统内存大小：28G
```





#### 对象在堆中的生命周期

在 JVM 内存模型的堆中，堆被划分为新生代和老年代 

- 新生代又被进一步划分为 **Eden区** 和 **Survivor区**，`Survivor` 区由 `From Survivor` 和 `To Survivor` 组成

当创建一个对象时，对象会被优先分配到新生代的 Eden 区 

- 此时 JVM 会给对象定义一个**对象年轻计数器**（`-XX:MaxTenuringThreshold`）

> `-XX:MaxTenuringThreshold`用于指定对象在新生代（`Young Generation`）中经过多少次垃圾回收后才会被晋升到老年代（Old Generation）:
>
> 
>
> 在新生代中，通常有两个 `Survivor` 区，称为 "S0" 和 "S1"。当一个对象在 Eden 区被分配后，如果经过一次 Minor GC 后仍然存活，它会被移到其中一个 Survivor 区。如果在 Survivor 区中经过一定次数的垃圾回收（取决于 `-XX:MaxTenuringThreshold` 的设置），则会被晋升到老年代
>
> 
>
> 默认情况下，`-XX:MaxTenuringThreshold` 的值通常为 15，表示一个对象在 Survivor 区中经过 15 次垃圾回收后，如果仍然存活，则会被晋升到老年代(这个说法也不完全准确！)。

当 Eden 空间不足时，JVM 将执行新生代的垃圾回收（Minor GC） 

- JVM 会把存活的对象转移到 Survivor 中，并且对象年龄 +1
- 对象在 Survivor 中同样也会经历 Minor GC，每经历一次 Minor GC，对象年龄都会+1

:exclamation: 如果分配的对象超过了`-XX:PretenureSizeThreshold`的大小，对象会**直接被分配到老年代**





#### TLAB

`Thread Local Allocation Buffer`（TLAB）是Java虚拟机（JVM）中一种用于优化对象分配的技术。**TLAB是一种线程本地缓冲区，用于在线程的栈上分配对象**，以提高对象分配的效率

在Java中，**对象的分配通常是在堆内存上进行的，而且通常是多线程共享的。当多个线程同时进行对象分配时，可能会导致竞争和锁冲突，从而降低分配效率**。为了避免这种竞争，JVM引入了`Thread Local Allocation Buffer`（TLAB）技术

**TLAB的基本思想是为每个线程预先在堆上分配一块小的缓冲区，用于该线程的对象分配(对 `Eden` 区域继续进行划分，`JVM` 为每个线程分配了一个私有缓存区域，它包含在 `Eden` 空间内)。当线程需要分配对象时，它可以在自己的TLAB上进行分配，而不需要在全局堆上竞争。这样，每个线程都有自己的独立缓冲区，避免了线程之间的竞争，提高了对象分配的效率。**

TLAB的使用可以减少对全局锁的竞争，从而提高多线程程序的性能。不过，**TLAB的大小是有限的，当一个线程的TLAB用尽时，它还是需要在全局堆上分配对象**。JVM会动态调整TLAB的大小，以适应不同线程的对象分配需求。

需要注意的是，TLAB是JVM的一种实现细节，可能在不同的JVM版本和垃圾回收器中有所不同。不同的JVM实现可以使用不同的策略来优化对象分配和TLAB的使用







### 方法区

方法区用于存储已被虚拟机加载的类型信息、常量、静态变量、**即时编译器编译后的代码缓存**等

方法区和堆一样，是线程共享的区域，它用来存储已经被 Java 虚拟机加载的类信息、常量、静态变量，以及便器编译后的代码等，虽然 Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫 `Non-Heap`（非堆），目的应该是与 Java 堆区分开



JVM的方法区主要用于存储以下数据:

- 已经加载的类信息:包括类名、父类名、接口信息、成员变量和方法等。这些数据会在类加载时被加载到方法区。
- 运行时常量池:方法区中包含类的运行时常量池,存储字符串字面量、数字字面量和符号引用。
- 静态变量:所有类的静态变量数据都被存储在方法区中。
- 类元数据:包括有关类的信息,如annotations、泛型信息等。
- 方法字节码:所有的类中的方法对应字节码都存储在方法区中。
- **JIT代码缓存：热点代码**
- 指向方法区的全局变量:虚拟机规范保留了一些指向方法区数据的全局变量,类似于方法区的引用。



> 《Java 虚拟机规范》中只规定了有方法区这么一个概念和它的作用，并没有规定如何去实现它。那么不同的 Java 虚拟机可能就会有不同的实现。永久代是 HotSpot 对方法区的一种实现形式。也就是说，永久代只是 HotSpot 中的一个概念，而方法区则是 Java 虚拟机规范中的一个定义，一种规范
>
> 换句话说，方法区和永久代的关系就像是 Java 中接口和类的关系，类实现了接口

在方法区中，有一块非常重要的部分，也就是**运行时常量池**。在讲 `class` 文件的时候，提到了每个 `class` 文件都会有个常量池，用来存放字符串常量、类和接口的名字、字段名、常量等等。运行时常量池和 `class` 文件的常量池是一一对应的，它就是通过 `class` 文件中的常量池来构建的

**JDK 7 之前，运行时常量池中包含着字符串常量池，都在方法区**，此时的方法区实现是**永久代**

**JDK 7 的时候，字符串常量池从方法区中拿出来放到了堆中，运行时常量池中的其他东西还在方法区中**，此时的方法区实现仍然是**永久代**

**JDK 8 的时候，HotSpot 移除了永久代，也就是说方法区不存在了，取而代之的是元空间。也就意味着字符串常量池在堆中(类的静态变量同样转移到了堆中)，运行时常量池跑到了元空间(永久代中的 `class metadata` 转移到了 `native memory`)**



![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/method-area-implementation.png)





- 方法区（Method Area）与 Java 堆一样，是所有线程共享的内存区域
- 虽然 Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫 Non-Heap（非堆），目的应该是与 Java 堆区分开
- 运行时常量池（`Runtime Constant Pool`）是方法区的一部分。Class 文件中除了有类的版本/字段/方法/接口等描述信息外，**还有一项信息是常量池（Constant Pool Table），用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放**。运行期间也可能将新的常量放入池中，这种特性被开发人员利用得比较多的是 `String.intern()`方法。受方法区内存的限制，当常量池无法再申请到内存时会抛出 `OutOfMemoryError` 异常
- 方法区的大小和堆空间一样，可以选择固定大小也可选择可扩展，方法区的大小决定了系统可以放多少个类，如果系统类太多，导致方法区溢出，虚拟机同样会抛出内存溢出错误
- JVM 关闭后方法区即被释放





> 再来说说为什么要将永久代 (PermGen) 或者说方法区替换为元空间 (MetaSpace) 

第一，永久代放在 Java 虚拟机中，就会受到 Java 虚拟机内存大小的限制，而元空间使用的是本地内存，也就脱离了 Java 虚拟机内存的限制

第二，元空间里面存放的是类的元数据，这样加载多少类的元数据就不由 `MaxPermSize` 控制了, 而由系统的实际可用空间来控制，这样能加载的类就更多了。

第三，JDK 8 的时候，在 HotSpot 中融合了 JRockit 虚拟机，而 JRockit 中并没有永久代的概念，因此新的 HotSpot 就没有必要再开辟一块空间来作为永久代了





>  总结一下：方法区在 JDK6、7、8中的演进细节.....

首先要清楚只有 HotSpot 才有永久代的概念

| JDK版本      | 是否有永久代，字符串常量池放在哪里？                         | 方法区逻辑上规范，由哪些实际的部分实现的？                   |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| jdk1.6及之前 | 有永久代，运行时常量池（包括字符串常量池），**静态变量存放在永久代上** | 这个时期方法区在HotSpot中是由永久代来实现的，以至于**这个时期说方法区就是指永久代** |
| jdk1.7       | 有永久代，但已经逐步“去永久代”，**字符串常量池、静态变量移除，保存在堆中；** | 这个时期方法区在HotSpot中由**永久代**（类型信息、字段、方法、常量）和**堆**（字符串常量池、静态变量）共同实现 |
| jdk1.8及之后 | 取消永久代，类型信息、字段、方法、常量保存在本地内存的元空间，但字符串常量池、静态变量仍在堆中 | 这个时期**方法区**在HotSpot中由本地内存的**元空间**（类型信息、字段、方法、常量）和**堆**（字符串常量池、静态变量）**共同实现** |









### 常量池

**运行时常量池：**

先来看看字节码中的常量池和运行时常量池的区别在哪里：

运行时常量池（Runtime Constant Pool）和字节码中的常量池（Constant Pool）是Java虚拟机（JVM）中两个不同的概念，但它们之间存在着密切的关系。

1. **字节码中的常量池（Constant Pool）：** 在Java源代码编译成字节码文件（`.class`文件）时，编译器将所有的字面量常量（如字符串、整数、浮点数等）和符号引用（如类、方法、字段的引用）都存储在字节码的常量池中。字节码中的常量池是一种表格数据结构，它包含了多个常量项（Constant Pool Entry）。字节码文件中的指令使用这些常量项来表示所需的常量值或符号引用。这个常量池在类加载时会被加载到JVM的方法区中，并供运行时使用。
2. **运行时常量池（Runtime Constant Pool）：** 运行时常量池是Java虚拟机在内存中的一部分，它是字节码中常量池的运行时表现形式。在类加载后，JVM会将字节码中的常量池内容转移到运行时常量池中，供程序在运行时使用。运行时常量池是方法区的一部分，用于存放**运行时常量和符号引用**。在运行时，Java程序可以动态生成一些常量，并且运行时常量池会动态扩展以适应新的常量添加。

可以看出，字节码中的常量池是在编译阶段生成的，它是`.class`文件的一部分。而运行时常量池是在类加载过程中，将字节码中的常量池内容加载到JVM的方法区中形成的，供程序在运行时使用。

总结来说，字节码中的常量池是编译时的静态常量表，而运行时常量池是运行时动态生成的常量表，它们之间是一种静态和动态的对应关系





**字符串常量池：**

**字符串常量池** 是 JVM 为了提升性能和减少内存消耗针对字符串（`String` 类）专门开辟的一块区域，主要目的是为了避免字符串的重复创建

```java
// 在堆中创建字符串对象”ab“,因为JDK7之后字符串常量池已经在堆中了
// 将字符串对象”ab“的引用保存在字符串常量池中
String aa = "ab";
// 直接返回字符串常量池中字符串对象”ab“的引用
String bb = "ab";
System.out.println(aa==bb);// true
```

HotSpot 虚拟机中字符串常量池的实现是 `src/hotspot/share/classfile/stringTable.cpp` ,`StringTable` 可以简单理解为一个固定大小的`HashTable` ，容量为 `StringTableSize`（可以通过 `-XX:StringTableSize` 参数来设置），保存的是字符串（key）和 字符串对象的引用（value）的映射关系，字符串对象的引用(**准确说位于方法区中**)指向堆中的字符串对象

JDK1.7 之前，字符串常量池(包括静态变量)存放在永久代，**JDK1.7 时字符串常量池和静态变量从永久代移动了 Java 堆中**(**此时元空间还不是方法区的实现，此时还被称做是永久代**)

观察以下图即可得出结论：

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/method-area-jdk1.6.png" style="zoom: 67%;" />



<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/method-area-jdk1.7.png" style="zoom: 67%;" />



**JDK 1.7 为什么要将字符串常量池移动到堆中？**

主要是因为永久代（方法区实现）的 GC 回收效率太低，只有在整堆收集`Full GC`的时候才会被执行 `GC`(一般都是针对新生代的GC——`Minor GC`)。**Java 程序中通常会有大量的被创建的字符串等待回收，将字符串常量池放到堆中，能够更高效及时地回收字符串内存。**













## 类加载 :cactus:



### 加载流程

Java 的类加载过程可以分为 5 个阶段：载入、验证、准备、解析和初始化(**中间三个阶段可合并为连接**)。这 5 个阶段一般是顺序发生的，但在动态绑定的情况下，解析阶段发生在初始化阶段之后

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/class-loading-procedure.png" style="zoom: 67%;" />



1、载入

类加载过程的第一步，主要完成下面 3 件事情：

1. 通过全类名**获取**定义此类的二进制字节流

   > 虚拟机规范上面这 3 点并不具体，因此是非常灵活的。比如："通过全类名获取定义此类的二进制字节流" 并没有指明具体从哪里获取（ `ZIP`、 `JAR`、`EAR`、`WAR`、网络、动态代理技术运行时动态生成、其他文件生成比如 `JSP`...）、怎样获取

2. **将字节流所代表的静态存储结构转换为方法区的运行时数据结构**。

3. **在内存中生成一个代表该类的 `Class` 对象，作为方法区这些数据的访问入口**



加载这一步主要是通过我们后面要讲到的 **类加载器** 完成的。类加载器有很多种，当我们想要加载一个类的时候，具体是哪个类加载器加载由 **双亲委派模型** 决定（不过，我们也能打破由双亲委派模型）

每个 Java 类都有一个引用指向加载它的 `ClassLoader`。不过，数组类不是通过 `ClassLoader` 创建的，而是 JVM 在需要的时候自动创建的，数组类通过`getClassLoader()`方法获取 `ClassLoader` 的时候和该数组的元素类型的 `ClassLoader` 是一致的。

一个非数组类的加载阶段（加载阶段获取类的二进制字节流的动作）是可控性最强的阶段，这一步我们可以去完成还可以自定义类加载器去控制字节流的获取方式（重写一个类加载器的 `loadClass()` 方法）

> 数组类是指用于表示数组对象的类,Java中数组类的特点如下：
>
> 1. 数组类是Java的内置类，不需要额外导入
> 2. 数组类是Java语言提供的一种数据结构，可以存储多个相同数据类型的元素
> 3. 数组类是对象，继承自`java.lang.Object`类，因此它可以使用`Object`类的方法，比如`toString()`和`hashCode()`等

JVM 在该阶段的主要目的是**将字节码从不同的数据源**（可能是 class 文件、也可能是 jar 包，甚至网络）**转化为二进制字节流加载到内存中**，并生成一个代表该类的 `java.lang.Class` 对象







2、验证

JVM 会在该阶段对二进制字节流进行校验，只有符合 JVM 字节码规范的才能被 JVM 正确执行。**该阶段是保证 JVM 安全的重要屏障，防止恶意代码的执行**，验证阶段主要由四个检验阶段组成：

1. 文件格式验证（Class 文件格式检查）
2. 元数据验证（字节码语义检查）
3. 字节码验证（程序语义检查）
4. 符号引用验证（类的正确性检查）

下面是一些主要的检查：

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/class-loading-process-verification.png" style="zoom: 80%;" />

文件格式验证这一阶段是基于该类的二进制字节流进行的，主要目的是保证输入的字节流能正确地解析并存储于方法区之内，格式上符合描述一个 Java 类型信息的要求。除了这一阶段之外，**其余三个验证阶段都是基于方法区的存储结构上进行的，不会再直接读取、操作字节流了**

**符号引用验证发生在类加载过程中的解析阶段，具体点说是 JVM 将符号引用转化为直接引用**的时候





3、准备

**准备阶段是正式为类变量分配内存并设置类变量默认值的阶段**，这些内存都将在方法区中分配(不同版本jdk方法区实现不同，导致类变量存放的位置也不同)

> 对于该阶段有以下几点需要注意：
>
> 1. 这时候进行内存分配的仅包括类变量（ Class Variables ，即**静态变量**，被 `static` 关键字修饰的变量，只与类相关，因此被称为类变量），而**不包括实例变量**。实例变量会在对象实例化时随着对象一块分配在 Java 堆中。
> 2. 从概念上讲，类变量所使用的内存都应当在 **方法区** 中进行分配。不过有一点需要注意的是：JDK 7 之前，HotSpot 使用永久代来实现方法区的时候，实现是完全符合这种逻辑概念的。 而**在 JDK 7 及之后，HotSpot 已经把原本放在永久代的字符串常量池、静态变量等移动到堆中，这个时候类变量则会随着 Class 对象一起存放在 Java 堆中(这块很重要！！！)**
> 3. 这里所设置的初始值"通常情况"下是数据类型默认的零值（如 0、0L、null、false 等），比如我们定义了`public static int value=111` ，那么 value 变量在准备阶段的初始值就是 0 而不是 111（初始化阶段才会赋值）。特殊情况：比如给 value 变量加上了 final 关键字`public static final int value=111` ，那么准备阶段 value 的值就被赋值为 111

JVM 会在该阶段对类变量（也称为静态变量，`static` 关键字修饰的）分配内存并初始化（对应数据类型的默认初始值，如 0、0L、null、false 等），也就是说假如有这样一段代码：

```java
public String chenmo = "沉默";
public static String wanger = "王二";
public static final String cmower = "沉默王二";
```

- `chenmo` 不会被分配内存，而 `wanger` 会；但 `wanger` 的初始值不是“王二”而是 `null`。

- 需要注意的是，`static final` 修饰的变量被称作为常量，和类变量不同。常量一旦赋值就不会改变了，所以 `cmower` 在准备阶段的值为“`沉默王二`”而不是 `null`
- 字符串常量`"沉默王二"`被存放在字符串常量池中，在JAVA7之前，字符串常量池在方法区中，JAVA7(包括)之后字符串常量池及静态变量都被转移到了堆中！！







4、解析

**解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程**

> 1. **符号引用（Symbolic Reference）：** 在Java代码的编译阶段，所有的类名、方法名、字段名等都以符号引用的形式存在。符号引用是一种符号化的引用，它**并不具体指向内存中的实际数据**，而是一个对其所引用目标的符号化描述。例如，在Java代码中使用类名调用方法，这个方法的引用在编译阶段是以符号引用的方式存在
> 2. **直接引用（Direct Reference）：** 在Java代码的运行时阶段，虚拟机需要**通过符号引用来定位具体的内存地址**。在类加载过程中，虚拟机会将符号引用转换为直接引用，即将类、方法、字段等符号引用解析为实际的内存地址。**直接引用可以是指向方法区中的运行时常量池、堆中的对象实例、本地方法栈中的本地方法等**

例如，考虑以下两个Java类：

```java
// MyClass.java
public class MyClass {
    public static void main(String[] args) {
        int result = MyUtils.add(3, 5);
        System.out.println("Result: " + result);
    }
}
```

```java
// MyUtils.java
public class MyUtils {
    public static int add(int a, int b) {
        return a + b;
    }
}
```

在`MyClass`类的`main`方法中，我们调用了`MyUtils`类的`add`方法。在编译阶段，Java编译器会生成符号引用，表示`MyUtils.add`方法的调用

在运行时，虚拟机会将这个符号引用转换为直接引用。假设**`MyUtils`类已经被加载到内存中，`add`方法也已经被解析到方法区中的运行时常量池。虚拟机通过解析符号引用，得到具体的内存地址，使得代码能够正确地调用`MyUtils.add`方法，计算出结果并输出**。

这个例子中，**符号引用是在代码编译阶段生成的，而直接引用是在运行时通过解析符号引用得到的**，使得Java程序能够正确地访问和调用其他类中的方法



**综上所述：**解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程，也就是得到类或者字段、方法在内存中的指针或者偏移量。	

> 在Java字节码中，符号引用（Symbolic Reference）是一种用来表示符号名称（如类名、字段名、方法名）的引用，而不是直接指向对应的内存地址或具体实现。符号引用是一种抽象的引用，它在编译期间用于进行编译和链接，最终在**运行**时通过解析转换为直接引用。
>
> 符号引用在Java字节码中通常用常量池（`Constant Pool`）来表示。常量池是字节码文件中的一个表，用于存储类、字段、方法等的符号引用信息。它包含了多种常量类型，其中就包括符号引用。
>
> 在常量池中，**符号引用会被编码成一个索引值，该索引值指向常量池中另一个常量项。这个被索引的常量项具体表示了符号引用的信息，包括所属的类名、字段或方法的名称和描述符等**。
>
> 通过符号引用的使用，**Java字节码实现了一种间接引用的方式，使得类、字段和方法的引用在编译期间可以解析和确认**，**而具体的内存地址或实现则在运行时动态解析和连接(运行时才执行字节码文件)**。



5、初始化

**初始化阶段是执行初始化方法 `<classinit> ()`方法的过程，是类加载的最后一步，这一步 JVM 才开始真正执行类中定义的 Java 程序代码(字节码)**

该阶段是类加载过程的最后一步。**在准备阶段，类变量已经被赋过默认初始值，而在初始化阶段，类变量将被赋值为代码期望赋的值**，在Java中对类变量(静态变量)进行初始值设定有两种方式:

- 声明类变量是指定初始值
- 使用静态代码块为类变量指定初始值



> **类初始化时机**: 只有当对类的主动使用的时候才会导致类的初始化，类的主动使用包括以下六种:
>
> - 创建类的实例，也就是new的方式
> - 访问某个类或接口的静态变量，或者对该静态变量赋值
> - 调用类的静态方法
> - 反射(如Class.forName("com.pdai.jvm.Test"))
> - 初始化某个类的子类，则其父类也会被初始化
> - Java虚拟机启动时被标明为启动类的类(Java Test)，直接使用java.exe命令来运行某个主类



6、使用与卸载

**卸载类即该类的 Class 对象被 GC**，卸载类需要满足 3 个要求:

1. 该类的所有的实例对象都已被 GC，也就是说堆不存在该类的实例对象。
2. 该类没有在其他任何地方被引用
3. 该类的类加载器的实例已被 GC

所以，在 `JVM` 生命周期内，由 `jvm` 自带的类加载器加载的类是不会被卸载的。但是由我们自定义的类加载器加载的类是可能被卸载的。

只要想通一点就好了，**JDK 自带的 `BootstrapClassLoader`, `ExtClassLoader`, `AppClassLoader` 负责加载 JDK 提供的类，所以它们(类加载器的实例)肯定不会被回收**。而我们自定义的类加载器的实例是可以被回收的，所以使用我们自定义加载器加载的类是可以被卸载掉的





### 类加载器

> **JVM 判定两个 Java 类是否相同的具体规则**：JVM 不仅要看类的全名是否相同，还要看加载此类的类加载器是否一样。只有两者都相同的情况，才认为两个类是相同的。即使两个类来源于同一个 `Class` 文件，被同一个虚拟机加载，只要加载它们的类加载器不同，那这两个类就必定不相同

对于任意一个类，都需要由它的类加载器和这个类(`.class`)本身一同确定其在 JVM 中的唯一性。也就是说，如果两个类的加载器不同，即使两个类来源于同一个`class`字节码文件，那这两个类就必定不相等（比如两个类的 Class 对象不 `equals`）

- 类加载器是一个负责加载类的对象，用于实现类加载过程中的加载这一步
- 每个 Java 类都有一个引用指向加载它的 `ClassLoader`
- 数组类不是通过 `ClassLoader` 创建的（数组类没有对应的二进制字节流），是由 JVM 直接生成的

站在程序员的角度来看，Java 类加载器可以分为三种：

1）启动类加载器（`Bootstrap Class-Loader`），加载 `jre/lib` 包下面的 jar 文件，比如说常见的 rt.jar。

2）扩展类加载器（`Extension or Ext Class-Loader`），加载 `jre/lib/ext` 包下面的 jar 文件。

3）应用类加载器（`Application or AppClass-Loader`），根据程序的类路径（`classpath`）来加载 Java 类。

> JVM 中内置了三个重要的 `ClassLoader`：
>
> 1. **`BootstrapClassLoader`(启动类加载器)**：最顶层的加载类，由 C++实现，通常表示为 null，并且没有父级，主要用来加载 JDK 内部的核心类库（ `%JAVA_HOME%/lib`目录下的 `rt.jar`、`resources.jar`、`charsets.jar`等 jar 包和类）以及被 `-Xbootclasspath`参数指定的路径下的所有类
> 2. **`ExtensionClassLoader`(扩展类加载器)**：主要负责加载 `%JRE_HOME%/lib/ext` 目录下的 jar 包和类以及被 `java.ext.dirs` 系统变量所指定的路径下的所有类
> 3. **`AppClassLoader`(应用程序类加载器)**：面向我们用户的加载器，负责加载当前应用 classpath 下的所有 jar 包和类

来一段代码分析一下：

```java
public class Test {
	public static void main(String[] args) {
		ClassLoader loader = Test.class.getClassLoader();
		while (loader != null) {
			System.out.println(loader.toString());
			loader = loader.getParent();
		}
	}
}
```

每个 Java 类都维护着一个指向定义它的类加载器的引用，通过 `类名.class.getClassLoader()` 可以获取到此引用；然后通过 `loader.getParent()` 可以获取类加载器的上层类加载器。

这段代码的输出结果如下：

```text
sun.misc.Launcher$AppClassLoader@73d16e93
sun.misc.Launcher$ExtClassLoader@15db9742
```

第一行输出为 `Test` 的类加载器，即应用类加载器`AppClassLoader`，它是 `sun.misc.Launcher$AppClassLoader` 类的实例；第二行输出为扩展类加载器`ExtensionClassLoader`，是 `sun.misc.Launcher$ExtClassLoader` 类的实例。那启动类加载器呢？

按理说，扩展类加载器的上层类加载器是启动类加载器`BootStrapLoader`，但在这个版本的 JDK 中， 扩展类加载器的 `getParent()` 返回 `null`，所以没有输出。

> **为什么 获取到 `ClassLoader` 为`null`就是 `BootstrapClassLoader` 加载的呢？** 这是因为`BootstrapClassLoader` 由 C++ 实现，由于这个 C++ 实现的类加载器在 Java 中是没有与之对应的类的，所以拿到的结果是 null

除了这三种类加载器之外，用户还可以加入自定义的类加载器来进行拓展，以满足自己的特殊需求。就比如说，我们可以对 Java 类的字节码（ `.class` 文件）进行加密，加载时再利用自定义的类加载器对其解密

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/class-loader-parents-delegation-model.png" style="zoom:67%;" />



> 如何自定义`ClassLoader`类加载器？

除了 `BootstrapClassLoader` 其他类加载器均由 `Java` 实现且全部继承自`java.lang.ClassLoader`。如果我们要自定义自己的类加载器，很明显需要继承 `ClassLoader`抽象类

`ClassLoader` 类有两个关键的方法：

- `protected Class loadClass(String name, boolean resolve)`：加载指定二进制名称的类，**实现了双亲委派机制**。`name` 为类的二进制名称，`resove` 如果为 true，在加载时调用 `resolveClass(Class<?> c)` 方法解析该类

  `loadClass(String name, boolean resolve)` 方法：该方法是 `ClassLoader` 类中的主要方法，它的作用是根据给定的类名加载相应的类。这个方法首先会检查缓存中是否已经加载了该类，如果已经加载了，则直接返回缓存中的类；如果没有加载，则会调用父类加载器来尝试加载类。如果父类加载器也没有加载该类，则会调用 `findClass()` 方法来加载类。

- `protected Class findClass(String name)`：根据类的二进制名称来查找类，默认实现是空方法。

  该方法是 `ClassLoader` 中的保护方法，它的作用是查找并加载指定名称的类。如果子类需要加载一个新的类，可以重写该方法。在实现该方法时，通常是通过读取字节码文件，并调用 `defineClass()` 方法来创建一个类的 `Class` 对象。

总的来说，`loadClass()` 方法主要负责委派父类加载器来加载类，而 `findClass()` 方法则是子类加载器用来自定义加载类的实现方法









### 双亲委派模型 :astonished:



<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/class-loader-parents-delegation-model.png" style="zoom:75%;" />

- `ClassLoader` 类使用委托模型来搜索类和资源。

- 双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都应有自己的父类加载器。

- **每个`ClassLoader` 实例会在试图亲自查找类或资源之前，将搜索类或资源的任务委托给其父类加载器**



执行流程按照图中的理解分为以下几步：

1. 当`AppClassLoader`加载一个`class`时，它首先不会自己去尝试加载这个类，而是把类加载请求委派给父类加载器`ExtClassLoader`去完成(通过`loadClass()`方法来委派上层)
2. 当`ExtClassLoader`加载一个`class`时，它首先也不会自己去尝试加载这个类，而是把类加载请求委派给`BootStrapClassLoader`去完成
3. 如果`BootStrapClassLoader`加载失败(例如在$JAVA_HOME/jre/lib里未查找到该class)，会使用`ExtClassLoader`来尝试加载；
4. 若`ExtClassLoader`也加载失败，则会使用`AppClassLoader`来加载，如果`AppClassLoader`也加载失败，则会报出异常`ClassNotFoundException`(我们可以自定义`classloader`才处理这种情况)





注意:question: : 双亲委派模型并不是一种强制性的约束，只是 JDK 官方推荐的一种方式。如果我们因为某些特殊需求想要打破双亲委派模型，也是可以的，后文会介绍具体的方法。

双亲委派模型的实现代码非常简单:

```java
protected Class<?> loadClass(String name, boolean resolve)
    throws ClassNotFoundException
{
    synchronized (getClassLoadingLock(name)) {
        //首先，检查该类是否已经加载过
        Class c = findLoadedClass(name);
        if (c == null) {
            //如果 c 为 null，则说明该类没有被加载过
            long t0 = System.nanoTime();
            try {
                if (parent != null) {
                    //当父类的加载器不为空，则通过父类的loadClass来加载该类
                    c = parent.loadClass(name, false);
                } else {
                    //当父类的加载器为空，则调用启动类加载器来加载该类
                    c = findBootstrapClassOrNull(name);
                }
            } catch (ClassNotFoundException e) {
                //非空父类的类加载器无法找到相应的类，则抛出异常
            }

            if (c == null) {
                //当父类加载器无法加载时，则调用findClass方法来加载该类
                //用户可通过覆写该方法，来自定义类加载器
                long t1 = System.nanoTime();
                c = findClass(name);

                //用于统计类加载器相关的信息
                sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0);
                sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1);
                sun.misc.PerfCounter.getFindClasses().increment();
            }
        }
        if (resolve) {
            //对类进行link操作
            resolveClass(c);
        }
        return c;
    }
}

```

结合上面的源码，简单总结一下双亲委派模型的执行流程：

- 在类加载的时候，系统会首先判断当前类是否被加载过。已经被加载的类会直接返回，否则才会尝试加载（每个父类加载器都会走一遍这个流程）
- 类加载器在进行类加载的时候，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成（调用父加载器 `loadClass()`方法来加载类），这样所有的请求最终都会传送到顶层的启动类加载器 `BootstrapClassLoader` 中
- 只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载（调用自己的 `findClass()` 方法来加载类）





> 那么使用双亲委派模型的好处在哪里？

双亲委派模型保证了 Java 程序的稳定运行，可以避免类的重复加载（JVM 区分不同类的方式不仅仅根据类名，相同的类文件被不同的类加载器加载产生的是两个不同的类），也保证了 Java 的核心 API 不被篡改。

如果没有使用双亲委派模型，而是每个类加载器加载自己的话就会出现一些问题，比如我们编写一个称为 `java.lang.Object` 类的话，那么程序运行的时候，系统就会出现两个不同的 `Object` 类。双亲委派模型可以保证加载的是 JRE 里的那个 `Object` 类，而不是你写的 `Object` 类。这是因为 `AppClassLoader` 在加载你的 `Object` 类时，会委托给 `ExtClassLoader` 去加载，而 `ExtClassLoader` 又会委托给 `BootstrapClassLoader`，`BootstrapClassLoader` 发现自己已经加载过了 `Object` 类，会直接返回，不会去加载你写的 `Object` 类





> 如何打破双亲委派模型呢？

自定义加载器的话，需要继承 `ClassLoader` 。如果我们要打破双亲委派模型，就需要重写 `ClassLoader` 类中的 `findClass()` 方法即可，该方法会在父类加载器无法加载该类时被调用，通过这个方法我们可以自己实现类的加载过程，从而打破双亲委派模型。









> **`Tomcat`如何实现应用隔离的？  **为每个web应用分配一个WebAppClassLoader加载器实例



我们比较熟悉的 Tomcat 服务器为了能够优先加载 Web 应用目录下的类，然后再加载其他目录下的类，就自定义了类加载器 `WebAppClassLoader` 来打破双亲委托机制。这也是 Tomcat 下 Web 应用之间的类实现隔离的具体原理

1、**WebAppClassLoader**

若使用JVM默认的`AppClassLoader`加载Web应用，`AppClassLoader`只能加载一个`Servlet`类，在加载第二个同名`Servlet`类时，`AppClassLoader`会返回第一个`Servlet`类的`Class`实例。因为在`AppClassLoader`眼里，同名`Servlet`类只能被加载一次,于是，Tomcat自定义了一个类加载器`WebAppClassLoader`， 并为每个Web应用创建一个`WebAppClassLoader`实例

每个Web应用自己的Java类和依赖的JAR包，分别放在WEB-INF/classes和WEB-INF/lib目录下，都是WebAppClassLoader加载的

**Context容器组件对应一个Web应用，因此，每个Context容器创建和维护一个WebAppClassLoader加载器实例**。不同加载器实例加载的类被认为是不同的类，即使类名相同。这就相当于在JVM内部创建相互隔离的Java类空间，每个Web应用都有自己的类空间，Web应用之间通过各自的类加载器互相隔



2、**SharedClassLoader:**

两个Web应用之间怎么共享**库类**，并且不能重复加载相同的类？

**双亲委派机制的各子加载器都能通过父加载器去加载类，于是考虑把需共享的类放到父加载器的加载路径**

不同的WEB应用程序即是通过该方式**共享JRE核心类**:

(1) Tomcat搞了个类加载器`SharedClassLoader`，作为`WebAppClassLoader`的父加载器，以加载Web应用之间共享的类

(2) 若`WebAppClassLoader`未加载到某类，就委托父加载器`SharedClassLoader`去加载该类，`SharedClassLoader`会在指定目录下加载共享类，之后返回给`WebAppClassLoader`，即可解决共享问题



3、**CatalinaClassLoader:**

如何隔离Tomcat本身的类和Web应用的类？

兄弟关系：两个类加载器是平行的，它们可能**拥有同一父加载器**，**但两个兄弟类加载器加载的类是隔离的**。于是，Tomcat搞了`CatalinaClassLoader`，**专门加载Tomcat自身的类**

问题是，当Tomcat和各Web应用之间需要共享一些类时该怎么办？(依赖`CommonClassLoader`)



4、**CommonClassLoader:**

共享依旧靠父子关系。

故再增加个`CommonClassLoader`，作为`CatalinaClassLoader`和`SharedClassLoader`的父加载器。



`CommonClassLoader`能加载的类都可被`CatalinaClassLoader`、`SharedClassLoader` 使用，而`CatalinaClassLoader`和`SharedClassLoader`能加载的类则与对方相互隔离。`WebAppClassLoader`可以使用`SharedClassLoader`加载到的类，但各个`WebAppClassLoader`实例之间相互隔离



`Tomcat` 的类加载器的层次结构如下：

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/tomcat.png" style="zoom:50%;" />

> **场景：**
>
> 1、如果Tomcat里面运行了两个Web应用程序，两个Web应用程序中有同名的[Servlet](https://so.csdn.net/so/search?q=Servlet&spm=1001.2101.3001.7020)，但功能不同，Tomcat需要同时加载和管理这两个同名的 Servlet 类，保证它们不会冲突，因此 Web 应用之间的类需要隔离
>
> 2、如果两个 Web 应用都依赖同一个第三方的 JAR 包，比如 Spring，那 Spring 的 JAR 包被加载到内存后，Tomcat 要保证这两个 Web 应用能够共享，也就是说Spring 的 JAR 包只被加载一次，否则随着依赖的第三方JAR 包增多，JVM 的内存会膨胀

解决方法如下：

(1)为了解决`AppClassLoader`同类名的`Servlet`类只能被加载一次的问题，Tomcat 自定义一个类加载器`WebAppClassLoader`， 并且给每个 Web 应用创建一个类加载器实例。Context 容器组件对应一个 Web 应用，因此，每个 Context 容器负责创建和维护一个`WebAppClassLoader` 加载器实例。**原理是，不同的加载器实例加载的类被认为是不同的类，即使它们的类名相同。这就相当于在 Java 虚拟机内部创建了一个个相互隔离的 Java 类空间，每一个 Web 应用都有自己的类空间，Web 应用之间通过各自的类加载器互相隔离**

(2)**为了Tomcat可以存放多个Web应用，Tomcat实现了Web应用的隔离，从而达到可以加载不同Web应用下相同名的Servlet类，从而编写了自己的类加载器，其内部类加载器模型如下图所示：**

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/tomcat.png" style="zoom:50%;" />

（1）`SharedClassLoader`：该类加载器存在是为了解决不同Web应用之间共享类库，并且不会重复加载相同的类。它作为`WebAppClassLoader`的父加载器，专门加载Web应用之间的共享类。
（2）`CatalinaClassloader`：该类加载器专门加载Tomcat自身的类，从而和web应用的类做一个隔离。
（3）`CommonClassLoader`：`CatalinaClassLader`实现了Tomcat类和web应用类的隔离，如果二者之间需要共享一些类怎么办？这里就需要`CommonClassLoader`，它所加载的所有类都可以被`SharedClassLoader`和`CatalinaClassLoader`使用，从而实现web应用和tomcat对一些类的共享







## JIT & 逃逸分析

首先要知道`HotSpot` VM：`OracleJDK`（商用）和 `OpenJDK`（开源）的默认虚拟机，也是目前使用最广泛的 Java 虚拟机。`HotSpot` 的技术优势就在于热点代码探测技术（名字就从这来）和准确式内存管理技术，**热点代码探测**指的是，通过执行计数器找出最具有编译价值的代码，然后通知即时编译器以方法为单位进行编译，解释器就可以不再逐行的将字节码翻译成机器码，而是将一整个方法的所有字节码翻译成机器码再执行

常见的编译型语言如 C++，通常会把代码直接编译成 CPU 所能理解的机器码来运行。而 Java 为了实现“一次编译，处处运行”的特性，把编译的过程分成两部分，首先它会先由 javac 编译成通用的中间形式——字节码，然后再由解释器逐条将字节码解释为机器码来执行。所以在性能上，Java 可能会干不过 C++ 这类编译型语言

为了优化 Java 的性能 ，JVM 在解释器之外引入了 JIT 编译器：当程序运行时，解释器首先发挥作用，代码可以直接执行。随着时间推移，即时编译器逐渐发挥作用，把越来越多的代码编译优化成本地代码，来获取更高的执行效率。解释器这时可以作为编译运行的降级手段，在一些不可靠的编译优化出现问题时，再切换回解释执行，保证程序可以正常运行



> 怎么样才会被认为是热点代码呢？

JVM中会设置一个阈值，**当方法或者代码块的在一定时间内的调用次数超过这个阈值时就会被编译，存入`codeCache`中**，当下次执行时，再遇到这段代码，就会从`CodeCache`中读取机器码直接执行，以此来提升程序运行的性能。整体的执行过程大致如下图所示：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E7%83%AD%E7%82%B9%E4%BB%A3%E7%A0%81.png)



`CodeCache` 中存放的是 `JIT` 编译器生成的**本地代码**，而不是字节码 `class` 文件！！





逃逸分析：

而逃逸分析是一种在编译器或运行时优化中使用的技术，用于分析对象的生命周期，判断对象是否在方法之外被引用（即逃逸出方法的作用域），以便进行相应的优化。

在Java中，当一个对象在方法内部被创建后，它可能被分配到栈上或堆上。如果在方法内部创建的对象没有逃逸出方法的作用域，即在方法内部使用并不会在方法外部被引用，那么编译器或运行时系统可以对其进行优化，将对象分配到栈上而不是堆上。

**逃逸分析的主要目的是通过减少对象的堆分配，从而减少垃圾回收的压力，提高程序的性能。在栈上分配对象可以使对象的生命周期更短，当方法调用结束时，栈上的对象会自动释放，不需要进行垃圾回收，从而减少了内存的开销和垃圾回收的时间**，同时逃逸分析也在锁消除中发挥了作用，如果一个变量声明为局部变量且不会被其他线程所访问(只在自己栈中)，那么会将一些不必要的锁给消除掉











## 垃圾回收

针对 HotSpot VM 的实现，它里面的 GC 其实准确分类只有两大种：

部分收集 (Partial GC)：

- 新生代收集（Minor GC / Young GC）：只对新生代进行垃圾收集；
- 老年代收集（Major GC / Old GC）：只对老年代进行垃圾收集。需要注意的是 Major GC 在有的语境中也用于指代整堆收集；
- 混合收集（Mixed GC）：对整个新生代和部分老年代进行垃圾收集。

整堆收集 (Full GC)：收集整个 Java 堆和方法区









### 如何判断死亡对象？





1、**引用计数器：**

引用计数算法（Reachability Counting）是通过在对象头中分配一个空间来保存该对象被引用的次数（Reference Count）。如果该对象被其它对象引用，则它的引用计数加1，如果删除对该对象的引用，那么它的引用计数就减1，当该对象的引用计数为0时，那么该对象就会被回收。

```java
String m = new String("jack");
```

先创建一个字符串，这时候"jack"有一个引用 m：

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E5%BC%95%E7%94%A81.jpg" style="zoom: 67%;" />

然后将 m 设置为 null，这时候"jack"的引用次数就等于0了，在引用计数算法中，意味着这块内容就需要被回收了

引用计数算法是**将垃圾回收分摊到整个应用程序的运行当中了**，而不是在进行垃圾收集时：挂起整个应用的运行，直到对堆中所有对象的处理都结束。因此，采用引用计数的垃圾收集不属于严格意义上的"`Stop-The-World`"的垃圾收集机制

而且这种算法存在**循环引用问题**：

```java
public class ReferenceCountingGC {
    public Object instance;
    public ReferenceCountingGC(String name)
    {

    }

}
public static void testGC(){
    ReferenceCountingGC a = new ReferenceCountingGC("objA");
    ReferenceCountingGC b = new ReferenceCountingGC("objB");
    a.instance = b;  //a引用了b
    b.instance = a;  //b引用了a
    
    //置空各自的声明引用
    a = null; 
    b = null;
}

```

可以看到，最后这2个对象已经不可能再被访问了，但由于他们相互引用着对方，导致它们的引用计数永远都不会为0，通过引用计数算法，也就永远无法通知GC收集器回收它们







2、**可达性分析算法：**

算法的基本思想就是通过一系列的称为 **“`GC Roots`”** 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 `GC Roots` 没有**任何引用链**相连的话，则证明此对象是不可用的，需要被回收(**即一个对象没有被任何引用链所相连**)

下图中的 `Object 6 ~ Object 10` 之间虽有引用关系，但它们到 `GC Roots` 不可达，因此为需要被回收的对象：

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/jvm-gc-roots.png" style="zoom: 67%;" />



以下是一些可以作为`GC Roots`的对象类型：

1. 虚拟机栈中引用的对象：即当前线程正在使用的栈帧中引用的对象。

2. 方法区中类静态属性引用的对象：即类的静态变量引用的对象。

3. 方法区中常量引用的对象：即包括字符串常量在内的常量池中引用的对象。

4. 本地方法栈中 JNI（Java Native Interface）引用的对象：即由本地方法代码创建的对象引用。

5. **活动线程（Active Threads）**：**正在运行的线程是`GC Roots`，这些线程的调用栈中的对象都是可达的**

6. **静态变量（Static Variables）**：类的静态成员变量属于类本身，因此它们在类加载时被初始化，并一直存在于内存中。故方法区中类静态属性引用的对象也可作为`GC Roots`

   

例子：

虚拟机栈（栈帧中的本地变量表）中引用的对象 ，此时的 s 即为 GC Root，当s置空时，`localParameter` 对象也断掉了与 GC Root 的引用链，将被回收

```java
public class StackLocalParameter {
public StackLocalParameter(String name){}
}

public static void testGC(){
StackLocalParameter s = new StackLocalParameter("localParameter");
s = null;
}
```





> 如何判断一个常量是废弃常量？

假如在字符串常量池中存在字符串 "abc"，如果当前没有任何 String 对象引用该字符串常量的话，就说明常量 "abc" 就是废弃常量，如果这时发生内存回收的话而且有必要的话，"abc" 就会被系统清理出常量池了



> 如何判断类是否是一个无用的类？

方法区主要回收的是无用的类，那么如何判断一个类是无用的类的呢？

判定一个常量是否是“废弃常量”比较简单，而要判定一个类是否是“无用的类”的条件则相对苛刻许多。类需要同时满足下面 3 个条件才能算是 **“无用的类”**：

- 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例
- 加载该类的 `ClassLoader` 已经被回收
- 该类对应的 `java.lang.Class` 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法

虚拟机可以对满足上述 3 个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样不使用了就会必然被回收









### 引用类型总结

JDK1.2 之前，Java 中引用的定义很传统：如果 reference 类型的数据存储的数值代表的是另一块内存的起始地址，就称这块内存代表一个引用

JDK1.2 以后，Java 对引用的概念进行了扩充，将引用分为强引用、软引用、弱引用、虚引用四种（引用强度逐渐减弱）



1. 强引用

被强引用关联的对象不会被回收。使用 new 一个新对象的方式来创建强引用

```java
Object obj = new Object();
```



2. 软引用

**被软引用关联的对象只有在内存不够的情况下才会被回收**。使用 `SoftReference` 类来创建软引用

```java
Object obj = new Object();
SoftReference<Object> sf = new SoftReference<Object>(obj);  //sf软引用关联了第一行创建的对象
obj = null;  // 使对象只被软引用关联
```

软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收，JAVA 虚拟机就会把这个软引用加入到与之关联的引用队列中



3. 弱引用

被弱引用关联的对象一定会被回收，也就是说它只能存活到下一次垃圾回收发生之前(**只要进行GC就会回收弱引用指向的对象**)，使用 `WeakReference` 类来实现弱引用

```java
Object obj = new Object();
WeakReference<Object> wf = new WeakReference<Object>(obj);  //wf弱引用关联了第一行创建的对象
obj = null;
```

弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java 虚拟机就会把这个弱引用加入到与之关联的引用队列中



4. 虚引用

又称为幽灵引用或者幻影引用。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用取得一个对象。为一个对象设置虚引用关联的唯一目的就是能在这个对象被回收时收到一个系统通知。使用 PhantomReference 来实现虚引用

```java
Object obj = new Object();
PhantomReference<Object> pf = new PhantomReference<Object>(obj);
obj = null;
```

虚引用是最弱的引用类型，无法通过虚引用获取对象，主要用于对象被回收时的通知和后续处理







### 垃圾收集算法



1、**标记清除算法**(老年代用)

分为“标记（Mark）”和“清除（Sweep）”阶段：首先标记出所有不需要回收的对象，在标记完成后统一回收掉所有没有被标记的对象。它是最基础的收集算法，后续的算法都是对其不足进行改进得到。这种垃圾收集算法会带来两个明显的问题：

1. **效率问题**：标记和清除两个过程效率都不高。
2. **空间问题**：标记清除后会产生大量不连续的内存碎片。

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/mark-and-sweep-garbage-collection-algorithm.png" style="zoom: 67%;" />

整个标记-清除过程大致是这样的：

1. 当一个对象被创建时，给一个标记位，假设为 0 (**false—表示还未被引用**)；
2. 在标记阶段，我们将所有**可达对象**（或用户可以引用的对象）的标记位设置为 1 (true)；
3. **扫描阶段清除的就是标记位为 0 (false)的对象**





2、标记**复制算法**(新生代的两个`Survivor`区就是采取这种方法来减少内存碎片！！！)

为了解决标记-清除算法的效率和内存碎片问题，复制（`Copying`）收集算法出现了。它可以将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/copying-garbage-collection-algorithm.png" style="zoom:67%;" />

  

虽然改进了标记-清除算法，但依然存在下面这些问题：

- **可用内存变小**：可用内存缩小为原来的一半
- **不适合老年代**：如果存活对象数量比较大，**复制性能**会变得很差





标记-复制算法是一种常见的垃圾收集算法，用于回收新生代（Young Generation）中的内存。它主要分为以下三个阶段：

1. **标记阶段（Marking）**：
   - 在标记阶段，垃圾收集器会从根对象出发，遍历所有可达对象，并将它们标记为"存活"。根对象通常是指应用程序的栈帧中的引用对象、静态对象以及JNI（Java Native Interface）引用等。
   - 在这个阶段，垃圾收集器会停止应用程序的执行，进行标记操作(`Stop the world`)。标记完成后，所有存活的对象都会被标记为"存活"状态。
2. **复制阶段（Copying）**：
   - 在复制阶段，垃圾收集器会将所有标记为"存活"的对象复制到一个新的内存区域（通常是一个新的Survivor区域）中。这个新的内存区域被称为"To"空间或"to"区域。
   - 复制过程中，存活的对象会被复制到新的内存区域，并按照它们的相对位置顺序排列(减少了内存碎片)，保持了对象之间的相对位置关系
3. **清理阶段（Cleaning）**：
   - 在清理阶段，垃圾收集器会将所有的对象从原来的内存区域（通常是Eden区域和Survivor区域）中清除。这个原来的内存区域被称为"From"空间或"from"区域。
   - 在清理阶段，所有已经复制到新内存区域中的存活对象都会被清除，并且原来的内存区域将变为空闲状态，可以继续用来分配新的对象。



即先将存活对象复制到另一空白内存区域，然后再清除之前的内存区域



3、**标记整理算法**(老年代所采用的方式)

标记-整理（Mark-and-Compact）算法是根据老年代的特点提出的一种标记算法，标记过程仍然与“标记-清除”算法一样，但**后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存**

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/aaam.png" style="zoom:67%;" />

由于多了整理这一步，因此效率也不高，适合老年代这种垃圾回收频率不是很高的场景

> 老年代占据着2/3的堆内存空间，只有在 Major GC 的时候才会进行清理，每次 GC 都会触发“Stop-The-World”。内存越大，STW 的时间也越长，所以内存也不仅仅是越大就越好。**由于复制算法在对象存活率较高的老年代会进行很多次的复制操作，效率很低，所以老年代这里采用的是标记 --- 整理算法**







4、**分代收集算法**

当前虚拟机的垃圾收集都采用分代收集算法，根据对象存活周期的不同将内存分为几块。一般将 Java 堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。

比如在新生代中，每次收集都会有大量对象死去，所以可以选择”复制“算法，**只需要付出少量对象的复制成本就可以完成每次垃圾收集(S0<——>S1)**。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集

> 为什么HotSpot虚拟机要分为新生代和老年代？
>
> 
>
> HotSpot JVM（Java虚拟机）将堆内存划分为新生代（Young Generation）和老年代（Old Generation）是为了实现更高效的垃圾收集策略和内存管理
>
> 1. **对象生命周期假设：** 大多数Java应用程序中的对象生命周期短暂，即它们在创建后不久就变得不可达并且需要被回收。但也有一些对象具有较长的生命周期，如全局单例对象或缓存对象。将堆内存分为新生代和老年代，是基于这种对象生命周期假设。通过将新创建的对象放在新生代中，可以更快地回收这些对象，而较长生命周期的对象则放在老年代，减少频繁回收老年代的开销。
> 2. **不同垃圾回收策略：** 新生代和老年代通常使用不同的垃圾收集策略。在新生代中，因为对象的生命周期短暂，通常使用效率较高的Minor GC（Minor Garbage Collection），它主要关注新生代中的垃圾回收。而老年代中的对象生命周期较长，会采用更耗时但全面的Major GC（Major Garbage Collection）来进行垃圾回收。
> 3. **避免全局垃圾收集停顿：** 将堆内存分为新生代和老年代可以减少全局垃圾收集带来的停顿时间。在新生代中执行频繁但较短暂的Minor GC，而老年代的Major GC较少且耗时较长。这样可以在较小的内存区域内进行垃圾回收，减少全局垃圾收集的停顿时间，提高应用程序的响应性。
> 4. **空间效率：** 将堆内存划分为新生代和老年代，有助于更好地利用内存空间。新生代采用较大的Eden区和两个小的Survivor区（From和To），因为新对象通常在Eden区分配，并且有很多对象是短暂的，所以较大的Eden区提供了更高的空间效率。老年代相对较大，用于存放生命周期较长的对象。









**5、三色标记法**

三色标记法将对象的颜色分为了黑、灰、白，三种颜色。

- 黑色：该对象已经被标记过了，且该对象下的子对象也全部都被标记过了。（程序所需要的对象）
- 灰色：该对象自身已经被标记过了，但该对象下的子对象没有全被标记完。（GC需要从此对象中去寻找垃圾）
- 白色：未被扫描对象，如果扫描完所有对象之后，最终为白色的为不可达对象，即垃圾对象

![img](https://upload-images.jianshu.io/upload_images/25881088-0180395691fdfbef.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)



 根据可达性分析算法，从 GC Roots 开始进行遍历访问。

- 初始状态，所有的对象都是白色的，只有 GC Roots 是黑色的。

<img src="https://upload-images.jianshu.io/upload_images/25881088-1fbbbb3fbc892506.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img" style="zoom: 50%;" />

​	



- 初始标记阶段，GC Roots 标记直接关联对象置为灰色。

<img src="https://upload-images.jianshu.io/upload_images/25881088-0c81810021f46288.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img" style="zoom:50%;" />



- 并发标记阶段，扫描整个引用链。
  - 没有子节点的话，将本节点变为黑色。
  - 有子节点的话，则当前节点变为黑色，子节点变为灰色。

<img src="https://upload-images.jianshu.io/upload_images/25881088-4e7d981058966ae1.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img" style="zoom:50%;" />

- 重复并发标记阶段，直至灰色对象没有其它子节点引用时结束。

<img src="https://upload-images.jianshu.io/upload_images/25881088-194e16e47ef16cfc.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img" style="zoom:50%;" />

<img src="https://upload-images.jianshu.io/upload_images/25881088-4884e20ee151399b.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img" style="zoom: 50%;" />

- 扫描完成

  此时黑色对象就是存活的对象，白色对象就是已消亡可回收的对象。

  即（A、D、E、F、G）可达也就是存活对象，（B、C、H）不可达可回收的对象。





存在问题：

1. 浮动垃圾：并发标记的过程中，**若一个已经被标记成黑色或者灰色的对象，突然变成了垃圾(上图中D—>E之间的引用链突然断开)，此时，此对象不是白色的不会被清除，重新标记也不能从`GC Root`中去找到，所以成为了浮动垃圾**，这种情况对系统的影响不大，留给下一次GC进行处理即可。

<img src="https://upload-images.jianshu.io/upload_images/25881088-d1f746e05b64dc4e.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img" style="zoom:50%;" />

假设已经遍历到 E（变为灰色了），此时应用执行了 objD.fieldE = null (D > E 的引用断开)

D > E 的引用断开之后，E、F、G 三个对象不可达，应该要被回收的。然而因为 E 已经变为灰色了，其仍会被当作存活对象继续遍历下去。最终的结果是：这部分对象仍会被标记为存活，即本轮 GC 不会回收这部分内存。







2. 对象漏标问题（需要的对象被回收）：并发标记的过程中，一个业务线程将一个未被扫描过的白色对象断开引用成为垃圾（删除引用），同时黑色对象引用了该对象（增加引用）（这两部可以不分先后顺序）；因为黑色对象的含义为其属性都已经被标记过了，重新标记也不会从黑色对象中去找，导致该对象被程序所需要，却又要被GC回收，此问题会导致系统出现问题，而`CMS`与`G1`，两种回收器在使用三色标记法时，都采取了一些措施来应对这些问题，==CMS对增加引用环节进行处理（Increment Update），G1则对删除引用环节进行处理(SATB)。==

假设 GC 线程已经遍历到 E（变为灰色了），此时应用线程先执行了：

```
var G = objE.fieldG; objE.fieldG = null;  // 灰色E 断开引用 白色G 
objD.fieldG = G;  // 黑色D 引用 白色G
```

<img src="https://upload-images.jianshu.io/upload_images/25881088-27fdde960bb1b29a.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img" style="zoom:50%;" />

此时切回到 GC 线程，因为 E 已经没有对 G 的引用了，所以不会将 G 置为灰色；尽管因为 D 重新引用了 G，但因为 D 已经是黑色了，不会再重新做遍历处理。

最终导致的结果是：G 会一直是白色，最后被当作垃圾进行清除。这直接影响到了应用程序的正确性，是不可接受的。

总结就是：已经被标记为黑色的对象，在标记过程中重新引用了一个还未来得及被相连的灰色对象标记时，白色对象就已经被断开了，而白色对象会被GC回收，导致程序错误





**CMS解决办法:增量更新**

在应对漏标问题时，CMS使用了增量更新(Increment Update)方法来做：

在一个未被标记的对象（白色对象）被重新引用后，**「引用它的对象若为黑色则要变成灰色，在下次二次标记时让GC线程继续标记它的属性对象」**。

但是就算是这样，其仍然是存在漏标的问题：

- 在一个灰色对象正在被一个GC线程回收时，当它已经被标记过的属性指向了一个白色对象（垃圾）
- 而这个对象的属性对象本身还未全部标记结束，则为灰色不变
- **「而这个GC线程在标记完最后一个属性后，认为已经将所有的属性标记结束了，将这个灰色对象标记为黑色，被重新引用的白色对象，无法被标记」**













### 垃圾收集器



在垃圾回收（GC）的过程中，吞吐量和停顿时间之间通常存在一种权衡关系。

**吞吐量是指单位时间内cpu完成的有效工作量**，例如程序执行的业务逻辑所占用的时间比例。

**停顿时间**是指GC过程中**应用程序暂停执行**的时间，也称为停顿或暂停时间





1、**`Serial`收集器：**

这个收集器是一个单线程收集器了。它的 **“单线程”** 的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（ **"Stop The World"** ），直到它收集结束

但是 Serial 收集器有没有优于其他垃圾收集器的地方呢？当然有，它**简单而高效（与其他收集器的单线程相比）**。Serial 收集器由于没有线程交互的开销，自然可以获得很高的单线程收集效率。Serial 收集器对于运行在 Client 模式下的虚拟机来说是个不错的选择







2、**`ParNew`收集器：**

ParNew 收集器其实就是 Serial 收集器的多线程版本，除了**使用多线程进行垃圾收集外**，其余行为（控制参数、收集算法、回收策略等等）和 Serial 收集器完全一样

**新生代采用标记-复制算法，老年代采用标记-整理算法**

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/parnew-garbage-collector.png" style="zoom: 80%;" />







3、**`Parallel Scavenge` 收集器:**

与 `ParNew` 一样是多线程收集器

**其它收集器关注点是尽可能缩短垃圾收集时用户线程的停顿时间**，而它的目标是达到一个可控制的吞吐量，它被称为“吞吐量优先”收集器。这里的吞吐量指 CPU 用于运行用户代码的时间占总时间的比值

Parallel Scavenge 收集器关注点是吞吐量（高效率的利用 CPU）。CMS 等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。





4、**CMS收集器(重要:exclamation:**   针对的是老年代)

**CMS（`Concurrent` Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它非常符合在注重用户体验的应用上使用 **

> CMS回收器主要**关注老年代的内存回收**，它采用了**并发标记-清除**（Mark-Sweep）算法，以最大程度地减少垃圾回收时的停顿时间。在CMS回收过程中，会**尽量避免全局的内存整理和移动对象(G1则注重了内存整理，因为G1在不区分代的前提下将内存区域划分成了一个个`Region`)**，因此它在老年代的回收工作是以更细粒度的区域为单位进行的。
>
> 具体来说，CMS回收器将老年代划分为多个较小的区域（也称为CMS标记段或CMS块），每个区域可以独立地进行垃圾收集。CMS回收器采用并发标记的方式来标记存活对象，然后使用清除（Sweep）阶段来回收标记为垃圾的对象，并在清除阶段对每个CMS标记段进行处理，将未被标记的对象回收。

从名字中的**Mark Sweep**这两个词可以看出，CMS 收集器是一种 **“标记-清除”算法**实现的，它的运作过程相比于前面几种垃圾收集器来说更加复杂一些。整个过程分为四个步骤：

- **初始标记阶段（Initial Mark）**：

  - 初始标记阶段是一次短暂的暂停，它标记出所有直接与根对象有关的对象(**什么样的对象可以被视为`GC Roots`?**)，包括从根对象直接可达的对象
  - **在这个阶段，应用程序的执行会被暂停**，以确保从根对象出发的引用链能够被标记为"可达"。

  **并发标记阶段（Concurrent Mark）**：**开始遍历引用链 同时用户程序继续运行导致引用链再次发生小范围更新**

  - 并发标记阶段是CMS的主要特点，它与应用程序的执行并发进行，不需要暂停应用程序。
  - 在这个阶段，CMS收集器会遍历堆中的对象图，并标记所有与根对象可达的对象。由于应用程序仍在执行，堆中的对象可能在此期间发生变化，因此CMS使用一些特殊的手段来记录这些变化，并在标记过程中保持一致性。

  **重新标记阶段（Remark）**：

  - 重新标记阶段是一次短暂的暂停，它的目的是**处理在并发标记阶段中有可能发生的变化**
  - 在并发标记期间，由于应用程序的并发执行，有些对象的引用关系可能发生了变化，而这些变化可能导致一些对象在标记阶段被错误地标记为垃圾(其实这些对象已经被加入到引用链中了)。**重新标记阶段就是为了处理这些变化，确保所有存活的对象都能被正确标记。**

  **并发清除阶段（Concurrent Sweep）**：

  - 并发清除阶段与应用程序的执行并发进行，它负责清除标记为垃圾的对象，并回收内存空间
  - 在这个阶段，CMS收集器会回收垃圾对象所占用的内存，并将内存空间重新划分为可用空间，以便给新对象分配内存

- 在整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，不需要进行停顿
- 在CMS（Concurrent Mark-Sweep）收集器的并发标记阶段，**不会进行全面的GC（垃圾回收），也就是不会清除标记为垃圾的对象。并发标记阶段的目的是标记所有与根对象可达的存活对象(在不停止用户程序执行的前提下)，而不对垃圾对象进行清理**
- `Remark`阶段会对并发标记过程中可能发生变化的部分进行重新标记，并处理一些特殊情况。重新标记阶段是一个短暂的暂停阶段(`Stop The World`)，它与应用程序的执行不是并发进行的
- 在并发标记和重新标记阶段结束后，最终的垃圾回收工作是在并发清除阶段（Concurrent Sweep）进行的。在这个阶段，CMS收集器会清除标记为垃圾的对象，并回收内存空间，以便给新对象分配内存。并发清除阶段是与应用程序并发进行的，因此整个CMS的垃圾回收过程中，大部分时间应用程序都能保持执行状态，从而降低了停顿时间







5、G1收集器(重要 :grey_exclamation: )

https://pdai.tech/md/java/jvm/java-jvm-gc-g1.html

G1具备以下特点：

- G1垃圾回收器是基于**`compacting`**标记整理算法的，因此其回收得到的空间是连续的。这避免了CMS回收器因为不连续空间所造成的问题
- G1回收器的内存与CMS回收器要求的内存模型有极大的不同。G1将内存划分一个个固定大小的`region`，每个`region`可以是年轻代、老年代的一个。**内存的回收是以`region`作为基本单位的**；相比之下，**CMS回收器是以堆空间中的不同代（Generation）为单位进行内存回收**
- G1的设计原则是"**首先收集尽可能多的垃圾**(Garbage First)"。因此，G1并不会等内存耗尽(串行、并行)或者快耗尽(CMS)的时候开始垃圾收集，而是在内部采用了启发式算法，在老年代找出具有高收集收益的分区进行收集

- **并行与并发**：G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU（CPU 或者 CPU 核心）来缩短 Stop-The-World 停顿时间。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 java 程序继续执行
- **空间整合**：**与 CMS 的“标记-清除”算法不同，G1 从整体来看是基于“标记-整理”算法实现的收集器；从局部上来看是基于“标记-复制”算法实现的。**
- **可预测的停顿**：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在垃圾收集上的时间不得超过 N 毫秒。



G1（Garbage-First）收集器是Java虚拟机中一种面向服务器端应用的垃圾收集器，它的执行流程相对于传统的垃圾收集器有所不同( **以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征**)，G1收集器的执行流程大致分为以下几个阶段：

1. **初始标记阶段（Initial Mark）**：
   - 初始标记阶段与CMS收集器的初始标记阶段类似，是一次短暂的暂停。**它标记出所有引用链直接与根对象`GC Root`有关的对象**。
   - **在这个阶段，应用程序的执行会被暂停**，以确保从根对象出发的引用链能够被标记为"可达"。
2. **并发标记阶段（Concurrent Mark）**：
   - 并发标记阶段是G1的主要特点，它与应用程序的执行并发进行，不需要暂停应用程序。
   - 在这个阶段，G1收集器会遍历堆中的对象图，并标记所有与根对象可达的对象。由于应用程序仍在执行，堆中的对象可能在此期间发生变化，因此G1使用一些特殊的手段来记录这些变化，并在标记过程中保持一致性。
3. **最终标记阶段（Final Remark）**：
   - 最终标记阶段是一次短暂的暂停，它的目的是处理在并发标记阶段中有可能发生的变化。
   - 在并发标记期间，由于应用程序的并发执行，有些对象的引用关系可能发生了变化，而这些变化可能导致一些对象在标记阶段被错误地标记为垃圾。最终标记阶段就是为了处理这些变化，确保所有存活的对象都能被正确标记。
4. **筛选回收阶段（Live Data Counting and Evacuation）**：
   - 在最终标记阶段完成后，G1收集器会对堆中的存活对象进行统计，以确定需要回收的垃圾对象的数量。同时，它还会确定哪些存活对象将被转移到其他地方（例如Survivor区或者Old Generation）。
   - 这个阶段的目标是找到存活对象的数量和位置，以便在下一步进行垃圾回收。
5. **并发回收阶段（Concurrent Cleanup）**： 此阶段用了标记复制算法
   - 并发回收阶段与应用程序的执行并发进行，它负责清除标记为垃圾的对象，并回收内存空间。
   - 在这个阶段，G1收集器会回收垃圾对象所占用的内存，并将内存空间重新划分为可用空间，以便给新对象分配内存。

G1收集器通过将堆内存划分为多个大小相等的区域（`Region`），并采用并发标记-整理（Mark-Compact）的方式来进行垃圾回收，从而有效地控制停顿时间和提高吞吐量。相比传统的垃圾收集器，G1收集器更加适用于大内存的多核服务器环境，能够在减少停顿时间的同时保持高的吞吐量。



**G1 收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region(这也就是它的名字 Garbage-First 的由来)** 。这种使用 Region 划分内存空间以及有优先级的区域回收方式，保证了 G1 收集器在有限时间内可以尽可能高的收集效率（把内存化整为零）







**G1中几个重要概念:**



在 G1的实现过程中，引入了一些新的概念，对于实现**高吞吐、没有内存碎片、收集时间可控**等功能起到了关键作用。下面我们就一起看一下 G1中的这几个重要概念：



1、Region

传统的GC收集器将连续的内存空间划分为新生代、老年代和永久代（JDK 8去除了永久代，引入了元空间Metaspace），这种划分的特点是各代的存储地址（逻辑地址，下同）是连续的。如下图所示：![传统GC内存布局](https://awps-assets.meituan.net/mit-x/blog-images-bundle-2016/8a9db36e.png)



而G1的各代存储地址是不连续的，**每一代都使用了n个不连续的大小相同的Region**，每个Region占有一块连续的虚拟内存地址。如下图所示：

<img src="https://awps-assets.meituan.net/mit-x/blog-images-bundle-2016/8ca16868.png" alt="g1 GC内存布局" style="zoom: 80%;" />

在上图中，我们注意到**还有一些Region标明了H**，它代表Humongous，这表示这些Region存储的是巨大对象（humongous object，H-obj），即大小大于等于region一半的对象

**G1和其他GC算法最大的区别是弱化分代概念，引入分区思想！！！**



2、Rset

**G1垃圾收集器里每一个`RSet`对应的是一个`Region`内部对象引用情况**，说白了就是存在Region中存活对象的指针。在标记存活对象的时候，G1使用RSet概念，将每个分区指向分区内的引用记录在该分区，**避免对整个堆扫描**，并行独立处理垃圾集合；

如下图，我们可以看到3个分区，x（年轻代分区）、y 和 z（老年代分区）。x有一个来自z的对内引用。这个引用记录在x的RSet中，分区z有2个对内引用，一个来自x一个来自y，**因为年轻代分区作为一个整体回收的，所以只需记录来自y的对内引用**，不用记录x的对内引用：

<img src="https://img2018.cnblogs.com/i-beta/1465200/202001/1465200-20200126211309597-1194163731.png" alt="img" style="zoom: 80%;" />

RSet 在 G1 垃圾回收器中用于以下目的：

1. **减少扫描范围：** 在执行垃圾回收时，G1 垃圾回收器首先会选择一组包含垃圾对象的区域进行回收。而 **RSet 的作用之一就是记录了哪些区域内的对象引用了当前区域内的对象。这样，在进行回收时，只需要扫描 RSet 中标记的区域，而不需要遍历整个堆，**从而大大减少了扫描范围，提高了回收效率。
2. **标记阶段辅助：** 在 G1 的并发标记阶段，垃圾回收器需要知道哪些对象仍然是被引用的。RSet 用于记录从其他区域到当前区域的引用关系，以帮助标记哪些对象仍然可达。
3. **并发清理：** **在 G1 的并发清理阶段，RSet 也起到了重要作用。G1 垃圾回收器会通过 RSet 确定哪些引用关系仍然有效，**从而确保在清理阶段不会错误地清理掉仍然可达的对象。









### 垃圾回收停顿

> 很多低延迟高可用Java服务的系统可用性经常受GC停顿的困扰。GC停顿指垃圾回收期间STW（Stop The World），当STW时，所有应用线程停止活动，等待GC停顿结束才可继续执行，对于用户的感知十分明显

下面以G1为例，通过G1中标记-复制算法过程（G1的Young GC和Mixed GC均采用该算法），分析G1停顿耗时的主要瓶颈。

标记阶段停顿分析

- **初始标记阶段**：初始标记阶段是指从GC Roots出发标记全部直接子节点的过程，该阶段是STW的。由于GC Roots数量不多，通常该阶段耗时非常短。
- **并发标记阶段**：并发标记阶段是指从GC Roots开始对堆中对象进行可达性分析，找出存活对象。该阶段是并发的，即应用线程和GC线程可以同时活动。并发标记耗时相对长很多，但因为不是STW，所以我们不太关心该阶段耗时的长短。
- **再标记阶段**：重新标记那些在并发标记阶段发生变化的对象。该阶段是STW的。

清理阶段停顿分析

- **清理阶段**清点出有存活对象的分区和没有存活对象的分区，该阶段不会清理垃圾对象，也不会执行存活对象的复制。该阶段是STW的。

复制阶段停顿分析

- **复制算法**中的转移阶段需要分配新内存和复制对象的成员变量。转移阶段是STW的，其中内存分配通常耗时非常短，但对象成员变量的复制耗时有可能较长，这是因为复制耗时与存活对象数量与对象复杂度成正比。对象越复杂，复制耗时越长。

四个STW过程中，初始标记因为只标记`GC Roots`，耗时较短。再标记因为对象数少，耗时也较短。清理阶段因为内存分区数量少，耗时也较短。转移阶段要处理所有存活的对象，耗时会较长。因此，**G1停顿时间的瓶颈主要是标记-复制中的转移阶段STW**。为什么转移阶段不能和标记阶段一样并发执行呢？主要是G1未能解决转移过程中准确定位对象地址的问题。

G1的Young GC和CMS的Young GC，其标记-复制全过程STW，这里不再详细阐述

总结就是：垃圾回收停顿现象主要发生在标记复制算法中的对象转移阶段！！

https://pdai.tech/md/java/jvm/java-jvm-gc-zgc.html#zgc%E5%8E%9F%E7%90%86





### 什么时候触发GC?



1. **Minor GC（新生代垃圾回收）：**
   - Minor GC 主要发生在新生代（Young Generation）中。
   - 当新生代中的对象数量达到一定阈值时，会触发 Minor GC。
   - Minor GC 的目标是回收新生代中的垃圾对象，并将存活的对象晋升到老年代。
2. **Major GC（老年代垃圾回收）：**
   - Major GC 通常指的是对老年代（Old Generation）的垃圾回收，但不一定会清理整个老年代，可能只是对部分老年代进行回收。
   - Major GC 可能在以下情况下触发：
     - 老年代空间不足，无法分配大对象或晋升对象时。
     - 晋升失败（例如老年代无法容纳晋升的对象）。
     - 显式调用 `System.gc()` 方法时。
3. **Full GC（全局垃圾回收）：**
   - Full GC 会对整个堆内存进行垃圾回收，包括新生代和老年代。
   - Full GC 可能在以下情况下触发：
     - 老年代空间不足，且无法进行 Major GC 以满足空间需求。
     - 显式调用 `System.gc()` 方法。
     - 由垃圾收集器自行决定的其他情况。

需要注意的是，不同的垃圾收集器和不同的虚拟机实现可能会有不同的触发条件和行为。例如，使用不同的垃圾收集器可能会导致不同类型的垃圾回收在不同的时机触发。通常情况下，虚拟机会根据堆内存的状态和各个区域的使用情况来自动触发不同类型的垃圾回收，以保证内存的有效利用和应用程序的性能。





## JVM实战





###  JVM参数



> 堆内存/栈空间相关参数：

1、显式指定堆内存`–Xms`和`-Xmx`:

根据应用程序要求初始化堆内存。如果我们需要指定最小和最大堆大小（推荐显示指定大小），以下参数可以帮助你实现：

```shell
-Xms<heap size>[unit]
-Xmx<heap size>[unit]
```

- **heap size** 表示要初始化内存的具体大小
- **unit** 表示要初始化内存的单位

举个栗子 🌰，如果我们要为 JVM 分配最小 2 GB 和最大 5 GB 的堆内存大小，我们的参数应该这样来写：

```shell
-Xms2G -Xmx5G
```



2、设置每个线程的Java虚拟机栈（JVM Stack）的大小：

```shell
-Xss 256k  #表示将每个线程的栈大小设置为256K字节 
```

增加线程栈的大小可以让每个线程能够处理更深的方法调用层级和更大的局部变量，但同时也会占用更多的内存。





3、显式指定新生代/老年代内存大小：

(1) 举个栗子 🌰，如果我们要为 **新生代分配** 最小 256m 的内存，最大 1024m 的内存我们的参数应该这样来写：

```shell
-XX:NewSize=256m
-XX:MaxNewSize=1024m
```

(2)但是如果我们要为 新生代分配 256m 的内存（NewSize 与 MaxNewSize 设为一致），我们的参数应该这样来写：

```shell
-Xmn256m
```



设置老年代(元空间)：

```shell
#设置 Metaspace 的初始大小（是一个常见的误区，后面会解释） 实际 表示 Metaspace 使用过程中触发 Full GC 的阈值
-XX:MetaspaceSize=N 

-XX:MaxMetaspaceSize=N #设置 Metaspace 的最大大小
```





4、通过 **`-XX:NewRatio=<int>`** 来设置老年代与新生代内存的比值：

```shell
-XX:NewRatio=1
```

上述参数就是设置老年代与新生代内存的比值为 1。也就是说老年代和新生代所占比值为 1：1，新生代占整个堆栈的 1/2







> GC相关参数：

1、JVM 具有四种类型的 GC 实现：

- 串行垃圾收集器
- 并行垃圾收集器
- CMS 垃圾收集器
- G1 垃圾收集器

```shell
-XX:+UseSerialGC
-XX:+UseParallelGC
-XX:+UseParNewGC
-XX:+UseG1GC
```



2、显式的禁用System.gc()：调用该函数是很浪费性能的，JVM会在需要GC的时候自己触发GC

```shell
-XX:+DisableExplicitGC
```



3、指定并行垃圾收集器的线程数量：

```shell
-XX:ParallelGCThreads=4
```



4、打印必要的GC日志记录：

```shell
-XX:+PrintGCDetails# 必选 ，打印基本 GC 信息
-XX:+PrintGCDateStamps
-XX:+PrintReferenceGC    # 打印Reference处理信息
-XX:+PrintGCApplicationStoppedTime # 打印STW时间
```

















### 监控工具

1、jps(JVM Process Status)  类似 UNIX 的 `ps` 命令:

例如启动微服务项目后，jps显示如下：

```shell
C:\Users\aa>jps -l
23152 org.jetbrains.idea.maven.server.RemoteMavenServer36
18004 com.xuecheng.system.SystemApplication
20548 com.xuecheng.OrdersApiApplication
28708 com.xuecheng.GatewayApplication
28788
12952 org.jetbrains.jps.cmdline.Launcher
29368 com.xuecheng.LearningApiApplication
6568 sun.tools.jps.Jps
26204 com.xuecheng.ContentApiApplication
```

jps参数

```bash
-q：仅输出VM标识符，不包括classname,jar name,arguments in main method 
-m：输出main method的参数 
-l：输出完全的包名，应用主类名，jar的完全路径名 
-v：输出jvm参数 
-V：输出通过flag文件传递到JVM中的参数(.hotspotrc文件或-XX:Flags=所指定的文件 
-Joption：传递参数到vm,例如:-J-Xms512m
```







2、`jstat`：监视虚拟机各种运行状态信息

```shell
jstat [option] vmid [interval[s|ms] [count]]
```

- option:指定需要统计的信息,常用的有 -class、-gcutil、-gccause 等
- vmid:需要监控的 JVM 进程 ID,可以通过 jps 命令查看
- interval:查看状态信息的时间间隔,单位可以是 s(秒) 或者 ms(毫秒)
- count:统计次数,默认 beloved

它可以显示本地或者远程虚拟机进程中的类信息、内存、垃圾收集、JIT 编译等运行数据

比如 `jstat -gc -h3 20548 1000 10`表示分析进程 id 为 20548 的 gc 情况，每隔 1000ms 打印一次记录，打印 10 次停止，每 3 行后打印指标头部

```java
C:\Users\aa>jstat -gc -h3 20548 1000 10
 S0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT
20480.0 24064.0  0.0    0.0   678912.0 323175.9  317440.0   36543.7   60080.0 56551.0 8320.0 7698.7      8    0.043   3      0.219    0.262
20480.0 24064.0  0.0    0.0   678912.0 326193.3  317440.0   36543.7   60080.0 56551.0 8320.0 7698.7      8    0.043   3      0.219    0.262
20480.0 24064.0  0.0    0.0   678912.0 326193.3  317440.0   36543.7   60080.0 56551.0 8320.0 7698.7      8    0.043   3      0.219    0.262
 S0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT
20480.0 24064.0  0.0    0.0   678912.0 326193.3  317440.0   36543.7   60080.0 56551.0 8320.0 7698.7      8    0.043   3      0.219    0.262
20480.0 24064.0  0.0    0.0   678912.0 326193.3  317440.0   36543.7   60080.0 56551.0 8320.0 7698.7      8    0.043   3      0.219    0.262
20480.0 24064.0  0.0    0.0   678912.0 326193.3  317440.0   36543.7   60080.0 56551.0 8320.0 7698.7      8    0.043   3      0.219    0.262
 S0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT
20480.0 24064.0  0.0    0.0   678912.0 326193.3  317440.0   36543.7   60080.0 56551.0 8320.0 7698.7      8    0.043   3      0.219    0.262
20480.0 24064.0  0.0    0.0   678912.0 326193.3  317440.0   36543.7   60080.0 56551.0 8320.0 7698.7      8    0.043   3      0.219    0.262
20480.0 24064.0  0.0    0.0   678912.0 326193.3  317440.0   36543.7   60080.0 56551.0 8320.0 7698.7      8    0.043   3      0.219    0.262
 S0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT
20480.0 24064.0  0.0    0.0   678912.0 326193.3  317440.0   36543.7   60080.0 56551.0 8320.0 7698.7      8    0.043   3      0.219    0.262
```





3、jstack：线程栈信息查看

`jstack`（Stack Trace for Java）命令用于生成当前虚拟机进程在当前时刻的**线程快照**。线程快照就是**当前虚拟机内每一条线程正在执行的方法堆栈的集合**

使用jstack来分析死锁：

```java
public class DeadLockDemo {
    private static Object resource1 = new Object();//资源 1
    private static Object resource2 = new Object();//资源 2

    public static void main(String[] args) {
        new Thread(() -> {
            synchronized (resource1) {
                System.out.println(Thread.currentThread() + "get resource1");
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread() + "waiting get resource2");
                synchronized (resource2) {
                    System.out.println(Thread.currentThread() + "get resource2");
                }
            }
        }, "线程 1").start();

        new Thread(() -> {
            synchronized (resource2) {
                System.out.println(Thread.currentThread() + "get resource2");
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread() + "waiting get resource1");
                synchronized (resource1) {
                    System.out.println(Thread.currentThread() + "get resource1");
                }
            }
        }, "线程 2").start();
    }
}

```

Output:

```text
Thread[线程 1,5,main]get resource1
Thread[线程 2,5,main]get resource2
Thread[线程 1,5,main]waiting get resource2
Thread[线程 2,5,main]waiting get resource1
```

线程 A 通过 `synchronized (resource1)` 获得 resource1 的监视器锁，然后通过` Thread.sleep(1000);`让线程 A 休眠 1s 为的是让线程 B 得到执行然后获取到 resource2 的监视器锁。线程 A 和线程 B 休眠结束了都开始企图请求获取对方的资源，然后这两个线程就会陷入互相等待的状态，这也就产生了死锁



通过`Jstack`命令来排查问题：

```
C:\Users\aa>jps
23152 RemoteMavenServer36
18004 SystemApplication
18612 DeadLockDemo            #死锁发生的JVM进程
20548 OrdersApiApplication
28708 GatewayApplication
28788
14920 Jps
29368 LearningApiApplication
10204 Launcher
26204 ContentApiApplication

C:\Users\aa>jstack DeadLockDemo
Found one Java-level deadlock:
=============================
"线程 2":
  waiting to lock monitor 0x000000000333e668 (object 0x00000000d5efe1c0, a java.lang.Object),
  which is held by "线程 1"
"线程 1":
  waiting to lock monitor 0x000000000333be88 (object 0x00000000d5efe1d0, a java.lang.Object),
  which is held by "线程 2"

Java stack information for the threads listed above:
===================================================
"线程 2":
        at DeadLockDemo.lambda$main$1(DeadLockDemo.java:31)
        - waiting to lock <0x00000000d5efe1c0> (a java.lang.Object)
        - locked <0x00000000d5efe1d0> (a java.lang.Object)
        at DeadLockDemo$$Lambda$2/1078694789.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:748)
"线程 1":
        at DeadLockDemo.lambda$main$0(DeadLockDemo.java:16)
        - waiting to lock <0x00000000d5efe1d0> (a java.lang.Object)
        - locked <0x00000000d5efe1c0> (a java.lang.Object)
        at DeadLockDemo$$Lambda$1/1324119927.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:748)

Found 1 deadlock.

```

可以看到 `jstack` 命令已经帮我们找到发生死锁的线程的具体信息







4、**`jmap`**:用于生成Java进程的内存快照，并查看Java堆内存中的对象信息

假设你有一个正在运行的Java应用程序，它的进程ID是`12345`，你想要生成该Java进程的堆内存快照并保存到文件中，以便后续分析内存使用情况。可以使用以下命令来执行:

```shell
jmap -dump:format=b,file=heapdump.bin 12345
```

执行上述命令后，`jmap`会生成一个名为`heapdump.bin`的二进制文件，其中包含了Java进程的堆内存快照。

接下来，你可能希望查看该Java进程的堆内存信息，了解堆大小、使用情况、GC情况等。你可以使用以下命令来执行：

```java
jmap -heap 12345
```



例如通过`jmap`命令查看进程`SystemApplication`的堆内存信息：

```shell
C:\Users\aa>jps
23152 RemoteMavenServer36
24864 Jps
18004 SystemApplication   #被查看的进程
18612 DeadLockDemo
20548 OrdersApiApplication
28708 GatewayApplication
28788
19800 Launcher
29368 LearningApiApplication
26204 ContentApiApplication


C:\Users\aa>jmap  -heap 18004
Attaching to process ID 18004, please wait...
Debugger attached successfully.
Server compiler detected.
JVM version is 25.192-b12

using thread-local object allocation.
Parallel GC with 10 thread(s)

Heap Configuration:
   MinHeapFreeRatio         = 0
   MaxHeapFreeRatio         = 100
   MaxHeapSize              = 8541700096 (8146.0MB)
   NewSize                  = 178257920 (170.0MB)
   MaxNewSize               = 2846883840 (2715.0MB)
   OldSize                  = 356515840 (340.0MB)
   NewRatio                 = 2
   SurvivorRatio            = 8
   MetaspaceSize            = 21807104 (20.796875MB)
   CompressedClassSpaceSize = 1073741824 (1024.0MB)
   MaxMetaspaceSize         = 17592186044415 MB
   G1HeapRegionSize         = 0 (0.0MB)

Heap Usage:
PS Young Generation
Eden Space:
   capacity = 261095424 (249.0MB)
   used     = 124858824 (119.07465362548828MB)
   free     = 136236600 (129.92534637451172MB)
   47.82114603433264% used
From Space:
   capacity = 14155776 (13.5MB)
   used     = 14135376 (13.480545043945312MB)
   free     = 20400 (0.0194549560546875MB)
   99.85588921440973% used
To Space:
   capacity = 15728640 (15.0MB)
   used     = 0 (0.0MB)
   free     = 15728640 (15.0MB)
   0.0% used
PS Old Generation
   capacity = 351797248 (335.5MB)
   used     = 18767584 (17.898162841796875MB)
   free     = 333029664 (317.6018371582031MB)
   5.33477282914959% used

19969 interned Strings occupying 1829848 bytes.
```













### 调优案例



1、**上述提到的使用`jstack`命令来分析死锁(针对堆外内存)：** 

```java
public class DeadLockDemo {
    private static Object resource1 = new Object();//资源 1
    private static Object resource2 = new Object();//资源 2

    public static void main(String[] args) {
        new Thread(() -> {
            synchronized (resource1) {
                System.out.println(Thread.currentThread() + "get resource1");
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread() + "waiting get resource2");
                synchronized (resource2) {
                    System.out.println(Thread.currentThread() + "get resource2");
                }
            }
        }, "线程 1").start();

        new Thread(() -> {
            synchronized (resource2) {
                System.out.println(Thread.currentThread() + "get resource2");
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread() + "waiting get resource1");
                synchronized (resource1) {
                    System.out.println(Thread.currentThread() + "get resource1");
                }
            }
        }, "线程 2").start();
    }
}

```

Output:

```text
Thread[线程 1,5,main]get resource1
Thread[线程 2,5,main]get resource2
Thread[线程 1,5,main]waiting get resource2
Thread[线程 2,5,main]waiting get resource1
```

线程 A 通过 `synchronized (resource1)` 获得 resource1 的监视器锁，然后通过` Thread.sleep(1000);`让线程 A 休眠 1s 为的是让线程 B 得到执行然后获取到 resource2 的监视器锁。线程 A 和线程 B 休眠结束了都开始企图请求获取对方的资源，然后这两个线程就会陷入互相等待的状态，这也就产生了死锁



通过`Jstack`命令来排查问题：

```
C:\Users\aa>jps
23152 RemoteMavenServer36
18004 SystemApplication
18612 DeadLockDemo            #死锁发生的JVM进程
20548 OrdersApiApplication
28708 GatewayApplication
28788
14920 Jps
29368 LearningApiApplication
10204 Launcher
26204 ContentApiApplication

C:\Users\aa>jstack DeadLockDemo
Found one Java-level deadlock:
=============================
"线程 2":
  waiting to lock monitor 0x000000000333e668 (object 0x00000000d5efe1c0, a java.lang.Object),
  which is held by "线程 1"
"线程 1":
  waiting to lock monitor 0x000000000333be88 (object 0x00000000d5efe1d0, a java.lang.Object),
  which is held by "线程 2"

Java stack information for the threads listed above:
===================================================
"线程 2":
        at DeadLockDemo.lambda$main$1(DeadLockDemo.java:31)
        - waiting to lock <0x00000000d5efe1c0> (a java.lang.Object)
        - locked <0x00000000d5efe1d0> (a java.lang.Object)
        at DeadLockDemo$$Lambda$2/1078694789.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:748)
"线程 1":
        at DeadLockDemo.lambda$main$0(DeadLockDemo.java:16)
        - waiting to lock <0x00000000d5efe1d0> (a java.lang.Object)
        - locked <0x00000000d5efe1c0> (a java.lang.Object)
        at DeadLockDemo$$Lambda$1/1324119927.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:748)

Found 1 deadlock.

```

可以看到 `jstack` 命令已经帮我们找到发生死锁的线程的具体信息







2、排查`OutOfMemoryError`(**针对堆内内存**):

假设-Xmx最大内存配置为2GB

```java
public void testOom1() {
	List<Map<String, Object>> mapList = new ArrayList<>();
	for (int i = 0; i < 1000000; i++) {
		Map<String, Object> map = new HashMap<>();
		for (int j = 0; j < i; j++) {
				map.put(String.valueOf(j), j);
		}
		mapList.add(map);
	}
}
```

上述的代码执行会导致：old区(**字符串大对象创建后直接进入老年代**)占用过多导致频繁`Full GC`，最终导致GC overhead limit exceed：

```shell
java.lang.OutOfMemoryError: GC overhead limit exceeded
at java.util.HashMap.newNode(HashMap.java:1747) ~[na:1.8.0_181]
at java.util.HashMap.putVal(HashMap.java:642) ~[na:1.8.0_181]
at java.util.HashMap.put(HashMap.java:612) ~[na:1.8.0_181]
at tech.pdai.test.oom.controller.TestOomController.testOom1(TestOomController.java:33) ~[classes/:na]
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_181]
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_181]
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_181]
at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_181]
at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:197) ~[spring-web-5.3.9.jar:5.3.9]
at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:141) ~[spring-web-5.3.9.jar:5.3.9]
at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:106) ~[spring-webmvc-5.3.9.jar:5.3.9]
at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895) ~[spring-webmvc-5.3.9.jar:5.3.9]
at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808) ~[spring-webmvc-5.3.9.jar:5.3.9]
at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) ~[spring-webmvc-5.3.9.jar:5.3.9]
at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1064) ~[spring-webmvc-5.3.9.jar:5.3.9]
at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963) ~[spring-webmvc-5.3.9.jar:5.3.9]
at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) ~[spring-webmvc-5.3.9.jar:5.3.9]
at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898) ~[spring-webmvc-5.3.9.jar:5.3.9]
at javax.servlet.http.HttpServlet.service(HttpServlet.java:655) ~[tomcat-embed-core-9.0.50.jar:4.0.FR]
at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) ~[spring-webmvc-5.3.9.jar:5.3.9]
at javax.servlet.http.HttpServlet.service(HttpServlet.java:764) ~[tomcat-embed-core-9.0.50.jar:4.0.FR]
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:228) ~[tomcat-embed-core-9.0.50.jar:9.0.50]
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:163) ~[tomcat-embed-core-9.0.50.jar:9.0.50]
at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) ~[tomcat-embed-websocket-9.0.50.jar:9.0.50]
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:190) ~[tomcat-embed-core-9.0.50.jar:9.0.50]
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:163) ~[tomcat-embed-core-9.0.50.jar:9.0.50]
at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) ~[spring-web-5.3.9.jar:5.3.9]
at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.3.9.jar:5.3.9]
at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:190) ~[tomcat-embed-core-9.0.50.jar:9.0.50]
at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:163) ~[tomcat-embed-core-9.0.50.jar:9.0.50]
at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) ~[spring-web-5.3.9.jar:5.3.9]
at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.3.9.jar:5.3.9]
```

​	





### 线上故障排查

















# Spring



## 基本组件

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/spring-framework-introduce-8.png" style="zoom:67%;" />





1、Core Container：

Spring 框架的核心，主要提供控制反转、依赖注入功能。Spring 其他所有功能基本都需要依赖于该模块

- **spring-core**：Spring 框架基本的核心工具类
- **spring-beans**：提供对 bean 的创建、配置和管理等支持，例如管理Bean的作用域、Bean的生命周期
- **Context 上下文模块**：建立在 Core 和 Beans 模块的基础之上，集成 Beans 模块功能并添加资源绑定、数据验证、国际化、Java EE 支持、容器生命周期、事件传播等。`Context`模块给`Spring`提供一个运行时的环境，用于保存各个对象的状态。如`ApplicationContext`，它是`BeanFactory`的扩展，提供了更多特性，`Context`就是`IOC`容器，通过配置文件（如XML配置文件）或注解，开发者可以告诉Spring框架需要哪些Bean以及它们之间的依赖关系。然后，Spring容器负责根据配置来实例化、初始化和注入这些Bean。同时 `ApplicationContext` 支持事件的发布和监听机制，允许Bean在某些事件发生时产生通知，并让其他Bean监听这些事件

> `IOC`容器的扩展点:
>
>  
>
>  对Spring的IOC容器来说，主要有`BeanFactoryPostProcessor`和`BeanPostProcessor`，他们分别在构建`BeanFactory`和构建`Bean`对象时调用，还有就是`InItializingBean`和`DisposableBean`，他们分别在`Bean`创建和销毁时调用，用户可以自定义实现这些接口中的方法，Spring会在适当的时候调用他们





2、Data Access/Integration：

- **spring-jdbc**：提供了对数据库访问的抽象 JDBC。不同的数据库都有自己独立的 API 用于操作数据库，而 Java 程序只需要和 JDBC API 交互，这样就屏蔽了数据库的影响(SPI机制)

  1. **提供了对数据库访问的抽象 JDBC：** JDBC（Java Database Connectivity）是Java提供的标准API，用于与关系型数据库进行通信。不同类型的数据库（如MySQL、Oracle、SQL Server等）有不同的数据库驱动程序和API，开发者需要了解并使用特定数据库的API才能操作数据库。而`spring-jdbc`模块提供了一个抽象层，允许开发者使用统一的API来执行数据库操作，而不需要关心底层不同数据库的差异。
  2. **屏蔽了数据库的影响：** 使用`spring-jdbc`模块，Java程序只需要与JDBC API 进行交互，而不需要直接与特定数据库的API交互。这意味着您可以编写一套数据库访问代码，然后在不同的数据库系统之间进行切换，而不必改变代码。`spring-jdbc`模块会在底层处理不同数据库的细节，从而屏蔽了这些差异，使开发者可以更专注于业务逻辑。

  总之，`spring-jdbc`模块通过提供抽象的JDBC访问层，使开发者能够以一种通用的方式访问和操作数据库，而不受特定数据库的限制。这提高了代码的可移植性和可维护性，使得应用程序能够更灵活地适应不同类型的数据库



- **Transactions 事务模块**：提供事务支持与管理

- **ORM 模块**：提供对 Hibernate、JPA、iBatis 等 ORM 框架的支持(无缝集成的API)

  ( ORM 模块的主要目标是将数据库中的数据与Java对象之间建立映射，从而使开发者可以使用面向对象的方式来操作数据库，而无需处理 SQL 语句和数据库连接细节)







3、Web模块：

- **spring-websocket**：提供了对 WebSocket 的支持，WebSocket 可以让客户端和服务端进行双向通信

- spring-web:`Servlet`在Spring框架中的使用是通过`spring-web`模块来实现的

  下是`spring-web`模块中主要包含的内容：

  1. **Web MVC Framework：**
     - 提供了用于构建基于模型-视图-控制器（MVC）架构的Web应用程序的支持。
     - 包括`DispatcherServlet`，负责将请求分发给适当的控制器，以及将响应返回给客户端。
     - 提供了控制器、视图解析、数据绑定、表单处理、数据验证等功能。
  2. **异常处理和视图解析：**
     - 提供了异常处理机制，可以将异常映射到适当的错误页面或处理程序。
     - 提供了视图解析机制，用于解析并渲染视图，如JSP、Thymeleaf等。





4、AOP：

**AOP 模块**：提供了面向切面编程实现，提供比如日志记录、权限控制、事务管理、性能统计等通用功能和业务逻辑分离的技术，并且能动态的把这些功能添加到需要的代码中，这样各司其职，降低业务逻辑和通用功能的耦合

**Aspects 模块**：提供与 AspectJ 的集成，是一个功能强大且成熟的面向切面编程（AOP）框架









## IOC



> **为什么叫控制反转？**

- **控制**：指的是对象创建（实例化、管理）的权力
- **反转**：控制权交给外部环境（Spring 框架、IoC 容器）

1、IoC 容器就像是一个工厂一样，当我们需要创建一个对象的时候，只需要配置好配置文件/注解即可，完全不用考虑对象是如何被创建出来的， IoC 容器实际上就是个 Map（key，value），Map 中存放的是各种对象

2、在IOC容器中，通常使用的数据结构是一个以Bean名称为Key，以对应的Bean实例对象为Value的映射关系。可以将Key看作是Bean的标识符，用于在容器中唯一标识和定位一个特定的Bean。而Value则是对应的Bean实例对象，即具体的应用程序组件。

且在Spring框架中，常用的IOC容器是`ApplicationContext`。它内部维护了一个`BeanFactory`(`ApplicationContext`接口本身就是`BeanFactory`的一个子接口，它继承了`BeanFactory`接口)，**`BeanFactory`使用了类似Map的数据结构，其中Key是Bean的名称（可以是ID或者别名），Value是对应的Bean实例对象**

`BeanFactory`主要方法如下：

```java
public interface BeanFactory {

    Object getBean(String var1) throws BeansException;

    boolean isSingleton(String var1) throws NoSuchBeanDefinitionException;
}
```



3、在实际项目中一个 Service 类可能依赖了很多其他的类，假如我们需要实例化这个 Service，每次都要搞清这个 Service 所有底层类的构造函数。如果利用 IOC 的话，只需要配置好，然后在需要的地方引用就行了，这大大增加了项目的可维护性且降低了开发难度————**后面提到了Spring如何解决循环依赖问题**

传统应用程序都是由我们在类内部主动创建依赖对象,有了IOC容器后，**把创建和查找依赖对象的控制权交给了容器，由容器进行注入组合对象，所以对象与对象之间是 松散耦合** (应用程序原本是老大，要获取什么资源都是主动出击，但是在IOC/DI思想中，应用程序就变成被动的了，被动的等待IOC容器来创建并注入它所需要的资源了)











### Bean的配置方式



#### XML

```java
<beans xmlns="http://www.springframework.org/schema/beans"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
       xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd">

    <!-- 定义一个Bean -->
    <bean id="myBean" class="com.example.MyBean">
        <property name="message" value="Hello, Spring!" />
    </bean>

</beans>
    
        
 <!--
使用<bean>标签定义了一个id名为myBean的Bean。class属性指定了Bean的Java类路径。<property>标签用于设置Bean的属性值，
name属性指定了要设置的属性名，value属性指定了属性的值 -- >       
```





然后在应用程序中加载并使用配置文件：

``` java
javaCopy codeimport org.springframework.context.ApplicationContext;
import org.springframework.context.support.ClassPathXmlApplicationContext;

public class MainApp {
    public static void main(String[] args) {
        // 加载配置文件
        ApplicationContext context = new ClassPathXmlApplicationContext("applicationContext.xml");

        // 获取Bean实例  通过beanName————唯一id 来获取bean实例
        MyBean myBean = (MyBean) context.getBean("myBean");

        // 使用Bean
        myBean.printMessage();
    }
}


//BeanFactoy中getBean方法如下：
Object getBean(String name) throws BeansException;
```







> 问题来了，Spring如何创建和获取Bean的实例呢？

在Spring中，当使用XML配置Bean时，Spring框架会**通过反射机制来创建和获取Bean的实例**

具体来说，当Spring容器启动时，会解析XML配置文件，并根据配置文件中定义的Bean信息创建相应的Bean实例。对于每个Bean定义，**Spring会通过Java反射机制动态加载相应的类，并使用反射来实例化Bean对象**

Spring通过使用反射机制可以做到以下几点：

1. 实例化Bean对象：Spring根据配置文件中的Bean定义，使用反射来创建Bean的实例。它会通过类的全限定名使用`Class.forName()`方法加载类，并调用构造函数(一般为`public`)来创建对象实例

2. 调用构造函数和设置属性(初始化)：一旦Bean实例化，Spring会使用反射调用**适当的构造函数来初始化Bean**，并通过反射设置Bean的属性值(**只是设置对象属性，并没有真正赋值**)————通过`Class`对象的`.getConstructors()`方法可以获取类的所有公共构造方法，而`.getDeclaredConstructors()`方法可以获取类的所有构造方法（包括私有的）。然后可以遍历这些构造方法，找到需要的构造方法。

3. 调用初始化方法<init>：如果Bean定义中指定了初始化方法，Spring会通过反射调用该方法来完成Bean的初始化操作

   初始化方法的定义可以在XML配置、Java注解或Java代码中完成：

   (1)**XML配置：** 在XML配置文件中，你可以使用`<bean>`元素的`init-method`属性来指定初始化方法。例如：

   ```XML
   <bean id="myBean" class="com.example.MyBean" init-method="initMethod">
       <!-- 其他配置 -->
   </bean>
   
   init-method属性将initMethod作为初始化方法，Spring会在创建myBean实例时自动调用initMethod方法。
   ```

   (2)**Java注解：** 如果你使用注解配置Spring Bean，你可以在Bean类的方法上使用`@PostConstruct`注解来标记初始化方法。例如：

   ```JAVA
   @Component
   public class MyBean {
       // 构造函数和其他属性和方法
       
       @PostConstruct
       public void initMethod() {
           // 初始化逻辑
       }
   }
   ```

   

4. 获取Bean实例：一旦Bean实例化和初始化完成，Spring会将其存储在容器中，并通过Bean的唯一标识符（通常是Bean名称）来索引和获取相应的Bean实例

需要注意的是，Spring不仅仅使用反射机制来获取和创建Bean实例，它还提供了其他机制，如**工厂方法、实例工厂**等，来创建和获取Bean，但是在XML配置方式下，反射机制是最常用和默认的方式来实现Bean的创建和获取





#### 纯java配置

通过编写Java类，使用Spring提供的配置类（如`@Configuration`）和相应的注解（如`@Bean`）来定义Bean的创建和依赖关系。可以在配置类中通过方法返回Bean实例，并使用注解进行依赖注入：

1、首先创建一个java类作为配置类：

```java
@Configuration
public class AppConfig {
    @Bean
    public MyBean myBean() {
        MyBean myBean = new MyBean();
        myBean.setMessage("Hello, Spring!");
        return myBean;
    }
}

```

上述代码使用了`@Configuration`注解将该类标记为配置类，并通过在方法上使用`@Bean`注解，我们定义了一个名为`myBean`的Bean(**如果通过这种方式配置Bean，Bean被注入IOC容器后的默认name为方法名，前提是如果不指定@Bean(name="customBeanName")的话**)，并在方法体中进行实例化和设置属性

2、然后在应用程序中加载配置类并获取Bean实例：

```java
import org.springframework.context.ApplicationContext;
import  org.springframework.context.annotation.AnnotationConfigApplicationContext;

public class MainApp {
    public static void main(String[] args) {
        // 加载配置类
        ApplicationContext context = new AnnotationConfigApplicationContext(AppConfig.class);

        // 获取Bean实例
        MyBean myBean = context.getBean(MyBean.class);

        // 使用Bean
        myBean.printMessage();
    }
}

```

使用`AnnotationConfigApplicationContext`类加载配置类`AppConfig`，然后使用`getBean()`方法根据Bean的类型获取实例，最后我们可以使用实例调用Bean的方法

通过Java配置方式，我们可以通过编写Java类来定义和配置Bean，避免了使用XML的繁琐和冗余。配置类中的方法使用`@Bean`注解返回Bean实例，并在方法体中进行实例化和设置属性。通过加载配置类，Spring会自动创建和管理相应的Bean，并提供依赖注入和其他特性

**需要注意的是，Java配置方式也可以与注解配置方式相结合使用，使用`@ComponentScan`注解进行自动扫描并注册其他使用注解配置的Bean**









#### 注解



通过在类上加注解的方式，来声明一个类交给Spring管理，Spring会自动扫描带有`@Component，@Controller，@Service，@Repository`这四个注解的类，然后帮我们创建并管理，前提是需要先配置Spring的注解扫描器

`@Component`：通用的注解，可标注任意类为 `Spring` 组件。如果一个 Bean 不知道属于哪个层，可以使用`@Component` 注解标注

`@Repository` : 对应持久层即 `Dao` 层，主要用于数据库相关操作

`@Service` : 对应服务层，主要涉及一些复杂的逻辑，需要用到 `Dao` 层

`@Controller` : 对应 `Spring MVC` 控制层，主要用于接受用户请求并调用 `Service` 层返回数据给前端页面。

以下是使用注解方式在Spring中定义和配置一个简单的Bean的例子：

```java
@Component
public class MyBean {
    private String message;

    public void setMessage(String message) {
        this.message = message;
    }

    public void printMessage() {
        System.out.println("Message: " + message);
    }
}
```

在上述示例中，我们使用了`@Component`注解将`MyBean`类标记为一个`Spring Bean`。通过该注解，`Spring`会自动将该类实例化为一个可用的Bean，并进行相应的管理和依赖注入





然后在应用程序中启用注解扫描并获取Bean实例：

```java
import org.springframework.context.ApplicationContext;
import org.springframework.context.annotation.AnnotationConfigApplicationContext;

public class MainApp {
    public static void main(String[] args) {
        // 启用注解扫描
        ApplicationContext context = new AnnotationConfigApplicationContext("com.example");
        
      

        // 获取Bean实例
        MyBean myBean = context.getBean(MyBean.class);

        // 使用Bean
        myBean.printMessage();
    }
}





//
  public AnnotationConfigApplicationContext(String... basePackages) {
		this();
		scan(basePackages);
		refresh();
	}
```

上述示例中，我们使用`AnnotationConfigApplicationContext`类并传入要扫描的基础包路径（例如`com.example`），以启用注解扫描和注册。Spring会自动扫描并识别使用注解配置的Bean







### DI



**IOC和DI是什么关系？**

IoC是设计思想，DI是实现方式。组件之间依赖关系由容器在运行期决定，形象的说，即**由容器动态的将某个依赖关系注入到组件之中**



在Spring框架中，实现依赖注入（`Dependency Injection`）的方式有多种，包括：

1. 构造函数注入（`Constructor Injection`）：通过构造函数来注入依赖项。可以在类的构造函数中声明依赖项的参数，并由Spring容器负责解析和注入依赖项。
2. Setter方法注入（`Setter Injection`）：通过`Setter`方法来注入依赖项。可以在类中定义相应的`Setter`方法，并使用`@Autowired`注解或XML配置来指定要注入的依赖项。
3. 字段注入（`Field Injection`）：通过直接注入字段来实现依赖注入。可以在类的字段上使用`@Autowired`注解来指定要注入的依赖项。这种方式一般不被推荐，因为直接注入字段会破坏封装性。
4. 接口注入（`Interface Injection`）：通过实现特定的接口来注入依赖项。可以定义一个接口，其中包含用于设置依赖项的方法，然后在类中实现该接口并使用`@Autowired`注解来注入依赖项。
5. 注解注入（`Annotation-based Injection`）：使用注解来实现依赖注入。可以在类的构造函数、Setter方法、字段等位置使用`@Autowired`注解来指定要注入的依赖项。同时，还可以使用其他注解如`@Resource`、`@Inject`等来实现依赖注入。



#### 字段注入 :sun_with_face:



> 首先需要区分一下字段注入和注解注入：
>
> 在Spring依赖注入中，注解注入和字段注入并不是完全相同的概念，尽管它们经常同时使用
>
> 1. 注解注入（Annotation-based Injection）：注解注入是一种使用注解来实现依赖注入的方式。通过在类的构造函数、Setter方法、字段等位置使用注解（如`@Autowired`、`@Resource`、`@Inject`等）来标识要注入的依赖项。注解告诉Spring容器要自动注入相关的依赖项
> 2. 字段注入（Field Injection）：字段注入是一种特定的依赖注入方式，它将依赖项直接注入到类的字段中。使用`@Autowired`注解或其他相关的注解来标记字段，告诉Spring容器要将相关的依赖项注入到这些字段中
>
> 尽管在实践中，使用注解注入时通常会将注解放在字段上，以实现字段注入。但注解注入并不限于字段注入，还可以用于构造函数注入和Setter方法注入。注解注入提供了一种更灵活的方式来定义和配置依赖项的注入方式，可以根据需要选择在不同位置使用注解来实现依赖注入



使用最简单的**字段注入**方式来注入Bean：

```java
@Service
public class UserServiceImpl {

    @Autowired
    private UserDaoImpl userDao;

    public List<User> findUserList() {
        return userDao.findUserList();
    }

}
```

观察以上代码：`@Service`注解表示`UserServiceImpl`类是一个服务类型的`bean`，通过`@Autowired`注解，将`UserDaoImpl`类的实例自动注入到`userDao`属性中，而`findUserList()`方法用于调用`userDao`的`findUserList()`方法来获取用户列表





注意：:exclamation: :exclamation:  如果存在循环依赖（A Bean依赖于B Bean，B Bean同时也依赖于A Bean），此时字段注入可能会引发问题。构造函数注入可以更好地处理这种情况。



#### Setter注入

需要注意的是 `Setter`方式实现注入需要配合XML或者注解来实现

来看看使用`Setter()`+`XML` 实现bean的注入：

1、创建一个Java类作为`UserServiceImpl`：

```java
public class UserServiceImpl {
    private UserDao userDao;

    public void setUserDao(UserDao userDao) {
        this.userDao = userDao;
    }

    public List<User> findUserList() {
        return userDao.findUserList();
    }
```

在上述示例中，`UserServiceImpl`类是一个普通的Java类，没有使用任何注解。它依赖于`UserDao`接口，通过`Setter`方法`setUserDao()`来设置`userDao`属性



2、创建Spring的配置文件（例如`applicationContext.xml`），定义和配置Bean：

```java
xmlCopy code<beans xmlns="http://www.springframework.org/schema/beans"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
       xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd">

    <!-- 定义 UserDaoImpl Bean -->
        <bean id="userDao" class="com.example.UserDaoImpl" />

    <!-- 定义 UserServiceImpl Bean -->
    <bean id="userService" class="com.example.UserServiceImpl">
        <property name="userDao" ref="userDao" />
    </bean>

</beans>
```

在上述XML配置中，我们使用`<bean>`标签分别定义了`UserDao`和`UserServiceImpl`的Bean。通过`class`属性指定类的路径。在`UserServiceImpl`的配置中，使用`<property>`标签将`userDao`属性注入到id为`userDao` 的Bean中去



3、最后在应用程序中加载并使用配置文件：

```java
import org.springframework.context.ApplicationContext;
import org.springframework.context.support.ClassPathXmlApplicationContext;

public class MainApp {
    public static void main(String[] args) {
        // 加载配置文件
            ApplicationContext context = new ClassPathXmlApplicationContext("applicationContext.xml");

        // 获取 Bean 实例
        UserServiceImpl userService = (UserServiceImpl) context.getBean("userService");

        // 使用 Bean
        userService.findUserList();
    }
}

```

首先使用`ApplicationContext`接口来加载配置文件，并使用`getBean()`方法根据Bean的ID获取`UserServiceImpl`实例。然后，我们可以使用实例调用服务方法

可以看出来`XML`+`Setter`的实现方式麻烦了许多😅😅😅



然后我们再来看看注解+`Setter`是如何实现Bean的注入的：

假设有一个 `UserDao` 接口和它的实现类 `UserDaoImpl`：

```java
public interface UserDao {
    // ...
}

@Repository
public class UserDaoImpl implements UserDao {
    // ...
}

```

然后有一个Service类，通过setter方法进行依赖注入：

```java
@Service
public class UserService {

    private UserDao userDao;

    @Autowired
    public void setUserDao(UserDao userDao) {
        this.userDao = userDao;
    }
    
    // ...
}

```

这个示例中，通过使用 `@Autowired` 注解在 `setUserDao()` 方法上，告诉Spring在容器中找到实现了 `UserDao` 接口的Bean，并将它注入到 `userDao` 字段中，当然还可以使用更简化的方式，将 `@Autowired` 注解直接放在字段上，而不是放在setter方法上：

```java
@Service
public class UserService {

    @Autowired
    private UserDao userDao;
    
    // ...
}
```



> 这里有个问题：为什么注入的是`UserDao`而不是声明了`@Repository`注解的`UserDaoImpl`?



当使用`Spring`的依赖注入时，您注入的是接口（或抽象类）的类型，而不是具体的实现类。这是因为Spring的依赖注入是基于抽象的编程原则，即“面向接口编程”，以实现松耦合和可替换的设计

同时使用`@AutoWired`时，，程序在spring的容器中查找类型时`UserDao`的`bean`，刚好找到有且只有一个此类型的bean，即`UserDaoImpl`，所以就把`UserDaoImpl`注入到了`UserService`的属性`UserDao`中





#### 构造函数注入

构造函数注入bean也需要**配合XML或注解**来实现，这里来看看结合注解是怎么做的：

```java
@Service
public class UserServiceImpl {

    private final UserDaoImpl userDao;  //对象属性
    
    //将userDao作为构造函数的参数，并由Spring框架负责解析和注入依赖项
    @Autowired 
    public UserServiceImpl(UserDaoImpl userDaoImp) {
        this.userDao = userDaoImp;
    }

    public List<User> findUserList() {
        return userDao.findUserList();
    }
}
```

通过在该类的构造方法上添加`@AutoWired`注解来注入对象的Bean属性，此时就无需在`applicationContext.xml`里进行额外的配置和声明了







#### 接口注入







#### 实现Bean注入的相关注解  :angel:



`@Autowired`:

当使用@`Autowired`注解时，`Spring`容器会自动查找和注入与被注入字段、方法参数或构造方法参数具有相同类型的Bean，默认是根据type类型进行匹配：

- 如果被注入的字段或方法参数的类型与一个唯一的`Bean`类型匹配，`Spring`容器将自动注入该`Bean`
- 如果存在多个与类型匹配的`Bean`时，会发生装配异常。此时可以结合使用`@Qualifier`注解，通过指定具体的`Bean`名称来解决歧义(下面有讲)







需要注意的是，**`@Autowired`注解默认是`required=true`**，**即要求必须存在与类型匹配的 Bean** ，**如果设置required=false，则表示允许依赖的Bean不存在，注入为null值**



> `@Autowired` 属于 Spring 内置的注解，默认的注入方式为`byType`（根据类型进行匹配），也就是说会优先根据接口类型去匹配并注入 Bean （接口的实现类）
>
> 
>
> **这会有什么问题呢？** 当一个接口存在多个实现类(且都被IOC容器管理)，`byType`这种方式就无法正确注入对象了，因为这个时候 Spring 会同时找到多个满足条件的选择，默认情况下它自己不知道选择哪一个
>
> 
>
> 这种情况下，注入方式会变为 `byName`（根据名称进行匹配），这个名称通常就是类名（首字母小写），比如说下面代码中的 `smsService` 就是这里所说的名称：
>
> 

```java
// smsService 就是我们上面所说的名称
@Autowired
private SmsService smsService;
```

举个例子，`SmsService` 接口有两个实现类: `SmsServiceImpl1`和 `SmsServiceImpl2`，且它们都已经被 Spring 容器所管理

```java
// 报错，byName 和 byType 都无法匹配到 bean
@Autowired
private SmsService smsService;




// 正确注入  SmsServiceImpl1 对象对应的 bean
// smsServiceImpl1 就是我们上面所说的名称
@Autowired
@Qualifier(value = "smsServiceImpl1")
private SmsService smsService;
```





`@Resource`：

- @Resource是JavaEE提供的注解，也可以用于Spring中，用于自动装配Bean的依赖关系

- @Resource可以用于字段、Setter方法以及普通方法上(**不能用在构造方法上！，即不支持构造方法注入** )

- 它可以根据名称进行自动装配，**且默认按照Bean名称进行匹配(不同于`@Autowired`和`@Inject`的最大之处！！)**  ，如果找不到与名称匹配的Bean，可以结合`@Qualifier`注解指定具体的Bean名称；如果无法通过名称匹配到对应的 Bean 的话，注入方式会变为`byType`

- @Autowired和@Inject可以结合@Qualifier注解来指定具体的Bean名称，而@Resource直接通过`name`属性指定Bean名称:

  ```java
  public @interface Resource {
      String name() default "";
      Class<?> type() default Object.class;
  }
  ```

  `@Resource`默认是按照Bean的名称进行匹配；如果仅指定 `name` 属性则注入方式为`byName`，如果指定`type`属性则注入方式为`byType`；如果同时指定`name` 和`type`属性（不建议这么做）则注入方式为`byType`+`byName`

  ```java
  // 报错，byName 和 byType 都无法匹配到 bean
  @Resource
  private SmsService smsService;
  
  
  
  
  
  // 正确注入 SmsServiceImpl1 对象对应的 bean（比较推荐这种方式）
  @Resource(name = "smsServiceImpl1")
  private SmsService smsService;
  ```

  简单总结一下：
  
  - `@Autowired` 是 Spring 提供的注解，`@Resource` 是 JDK 提供的注解
  - `@Autowired` 默认的注入方式为`byType`（根据类型进行匹配），`@Resource`默认注入方式为 `byName`（根据名称进行匹配）
  - 当一个接口存在多个实现类的情况下，`@Autowired` 和`@Resource`都需要通过名称才能正确匹配到对应的 Bean。`Autowired` 可以通过 `@Qualifier` 注解来显式指定名称，`@Resource`可以通过 `name` 属性来显式指定名称
  
  



`@Inject`：

- @Inject是Java规范(javax扩展包)中定义的注解，可以用于Spring中，也可以与JavaEE容器一起使用

- @Inject可以用于字段、构造方法、Setter方法以及普通方法上
- 它和`@Autowired`注解的作用类似，用于自动装配Bean的依赖关系
- @Inject注解可以使用`@Named`(作用类似于`@Qualified`)注解来指定具体的Bean名称





### @Component 和 @Bean 的区别？

- @Component注解：

  - @Component是通用的注解，用于标识一个类作为组件(通用组件)被Spring管理。
  - @Component注解可以用在任何类上，表示将该类实例化为一个Bean对象，并由Spring容器进行管理。
  - @Controller、@Service、@Repository注解是@Component注解的派生注解，用于表示不同类型的组件
- @Bean注解：

  - @Bean注解用于在配置类（通常是带有@Configuration注解的类）中声明方法，这些方法会返回一个Bean对象
  - @Bean注解可以放在方法上，表示将方法的返回值实例化为一个Bean对象，并将其注册到Spring容器中
  - @Bean注解允许开发人员完全控制Bean的创建过程，可以在方法中进行自定义的实例化、属性设置等操作

  





### Bean的作用域



Bean的作用域定义了Bean对象的生命周期以及在容器中的可见范围。Spring框架提供了以下几种常用的Bean作用域：

1. `Singleton`（默认）：在整个应用程序上下文中，每个Bean定义对应一个实例。默认情况下，Spring容器中的Bean都是Singleton作用域。在Singleton作用域下，Spring容器只会创建一个Bean实例(**Spring会通过反射或者cglib来生成bean实例**)，并在需要时重复使用该实例(处理多次请求时在**Spring**容器里只实例化出一个bean，后续的请求都公用这个对象，当有请求来的时候会先从缓存**map**里查看有没有，有的话直接使用这个对象，没有的话才实例化一个新的对象)
2. Prototype：每次通过容器获取Bean时，都会创建一个新的Bean实例。每个Bean定义对应多个实例，每次获取Bean时都会创建一个新的实例。Prototype作用域适用于需要每次获取都是全新实例的情况
3. Request：每个HTTP请求都会创建一个新的Bean实例。适用于Web应用程序，每个请求都需要独立的Bean实例
4. Session：每个用户会话（Session）都会创建一个新的Bean实例。适用于Web应用程序，每个用户会话都需要独立的Bean实例

> 为什么默认是单例？
>
> (1)当Bean被声明为Singleton作用域时，Spring容器只会创建一个实例并将其缓存起来。在后续的请求中，如果需要该Bean，容器将直接返回缓存的实例，而不是每次都创建新的实例。这样可以**减少对象创建和销毁的开销**，提高应用程序的性能。
>
> 
>
> (2)此外，Singleton作用域还可以**确保Bean之间的状态共享**。在Singleton作用域下，**多个Bean可以引用同一个实例**，这样可以方便地共享数据和状态，提高应用程序的可维护性和一致性
>
> 
>
> (3)同时由于多次请求bean只会创建一个实例，**减少jvm垃圾回收的对象**，并且**由于后续请求bean都是直接从Map缓存中查找，所以可以快速获取一个Bean**
>
> 
>
> 
>
> 然而需要注意的是，Singleton作用域并不适用于所有的情况。在某些情况下，需要每次获取Bean都是全新实例，或者需要每个请求/会话都有独立的Bean实例。这时可以使用Prototype、Request、Session或Global Session等其他作用域





### Bean的线程安全问题

https://blog.csdn.net/xylitolz/article/details/123225348



分析这个问题要先知道什么是有状态/无状态的Bean？

> JavaGuide上总结：有状态 Bean 是指包含可变的成员变量的对象，因此多个线程竞争该Bean时存在线程安全问题

**"有状态的Bean"：**指的是具有状态或数据的Bean，它们在多次方法调用之间保持状态，并且可以在不同的方法调用之间共享数据。有状态的Bean的状态可以在多个请求或会话之间保持，对于每个客户端或用户来说，它们是唯一的，举一个有状态Bean的例子：

```java
@Component
@Scope("prototype")
public class ShoppingCart {
    private List<Item> items = new ArrayList<>();

    public void addItem(Item item) {
        items.add(item);
    }

    public void removeItem(Item item) {
        items.remove(item);
    }

    public List<Item> getItems() {
        return items;
    }
}

```

在上述示例中，`ShoppingCart`类被标记为`@Component`以使其成为一个Spring管理的Bean，并且`@Scope("prototype")`指定了其作用域为Prototype，即每次获取该Bean时都会创建一个新的实例

`ShoppingCart`类代表一个购物车，它具有状态。它包含一个`items`列表用于存储添加到购物车中的商品项

**由于`ShoppingCart`是有状态的Bean，每个用户或客户端在获取`ShoppingCart`实例时，都会得到一个新的、独立的购物车对象，每个购物车对象维护自己的状态。这样，每个用户的购物车是独立的，它们可以独立地操作和管理自己的商品项**



**"无状态的Bean"**：在Spring中，"无状态的Bean"指的是不具有状态或数据的Bean，它们在每次方法调用之间不保持状态，不共享数据。无状态的Bean的方法调用是独立的，不依赖于之前的方法调用或其他请求的状态

无状态的Bean通常**用于表示纯粹的业务逻辑、服务类或工具类，它们不需要维护特定的状态信息**

以下是一个示例：

```java
@Service
public class CalculatorService {
    public int add(int a, int b) {
        return a + b;
    }

    public int multiply(int a, int b) {
        return a * b;
    }
}
```



在上述示例中，`CalculatorService`类被标记为`@Service`以使其成为一个Spring管理的Bean。它是一个无状态的Bean，用于提供基本的计算功能。它包含了`add()`和`multiply()`方法，这些方法是独立的，不会受到之前调用的影响。每次调用这些方法时，它们会根据传入的参数进行计算，并返回结果

由于`CalculatorService`是无状态的Bean，每个用户或客户端在获取`CalculatorService`实例时，都会得到同一个实例，它不会维护特定的状态信息。这样，**不同用户或请求之间的`CalculatorService`实例是独立的，它们可以并发地执行计算操作而不会相互干扰**





一般来说要把有状态的Bean设计为多例，把无状态的Bean设计为单例

有状态的Bean包含状态或数据，可能会在不同的方法调用之间保持状态，并且可能需要在多个请求或会话之间共享数据。将有状态的Bean设计为多例可以确保每次获取Bean时都创建一个新的实例，避免多个请求或会话之间的状态共享问题。

**无状态的Bean不包含状态或数据，每次方法调用之间不保持状态，也不需要共享数据。将无状态的Bean设计为单例可以节省资源，避免重复创建实例的开销，并且可以方便地在应用程序的不同部分共享和重用**





**再回到最初的问题上来，单例是线程安全的吗？**

在Spring中，默认情况下，Bean的作用域是Singleton（单例），也就是说在整个应用程序上下文中只存在一个Bean实例，单例Bean在多线程环境下是线程安全的：

1. 单一实例：单例Bean只有一个实例存在于内存中，多个线程共享同一个实例。因此，不存在多个实例之间的竞态条件或**数据不一致性问题**。

2. 无可变状态：单例Bean通常应该是无状态或不可变的，**它们不会维护可变的状态信息**，或者将状态信息封装在不可变的对象中。因此，多个线程可以同时读取单例Bean的状态，而不会引起线程安全问题。

3. 线程安全设计：Spring框架本身会确保单例Bean的线程安全性，**Spring容器在初始化单例Bean时，会处理并发访问和状态初始化的问题**，以确保单例Bean的正确性

   

需要注意的是，虽然单例Bean本身是线程安全的，但**如果单例Bean依赖于共享的可变资源** 例如静态变量、全局变量或共享的数据库连接等 (**下面就有个例子针对单例下的线程安全问题**)，仍然需要考虑线程安全性并采取适当的并发控制措施

总结而言，单例Bean在多线程环境下一般是线程安全的，因为它们是唯一的实例，通常没有可变的状态，并且Spring框架会确保其线程安全性。但需要注意，如果单例Bean依赖于共享的可变资源，仍需谨慎处理并发访问和状态修改的问题





在Spring框架中，单例Bean的线程安全性是通过以下几种方式来确保的：

1. **无状态的Bean：** Spring鼓励将单例Bean设计为无状态的，即不包含实例变量。无状态Bean不会在多个线程之间共享状态，从而避免了线程安全性问题。
2. **只读操作：** 如果单例Bean包含状态，但仅进行只读操作，那么多个线程之间共享Bean实例也是安全的。只读操作不会引发并发问题。
3. **方法内部变量：** Spring通过将实例变量声明为方法内部变量（方法局部变量）来保证线程安全性。这是因为方法内部变量在栈上分配，每个线程都有自己的栈，因此不会产生线程之间的干扰。
4. **同步控制：** 在一些情况下，如果单例Bean的状态需要在多个线程之间共享，您可以在Bean的方法中使用同步机制（如`synchronized`关键字）来确保方法级别的线程安全。
5. **ThreadLocal变量：** Spring支持在单例Bean中使用ThreadLocal变量，这使得每个线程都可以拥有自己的变量副本，从而避免了共享状态带来的问题。











> 引申:`Spring`如何使用`ThreadLocal`解决单例下的线程安全问题？

在使用Spring时，很多人可能对Spring中为什么DAO和Service对象采用单实例方式很迷惑，这些读者是这么认为的:"DAO对象必须包含一个数据库的连接Connection，**而这个Connection不是线程安全的，所以每个DAO都要包含一个不同的Connection对象实例，这样一来DAO对象就不能是单实例的了**"

上述观点对了一半,对的是“每个DAO对象都要包含一个不同的Connection对象实例”这句话，错的是“DAO对象就不能是单实例”。其实Spring在实现Service和DAO对象时，使用了`ThreadLocal`这个类，这个是一切的核心:



一般的Web应用划分为展现层、服务层和持久层三个层次，在不同的层中编写对应的逻辑，下层通过接口向上层开放功能调用。**在一般情况下，从接收请求到返回响应所经过的所有程序调用都同属于一个线程**。这样你就可以根据需要，将一些非线程安全的变量以ThreadLocal存放，在同一次请求响应的调用线程中，所有关联的对象引用到的都是同一个变量
下面的实例能够体现Spring对有状态Bean的改造思路：

```JAVA
public class TopicDao {
    
	//①一个非线程安全的变量
　　private Connection conn;
    
	//②引用非线程安全变量
　　public void addTopic() {
		Statement stat = conn.createStatement();
　　}
}



```

由于①处的conn是成员变量，因为addTopic()方法是非线程安全的，必须在使用时创建一个新TopicDao实例（非singleton）。下面使用ThreadLocal对conn这个非线程安全的状态进行改造：

```JAVA
public class TopicDao {  
    //①使用ThreadLocalMap保存Connection变量——connThreadLocal为Map<K,V>中的K
    private static ThreadLocal <Connection>connThreadLocal = newThreadLocal<Connection>();  
    public static Connection getConnection() {  
   // ②如果connThreadLocal没有本线程对应的Connection 则创建一个新的Connection，  
   // 并将其保存到线程本地变量中  
       if (connThreadLocal.get() == null) {  
           Connection conn = getConnection();  
           connThreadLocal.set(conn);  
           return conn;  
       }
       // ③直接返回线程本地变量
       return connThreadLocal.get();  
    }

    public void addTopic() {  
       // ④从ThreadLocal中获取线程对应的Connection  
       try {
           Statement stat = getConnection().createStatement();  
       } catch (SQLException e) {  
           e.printStackTrace();  
       }
    }
}

```

不同的线程在使用TopicDao时，先判断`connThreadLocal`对应的`value`是否是null，如果是null则说明当前线程还没有对应的`Connection`对象，**这时创建一个Connection对象并添加到本地线程变量中**；如果不为null，则说明当前的线程已经拥有了Connection对象，直接使用就可以了。这样，就保证了不同的线程使用线程相关的Connection，而不会使用其它线程的Connection。因此，这个TopicDao就可以做到**singleton共享**了

总结：

`Spring`中`DAO`和`Service`都是以单实例的`bean`形式存在，**Spring通过`ThreadLocal`类将Bean具有的有状态变量（例如数据库连接`Connection`）本地线程化，从而做到多线程状况下的安全**。在一次请求响应的处理线程中， 该线程贯通展示、服务、数据持久化三层，通过`ThreadLocal`使得所有关联的对象引用到的都是同一个变量









`JavaGuide`上对于Bean是否线程安全的说法：

> Spring 框架中的 Bean 是否线程安全，取决于其作用域和状态。
>
> 我们这里以最常用的两种作用域 prototype 和 singleton 为例介绍。几乎所有场景的 Bean 作用域都是使用默认的 singleton ，重点关注 singleton 作用域即可。
>
> prototype 作用域下，每次获取都会创建一个新的 bean 实例，不存在资源竞争问题，所以不存在线程安全问题。singleton 作用域下，IoC 容器中只有唯一的 bean 实例，可能会存在资源竞争问题（取决于 Bean 是否有状态）。如果这个 bean 是有状态的话，那就存在线程安全问题（有状态 Bean 是指包含可变的成员变量的对象）。
>
> 不过，大部分 Bean 实际都是无状态（没有定义可变的成员变量）的（比如 Dao、Service），这种情况下， Bean 是线程安全的。
>
> 对于有状态单例 Bean 的线程安全问题，常见的有两种解决办法：
>
> 
>
> 1. 在 Bean 中尽量避免定义可变的成员变量————Bean实例的成员属性最好不要是有状态的
> 2. 在类中定义一个 `ThreadLocal` 成员变量，将需要的可变成员变量保存在 `ThreadLocal` 中（推荐的一种方式）
>
> 







> 将有状态的`bean`设计为多例  和 使用`threadlocal`来设计无状态的bean，这两者区别在哪里？

有状态的 `bean` 设计为多例 和 "使用 `ThreadLocal` 来设计无状态的`bean`" 都是在 Java 中处理对象实例状态的方法，但它们解决的问题和应用场景略有不同：

1. **有状态的Bean设计为多例：**在 Spring 框架中，Bean 可以被定义为单例或多例。有状态的 Bean 指的是每个实例都维护着自己的状态，并且可能会受到多个客户端的交互影响。如果你将有状态的 Bean 设计为多例，意味着每次请求该 Bean 的时候都会创建一个新的实例，不同的客户端请求不会共享状态。这在多线程环境中可以避免状态混乱的问题，但也可能会导致资源消耗较大
2. **使用 ThreadLocal 来设计无状态的Bean：** ThreadLocal 是 Java 提供的一个线程局部变量，它能够让每个线程都拥有自己的变量副本。这对于设计无状态的 Bean 很有用，因为无状态的 Bean 不依赖于特定的客户端状态。通过在每个线程中维护一个副本，可以避免多线程之间的状态干扰。这在某些情况下能够提高性能，因为避免了线程同步的开销









### Bean生命周期

对于 Spring Bean 的生命周期来说：

- 实例化 Instantiation
- 属性赋值 Populate
- 初始化 Initialization
- 销毁 Destruction

实例化 -> 属性赋值 -> 初始化 -> 销毁



`Spring` 只帮我们管理单例模式 `Bean` 的**完整**生命周期，对于 `prototype` 的 `bean` ，`Spring` 在创建好交给使用者之后则不会再管理后续的生命周期

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/spring-framework-ioc-source-102.png)

上图为单例Bean的生命周期(**针对的是非懒加载的Bean**)，总结为以下几条：

- 如果 `BeanFactoryPostProcessor` 和 `Bean` 关联, 则调用`postProcessBeanFactory`方法(即首**先尝试从Bean工厂中获取Bean**)
- `Bean`容器找到配置文件中`Bean`的定义，调用该`Bean`的`Construct`无参构造方法**实例化 Bean**

   在`Spring`容器中，创建`Bean`实例的方式取决于使用的实例化策略。主要有两种方式：

1. 用反射创建`Bean`实例：当定义的`Bean`通过无参构造函数进行实例化时，`Spring`容器会使用反射机制来创建`Bean`实例。它会通过调用`Bean`类的无参构造方法来实例化对象。这种方式适用于大多数情况，当`Bean`的实例化过程没有特殊要求时，Spring会自动使用反射机制创建实例。
2. 利用Bean类的构造方法创建Bean实例：有时候，Bean的实例化可能需要特殊的处理逻辑或依赖注入，这时候可以通过**在Bean类中定义带参数的构造方法来实现**。当使用构造方法注入或通过`FactoryBean`等方式实例化`Bean`时，Spring容器会调用Bean类的特定构造方法来创建Bean实例。在这种情况下，Spring会使用指定的构造方法来实例化Bean对象，而不是使用反射机制。

- 利用依赖注入DI(Setter、构造函数注入、字段注入)完成 Bean 中所有**属性值的配置注入**

- **调用一系列xxxAware接口** (**让当前Bean感知到各种东西**) 
>这里特别说明一下Aware接口:**Spring的依赖注入最大亮点就是所有的Bean对Spring容器的存在是没有意识的**。但是在实际项目中，我们有时不可避免的要用到Spring容器本身提供的资源，这时候要让 Bean **主动意识到Spring容器的存在**，**才能调用Spring所提供的资源**，这就是Spring的Aware接口，**Aware接口是个标记接口，标记这一类接口是用来“感知”属性的**，Aware的众多子接口则是表征了具体要“感知”什么属性。例如BeanNameAware接口用于“感知”自己的名称，ApplicationContextAware接口用于“感知”自己所处的上下文。其实Spring的Aware接口是Spring设计为框架内部使用的，在大多数情况下，我们不需要使用任何Aware接口，除非我们真的需要它们，实现了这些接口会使应用层代码耦合到Spring框架代码中

- 第一类Aware接口
  
  - 如果 Bean 实现了 `BeanNameAware` 接口(用于通知 Bean 其在容器中的名称（即 Bean 的 ID 或名称）,允许 Bean 在容器中感知自己的名称，以便于进行一些自定义的逻辑处理)，则 Spring 调用 Bean 的 `setBeanName`() 方法传入当前 Bean 的 id 值
    - 如果 Bean 实现了 `BeanClassLoaderAware` 接口，则 Spring 调用 `setBeanClassLoader`() 方法传入`classLoader`的引用到bean中
    - 如果 Bean 实现了 `BeanFactoryAware` 接口，则 Spring 调用 `setBeanFactory`() 方法传入当前工厂实例的引用到bean中
  
- 第二类Aware接口
  
  - 如果 Bean 实现了 `EnvironmentAware` 接口，则 Spring 调用 `setEnvironment`() 方法传入当前 `Environment` 实例的引用到Bean中
  
  - 如果 Bean 实现了 `EmbeddedValueResolverAware` 接口，则 Spring 调用 `setEmbeddedValueResolver`() 方法传入当前 `StringValueResolver` 实例的引用到bean中
  
  - 如果 Bean 实现了 `ApplicationContextAware` 接口，则 `Spring` 调用 `setApplicationContext`() 方法传入当前 `ApplicationContext` 实例的引用到bean中
- 如果 `BeanPostProcessor` 和 Bean 关联，则 Spring 将调用该接口的预初始化方法 `postProcessBeforeInitialzation`() 对 Bean 进行**加工**操作，(此处非常重要!! **AOP 就是利用它实现的**)

- 如果 Bean 实现了 `InitializingBean` 接口，则 Spring 将调用 `afterPropertiesSet`() 方法。(或者有执行@`PostConstruct`注解的方法)

- 如果在Bean配置文件中通过 **init-method** 属性指定了初始化方法，则调用该初始化方法

```xml
<bean id="myBean" class="com.example.MyBean" init-method="init"/>
```

上述配置指定了`MyBean`类的`init()`方法作为初始化方法，在Bean实例化后调用

```java
@Component
public class MyBean {
  //使用注解来标注Bean的初始化方法。通过在Bean类的方法上添加@PostConstruct注解，该方法将被标识为Bean的初始化方法
    @PostConstruct
    public void init() {
        // 初始化逻辑
    }
}

```

上述代码使用`@PostConstruct`注解标注了`init()`方法，使其成为Bean的初始化方法

- 此时如果 `BeanPostProcessor` 和 Bean 关联(结合前面的)，则 Spring 将调用该接口的初始化方法 `postProcessAfterInitialization`()，此时 Bean 已经可以被系统使用

- 如果在 `<bean>` 中指定了该 Bean 的作用范围为 scope="singleton"，则将该 Bean 放入 Spring IoC 的缓存池中，将触发 Spring 对该 Bean 的生命周期管理；如果在 `<bean>` 中指定了该 Bean 的作用范围为 scope="prototype"，则将该 Bean 交给调用者，调用者管理该 Bean 的生命周期，Spring 不再管理该 Bean

- 如果 Bean 实现了 DisposableBean 接口，则 Spring 会调用 destory() 方法将 Spring 中的 Bean 销毁；(或者有执行@PreDestroy注解的方法)

- 如果在配置文件中通过 **destory-method** 属性指定了 Bean 的销毁方法，则 Spring 将调用该方法对 Bean 进行销毁

  

  

  
  
  
  
  
  
  ​    

### Bean的循环依赖问题 未完结:sleeping:

Bean的循环依赖问题是指两个或多个Bean之间存在相互依赖关系，形成了一个循环链，导致**无法正确实例化和注入这些Bean的依赖关系**。例如，假设Bean A 依赖于 Bean B，而 Bean B 又依赖于 Bean A，它们之间形成了一个循环依赖。在这种情况下，当容器尝试实例化这些Bean时，会陷入无限循环，导致程序无法正常启动或出现死锁的情况，体现到代码层面上是这个样子：

```java
@Component
public class A {
    // A中注入了B
    @Autowired
    private B b;
}
@Component
public class B {
    // B中也注入了A
    @Autowired
    private A a;
}
```







但是Spring解决循环依赖是有前置条件的：

出现循环依赖的Bean只能是单例  (为什么❓❓)

> 循环依赖问题主要存在于单例（Singleton）作用域的Bean之间，而原型（Prototype）作用域的Bean不会引发循环依赖问题。这是因为**单例Bean的实例化和依赖注入发生在容器启动阶段，而原型Bean的实例化和依赖注入发生在每次获取Bean实例的时候**(这样每个Bean实例化的时间就**错开**了)
>
> 当两个或多个单例Bean之间存在相互依赖关系时，它们的实例化和依赖注入是在容器启动阶段同时进行的。在这种情况下，如果两个Bean互相依赖，容器将无法解决循环依赖问题，因为其中一个Bean的实例化需要另一个Bean的实例，而另一个Bean的实例化又需要第一个Bean的实例，形成了一个循环链，导致无法完成依赖的解析和注入
>
> 为了解决单例Bean之间的循环依赖问题，Spring使用了"**提前暴露半成品**"的机制。当容器创建一个单例Bean时，会先创建一个半成品的Bean实例，并将其暴露给其他Bean进行依赖注入。然后，在依赖注入完成后，容器会回过头来完成半成品Bean实例的创建和属性填充

```java
@Component
public class A {
//    @Autowired
//    private B b;
    public A(B b) {

    }
}

@Component
public class B {

//    @Autowired
//    private A a;

    public B(A a){

    }
}
```

在上面的例子中，A中注入B的方式是通过构造器，B中注入A的方式也是通过构造器，这个时候循环依赖是无法被解决，如果你的项目中有两个这样相互依赖的Bean，在启动时就会报出以下错误：

```java
Caused by: org.springframework.beans.factory.BeanCurrentlyInCreationException: Error creating bean with name 'a': Requested bean is currently in creation: Is there an unresolvable circular reference?
```

为了测试循环依赖的解决情况跟注入方式的关系，我们做如下四种情况的测试

|        依赖情况        |                    依赖注入方式                    | 循环依赖是否被解决 |
| :--------------------: | :------------------------------------------------: | :----------------- |
| AB相互依赖（循环依赖） |                均采用setter方法注入                | 是                 |
| AB相互依赖（循环依赖） |                  均采用构造器注入                  | 否                 |
| AB相互依赖（循环依赖） | A中注入B的方式为setter方法，B中注入A的方式为构造器 | 是                 |
| AB相互依赖（循环依赖） | B中注入A的方式为setter方法，A中注入B的方式为构造器 | 否                 |

从上面的测试结果我们可以看到，不是只有在setter方法注入的情况下循环依赖才能被解决，即使存在构造器注入的场景下，循环依赖依然被可以被正常处理掉



接着来看看Spring如何解决最基础的循环依赖？

首先，我们要知道**Spring在创建Bean的时候默认是按照自然排序来进行创建的，所以第一步Spring会去创建A**

创建A的过程实际上就是调用`getBean`方法，这个方法有两层含义

1. 从缓存中获取到已经被创建的对象
2. 缓存中没有则创建一个新的Bean

故首先会调用`getSingleton(a)`方法，这个方法又会调用`getSingleton(beanName, true)`

```java
public Object getSingleton(String beanName) {
    return getSingleton(beanName, true);
}
```

`getSingleton(beanName, true)`这个方法实际上就是到缓存中尝试去获取Bean，整个缓存分为三级

1. `singletonObjects`，一级缓存，存储的是所有创建好了的单例Bean
2. `earlySingletonObjects`，完成实例化，但是还未进行属性注入及初始化的对象
3. `singletonFactories`，提前暴露的一个单例工厂，二级缓存中存储的就是从这个工厂中获取





当A完成了实例化并添加进了三级缓存后，就要开始为A进行属性注入了，在注入时发现A依赖了B，那么这个时候Spring又会去`getBean(b)`，然后反射调用`setter`方法完成属性注入

因为B需要注入A，所以在创建B的时候，又会去调用`getBean(a)`，这个时候就又回到之前的流程了，但是不同的是，之前的`getBean`是为了创建Bean，而此时再调用`getBean()`不是为了创建了，而是要从缓存中获取，因为之前A在实例化后已经将其放入了三级缓存`singletonFactories`中

这样注入到B中的A是通过`getEarlyBeanReference`方法提前暴露出去的一个对象，还不是一个完整的Bean,即在创建B时会提前给B注入了一个还未初始化的A对象，但是在创建A的流程中一直使用的是注入到B中的A对象的引用，之后会根据这个引用对A进行初始化





总结就是：

1. A创建过程需要B，于是A将自己放在三级缓存中，去实例化B    
2. B实例化的时候需要A，于是B先查找一级缓存，没有，再查二级缓存，还是没有，再查三级缓存，有了，于是将三级缓存中的A放在二级缓存中，并删除三级缓存中的A 
3. B顺利初始化完成后，将自己放到一级缓存中（此时B中的A仍是创建中状态） 
4. 此时返回来继续创建A，此时B已经创建结束了，直接从一级缓存拿到B，然后完成创建，并将A放入到 一级缓存中（此时B中的A已经是一个完整实例，因为指向的是内存中的同一块地方）













为什么`Setter()`注入可以解决循环依赖？

- 具体来说，当容器创建一个Bean实例时，如果存在循环依赖关系，容器会先创建Bean的一个半成品实例，并将其暴露给其他需要依赖它的Bean进行注入。在进行依赖注入时，Spring会使用代理对象来代替真正的Bean实例，以确保其他Bean可以正确地引用到该依赖
- 对于Setter方法注入，Spring会首先创建Bean的半成品实例，并将其注入到其他Bean中。然后，在完成所有Bean的创建和依赖注入后，容器会回过头来调用相应的Setter方法，将真正的Bean实例注入到其他Bean中。这样，通过Setter方法注入，容器可以在运行时动态解决循环依赖，确保所有Bean都能正确地获取到它们所依赖的其他Bean实例
- 需要注意的是，Setter方法注入是通过引入代理对象来实现的，因此在代码中使用Setter注入时，应当避免在构造函数中访问依赖的Bean。因为在构造函数执行时，依赖的Bean可能还没有完全初始化





### BeanFactory与FactoryBean区别



`BeanFactory`： `BeanFactory`是Spring Framework中的核心接口之一，它是`Spring`的IoC容器的基础。`BeanFactory`负责创建、管理和提供应用程序中的Bean对象。它是一个工厂模式的实现，用于创建和管理Bean的实例。`BeanFactory`接口提供了各种方法，如`getBean()`来获取Bean实例、`containsBean()`来检查是否存在指定的Bean等，`isSingleton()`来判断该Bean是否为单例Bean

BeanFactory的主要功能包括以下几个方面：

1. Bean的实例化：BeanFactory负责根据配置信息实例化Bean对象。它可以通过XML配置文件、Java注解或Java代码来定义Bean的配置元数据(底层实例化的原理都是基于反射获取到Class对象，然后利用 `Class` 对象的 `newInstance()` 方法创建类的实例。这会调用类的无参构造方法来完成实例化。如果类没有无参构造方法，或者构造方法为私有，那么实例化过程会失败)
2. 依赖注入：BeanFactory支持依赖注入，即将Bean所依赖的其他Bean注入到它们之中。这样可以通过配置的方式来解决Bean之间的依赖关系，使得Bean可以在运行时动态地获取所需的依赖对象。
3. 生命周期管理：BeanFactory管理Bean的生命周期，包括Bean的创建、初始化和销毁过程。它可以在Bean创建之前和销毁之后执行一些特定的操作，如初始化回调方法、销毁回调方法等。
4. 延迟初始化：BeanFactory支持延迟初始化(`@Lazy`注解、`lazy-init`属性)，即在需要使用Bean时才进行实例化。这可以提高应用程序的性能和内存效率，避免不必要的资源消耗
5. 容器管理：BeanFactory作为一个IoC容器，负责管理所有的Bean对象。它提供了各种方法来获取Bean实例，如按名称获取、按类型获取等———— getBean(String name)、 getBean(Class<T> requiredType)







`FactoryBean`： `FactoryBean`是一个特殊的Bean，它是由实现了`FactoryBean`接口的类所创建的。`FactoryBean`的作用是在创建Bean实例时提供更高级的控制和定制能力。通过让一个类实现`FactoryBean`接口，开发人员可以在该类中自定义实现其他Bean的创建逻辑，包括创建过程、初始化参数、依赖关系等。`FactoryBean`可以创建非常灵活的Bean实例，甚至可以创建其他Bean的代理

> FactoryBean接口的核心方法是`getObject()`，它用于返回该工厂创建的Bean实例。除此之外，FactoryBean接口还提供了其他一些方法，如`getObjectType()`用于获取创建的Bean的类型，`isSingleton()`用于指示创建的Bean是否是单例等
>
> ```java
> T getObject() throws Exception;
> 	
> Class<?> getObjectType();
> 
> default boolean isSingleton() {
> 		return true;
> 	}
> ```
>
> 

举个例子来说明，假设我们有一个自定义的`FactoryBean`实现类`MyFactoryBean`，它可以创建一个特殊的对象`MyObject`(对该Bean进行自定义)：

```java
public class MyObject {
    // ...
}

public class MyFactoryBean implements FactoryBean<MyObject> {

    public MyObject getObject() throws Exception {
        // 在这里自定义创建MyObject的逻辑
        MyObject myObject = new MyObject();
        // ...
        return myObject;
    }

    public Class<?> getObjectType() {
        return MyObject.class;
    }

    public boolean isSingleton() {
        return true; // 这里指定创建的Bean是单例的
    }
}
```

在上述示例中，`MyFactoryBean`实现了`FactoryBean<MyObject>`接口，并实现了`getObject()`方法来自定义创建`MyObject`实例的逻辑。在`getObject()`方法中，我们可以进行一些复杂的操作，如实例化对象、设置属性、依赖注入等。`getObjectType()`方法指定了创建的Bean的类型为`MyObject.class`，`isSingleton()`方法指定了创建的Bean是单例的当使用`FactoryBean`时，需要在Spring配置文件中进行相应的配置：

```xml
<bean id="myObjectFactory" class="com.example.MyFactoryBean" />

<bean id="myObject" factory-bean="myObjectFactory" factory-method="getObject" />
```

在上述示例中，我们通过`<bean>`标签配置了`myObject`的创建方式，使用了`myObjectFactory`作为`FactoryBean`，并指定了`getObject`方法作为创建实例的方法

通过`FactoryBean`，我们可以在创建`Bean`的过程中进行更多的定制和控制，使得Bean的创建逻辑更加灵活和自定义化







ChatGPT对两者区别的总结如下：

1. **FactoryBean：** `FactoryBean` 是一个接口，允许开发者创建自定义的工厂类，用于创建和管理特定类型的 Bean。通过实现 `FactoryBean` 接口，**你可以在 Spring 容器中注册一个工厂 Bean，这个工厂 Bean 负责返回特定类型的实例化对象**。通过使用 `FactoryBean`，你可以在实例化 Bean 的过程中进行一些自定义逻辑，从而实现更灵活的 Bean 创建。

   例如，你可以创建一个 `DataSource` 的工厂，它可以根据配置返回数据库连接池的实例。当你通过 `getBean("dataSource")` 获取 `DataSource` Bean 时，实际上得到的是这个工厂所创建的对象。

2. **BeanFactory：** `BeanFactory` 是 Spring 框架的核心接口之一，它是用于管理和访问 Spring 容器中的各种 Bean 的接口。`BeanFactory` 提供了各种方法来获取、创建和管理 Bean 实例。它是 Spring 容器的底层接口，定义了访问 Bean 的基本功能，包括实例化 Bean、依赖注入、生命周期管理等。

   `BeanFactory` 接口的实现类包括 `ApplicationContext`，它是 Spring 的一个更高级别的接口，提供了除了 BeanFactory 外的其他功能，如国际化、事件发布等。

区别：

- `FactoryBean` 是一个接口，允许你自定义一个工厂，用于创建特定类型的 Bean 实例。
- `BeanFactory` 是 Spring 容器的核心接口，用于管理和访问容器中的各种 Bean。
- 通过实现 `FactoryBean` 接口，你可以实现自定义逻辑来创建 Bean，而 `BeanFactory` 是整个容器的基础结构，提供了获取 Bean 的基本方法。
- `FactoryBean` 本身也是一个 Bean，可以在 Spring 容器中注册和管理。
- 当你从 Spring 容器中获取一个通过 `FactoryBean` 创建的 Bean 时，实际上获取的是工厂返回的对象，而不是工厂本身。





## AOP

OOP面向对象编程，针对业务处理过程的实体及其属性和行为进行抽象封装，以获得更加清晰高效的逻辑单元划分。而AOP则是针对业务处理过程中的切面进行提取，它所面对的是处理过程的某个步骤或阶段

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/spring-framework-aop-2.png)

AOP(Aspect-Oriented Programming:面向切面编程)能够将那些**与业务无关，却为业务模块所共同调用**的逻辑或责任（例如事务处理、**日志管理、权限控制**等）封装起来，便于减少系统的重复代码，降低模块间的耦合度





### AOP术语



**连接点（Jointpoint）**：表示需要在程序中插入横切关注点的扩展点，**连接点可能是类初始化、方法执行、方法调用、字段调用或处理异常等等**，Spring只支持方法执行连接点，在AOP中表示为**在哪里干**；

**切入点（Pointcut）**： 选择一组相关连接点的模式，即可以认为连接点的集合，Spring支持perl5正则表达式和AspectJ切入点模式，Spring默认使用AspectJ语法，在AOP中表示为**在哪里干的集合**；

**通知（Advice）**：在连接点上执行的行为，通知提供了在AOP中需要在切入点所选择的连接点处进行扩展现有行为的手段；包括前置通知（before advice）、后置通知(after advice)、环绕通知（around advice），在Spring中通过代理模式实现AOP，并通过拦截器模式以环绕连接点的拦截器链织入通知；在AOP中表示为**干什么**；

**方面/切面（Aspect）**：横切关注点的模块化，比如上边提到的日志组件。可以认为是通知、引入和切入点的组合；在Spring中可以使用Schema和@AspectJ方式进行组织实现；在AOP中表示为**在哪干和干什么集合**；

**引入（inter-type declaration）**：也称为内部类型声明，为已有的类添加额外新的字段或方法，Spring允许引入新的接口（必须对应一个实现）到所有被代理对象（目标对象）, 在AOP中表示为**干什么（引入什么）**；

**目标对象（Target Object）**：需要被织入横切关注点的对象，即该对象是切入点选择的对象，需要被通知的对象，从而也可称为被通知对象；由于Spring AOP 通过代理模式实现，从而这个对象永远是被代理对象，在AOP中表示为**对谁干**；

**织入（Weaving）**：把切面连接到其它的应用程序类型或者对象上，并创建一个被通知的对象。这些可以在编译时（例如使用AspectJ编译器），类加载时和运行时完成。Spring和其他纯Java AOP框架一样，在运行时完成织入。在AOP中表示为**怎么实现的**；

**AOP代理（AOP Proxy）**：AOP框架使用代理模式创建的对象，从而实现在连接点处插入通知（即应用切面），就是通过代理来对目标对象应用切面。在Spring中，AOP代理可以用JDK动态代理或CGLIB代理实现，而通过拦截器模型应用切面。在AOP中表示为**怎么实现的一种典型方式**；



> **通知类型**：

- **前置通知（Before advice）**：在某连接点之前执行的通知，但这个通知不能阻止连接点之前的执行流程（除非它抛出一个异常）
- **后置通知（After returning advice）**：在某连接点正常完成后执行的通知：例如，一个方法没有抛出任何异常，正常返回
- **异常通知（After throwing advice）**：在方法抛出异常退出时执行的通知
- **最终通知（After (finally) advice）**：当某连接点退出的时候执行的通知（不论是正常返回还是异常退出）
- **环绕通知（Around Advice）**：包围一个连接点的通知，如方法调用。这是最强大的一种通知类型。环绕通知可以在方法调用前后完成自定义的行为。它也会选择是否继续执行连接点或直接返回它自己的返回值或抛出异常来结束执行

环绕通知是最常用的通知类型。和AspectJ一样，Spring提供所有类型的通知，我们推荐你使用尽可能简单的通知类型来实现需要的功能。例如，**如果你只是需要一个方法的返回值来更新缓存，最好使用后置通知而不是环绕通知**，尽管环绕通知也能完成同样的事情



我们把这些术语串联到一起，方便理解：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/spring-framework-aop-3.png)









### AspectJ

AspectJ是一个java实现的AOP框架，它能够对java代码进行AOP编译（一般在编译期进行），让java代码具有AspectJ的AOP功能（当然需要特殊的编译器）

- AspectJ是更强的AOP框架，是实际意义的**AOP标准**；
- Spring为何不写类似AspectJ的框架？ Spring AOP使用纯Java实现, 它不需要专门的编译过程, 它一个**重要的原则就是无侵入性（non-invasiveness）**; Spring 小组完全有能力写类似的框架，只是Spring AOP从来没有打算通过提供一种全面的AOP解决方案来与AspectJ竞争。Spring的开发小组相信无论是基于代理（proxy-based）的框架如Spring AOP或者是成熟的框架如AspectJ都是很有价值的，他们之间应该是**互补而不是竞争的关系**
- Spring小组喜欢@AspectJ注解风格更胜于Spring XML配置； 所以**在Spring 2.0使用了和AspectJ 5一样的注解，并使用AspectJ来做切入点解析和匹配**。**但是，AOP在运行时仍旧是纯的Spring AOP，并不依赖于AspectJ的编译器或者织入器（weaver）**
- Spring 2.5对AspectJ的支持：在一些环境下，增加了对AspectJ的装载时编织支持，同时提供了一个新的bean切入点



了解AspectJ应用到java代码的过程（这个过程称为**织入**），对于织入这个概念，可以简单理解为aspect(切面)应用到目标函数(类)的过程。对于这个过程，一般分为**动态织入**和**静态织入**：

1. 动态织入的方式是在**运行时动态将要增强的代码织入到目标类**中，这样往往是通过动态代理技术完成的，如Java JDK的动态代理(Proxy，底层通过反射实现)或者CGLIB的动态代理(底层通过继承实现)，Spring AOP采用的就是基于运行时增强的代理技术
2. ApectJ采用的就是静态织入的方式。ApectJ主要采用的是**编译期织入**，**在这个期间使用AspectJ的acj编译器(类似javac)把aspect类编译成class字节码后，在java目标类编译时织入，即先编译aspect类再编译目标类**

   ![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/spring-framework-aop-6.png)



注意：与基于代理的Spring AOP不同，使用`AspectJ`时不需要使用`@EnableAspectJAutoProxy`注解来启用AOP。`AspectJ`会在运行时通过编译时织入或加载时织入的方式自动织入切面

### Aop配置方式

在Spring AOP中，有两种主要的配置方式：

1. 基于XML的配置方式：这是一种传统的配置方式，使用XML文件定义切面、切点和通知等元素
2. 基于@AspectJ注解的配置方式(常用)

如果目标类实现了接口，Spring AOP将使用基于接口的代理；如果目标类没有实现接口，Spring AOP将使用CGLIB来创建基于类的代理



>  那么**如何声明一个切入点？**

注意`pointcut`切入点的声明规则有多种：

(1)使用`@Pointcut`直接声明切入点： 这样好处是可以在多个通知中共享同一个切入点，避免了代码的重复。同时，它也使切面类的结构更加清晰，易于维护和理解

```java
import org.aspectj.lang.annotation.Aspect;
import org.aspectj.lang.annotation.Pointcut;
import org.aspectj.lang.annotation.Before;
import org.springframework.stereotype.Component;

@Aspect
@Component
public class LoggingAspect {
    
    @Pointcut("execution(public * com.example.MyService.*(..))")
    public void myPointcut() {}
    
    @Before("myPointcut()")
    public void beforeAdvice() {
        System.out.println("Before advice: Logging before method execution");
    }
}

```

在上述示例中，我们使用`@Pointcut`注解声明了一个名为`myPointcut()`的切入点，它匹配了`com.example.MyService`类中的所有方法。

然后，在`@Before`注解中，我们可以使用`myPointcut()`来引用这个切入点，并将其作为切面的通知





(2)直接使用`execution`参数来定义切入点表达式：

```java
import org.aspectj.lang.annotation.Aspect;
import org.aspectj.lang.annotation.Before;
import org.springframework.stereotype.Component;

@Aspect
@Component
public class LoggingAspect {

    @Before("execution(public * com.example.MyService.*(..)) && execution(public void com.example.MyService.someMethod())")
    public void beforeAdvice() {
        System.out.println("Before advice: Logging before method execution");
    }
}
```

上述示例中，我们直接在`@Before`注解中使用`execution`参数来定义切入点表达式。切入点表达式的语法和规则与之前相同，通过`execution`关键字指定匹配的方法



#### jdk动态代理

示例1 接口子类使用JDK代理：

- 定义接口

```java
/**
 * Jdk Proxy Service.
 *
 * @author pdai
 */
public interface IJdkProxyService {

    void doMethod1();

    String doMethod2();

    String doMethod3() throws Exception;
}
```

- 实现类

```java
/**
 * @author pdai
 */
@Service
public class JdkProxyDemoServiceImpl implements IJdkProxyService {

    @Override
    public void doMethod1() {
        System.out.println("JdkProxyServiceImpl.doMethod1()");
    }

    @Override
    public String doMethod2() {
        System.out.println("JdkProxyServiceImpl.doMethod2()");
        return "hello world";
    }

    @Override
    public String doMethod3() throws Exception {
        System.out.println("JdkProxyServiceImpl.doMethod3()");
        throw new Exception("some exception");
    }
}
```

- **定义切面**

```java
package tech.pdai.springframework.aspect;
import org.aspectj.lang.ProceedingJoinPoint;
import org.aspectj.lang.annotation.After;
import org.aspectj.lang.annotation.AfterReturning;
import org.aspectj.lang.annotation.AfterThrowing;
import org.aspectj.lang.annotation.Around;
import org.aspectj.lang.annotation.Aspect;
import org.aspectj.lang.annotation.Before;
import org.aspectj.lang.annotation.Pointcut;
import org.springframework.context.annotation.EnableAspectJAutoProxy;
import org.springframework.stereotype.Component;

//确保在Spring配置中启用了AspectJ自动代理，以便让Spring识别和应用这些切面
@EnableAspectJAutoProxy
@Component
@Aspect
public class LogAspect {

    /**
     * define point cut. 切入点(连接点的集合)——在哪里织入通知(多类型)
     */
    @Pointcut("execution(* tech.pdai.springframework.service.*.*(..))")
    private void pointCutMethod() {
     //pointCutMethod() 方法实际上被用作一个切入点表达式的占位符
    }


    /**
     * 环绕通知
     *
     * @param pjp pjp
     * @return obj
     * @throws Throwable exception
     */
    @Around("pointCutMethod()")
    public Object doAround(ProceedingJoinPoint pjp) throws Throwable {
        System.out.println("-----------------------");
        System.out.println("环绕通知: 进入方法");
        Object o = pjp.proceed();
        System.out.println("环绕通知: 退出方法");
        return o;
    }

    /**
     * 前置通知
     *doBefore()方法是一个前置通知，使用@Before注解标记
     *它绑定了切入点pointCutMethod()，表示在切入点处执行前置通知逻辑
     *
     */
    @Before("pointCutMethod()")
    public void doBefore() {
        System.out.println("前置通知");
    }


    /**
     * 后置通知
     *
     * @param result return val
     */
    @AfterReturning(pointcut = "pointCutMethod()", returning = "result")
    public void doAfterReturning(String result) {
        System.out.println("后置通知, 返回值: " + result);
    }

    /**
     * 异常通知
     *
     * @param e exception
     */
    @AfterThrowing(pointcut = "pointCutMethod()", throwing = "e")
    public void doAfterThrowing(Exception e) {
        System.out.println("异常通知, 异常: " + e.getMessage());
    }

    /**
     * 最终通知
     */
    @After("pointCutMethod()")
    public void doAfter() {
        System.out.println("最终通知");
    }

}
```



- **输出**

```java
-----------------------
环绕通知: 进入方法
前置通知
JdkProxyServiceImpl.doMethod1()
最终通知
环绕通知: 退出方法
-----------------------
环绕通知: 进入方法
前置通知
JdkProxyServiceImpl.doMethod2()
后置通知, 返回值: hello world
最终通知
环绕通知: 退出方法
-----------------------
环绕通知: 进入方法
前置通知
JdkProxyServiceImpl.doMethod3()
异常通知, 异常: some exception
最终通知
```



当然也可以不指明`@pointcut`实现AOP代理：

```java
public interface MyServiceInterface {
    void doSomething();
}

public class MyService implements MyServiceInterface {
    public void doSomething() {
        System.out.println("Doing something...");
    }
}

@Aspect
@Component
public class LoggingAspect {
    @Before("execution(* com.example.MyServiceInterface.doSomething())")
    public void beforeAdvice() {
        System.out.println("Before advice");
    }
}

```

上述示例中，`MyService`类实现了`MyServiceInterface`接口，并定义了一个`doSomething()`方法。`LoggingAspect`切面的切点表达式匹配了`MyServiceInterface`接口中的`doSomething()`方法







#### Cglib动态代理

示例2 非接口子类使用Cglib代理：

- **类定义**

```java
/**
 * Cglib proxy.
 *
 * @author pdai
 */
@Service
public class CglibProxyDemoServiceImpl {

    public void doMethod1() {
        System.out.println("CglibProxyDemoServiceImpl.doMethod1()");
    }

    public String doMethod2() {
        System.out.println("CglibProxyDemoServiceImpl.doMethod2()");
        return "hello world";
    }

    public String doMethod3() throws Exception {
        System.out.println("CglibProxyDemoServiceImpl.doMethod3()");
        throw new Exception("some exception");
    }
}
```

- **切面定义**

和上面相同

- **输出**

```java
-----------------------
环绕通知: 进入方法
前置通知
CglibProxyDemoServiceImpl.doMethod1()
最终通知
环绕通知: 退出方法
-----------------------
环绕通知: 进入方法
前置通知
CglibProxyDemoServiceImpl.doMethod2()
后置通知, 返回值: hello world
最终通知
环绕通知: 退出方法
-----------------------
环绕通知: 进入方法
前置通知
CglibProxyDemoServiceImpl.doMethod3()
异常通知, 异常: some exception
最终通知
```





### AOP应用



**1、 `Mybatis` 中的分页拦截器**

```java
@Configuration
@MapperScan("com.xuecheng.content.mapper")
public class MybatisPlusConfig {

    //定义分页的拦截器
    @Bean
    public MybatisPlusInterceptor getMybatisPlusInterceptor(){
        MybatisPlusInterceptor mybatisPlusInterceptor = new MybatisPlusInterceptor();
        mybatisPlusInterceptor.addInnerInterceptor(new PaginationInnerInterceptor(DbType.MYSQL));
        return mybatisPlusInterceptor;
    }
}
```

下面是分析 Mybatis-Plus 分页插件的简要工作原理：

1. **创建分页拦截器：** 在你的代码中，通过创建 `MybatisPlusInterceptor` 对象，并添加一个 `PaginationInnerInterceptor` 对象作为内部拦截器，用于处理分页逻辑。
2. **拦截 SQL 执行：** `PaginationInnerInterceptor` 会拦截执行的 SQL 语句，然后在执行前对 SQL 进行改造，添加分页逻辑。
3. **处理分页逻辑：** 分页拦截器会根据传入的分页参数（如页码、每页条数）来修改 SQL 语句，添加 LIMIT 子句（在 MySQL 中）或类似的分页限制条件，从而只查询符合分页条件的数据。
4. **执行 SQL 查询：** 修改后的 SQL 语句会被传递给底层数据库，执行查询操作，返回分页后的结果数据。

需要注意的是，Mybatis-Plus 分页插件的工作原理类似于 AOP，它在执行数据库查询前，将分页逻辑织入到原始的 SQL 查询语句中，从而实现了分页功能。这使得开发者可以在查询方法中不需要编写分页逻辑，而是通过配置拦截器来实现分页。



例如想要实现查询学生课程的分页，设置每页显示 10 条数据。假设你有一个 `StudentCourseMapper` 接口用于查询学生课程，以下是一个示例的代码演示：

1、定义Mapper接口：

```java
// StudentCourseMapper.java
@Mapper
public interface StudentCourseMapper extends BaseMapper<StudentCourse> {
    List<StudentCourse> getStudentCourses();
}
```



2、**编写查询方法：**

```java
// StudentCourseService.java
@Service
public class StudentCourseService {

@Autowired
private StudentCourseMapper studentCourseMapper;

public Page<StudentCourse> getStudentCoursesWithPagination(int currentPage) {
Page<StudentCourse> page = new Page<>(currentPage, 10); // 每页显示 10 条数据
studentCourseMapper.selectPage(page, null); // 第二个参数为查询条件，这里设为 null 表示不设置条件
return page;
}
}
```



3、配置 **MyBatis-Plus 分页插件：**

```java
// MybatisPlusConfig.java
@Configuration
@MapperScan("com.xuecheng.content.mapper")
public class MybatisPlusConfig {

    @Bean
    public MybatisPlusInterceptor getMybatisPlusInterceptor() {
        MybatisPlusInterceptor mybatisPlusInterceptor = new MybatisPlusInterceptor();
        mybatisPlusInterceptor.addInnerInterceptor(new PaginationInnerInterceptor(DbType.MYSQL));
        return mybatisPlusInterceptor;
    }
}
```



在 MyBatis-Plus 中，分页拦截器的配置已经在 `MybatisPlusConfig` 类中完成了，你已经创建了一个分页拦截器的 Bean，并且将其添加到了 `MybatisPlusInterceptor` 中。这个拦截器会自动地在查询语句执行前，根据分页参数来修改 SQL 语句，从而实现了分页功能。

在 `getStudentCoursesWithPagination` 方法中，你只需要创建一个 MyBatis-Plus 的 `Page` 对象，**并传入当前页码和每页显示条数**。然后，通过调用 `selectPage` 方法，MyBatis-Plus 框架会自动识别分页参数并应用分页拦截器，以执行分页查询。

所以，虽然你在 `getStudentCoursesWithPagination` 方法中没有直接看到分页拦截器的配置，但这是因为 MyBatis-Plus 在背后已经做了这个工作。这就是 MyBatis-Plus 分页插件的方便之处，它将分页逻辑的处理从你的业务代码中解耦出来，使你只需要关注分页参数和查询结果。	







## SpringMVC

### 执行流程

MVC架构用一种业务逻辑、数据、界面显示分离的方法，将业务逻辑聚集到一个部件里面，在改进和个性化定制界面及用户交互的同时，不需要重新编写业务逻辑



<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/spring-springframework-mvc-4.png" style="zoom:67%;" />

- **Model**（模型）是应用程序中用于处理应用程序数据逻辑的部分。通常**模型对象负责在数据库中存取数据**
- **View**（视图）是应用程序中处理数据显示的部分。通常视图是依据模型数据创建的
- **Controller**（控制器）是应用程序中处理用户交互的部分。通常控制器负责从视图读取数据，控制用户输入，并向模型发送数据



![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/mvcspring.png)

记住了下面这些组件，也就记住了 SpringMVC 的工作原理

- **`DispatcherServlet`**：**核心的中央处理器**，负责接收请求、分发，并给予客户端响应。
- **`HandlerMapping`**：**处理器映射器**，根据 uri 去匹配查找能处理的 `Handler` ，并会将请求涉及到的拦截器和 `Handler` 一起封装。
- **`HandlerAdapter`**：**处理器适配器**，根据 `HandlerMapping` 找到的 `Handler` ，适配执行对应的 `Handler`；
- **`Handler`**：**请求处理器**，处理实际请求的处理器。
- **`ViewResolver`**：**视图解析器**，根据 `Handler` 返回的逻辑视图 / 视图，解析并渲染真正的视图，并传递给 `DispatcherServlet` 响应客户端



SpringMvc流程如下：

1. 客户端（浏览器）发送http请求，`DispatcherServlet`负责拦截发来的请求
2. `DispatcherServlet`是Spring MVC的核心控制器，它作为前端控制器接收所有的HTTP请求。当请求到达时，`DispatcherServlet`负责处理请求并将其路由到适当的处理器
3. `DispatcherServlet` 根据请求信息调用 `HandlerMapping`，`HandlerMapping` 根据请求的URL路径和其他条件（如请求方法、请求参数等）确定应该由哪个处理器（`Controller`）来处理请求，处理器映射器维护一个处理器映射表，将请求映射到相应的处理器
4. 处理器适配器`HandlerAdapter`负责调用选定的处理器的处理方法`Handler`，并处理处理方法的返回值,随后返回一个 `ModelAndView` 对象给`DispatcherServlet`，`ModelAndView`顾名思义：包含了数据模型以及相应的视图的信息。`Model` 是返回的数据对象，`View` 是个逻辑上的 `View`
5. 视图解析器`ViewResolver`将**逻辑视图名称解析为实际的视图对象**。它根据配置规则查找视图资源，并将其与模型数据进行结合，生成最终的视图响应`View`
6. 上步生成的最终视图响应`View`负责将模型数据`Model`渲染到最终的输出格式，如HTML、XML或JSON。视图通常使用模板引擎（如`Thymeleaf`、`FreeMarker`）或其他技术来生成动态内容
7. 视图响应被发送回客户端，成为HTTP响应。客户端（浏览器）将显示最终的响应内容







### 拦截器执行顺序







### 源码剖析









## Spring三级缓存





## Spring框架中的设计模式 :astonished:



### 工厂模式

### 单例模式



### **代理模式**

Spring AOP通过动态代理实现代理模式，主要有两种代理方式：基于接口的代理（JDK动态代理）和基于类的代理（CGLIB动态代理）。

1. 基于接口的代理（JDK动态代理）： 当目标对象实现了接口时，Spring AOP会使用JDK动态代理来创建代理对象。JDK动态代理要求目标对象实现接口，并且通过反射机制动态地创建一个实现了相同接口的代理对象。代理对象拦截目标对象的方法调用，并在方法执行前后执行切面逻辑。
2. 基于类的代理（CGLIB动态代理）： 当目标对象没有实现接口时，Spring AOP会使用CGLIB动态代理来创建代理对象。CGLIB（Code Generation Library）是一个基于字节码生成的类库，它可以动态地生成目标对象的子类作为代理对象。代理对象继承自目标对象，拦截目标对象的方法调用，并在方法执行前后执行切面逻辑。

无论是JDK动态代理还是CGLIB动态代理，代理对象都实现了与目标对象相同的接口或继承了目标对象的类，使得代理对象可以替代原始对象使用。在方法调用时，代理对象会拦截方法的执行，根据配置的切面逻辑执行相应的通知（如前置通知、后置通知、环绕通知等）。



### 模板模式





### **观察者模式**



在Spring框架中，观察者模式（Observer Pattern）被广泛应用于事件驱动的编程模型，以实现解耦和事件通知的功能,比如我们每次添加商品的时候都需要重新更新商品索引，这个时候就可以利用观察者模式来解决这个问题

**Spring 事件驱动模型中的三种角色**:

1、事件角色`ApplicationEvent` 

`ApplicationEvent` (`org.springframework.context`包下)充当事件的角色,这是一个抽象类，开发人员可以通过继承`ApplicationEvent`并定义自己的事件类，来表示特定的事件

```java
public class CustomEvent extends ApplicationEvent {
    // 自定义事件的构造函数和方法
    // ...
}
```



2、事件监听者角色`ApplicationListener`

它是一个接口，用于定义事件监听器。开发人员可以实现`ApplicationListener`接口来创建自定义的事件监听器，并在监听器(`onApplicationEvent`)中处理特定的事件

```java
public class CustomEventListener implements ApplicationListener<CustomEvent> {
    @Override
    public void onApplicationEvent(CustomEvent event) {
        // 处理自定义事件的逻辑
    }
}
```



3、事件发布者角色 `ApplicationEventPublisher` 

充当了事件的发布者，它也是一个接口,`ApplicationContext`实现了该接口，故该类也是一个发布者角色，通过`ApplicationContext`的`publishEvent()`方法来发布事件。**当发布事件时，`ApplicationContext`会通知所有注册的监听器，并将事件传递给相应的监听器进行处理(第二步中的)**:

```java
ApplicationContext applicationContext = new ClassPathXmlApplicationContext("applicationContext.xml");
CustomEvent customEvent = new CustomEvent("Custom Event"); //创造事件
applicationContext.publishEvent(customEvent);//事件发布者将事件发布通知给事件监听者
```





Spring 的事件流程总结

1. 定义一个事件: 实现一个继承自 `ApplicationEvent`，并且写相应的构造函数；
2. 定义一个事件监听者：实现 `ApplicationListener` 接口，重写 `onApplicationEvent()` 方法；
3. 使用事件发布者发布消息: 可以通过 `ApplicationEventPublisher` 的 `publishEvent()` 方法发布消息





### **适配器模式**

在 Spring MVC 中，`DispatcherServlet` 根据请求信息调用 `HandlerMapping`，解析请求对应的 `Handler`。解析到对应的 `Handler`（也就是我们平常说的 `Controller` 控制器）后，开始由`HandlerAdapter` 适配器处理。`HandlerAdapter` 作为期望接口，具体的适配器实现类用于对目标类进行适配，`Controller` 作为被适配的类

**为什么要在 Spring MVC 中使用适配器模式？**

Spring MVC 中的 `Controller` 种类众多，不同类型的 `Controller` 通过不同的方法来对请求进行处理。如果不利用适配器模式的话，`DispatcherServlet` 直接获取对应类型的 `Controller`，需要的自行来判断，像下面这段代码一样：

```java
if(mappedHandler.getHandler() instanceof MultiActionController){
   ((MultiActionController)mappedHandler.getHandler()).xxx
}else if(mappedHandler.getHandler() instanceof XXX){
    ...
}else if(...){
   ...
}
```





## Spring事务

Spring 支持两种方式的事务管理

### 编程式事务管理

通过 `TransactionTemplate`或者`TransactionManager`手动管理事务，实际应用中很少使用

使用`TransactionTemplate` 进行编程式事务管理的示例代码如下：

```java
@Autowired
private TransactionTemplate transactionTemplate;
public void testTransaction() {

        transactionTemplate.execute(new TransactionCallbackWithoutResult() {
            @Override
            protected void doInTransactionWithoutResult(TransactionStatus transactionStatus) {

                try {

                    // ....  业务代码
                } catch (Exception e){
                    //出现异常时需要回滚
                    transactionStatus.setRollbackOnly();
                }

            }
        });
}

```

使用 `TransactionManager` 进行编程式事务管理的示例代码如下：

```java
@Autowired
private PlatformTransactionManager transactionManager;

public void testTransaction() {
  TransactionStatus status = transactionManager.getTransaction(new DefaultTransactionDefinition());
          try {
               // ....  业务代码
              transactionManager.commit(status);
          } catch (Exception e) {
              transactionManager.rollback(status);
          }
}
```

在编程式事务中，必须在每个业务操作中包含额外的事务管理代码，导致代码看起来非常的臃肿





### 声明式事务管理  :sunglasses:

推荐使用（代码侵入性最小），实际是通过 AOP 实现（基于`@Transactional` 的全注解方式使用最多）。

使用 `@Transactional`注解进行事务管理的示例代码如下：

```java
@Transactional(propagation = Propagation.REQUIRED)
public void aMethod {
  //do something
  B b = new B();
  C c = new C();
  b.bMethod();
  c.cMethod();
}
```

**声明式事务虽然优于编程式事务，但也有不足，声明式事务管理的粒度是方法级别，而编程式事务是可以精确到代码块级别的**



Spring 框架中，事务管理(**以下描述均针对声明式事务**)相关最重要的 3 个接口如下：

- **`PlatformTransactionManager`**：（平台）事务管理器，`Spring`事务策略的核心
- **`TransactionDefinition`**：事务定义信息(事务隔离级别、传播行为、超时、只读、回滚规则)
- **`TransactionStatus`**：事务运行状态



**`PlatformTransactionManager`** 会根据 **`TransactionDefinition`** 的定义比如事务超时时间、隔离级别、传播行为等来进行事务管理 ，而 **`TransactionStatus`** 接口则提供了一些方法来获取事务相应的状态比如是否新事务、是否可以回滚等等



`Spring` 将事务管理的核心抽象为一个事务管理器（`TransactionManager`），它的源码只有一个简单的接口定义，属于一个标记接口：

```java
public interface TransactionManager {
}
```

该接口有两个子接口，分别是编程式事务接口 `ReactiveTransactionManager` 和声明式事务接口 `PlatformTransactionManager`。我们来重点说说 `PlatformTransactionManager`，该接口定义了 3 个接口方法：

```java
interface PlatformTransactionManager extends TransactionManager{
    // 根据事务定义获取事务状态
    TransactionStatus getTransaction(TransactionDefinition definition)
            throws TransactionException;

    // 提交事务
    void commit(TransactionStatus status) throws TransactionException;

    // 事务回滚
    void rollback(TransactionStatus status) throws TransactionException;
}
```

- 通过 `PlatformTransactionManager` 这个接口，`Spring` 为各个平台如 JDBC(`DataSourceTransactionManager`)、Hibernate(`HibernateTransactionManager`)、JPA(`JpaTransactionManager`)等都提供了对应的事务管理器，但是具体的实现就是各个平台自己的事情了
- **参数 `TransactionDefinition` 和 `@Transactional` 注解是对应的**，比如说 `@Transactional` 注解中定义的事务传播行为、隔离级别、事务超时时间、事务是否只读等属性，在 `TransactionDefinition` 都可以找得到
- 返回类型 `TransactionStatus` 主要用来存储当前事务的一些状态和数据，比如说事务资源（`connection`）、回滚状态等



1、首先来看一下`TransactionDefinition.java：`做了什么工作：

```java
public interface TransactionDefinition {
    
    //事务传播机制
    int PROPAGATION_REQUIRED = 0;
    int PROPAGATION_SUPPORTS = 1;
    int PROPAGATION_MANDATORY = 2;
    int PROPAGATION_REQUIRES_NEW = 3;
    int PROPAGATION_NOT_SUPPORTED = 4;
    int PROPAGATION_NEVER = 5;
    int PROPAGATION_NESTED = 6;
    
    //事务隔离级别
    int ISOLATION_DEFAULT = -1;
    int ISOLATION_READ_UNCOMMITTED = 1;
    int ISOLATION_READ_COMMITTED = 2;
    int ISOLATION_REPEATABLE_READ = 4;
    int ISOLATION_SERIALIZABLE = 8;
    int TIMEOUT_DEFAULT = -1;

  // 事务的传播行为
  default int getPropagationBehavior() {
    return PROPAGATION_REQUIRED;
  }

  // 事务的隔离级别
  default int getIsolationLevel() {
    return ISOLATION_DEFAULT;
  }

  // 事务超时时间
  default int getTimeout() {
    return TIMEOUT_DEFAULT;
  }

  // 事务是否只读
  default boolean isReadOnly() {
    return false;
  }
}
```



2、`TransactionStatus.java`的内容：

`TransactionStatus`接口用来记录事务的状态 该接口定义了一组方法,用来获取或判断事务的相应状态信息

`PlatformTransactionManager.getTransaction(…)`方法返回一个`TransactionStatus` 对象

**`TransactionStatus` 接口内容如下：**

```java
public interface TransactionStatus{
    boolean isNewTransaction(); // 是否是新的事务
    boolean hasSavepoint(); // 是否有恢复点
    void setRollbackOnly();  // 设置为只回滚
    boolean isRollbackOnly(); // 是否为只回滚
    boolean isCompleted; // 是否已完成
}
```





3、最后看`Transactional`注解做了什么：

```java
@Target({ElementType.TYPE, ElementType.METHOD})
@Retention(RetentionPolicy.RUNTIME)
@Inherited
@Documented
public @interface Transactional {、
  //四个属性值
  Propagation propagation() default Propagation.REQUIRED;
  Isolation isolation() default Isolation.DEFAULT;
  int timeout() default TransactionDefinition.TIMEOUT_DEFAULT;
  boolean readOnly() default false;
                 
}
```

 大概讲一下这个用到最多的注解`@Transactional`:

- `@Transactional` 注解中的 `propagation` 对应 `TransactionDefinition` 中的 `getPropagationBehavior`，默认值为 `Propagation.REQUIRED(TransactionDefinition.PROPAGATION_REQUIRED)`
- `@Transactional` 注解中的 `isolation` 对应 `TransactionDefinition` 中的 `getIsolationLevel`，默认值为 `DEFAULT(TransactionDefinition.ISOLATION_DEFAULT)`。
- `@Transactional` 注解中的 `timeout` 对应 `TransactionDefinition` 中的 `getTimeout`，默认值为`TransactionDefinition.TIMEOUT_DEFAULT`
- `@Transactional` 注解中的 `readOnly` 对应 `TransactionDefinition` 中的 `isReadOnly`，默认值为 `false`







### 事务传播机制

**事务传播行为是为了解决业务层方法之间互相调用的事务问题**。

举个例子：我们在 A 类的`aMethod()`方法中调用了 B 类的 `bMethod()` 方法。这个时候就涉及到业务层方法之间互相调用的事务问题。如果我们的 `bMethod()`如果发生异常需要回滚，如何配置事务传播行为才能让 `aMethod()`也跟着回滚呢？ 

```java
@Service
Class A {
    @Autowired
    B b;
    @Transactional(propagation = Propagation.xxx)
    public void aMethod {
        //涉及到事务传播行为了
        b.bMethod();  
    }
}

@Service
Class B {
    @Transactional(propagation = Propagation.xxx)
    public void bMethod {
       //do something
    }
}
```





了解了上述场景后，再来看看声明式事务的传播行为，可以通过 `@Transactional` 注解中的 `propagation` 属性来定义，比如说：

```java
@Transactional(propagation = Propagation.REQUIRED)
public void savePosts(PostsParam postsParam) {
}
```

`TransactionDefinition` 一共定义了 7 种事务传播行为：

01、`PROPAGATION_REQUIRED`

这也是 @Transactional 默认的事务传播行为，指的是如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。更确切地意思是：

- 如果外部方法没有开启事务的话，`Propagation.REQUIRED` 修饰的内部方法会开启自己的事务，且开启的事务相互独立(相对外部事务独立)，互不干扰，此时内部事务上修饰的`Propagation.REQUIRED=Propagation.NESTED`
- **如果外部方法开启事务并且是 `Propagation.REQUIRED` 的话，所有 `Propagation.REQUIRED` 修饰的内部方法和外部方法均属于同一事务 ，只要一个方法回滚，整个事务都需要回滚**，但是如果内部事务没有被`Propagation.REQUIRED`修饰的话，又是另一回事了

```java
Class A {
    @Transactional(propagation=Propagation.PROPAGATION_REQUIRED)
    public void aMethod { //这里的a就是外部方法
        //do something
        B b = new B();
        b.bMethod();  //b为内部方法
    }
}

Class B {
    @Transactional(propagation=Propagation.PROPAGATION_REQUIRED)
    public void bMethod {
       //do something
    }
}
```

这个传播行为也最好理解，`aMethod` 调用了 `bMethod`，**只要其中一个方法回滚，整个事务均回滚**



02、`PROPAGATION_REQUIRES_NEW`

创建一个新的事务，如果当前存在事务，则把当前事务挂起。也就是说不管外部方法是否开启事务，`Propagation.REQUIRES_NEW` 修饰的内部方法都会开启自己的事务，且开启的事务与外部的事务相互独立，互不干扰

```java
Class A {
    @Transactional(propagation=Propagation.PROPAGATION_REQUIRED)
    public void aMethod {
        //do something
        B b = new B();
        b.bMethod();
    }
}

Class B {
    @Transactional(propagation=Propagation.REQUIRES_NEW)
    public void bMethod {
       //do something
    }
}
```

如果 `aMethod()`发生异常回滚，`bMethod()`不会跟着回滚，因为 `bMethod()`开启了独立的事务。但是，如果 `bMethod()`抛出了未被捕获的异常并且**这个异常满足事务回滚规则**的话,`aMethod()`同样也会回滚，因为这个异常被 `aMethod()`的事务管理机制检测到了

03、`PROPAGATION_NESTED`



表示在一个现有的事务中创建一个嵌套的事务。嵌套事务是外部事务的一部分，但有自己的保存点（`savepoint`）和提交或回滚的控制

- **在外围方法未开启事务的情况下，`Propagation.NESTED`和`Propagation.REQUIRED`作用相同，修饰的内部方法都会新开启自己的事务，且开启的事务相互独立，互不干扰**

- **在外围方法开启事务的情况下，`Propagation.NESTED`修饰的内部方法属于外部事务的子事务，外围主事务回滚，子事务一定回滚，但内部子事务可以单独回滚而不影响外围主事务和其他子事务**

这里还是简单举个例子：如果 `bMethod()` 回滚的话，`aMethod()`不会回滚。如果 `aMethod()` 回滚的话，`bMethod()`会回滚

```java
@Service
Class A {
    @Autowired
    B b;
    @Transactional(propagation = Propagation.REQUIRED)
    public void aMethod {
        //do something
        b.bMethod();
    }
}

@Service
Class B {
    @Transactional(propagation = Propagation.NESTED)
    public void bMethod {
       //do something
    }
}
```



再来看一个实例：

假设我们有一个注册的方法，方法中调用添加积分的方法，如果我们规定注册失败要影响`addPoint()`方法（**注册方法回滚添加积分方法也需要回滚**），那么`addPoint()`方法就需要这样实现：

```java
@Service
   public class MembershipPointServiceImpl implements MembershipPointService{

        @Transactional(propagation = Propagation.NESTED)
        public void addPoint(Point point){

            try {
                recordService.addRecord(Record record);
            } catch (Exception e) {
               //省略...
            }
            //省略...
        }
        //省略...
   }
```



`REQUIRED`,`REQUIRES_NEW`,`NESTED` 异同：

1. **NESTED 和 REQUIRED 修饰的内部方法都属于外围方法事务，如果外围方法抛出异常，这两种方法的事务都会被回滚。但是 REQUIRED 是加入外围方法事务，所以和外围事务同属于一个事务，一旦 REQUIRED 事务抛出异常被回滚，外围方法事务也将被回滚。而 NESTED 是外围方法的子事务，有单独的保存点，所以 NESTED 方法抛出异常被回滚，不会影响到外围方法的事务**
2. **NESTED 和 REQUIRES_NEW 都可以做到内部方法事务回滚而不影响外围方法事务。但是因为 NESTED 是嵌套事务，所以外围方法回滚之后，作为外围方法事务的子事务也会被回滚。而 REQUIRES_NEW 是通过开启新的事务实现的，内部事务和外围事务是两个事务，外围事务回滚不会影响内部事务**



04、`PROPAGATION_MANDATORY`

如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。

05、`PROPAGATION_SUPPORTS`

如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。

06、`PROPAGATION_NOT_SUPPORTED`

以非事务方式运行，如果当前存在事务，则把当前事务挂起。

07、`PROPAGATION_NEVER`

以非事务方式运行，如果当前存在事务，则抛出异常。

3、4、5、6、7 这 5 种事务传播方式不常用，了解即可





### 事务失效

1. 事务方法的访问修饰符为非public，Spring源码判断为非public，会不进行事务管理 修改方法：将方法修改为public； 开启AspectJ代理模式 注意：如果事务方法是static、final的，同样无法通过动态代理，事务也是不会生效的 spring的声明式事务是基于动态代理实现的，我们无法重写final修饰的方法; 不管是JDK动态代理还是Cglib的动态代理，都是要通过代理的方式获取到代理的具体对象，而static修 饰的方法是属于类的，不属于任何对象，所以static方法不能被重写，即便写法上是重写，但是并不具 备重写的含义，也就是说static方法也不能进行动态代理 

2. 抛出了某个异常，但是这个异常在`@Transactional`中的`rollbackFor`属性内没有声明该异常

3. 数据表本身不支持事务 例如使用的是MyIsam存储引擎 

4. 忘记加注解了，例如没有加上`@Service`注解，因此`@Transactional`注解所在的类没有被`spring`管理， 导致事务失效  解决方法是加上`@Service`注解或者其他能注册`Spring Bean`的方式 

5. 在自己的一个Impl类里面，一个非事务方法调用了自身的事务方法 由于@Transactional的实现原理是AOP，而AOP的实现原理是动态代理，而自己调用自己的过程，并不 存在代理对象的调用，这样就出现了自 调用注解失效的问题 

   解决办法：两个方法拆开放在不同的类里面，自己注入自己，这个时候自身的调用就不是通过this了，而是通过获取代理类，`AopContext.currentProxy()`.具体方法来进行调用，注意需要在主动调用的那个方法上添加@Transactional注解  

6. A调用B，B使用的是Propagation.NOT_SUPPORTED 表示不以事务运行，当前若存在事务存挂起，主动以非事务的方式运行 

7. 多线程导致事务失效： 两个方法不在同一个线程中，获取到的数据库连接不一样，从而是两个不同的事务。我们说的同一个事 务，其实是指同一个数据库连接，只有拥有同一个数据库连接才能同时提交和回滚。如果在不同的线 程，拿到的数据库连接肯定是不一样的，所以是不同的事务。







### @Transactional注解原理



`@Transactional` 的作用范围:

1. **方法**：推荐将注解使用于方法上，不过需要注意的是：**该注解只能应用到 public 方法上，否则不生效。**
2. **类**：如果这个注解使用在类上的话，表明该注解对该类中所有的 public 方法都生效。
3. **接口**：不推荐在接口上使用





**`@Transactional` 的常用配置参数总结**:

| 属性名        | 说明                                                         |
| :------------ | :----------------------------------------------------------- |
| `propagation` | 事务的传播行为，默认值为 REQUIRED                            |
| `isolation`   | 事务的隔离级别，默认值采用 DEFAULT                           |
| `timeout`     | 事务的超时时间，默认值为-1(不会超时),如果超过该时间限制但事务还没有完成，则自动回滚事务 |
| `readOnly`    | 指定事务是否为只读事务，默认值为 `false`                     |
| `rollbackFor` | 用于指定能够触发事务回滚的异常类型，并且可以指定多个异常类型 |





我们知道，**`@Transactional` 的工作机制是基于 AOP 实现的，AOP 又是使用动态代理实现的。如果目标对象实现了接口，默认情况下会采用 JDK 的动态代理，如果目标对象没有实现了接口,会使用 CGLIB 动态代理。**

🤐 多提一嘴：`createAopProxy()` 方法 决定了是使用 `JDK` 还是 `Cglib` 来做动态代理，源码如下：

------



```JAVA
public class DefaultAopProxyFactory implements AopProxyFactory, Serializable {
	@Override
	public AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException {
		if (config.isOptimize() || config.isProxyTargetClass() || hasNoUserSuppliedProxyInterfaces(config)) {
	Class<?> targetClass = config.getTargetClass();
	if (targetClass == null) {
throw new AopConfigException("TargetSource cannot determine target class: " +
	"Either an interface or a target is required for proxy creation.");
			}
			if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) {
				return new JdkDynamicAopProxy(config);
			}
			return new ObjenesisCglibAopProxy(config);
		}
		else {
			return new JdkDynamicAopProxy(config);
		}
	}
  .......
}
```

如果一个类或者一个类中的 `public` 方法上被标注`@Transactional` 注解的话，`Spring` 容器就会在启动的时候为其创建一个代理类，在调用被`@Transactional` 注解的 `public` 方法的时候，实际调用的是，`TransactionInterceptor` 类中的 `invoke()`方法。这个方法的作用就是在目标方法之前开启事务，方法执行过程中如果遇到异常的时候回滚事务，方法调用完成之后提交事务

> 事务拦截器（TransactionInterceptor）：事务拦截器是实现事务切面的关键组件。它是一个拦截器，负责拦截被`@Transactional`注解标记的方法调用。当方法调用进入事务拦截器时，会根据注解中的事务属性（如事务传播行为、隔离级别、超时时间等）来决定是否开启新的事务，或加入已有的事务。







## SpringBoot





### SpringBoot如何简化配置开发？

以下是一些Spring Boot简化Spring配置开发的方式：

1. 自动配置：Spring Boot提供了大量的自动配置类，它们会根据应用程序的依赖和配置自动配置各种组件。例如，**如果添加了Spring Data JPA的依赖，Spring Boot会自动配置数据源、实体管理器工厂等相关组件，你只需要提供数据库连接的配置**即可

2. Starter依赖：Spring Boot提供了一系列的Starter依赖，这些Starter依赖包含了一组相关的依赖库和默认的配置。你可以根据需要引入相应的Starter依赖，它们会自动配置所需的组件和功能。例如，如果你想开发Web应用程序，可以引入`spring-boot-starter-web`依赖，它会自动配置Web相关的组件

3. 注解驱动开发：Spring Boot鼓励**使用注解来简化配置**，通过使用注解，你可以在应用程序中声明各种配置、Bean、请求映射等，而**无需手动编写大量的XML配置文件**

4. 外部化配置：Spring Boot支持外部化配置，你可以将配置信息放在外部的属性文件、YAML文件、环境变量等中，并通过配置注解或配置类将其加载到应用程序中。这样，你可以在不修改代码的情况下，根据不同的环境或需求进行配置

5. 内嵌服务器：**Spring Boot内置了常见的Web服务器（如Tomcat、Jetty等）**，你可以将应用程序打包成可执行的JAR文件，直接运行，而无需安装和配置外部服务器

   
   
   
   
   

### 自动装配原理

我们先看一下 SpringBoot 的核心注解 `SpringBootApplication`：

```java
@Target({ElementType.TYPE})
@Retention(RetentionPolicy.RUNTIME)
@Documented
@Inherited
<1.>@SpringBootConfiguration
<2.>@ComponentScan
<3.>@EnableAutoConfiguration
public @interface SpringBootApplication {

}

@Target({ElementType.TYPE})
@Retention(RetentionPolicy.RUNTIME)
@Documented
@Configuration //实际上它也是一个配置类
public @interface SpringBootConfiguration {
}

```

可以把 `@SpringBootApplication`看作是 `@Configuration`、`@EnableAutoConfiguration`、`@ComponentScan` 注解的集合。根据 SpringBoot 官网，这三个注解的作用分别是：

- `@EnableAutoConfiguration`：启用 SpringBoot 的自动配置机制
- `@Configuration`：允许在上下文中注册额外的 bean 或导入其他配置类
- `@ComponentScan`：扫描被`@Component` (`@Service`,`@Controller`)注解的 bean，注解默认会扫描启动类所在的包下所有的类 ，也可以自定义不扫描某些 bean



`EnableAutoConfiguration` 只是一个简单的注解，自动装配核心功能的实现实际是通过 `AutoConfigurationImportSelector`类：

```java
@Target({ElementType.TYPE})
@Retention(RetentionPolicy.RUNTIME)
@Documented
@Inherited
@AutoConfigurationPackage //作用：将main包下的所有组件注册到容器中
@Import({AutoConfigurationImportSelector.class}) //加载自动装配类 xxxAutoconfiguration
public @interface EnableAutoConfiguration {
    String ENABLED_OVERRIDE_PROPERTY = "spring.boot.enableautoconfiguration";

    Class<?>[] exclude() default {};

    String[] excludeName() default {};
}

```



`AutoConfigurationImportSelector`类的继承体系如下：

```java
public class AutoConfigurationImportSelector implements DeferredImportSelector, BeanClassLoaderAware, ResourceLoaderAware, BeanFactoryAware, EnvironmentAware, Ordered {

}

public interface DeferredImportSelector extends ImportSelector {

}

public interface ImportSelector {
    String[] selectImports(AnnotationMetadata var1);
}
```

可以看出，`AutoConfigurationImportSelector` 类实现了 `ImportSelector`接口，也就实现了这个接口中的 `selectImports`方法，该方法主要用于**获取所有符合条件的类的全限定类名，这些类需要被加载到 IoC 容器中**

```JAVA
private static final String[] NO_IMPORTS = new String[0];

public String[] selectImports(AnnotationMetadata annotationMetadata) {
        // <1>.判断自动装配开关是否打开
        if (!this.isEnabled(annotationMetadata)) {
            return NO_IMPORTS;
        } else {
          //<2>.获取所有需要装配的bean
            AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader.loadMetadata(this.beanClassLoader);
            AutoConfigurationImportSelector.AutoConfigurationEntry autoConfigurationEntry = this.getAutoConfigurationEntry(autoConfigurationMetadata, annotationMetadata);
            return StringUtils.toStringArray(autoConfigurationEntry.getConfigurations());
        }
    }

```





以下是Spring Boot自动装配的主要原理：

1. 条件化配置（`Conditional Configuration`）：`Spring Boot`使用条件化配置来判断是否应该启用某个配置或组件。条件化配置通过条件注解（例如`@ConditionalOnClass`、`@ConditionalOnBean`、`@ConditionalOnProperty`等）来判断特定条件是否满足，只有条件满足时，相关的配置或组件才会被自动装配

2. 组件扫描（`Component Scanning`）：`Spring Boot`会自动扫描项目中的类，寻找被特定注解标记的类，如`@Component`、`@Service`、`@Repository`等。被扫描到的类将被注册为Spring容器中的Bean，从而可以在其他地方被注入和使用

3. 自动配置类（`Auto-Configuration Classes`）：`Spring Boot`会提供大量的自动配置类，这些类通过条件化配置来判断是否需要配置特定的Bean。自动配置类通常使用`@Configuration`注解，并提供了默认的配置，这些配置会在条件满足时生效

4. `spring.factories`文件：`Spring Boot`使用`spring.factories`文件来定义自动装配的配置类。该文件位于`META-INF/spring.factories`路径下，其中列出了所有自动配置类的全限定名。`Spring Boot`在启动时会自动加载这些配置类并进行条件化配置

   当Spring Boot应用程序启动时，Spring Boot会读取`spring.factories`文件中的配置，加载和实例化其中指定的自动配置类。这些自动配置类使用条件化配置（`Conditional Configuration`）和组件扫描（`Component Scanning`）等机制来决定是否需要配置相关的Bean，这种机制可以使得Spring Boot应用程序在引入第三方库时，自动获得该库所提供的特性和配置。同时，用户也可以通过自定义自己的`spring.factories`文件，覆盖默认的自动配置，实现自己的配置和扩展

   













# MySQL





## 执行一条Sql语句的过程

1、连接器：

- 与客户端进行 TCP 三次握手建立连接；
- 校验客户端的用户名和密码，如果用户名或密码不对，则会报错；
- 如果用户名和密码都对了，则读取该用户的权限，后续的权限逻辑判断都基于此时读取到的权限；

2、查询缓存(比较鸡肋)：将`sql`语句发送给`Mysql`服务，`Mysql`**去查询缓存看看之前有没有执行过该命令，如果查询的语句命中查询缓存，那么就会直接返回 value 结果给客户端**。如果查询的语句没有命中查询缓存中，那么就要往下继续执行，等执行完后，查询的结果就会被存入查询缓存中(因为只要一个表有更新操作，那么这个表的查询缓存就会被清空,所以缓存命中率一般很低)

> 此处查询缓存是 server 层的，也就是 MySQL 8.0 版本移除的是 server 层的查询缓存，并不是 Innodb 存储引擎中的 buffer pool



3、解析器+优化器：(解析sql中的关键字，优化sql处理逻辑)

通过**词法分析**识别输入`sql`字符串中的关键字，进而构建出 `SQL` 语法树，然后再`语法分析`，根据语法规则，判断输入的 `SQL` 语句是否满足 `MySQL` 语法

**优化器则主要负责将 SQL 查询语句的执行方案确定下来**，比如在表里面有多个索引的时候，优化器会基于查询成本的考虑，来决定选择使用哪个索引，下图的sql语句经优化后走了主键索引：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/explain%20%E7%B4%A2%E5%BC%95.png)

4、执行器：经历完优化器后，就确定了执行方案，在执行的过程中，执行器就会和存储引擎交互了，从存储引擎读取记录，返回给客户端

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/mysql%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B.webp" style="zoom:67%;" />







## Explain用法

[Explain 查看执行计划](https://xiaolincoding.com/mysql/index/index_interview.html#%E9%98%B2%E6%AD%A2%E7%B4%A2%E5%BC%95%E5%A4%B1%E6%95%88)

对于执行计划，参数有：

- id：每个 select 关键字都对应一个唯一id；
- select_type：select关键字对应的那个查询的类型，如 SIMPLE、PRIMARY、SUBQUERY、DEPENDENT、SNION；

- table：每个查询对应的表名；

- possible_keys 字段表示可能用到的索引；
- key 字段表示实际用的索引，如果这一项为 NULL，说明没有使用索引；
- key_len 表示索引的长度；
- rows 表示 MySQL 在执行查询语句时，需要扫描的行数的预估值。
- type 表示数据扫描类型，我们需要重点看这个。

`type` 字段就是描述了找到所需数据时使用的扫描方式是什么，常见扫描类型的**执行效率从低到高的顺序为**：

- All（全表扫描）；
- index（全索引扫描）；
- range（索引范围扫描）；
- ref（非唯一索引扫描）；
- eq_ref（唯一索引扫描）；
- const（结果只有一条的主键或唯一索引扫描）。

在这些情况里，all 是最坏的情况，因为采用了全表扫描的方式。index 和 all 差不多，只不过 index 对索引表进行全扫描，这样做的好处是不再需要对数据进行排序，但是开销依然很大。所以，要尽量避免全表扫描和全索引扫描。

range 表示采用了索引范围扫描，一般在 where 子句中使用 < 、>、in、between 等关键词，只检索给定范围的行，属于范围查找。**从这一级别开始，索引的作用会越来越明显，因此我们需要尽量让 SQL 查询可以使用到 range 这一级别及以上的 type 访问方式**

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/explainYongfa.png)

const 类型表示使用了主键或者唯一索引与常量值进行比较，比如 select name from product where id=1。

需要说明的是 const 类型和 eq_ref 都使用了主键或唯一索引，不过这两个类型有所区别，const 是与常量进行比较，查询效率会更快，而 eq_ref 通常用于多表联查中。

除了关注 type，也要关注 extra 显示的结果，这里说几个重要的参考指标：

1、Using filesort ：当查询语句中包含 group by 操作，而且无法利用索引完成排序操作的时候， 这时不得不选择相应的排序算法进行，甚至可能会通过文件排序，效率是很低的，所以要避免这种问题的出现。

2、Using temporary：使了用临时表保存中间结果，MySQL 在对查询结果排序时使用临时表，常见于排序 order by 和分组查询 group by。效率低，要避免这种问题的出现。

3、Using index：所需数据只需在索引即可全部获得，不须要再到表中取数据，也就是使用了覆盖索引，避免了回表操作，效率不错。



## 两阶段提交协议

事务提交后，redo log 和 binlog 都要持久化到磁盘，但是这两个是独立的逻辑，可能出现半成功的状态，这样就造成两份日志之间的逻辑不一致。

举个例子，假设 id = 1 这行数据的字段 name 的值原本是 'jay'，然后执行 `UPDATE t_user SET name = 'xiaolin' WHERE id = 1;` 如果在持久化 redo log 和 binlog 两个日志的过程中，出现了半成功状态，那么就有两种情况：

- **如果在将 redo log 刷入到磁盘之后， MySQL 突然宕机了，而 binlog 还没有来得及写入**。MySQL 重启后，通过 redo log 能将 Buffer Pool 中 id = 1 这行数据的 name 字段恢复到新值 xiaolin，但是 binlog 里面没有记录这条更新语句，在主从架构中，binlog 会被复制到从库，由于 binlog 丢失了这条更新语句，从库的这一行 name 字段是旧值 jay，与主库的值不一致性；
- **如果在将 binlog 刷入到磁盘之后， MySQL 突然宕机了，而 redo log 还没有来得及写入**。由于 redo log 还没写，崩溃恢复以后这个事务无效，所以 id = 1 这行数据的 name 字段还是旧值 jay，而 binlog 里面记录了这条更新语句，在主从架构中，binlog 会被复制到从库，从库执行了这条更新语句，那么这一行 name 字段是新值 xiaolin，与主库的值不一致性；

可以看到，在持久化 redo log 和 binlog 这两份日志的时候，如果出现半成功的状态，就会造成主从环境的数据不一致性。这是因为 redo log 影响主库的数据，binlog 影响从库的数据，所以 redo log 和 binlog 必须保持一致才能保证主从数据一致。

**MySQL 为了避免出现两份日志之间的逻辑不一致的问题，使用了「两阶段提交」来解决**，两阶段提交其实是分布式事务一致性协议，它可以保证多个逻辑操作要不全部成功，要不全部失败，不会出现半成功的状态

**两阶段提交把单个事务的提交拆分成了 2 个阶段，分别是「准备（Prepare）阶段」和「提交（Commit）阶段」**，每个阶段都由协调者（Coordinator）和参与者（Participant）共同完成。注意，不要把提交（Commit）阶段和 commit 语句混淆了，commit 语句执行的时候，会包含提交（Commit）阶段



参考[两阶段提交的过程是怎样的?](https://xiaolincoding.com/mysql/log/how_update.html#%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4%E7%9A%84%E8%BF%87%E7%A8%8B%E6%98%AF%E6%80%8E%E6%A0%B7%E7%9A%84)



两阶段提交协议（Two-Phase Commit Protocol, 2PC）是一种分布式系统中保证事务的原子性和一致性的协议。在分布式系统中，事务可能会跨越多个节点，而这些节点之间需要协调以保证事务的正确性。两阶段提交协议就是用来协调分布式系统中的事务的。

两阶段提交协议分为两个阶段：

第一阶段：准备阶段。在这个阶段，事务协调器（Transaction Coordinator）会向**所有参与者**（Participant）发送准备请求，询问参与者是否可以执行事务操作。如果参与者可以执行事务操作，则会向事务协调器发送“同意”响应，否则会发送“中止”响应。

第二阶段：提交阶段。在这个阶段，**如果所有参与者都同意执行事务操作，则事务协调器会向所有参与者发送提交请求，要求它们执行事务操作。如果有任何一个参与者发送了“中止”响应，则事务协调器会向所有参与者发送回滚请求，要求它们回滚事务操作。**

两阶段提交协议的优点是可以保证分布式系统中事务的原子性和一致性。在第一阶段中，所有参与者都会先进行准备操作，这样可以保证所有参与者都可以执行事务操作。在第二阶段中，如果所有参与者都同意执行事务操作，则可以保证事务的一致性。如果有任何一个参与者无法执行事务操作，则全部回滚，保证事务的原子性。





另一种理解： :exclamation:

2PC，是 Two-Phase-Comimit 的缩写，即「**二阶段提交**」，是计算机网络尤其是数据库领域内，为了使基于分布式系统架构的所有节点在进行**事务处理**过程中能够保持原子性和一致性而设计的一种协议。现在很多数据库都是采用的二阶段提交协议来完成**分布式事务**的处理。二阶段，顾名思义就是分两个阶段处理事务，流程如下：

阶段一：提交事务请求（”投票阶段“）

当要执行一个分布式事务的时候，事务发起者首先向协调者 `Coordinator` 发起事务请求，然后协调者会给所有参与者   `Participant` 发送 `prepare` 请求（其中包括事务内容）告诉参与者你们需要执行事务了，**如果能执行我发的事务内容那么就先执行但不提交，执行后请给我回复**。然后参与者收到 `prepare` 消息后，他们会开始执行事务（但不提交），并将 `Undo` 和 `Redo` 信息记入事务日志中，之后参与者就向协调者反馈是否准备好了



阶段二：执行事务提交

协调者根据各参与者的反馈情况决定最终是否可以提交事务，**如果反馈都是Yes，发送提交 `commit` 请求**，参与者提交成功后返回 `Ack` 消息，协调者接收后就完成了。**如果反馈是 No 或者超时未反馈，发送 `Rollback` 请求**，利用阶段一记录表的 `Undo` 信息执行回滚，并反馈给协调者 `Ack` ，中断消息





缺点如下：

- **单点故障问题**，如果协调者挂了那么整个系统都处于不可用的状态了
- **阻塞问题**，即当协调者发送 `prepare` 请求，参与者收到之后如果能处理那么它将会进行事务的处理但并不提交，这个时候会一直占用着资源不释放，如果此时协调者挂了，那么这些资源都不会再释放了，这会极大影响性能
- **数据不一致问题**，比如当第二阶段，协调者只发送了一部分的 `commit` 请求就挂了，那么也就意味着，收到消息的参与者会进行事务的提交，而后面没收到的则不会进行事务提交，那么这时候就会产生数据不一致性问题











## 存储引擎对比

1.事务支持：

- MyISAM：MyISAM存储引擎不支持事务，它使用表级锁定（Table-level locking）来处理并发访问。这意味着在执行写操作时，会锁定整个表，可能导致并发性能下降和数据冲突
- InnoDB：**InnoDB存储引擎支持事务**，它**使用行级锁定**（Row-level locking），可以实现更好的并发性能和数据一致性。InnoDB支持ACID（原子性、一致性、隔离性和持久性）属性，可以确保事务的原子性和数据的完整性

2.并发性能:

- MyISAM：由于使用表级锁定，MyISAM在并发写入场景下性能可能受到较大影响。并发写入可能会导致锁冲突，需要等待其他事务完成才能执行
- InnoDB：InnoDB使用行级锁定，支持更高的并发性能。它可以同时处理多个并发事务的读写操作，减少了锁冲突的可能性，提高了并发性能

3.数据完整性：

- MyISAM：MyISAM存储引擎不提供外键约束和崩溃恢复机制。它没有内置的故障恢复机制，当出现崩溃或断电等故障时，数据可能会损坏或丢失。无`redolog`
- InnoDB：InnoDB存储引擎支持外键约束、事务和崩溃恢复机制。它可以确保数据的完整性，并提供了事务回滚和崩溃恢复的能力。有`redolog`





## 预读失效 & `BufferPool` 污染

我们都知道：简单的 LRU 算法并没有被 MySQL 使用，因为简单的 LRU 算法无法避免下面这两个问题

- 预读失效；
- Buffer Pool 污染；

> 什么是预读失效？

先来说说 MySQL 的预读机制。程序是有空间局部性的，靠近当前被访问数据的数据，在未来很大概率会被访问到。所以，**MySQL 在加载数据页时，会提前把它相邻的数据页一并加载进来**，目的是为了减少磁盘 IO。

但是可能这些**被提前加载进来的数据页，并没有被访问**，相当于这个预读是白做了，这个就是**预读失效**。

如果使用简单的 LRU 算法，就会把预读页放到 LRU 链表头部，而当 Buffer Pool空间不够的时候，还需要把末尾的页淘汰掉。

如果这些预读页如果一直不会被访问到，就会出现一个很奇怪的问题，不会被访问的预读页却占用了 LRU 链表前排的位置，而末尾淘汰的页，可能是频繁访问的页，这样就大大降低了缓存命中率。



InnoDB 对 LRU 做了一些优化，我们熟悉的 LRU 算法通常是将最近查询的数据放到 LRU 链表的头部，而 InnoDB 做 2 点优化：

- 将 LRU 链表 分为**young 和 old 两个区域**，**划分这两个区域后，预读的页就只需要加入到 old 区域的头部，当页被真正访问的时候，才将页插入 young 区域的头部**。如果预读的页一直没有被访问，就会从 old 区域移除，这样就不会影响 young 区域中的热点数据。



> 什么是`BufferPool`污染？

当某一个SQL 语句扫描了大量的数据时，在Buffer Pool 空间比较有限的情况下，可能会将Buffer Pool 里的所有页都替换出去，导致大量热数据被淘汰了，等这些热数据又被再次访问的时候，由于缓存未命中，就会产生大量的磁盘IO，MySQL 性能就会急剧下降，这个过程被称为Buffer Pool 污染。









## 数据存储 :cat::kissing_cat::smile_cat:

> 以下内容均针对的是`innodb`存储引擎

每创建一个 `database`（数据库），都会在 /var/lib/mysql/ 目录里面创建一个以 database 为名的目录，然后保存表结构和表数据的文件都会存放在这个目录里，该目录下一般有三个文件：

- `db.opt`：用来存储当前数据库的默认字符集和字符校验规则
- `t_order.frm`：t_order 的**表结构**会保存在这个文件。在 `MySQL` 中建立一张表都会生成一个.frm 文件，**该文件是用来保存每个表的元数据信息的，主要包含表结构定义**
- `t_order.ibd`：t_order 的**表数据**会保存在这个文件。表数据既可以存在共享表空间文件（文件名：ibdata1）里，也可以存放在独占表空间文件（文件名：表名字.ibd）。这个行为是由参数 `innodb_file_per_table` 控制的，若设置了参数 `innodb_file_per_table` 为 1，则会将存储的数据、索引等信息单独存储在一个独占表空间，从 MySQL 5.6.6 版本开始，它的默认值就是 1 了，因此从这个版本之后， **MySQL 中每一张表的数据都存放在一个独立的 .ibd 文件**,这个文件也称为独占表空间文件 (**`innodb`中`ibd`文件包含了表数据和索引**，而`myisam`中表的数据和索引则分别存储在 `.MYD` 和 `.MYI` 文件中)——————`MyIsam`中表数据和索引分开存储，`Innodb`不是





`InnoDB` 存储引擎使用的是一种称为“表空间”的文件组织方式来**存储表的数据和索引**。

**表空间由段（`segment`）、区（`extent`）、页（`page`）、行（`row`）组成**，**InnoDB**存储引擎的逻辑存储结构大致如下图：<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E8%A1%A8%E7%A9%BA%E9%97%B4%E7%BB%93%E6%9E%84.drawio.webp"  />

1、行：数据库表中的记录都是按行（row）进行存放的，每行记录根据不同的行格式，有不同的存储结构

2、页：**记录是按照行来存储的，但是数据库的读取并不以「行」为单位，否则一次读取（也就是一次 I/O 操作）只能处理一行数据，效率会非常低**，**InnoDB 的数据是按「页」为单位来读写的**，也就是说，**当需要读一条记录的时候，并不是将这个行记录从磁盘读出来，而是以页为单位，将其整体读入内存**,**默认每个页的大小为 16KB**,意味着数据库每次读写都是以 16KB 为单位的，一次最少从磁盘中读取 16KB 的内容到内存中，一次最少把内存中的 16K 内容刷新到磁盘中

3、区：`InnoDB` 存储引擎是用 B+ 树来组织数据,**B+ 树每一层中的相邻页都是通过双向链表连接起来的**，**如果是以页为单位来分配存储空间，那么链表中相邻的两个页之间的物理位置并不是连续的，可能离得非常远，那么磁盘查询时就会有大量的随机I/O,那么让链表中相邻的页的物理位置也相邻，这样就可以使用顺序 I/O 了**，**为某个索引分配空间的时候就不再按照页为单位分配了，而是按照区（`extent`）为单位分配。每个区的大小为 1MB，对于 16KB 的页来说，连续的 64 个页会被划为一个区，这样就使得链表中相邻的页的物理位置也相邻，就能使用顺序 I/O 了**

4、段：表空间是由各个段（`segment`）组成的，段是由多个区（`extent`）组成的，**段一般分为数据段、索引段和回滚段**等

- 索引段：存放 B + 树的非叶子节点的区的集合；
- 数据段：存放 B + 树的叶子节点的区的集合；
- `undolog` 回滚段：存放的是回滚数据的区的集合，`事务隔离 (opens new window)`中的 `MVCC` 利用了回滚段实现了多版本查询数据



> 总结一下：
>
> - `Innodb`使用表空间来存储表数据和表索引，表的结构定义则存储在`MySQL`的系统表中
> - `InnoDB` 存储引擎会以区为单位进行分配，**每个区的大小为 1MB，对于 16KB 的页来说，连续的 64 个页会被划为一个区，这样就使得链表中相邻的页的物理位置也相邻，就能使用顺序 I/O 了**，按页分配的话，B+树中相邻的页(节点)，OS在依次给这些相邻页分配磁盘空间时不一定是能分配到相邻的位置
> - `InnoDB` 的数据是按「页」为单位来读写的





### `InnoDB`如何存储数据 (数据页的角度)

**InnoDB**中记录是按行来存储的，但是数据库的读取并不以「行」为单位，否则一次读取（也就是一次 I/O 操作）只能处理一行数据，数据库的读取是按**「数据页」为单位来读写的**， I/O 操作的最小单位是页，**InnoDB 数据页的默认大小是 16KB**，意味着数据库每次读写都是以 16KB 为单位的，一次最少从磁盘中读取 16KB 的内容到内存中，一次最少把内存中的 16KB 内容刷新到磁盘中

每个数据页中的`File Header` 处有两个指针，分别指向上一个数据页和下一个数据页，连接起来的页相当于一个双向的链表(B+树每层都是双向链表)，如下图所示：<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E6%95%B0%E6%8D%AE%E9%A1%B5.webp" style="zoom:80%;" />

采用链表的结构是让数据页之间不需要是物理上的连续的，而是逻辑上的连续

页目录(起到索引作用)与每条行记录`Record`的关系如下图：

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E9%A1%B5%E7%9B%AE%E5%BD%95%E4%B8%8E%E8%AE%B0%E5%BD%95%E5%85%B3%E7%B3%BB.webp" style="zoom:80%;" />

页目录创建的过程如下：

1. 将所有的记录划分成几个组，这些记录包括最小记录和最大记录，但不包括标记为“已删除”的记录；
2. 每个记录组的最后一条记录就是组内最大的那条记录，并且最后一条记录的头信息中会存储该组一共有多少条记录，作为 `n_owned` 字段（上图中粉红色字段）
3. **页目录用来存储每组最后一条记录的地址偏移量**，这些地址偏移量会按照先后顺序存储起来，每组的地址偏移量也被称之为槽（slot），**每个槽相当于指针指向了不同组的最后一个记录**。

从图中可以看到，**页目录就是由多个槽组成的，槽相当于分组记录的索引**。然后，因为记录是按照「主键值」从小到大排序的，所以**我们通过槽查找记录时，可以使用二分法快速定位要查询的记录在哪个槽（哪个记录分组），定位到槽后，再遍历槽内的所有记录，找到对应的记录**，无需从最小记录开始遍历整个页中的记录链表

以上面那张图举个例子，5 个槽的编号分别为 0，1，2，3，4，我想查找主键为 11 的用户记录：

- 先二分得出槽中间位是 (0+4)/2=2 ，2号槽里最大的记录为 8。因为 11 > 8，所以需要从 2 号槽后继续搜索记录；
- 再使用二分搜索出 2 号和 4 槽的中间位是 (2+4)/2= 3，3 号槽里最大的记录为 12。因为 11 < 12，所以主键为 11 的记录在 3 号槽里；
- 这里有个问题，**「槽对应的值都是这个组的主键最大的记录，如何找到组里最小的记录」**？比如槽 3 对应最大主键是 12 的记录，那如何找到最小记录 9。解决办法是：通过槽 3 找到 槽 2 对应的记录，也就是主键为 8 的记录。主键为 8 的记录的下一条记录就是槽 3 当中主键最小的 9 记录，然后开始向下搜索 2 次，定位到主键为 11 的记录，取出该条记录的信息即为我们想要查找的内容。



### B+树如何进行查询

在一个数据页中进行记录检索时：因为一个数据页中的记录是有限的，且主键值有序，所以通过对所有记录进行分组，然后将  **槽号——每组最后一条记录的地址偏移量**  存储到页目录，使其起到索引作用，通过二分查找主键的方法快速检索到记录(**或者说记录对应的数据页**)在哪个分组，来降低检索的时间复杂度

InnoDB 里的 B+ 树中的**每个节点都是一个数据页**，但是需要注意的是：

1. **只有叶子节点对应的数据页才会在页内部存放多个分组(每个分组中的行记录(该行记录不一定存放的是真实数据值！)通过单向链表来连接)**
2. **非叶子节点对应的数据页 页内虽然也有页目录，但是页中的每个分组只会存放索引列值和其对应的下一个数据页的位置！！等于说由上而下查找时查找到叶子节点之前都只是为了查到该数据到底位于哪个数据页，查到以后才会在页内通过槽来二分查找数据位于哪个分组下，最后在分组内进行链表的顺序遍历**

结构示意图如下：

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/B+%E6%A0%91%E6%9F%A5%E8%AF%A2.webp" style="zoom: 80%;" />

我们再看看 B+ 树如何实现快速查找主键为 6 的记录，以上图为例子：

- 从根节点开始，通过二分法快速定位到符合页内范围包含查询值的页，因为查询的主键值为 6，在[1, 7)范围之间，所以到页 30 中查找更详细的目录项；
- 在非叶子节点（页30）中，继续通过二分法快速定位到符合页内范围包含查询值的页，主键值大于 5，所以就到叶子节点（页16）查找记录；
- 接着，在叶子节点（页16）中，通过槽查找记录时，使用二分法快速定位要查询的记录在哪个槽（哪个记录分组），定位到槽后，再遍历槽内的所有记录，找到主键为 6 的记录。

可以看到，在定位记录所在哪一个页时，也是通过二分法快速定位到包含该记录的页。定位到该页后，又会在该页内进行二分法快速定位记录所在的分组（槽号），最后在分组内进行遍历查找



**数据页中的记录按照「主键」顺序组成单向链表**

**而数据页之间则通过`File Header`的两个指针组成双向链表**

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/v2-6bc6d5074f2a94ab0bc413381abd75c1_720w.webp)



### Mysql中一行记录如何存储

一条行记录的格式默认设置成 `compact`行格式：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/COMPACT.drawio.webp)

具体关注：三个隐式列、变长字段长度列表(存放列属性为varchar的具体长度-即该列具体占用多少字节)、Null值列表(每一位代表一个列属性是否为Null 为1时代表对应列值为Null)、记录头信息( delete_mask ：标识此条数据是否被删以及 next_record：下一条记录的位置)
https://xiaolincoding.com/mysql/base/row_format.html#%E8%AE%B0%E5%BD%95%E7%9A%84%E9%A2%9D%E5%A4%96%E4%BF%A1%E6%81%AF







## 索引

可以按照四个角度来分类索引

- 按「数据结构」分类：**B+tree索引、Hash索引、Full-text索引**
- 按「物理存储」分类：**聚簇索引（可能是主键索引）、二级索引（辅助索引）**
- 按「字段特性」分类：**主键索引、唯一索引、普通索引、前缀索引**
- 按「字段个数」分类：**单列索引、联合索引**

在创建表时，`InnoDB` 存储引擎会根据不同的场景选择不同的列作为索引：(主键索引不一定等于聚簇索引)

- 如果有主键，默认会使用主键作为聚簇索引(每张表只能有一个)的索引键（key），此时主键索引等于聚集索引；
- 如果**没有主键，就选择第一个不包含 NULL 值的唯一列(Unique)作为聚簇索引的索引键**（key）；
- 在上面两个都没有的情况下，`InnoDB` 将自动生成一个隐式自增 id 列作为聚簇索引的索引键（key）；

其它索引都属于辅助索引（辅助索引中索引的逻辑顺序与磁盘上行的物理存储顺序不同，一个表中可以拥有多个非聚集索引），也被称为二级索引或非聚簇索引。**创建的主键索引和二级索引默认使用的是 `B+Tree` 索引**

> 聚簇索引（Clustered Index）是数据库中一种索引类型，它决定了表中记录的物理排序和存储方式。聚簇索引的主要特点是**根据索引列的值对记录进行物理排序**，并将它们存储在磁盘上相邻的位置。
>
> 在聚簇索引中，**索引的顺序决定了数据在磁盘上的存储顺序。换句话说，具有相似索引值的记录将在磁盘上物理上相邻存储**。这种存储方式使得根据**聚簇索引列进行范围查询和顺序访问的操作非常高效，因为相关的数据在物理上紧密排列**，显著减少了磁盘I/O操作
>
> 
>
> 为了更好地理解聚簇索引，考虑一个示例表格，包含员工的信息，如员工ID、姓名、部门、工资等。如果我们根据员工ID创建聚簇索引，那么表格的数据将根据员工ID的顺序进行排序，并且具有相邻员工ID的行将存储在相邻的磁盘页面上(B+树中相邻的叶子节点在磁盘上存储的物理位置也是相邻的)。这样，当使用员工ID作为检索条件时，DBMS可以快速定位到相关的磁盘页面，并直接获取所需的数据行，而无需扫描整个表
>
> 
>
> 
>
> 还是该表，假设在工资列上建立了二级索引(非聚簇索引)，在该二级索引的B+树上相邻的两个叶子节点(假设一个员工工资为3000，另一个员工工资为3001)，对应的两条行记录在磁盘中的物理地址并不一定相邻，因为二级索引B+树叶子节点中key为工资值，data为其行记录对应的主键，此时还要再去聚簇索引(一般是主键索引)对应的B+树上再次进行查找————回表操作，那么这两条行记录在聚簇索引的B+树上查找就可能走不同的路径，所对应的磁盘物理地址也不一定相同了
>
> 
>
> 
>
> 其实想想上面的例子，也能体会到：
>
> - 聚簇索引的叶子节点存放的是实际数据，所有完整的用户记录都存放在聚簇索引的叶子节点；
> - 二级索引的叶子节点存放的是主键值，而不是实际数据。
>
> 因为用户记录存放在聚簇索引的叶子节点时，两条相似的记录位于同一页内/或者是相邻页，而`innodb`按区划分空间，这就导致这两条记录在磁盘位置上大概率也是相邻的，而如果非聚簇索引的话，由于叶子节点没有存放实际数据，就需要再次去查聚簇索引对应的B+树，这样就很可能走了不同的查找路径，最终导致两条记录对应的数据页相隔太远，在磁盘上的位置也不相邻了(非聚簇的理解)







### B+树相关问题



![image-20240324235914615](https://cdn.jsdelivr.net/gh/amonstercat/PicGo@master/202403242359029.png)



B 树的每一个节点最多可以包括 M 个子节点，M 称为 B 树的阶，所以 B 树就是一个多叉树

假设 M = 3，那么就是一棵 3 阶的 B 树，特点就是每个节点最多有 2 个（M-1个）数据和最多有 3 个（M个）子节点，超过这些要求的话，就会分裂节点



虽然，InnoDB 和 MyISAM 都支持 B+ 树索引，但是它们聚集索引的存储结构实现不同：

- InnoDB 存储引擎：B+ 树索引的叶子节点保存数据本身；
- MyISAM 存储引擎：**B+ 树索引的叶子节点保存数据的物理地址**；



1、为什么用B+树？其他数据结构有什么缺陷？

数组——>Hash索引——>二叉查找树BST——>平衡二叉树AVL——>红黑树——>B树——>B+树

- **数组 二分法理论上时间复杂度可行，但是插入一个元素时，需要将这个元素之后的所有元素后移一位，时间复杂度O(N),所以不能用线性结构**

- Hash 不适用于范围、顺序查询,虽然查找元素的时间复杂度为O(1)
- BST 时间复杂度容易从O(log2N)退化为链表的O(N)
- AVL需要频繁地进行旋转操作来保持平衡，会有较大的计算开销,且每个树节点仅存储一个数据，而每次进行磁盘 I/O 时只能读取一个节点的数据，如果需要查询的数据分布在多个节点上，那么就需要进行多次磁盘 I/O
- 红黑树

> 红黑树是一种自平衡二叉查找树，通过在插入和删除节点时进行**颜色变换和旋转**操作，使得树始终保持平衡状态，它具有以下特点：
>
> 1. 每个节点非红即黑；
> 2. 根节点总是黑色的；
> 3. 每个叶子节点都是黑色的空节点（NIL 节点）；
> 4. 如果节点是红色的，则它的子节点必须是黑色的（反之不一定）；
> 5. 从根节点到叶节点或空子节点的每条路径，必须包含相同数目的黑色节点（即相同的黑色高度）
>
> 和 AVL 树不同的是，红黑树并不追求严格的平衡，而是大致的平衡。正因如此，红黑树的查询效率稍有下降，因为红黑树的平衡性相对较弱，**可能会导致树的高度较高**，这可能会导致一些数据需要进行多次磁盘I/O 操作才能查询到，这也是 MySQL 没有选择红黑树的主要原因。也正因如此，**红黑树的插入和删除操作效率大大提高了，因为红黑树在插入和删除节点时只需进行 O(1) 次数的旋转和变色操作，即可保持基本平衡状态，而不需要像 AVL 树一样进行 O(logn) 次数的旋转操作**





- B树： B树的检索过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了。而 B+树的检索效率就很稳定了，任何查找都是从根节点到叶子节点的过程。**且在 B 树中进行范围查询时，首先找到要查找的下限，然后对 B 树进行中序遍历，直到找到查找的上限**；而 B+树的范围查询，只需要对链表进行遍历即可

> 补充：
>
> B 树的每个节点都包含数据（索引+记录），而用户的记录数据的大小很有可能远远超过了索引数据，这就需要花费更多的磁盘 I/O 操作次数来读到「有用的索引数据」。
>
> 而且，在我们查询位于底层的某个节点（比如 A 记录）过程中，「非 A 记录节点」里的记录数据会从磁盘加载到内存`BufferPool`中，但是这些记录数据是没用的，我们只是想读取这些节点的索引数据来做比较查询，而「非 A 记录节点」里的记录数据对我们是没用的，这样不仅增多磁盘 I/O 操作次数，也占用内存资源

- B+树：对于有 N 个叶子节点的 B+Tree，其搜索复杂度为`O(logdN)`，其中 d 表示节点允许的最大子节点个数为 d 个



2、B+树中数据是怎么存放的？

`MyISAM` 引擎中，B+Tree 叶节点的 `data` 域存放的是数据记录的地址。在索引检索的时候，首先按照 B+Tree 搜索算法搜索索引，如果指定的 `Key` 存在，则取出其 `data` 域的值，然后以 `data` 域的值为地址读取相应的数据记录。这被称为“**非聚簇索引(非聚集索引)**”

`InnoDB` 引擎中，其数据文件本身就是索引文件。相比 `MyISAM`，索引文件和数据文件是分离的，其表数据文件本身就是按 B+Tree 组织的一个索引结构，树的叶节点 data 域保存了完整的数据记录。这个索引的 `key` 是数据表的主键，因此 `InnoDB` 表数据文件本身就是主索引,这被称为“**聚簇索引（聚集索引）**”。而其余的索引都作为 **辅助索引** ，辅助索引的 `data` 域存储相应记录主键的值而不是地址，这也是和 `MyISAM` 不同的地方。在根据主索引搜索时，直接找到 `key` 所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引

主键索引的 B+Tree 和二级索引的 B+Tree 区别如下：

- 主键索引的 B+Tree 的叶子节点中 data 值存放的是实际数据，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里，非叶子节点存放的是主键和页号；

- 二级索引的 B+Tree 的叶子节点中 data 值存放的是主键值，而不是实际数据

  <img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E5%9B%9E%E8%A1%A8.drawio.webp"  />

当查询的数据是能在二级索引的 B+Tree 的叶子节点里查询到，这时就不用再查主键索引，比如下面这条查询语句：

```sql
select id from product where product_no = '0002';
```

**这种在二级索引的 B+Tree 就能查询到结果的过程就叫作「覆盖索引」**







### 索引失效

1、来看看**联合索引**中的索引失效问题：

首先看一个联合索引：

```sql
CREATE INDEX index_product_no_name ON product(product_no, name);
```

联合索引的非叶子节点用两个字段的值`(product_no, name)`作为 B+Tree 的 key 值,联合索引查询的 `B+Tree` 是先按 product_no 进行排序，在 `product_no` 相同的情况再按 name 字段排序，使用联合索引时，存在**最左匹配原则**，也就是按照最左优先的方式进行索引的匹配。如果不遵循「最左匹配原则」，联合索引会失效

比如，如果创建了一个 `(a, b, c)` 联合索引，如果查询条件是以下这几种，就可以匹配上联合索引：

- where a=1；
- where a=1 and b=2 and c=3；
- where a=1 and b=2；

需要注意的是，因为有查询优化器，所以 a 字段在 where 子句的顺序并不重要。

但是，如果查询条件是以下这几种，因为不符合最左匹配原则，所以就无法匹配上联合索引，联合索引就会失效:

- where b=2；
- where c=3；
- where b=2 and c=3；

上面这些查询条件之所以会失效，是因为`(a, b, c)` 联合索引，是先按 a 排序，在 a 相同的情况再按 b 排序，在 b 相同的情况再按 c 排序。所以，**b 和 c 是全局无序，局部相对有序的**，这样在没有遵循最左匹配原则的情况下，是无法利用到索引的

解释一下全局无序，局部有序：

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E8%81%94%E5%90%88%E7%B4%A2%E5%BC%95%E6%A1%88%E4%BE%8B.drawio.webp" style="zoom:80%;" />



可以看到，a 是全局有序的（1, 2, 2, 3, 4, 5, 6, 7 ,8），而 b 是全局是无序的（12，7，8，2，3，8，10，5，2）。因此，直接执行`where b = 2`这种查询条件没有办法利用联合索引的，**利用索引的前提是索引里的 key 是有序的**

只有在 a 相同的情况才，b 才是有序的，比如 a 等于 2 的时候，b 的值为（7，8），这时就是有序的，这个有序状态是局部的，因此，执行`where a = 2 and b = 7`是 a 和 b 字段能用到联合索引的，也就是联合索引生效了



联合索引有一些特殊情况，**并不是查询过程使用了联合索引查询，就代表联合索引中的所有字段都用到了联合索引进行索引查询**，也就是**可能存在部分字段用到联合索引的 B+Tree，部分字段没有用到联合索引的 B+Tree** 的情况，这种特殊情况就发生在范围查询。联合索引的最左匹配原则会一直向右匹配直到遇到「范围查询」就会停止匹配。**也就是范围查询的字段可以用到联合索引，但是在范围查询字段的后面的字段无法用到联合索引**：



接下来看几个范围查询的例子：

```sql
Q1: select * from t_table where a > 1 and b = 2，联合索引（a, b）哪一个字段用到了联合索引的 B+Tree？
```

由于联合索引（二级索引）是先按照 a 字段的值排序的，所以符合 a > 1 条件的二级索引记录肯定是相邻，在进行索引扫描的时候，可以定位到符合 a > 1 条件的第一条记录，然后沿着记录所在的链表向后扫描，直到某条记录不符合 a > 1 条件位置。所以 a 字段可以在联合索引的 B+Tree 中进行索引查询

**但是在符合 a > 1 条件的二级索引记录的范围里，b 字段的值是无序的**。比如前面图的联合索引的 B+ Tree 里，下面这三条记录的 a 字段的值都符合 a > 1 查询条件，而 b 字段的值是无序的：

- a 字段值为 5 的记录，该记录的 b 字段值为 8；
- a 字段值为 6 的记录，该记录的 b 字段值为 10；
- a 字段值为 7 的记录，该记录的 b 字段值为 5；

因此，我们不能根据查询条件 b = 2 来进一步减少需要扫描的记录数量（b 字段无法利用联合索引进行索引查询的意思）故**Q1 这条查询语句只有 a 字段用到了联合索引进行索引查询，而 b 字段并没有使用到联合索引**





```sql
Q2: select * from t_table where a >= 1 and b = 2，联合索引（a, b）哪一个字段用到了联合索引的 B+Tree？
```

由于联合索引（二级索引）是先按照 a 字段的值排序的，所以符合 >= 1 条件的二级索引记录肯定是相邻，于是在进行索引扫描的时候，可以定位到符合 >= 1 条件的第一条记录，然后沿着记录所在的链表向后扫描，直到某条记录不符合 a>= 1 条件位置。所以 a 字段可以在联合索引的 B+Tree 中进行索引查询。

虽然在符合 a>= 1 条件的二级索引记录的范围里，b 字段的值是「无序」的，**但是对于符合 a = 1 的二级索引记录的范围里，b 字段的值是「有序」的**（因为对于联合索引，是先按照 a 字段的值排序，然后在 a 字段的值相同的情况下，再按照 b 字段的值进行排序）

于是，在确定需要扫描的二级索引的范围时，当二级索引记录的 a 字段值为 1 时，可以通过 b = 2 条件减少需要扫描的二级索引记录范围（b 字段可以利用联合索引进行索引查询的意思）。也就是说，从符合 a = 1 and b = 2 条件的第一条记录开始扫描，而不需要从第一个 a 字段值为 1 的记录开始扫描





```sql
Q3: SELECT * FROM t_table WHERE a BETWEEN 2 AND 8 AND b = 2，联合索引（a, b）哪一个字段用到了联合索引的 B+Tree？
```

**该查询条件中 `a BETWEEN 2 AND 8` 的意思是查询 a 字段的值在 2 和 8 之间的记录。不同的数据库对 BETWEEN ... AND 处理方式是有差异的。在 MySQL 中，BETWEEN 包含了 value1 和 value2 边界值，类似于 >= and =<**，因此 **Q3 这条查询语句 a 和 b 字段都用到了联合索引进行索引查询**





```sql
Q4: SELECT * FROM t_user WHERE name like 'j%' and age = 22，联合索引（name, age）哪一个字段用到了联合索引的 B+Tree？
```

直接说结论：name和age字段都用到了联合索引进行查询：

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/q4-2.drawio.webp" style="zoom:67%;" />

虽然在符合前缀为 ‘j’ 的 name 字段的二级索引记录的范围里，age 字段的值是「无序」的，**但是对于符合 name = j 的二级索引记录范围里，age字段的值是「有序」的**（因为对于联合索引，是先按照 name 字段的值排序，然后在 name 字段的值相同的情况下，再按照 age 字段的值进行排序），即该查询语句会从符合 `name = 'j' and age = 22` 条件的第一条记录时开始扫描，而不需要从第一个 name 为 j 的记录开始扫描！





2、对索引字段使用函数，会导致索引失效

比如下面这条语句查询条件中对 **name** 字段使用了 `LENGTH` 函数，执行计划中的 `type=ALL`，代表了全表扫描：

```sql
// name 为二级索引——辅助索引
select * from t_user where length(name)=6;
```

因为索引保存的是索引字段的原始值，而不是经过函数计算后的值，自然就没办法走索引了

但是从 MySQL 8.0 开始，索引特性增加了函数索引，即**可以针对函数计算后的值建立一个索引**，也就是说该索引的值是函数计算后的值，所以就可以通过扫描索引来查询数据。

举个例子，我通过下面这条语句，对 length(name) 的计算结果建立一个名为 `idx_name_length` 的索引。

```text
alter table t_user add key idx_name_length ((length(name)));
```





3、在查询条件中对索引进行表达式计算，也会导致失效

比如，下面这条查询语句，执行计划中 type = ALL，说明是通过全表扫描的方式查询数据的：

```sql
explain select * from t_user where id + 1 = 10;
```

但是，如果把查询语句的条件改成 where id = 10 - 1，这样就不是在索引字段进行表达式计算了，于是就可以走索引查询了



4、使用左或者左右模糊匹配也就是 `like %xx` 或者 `like %xx%` 这两种方式都会造成索引失效

比如下面的 like 语句，查询 name 后缀为「林」的用户，执行计划中的 type=ALL 就代表了全表扫描，而没有走索引。

```sql
// name 字段为二级索引
select * from t_user where name like '%林';
```



如果是查询 name 前缀为林的用户，那么就会走索引扫描，执行计划中的 type=range 表示走索引扫描，key=index_name 看到实际走了 index_name 索引：

```sql
// name 字段为二级索引
select * from t_user where name like '林%';
```





5、`WHERE` 子句中的 `OR`

在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效

比如下面的查询语句，id 是主键，age 是普通列，从执行计划的结果看，是走了全表扫描。

```sql
select * from t_user where id = 1 or age = 18;
```

这是因为 OR 的含义就是两个只要满足一个即可，因此只有一个条件列是索引列是没有意义的，**只要有条件列不是索引列，就会进行全表扫描**

要解决办法很简单，将 age 字段设置为索引即可







### 索引下推

对于联合索引（a, b），在执行 `select * from table where a > 1 and b = 2` 语句的时候，只有 a 字段能用到索引，那在联合索引的 B+Tree 找到第一个满足条件的主键值（ID 为 2）后，还需要判断其他条件是否满足（看 b 是否等于 2），那是在联合索引里判断？还是回主键索引去判断呢？

- 在 MySQL 5.6 之前，只能从 ID2 （主键值）开始一个个回表，到「主键索引」上找出数据行，再对比 b 字段值。
- 而 MySQL 5.6 引入的**索引下推优化**（index condition pushdown)， **可以在联合索引遍历过程中，对联合索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数**





假设创建了一个 `(a, b, c)` 联合索引，如果查询条件为`where a = 1 and c = 3` ，符合最左匹配吗？

MySQL 5.5 的话，前面 a 会走索引，在联合索引找到主键值后，开始回表，到主键索引读取数据行，Server 层从存储引擎层获取到数据行后，然后在 Server 层再比对 c 字段的值。

从 MySQL 5.6 之后，有一个**索引下推功能**，可以在存储引擎层进行索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，再返还给 Server 层，从而减少回表次数。

索引下推的大概原理是：截断的字段不会在 Server 层进行条件判断，而是会被下推到「存储引擎层」进行条件判断（因为 c 字段的值是在 `(a, b, c)` 联合索引里的），然后过滤出符合条件的数据后再返回给 Server 层。**由于在引擎层就过滤掉大量的数据，无需再回表读取数据来进行判断，减少回表次数**，从而提升了性能。







### 索引优化

1. **建立联合索引时，要把区分度大的字段排在前面，这样区分度大的字段越有可能被更多的 SQL 使用到**，比如，性别的区分度就很小，不适合建立索引或不适合排在联合索引列的靠前的位置，而 `UUID` 这类字段就比较适合做索引或排在联合索引列的靠前的位置： 比如建立一个(a，b，c)的联合索引，a的区分度比较大，`innodb`在对a列进行查找时就已经过滤掉了大多数无效数据

2. 前缀索引优化：所谓前缀索引，说白了就是**对文本的前几个字符建立索引（具体是几个字符在建立索引时去指定）**，比如以产品名称的前 10 位来建索引，使用前缀索引是为了减小索引字段大小，可以增加一个索引页中存储的索引值，有效提高索引的查询速度。在一些大字符串的字段作为索引时，使用前缀索引可以帮助我们减小索引项的大小

3. 覆盖索引优化：是指 SQL语句 中查询的所有字段，从二级索引中就能查询得到记录，而不需要通过聚簇索引查询获得，避免回表操作

   假设只需要查询商品的名称、价格，有什么方式可以避免回表呢？

   可以建立一个联合索引，即「商品ID、名称、价格」作为一个联合索引。如果索引中存在这些数据，查询将不会再次检索主键索引，从而避免回表

   所以，**使用覆盖索引的好处就是，不需要查询出包含整行记录的所有信息，也就减少了大量的 I/O 操作，其实就是尽量避免回表操作，避免两次查找B+树，最好在第一次二级索引对应的B+树上就能查到数据**

4. **主键索引最好自增**：InnoDB 创建主键索引默认为聚簇索引，数据被存放在了 B+Tree 的叶子节点上，同一个叶子节点内的各个数据是按主键顺序存放的，因此，每当有一条新的数据插入时，数据库会根据主键将其插入到对应的叶子节点中

   **如果我们使用自增主键**，那么每次插入的新数据就会按顺序添加到当前索引节点的位置，不需要移动已有的数据，当页面写满，就会自动开辟一个新页面。因为每次**插入一条新记录，都是追加操作，不需要重新移动数据**

   **如果我们使用非自增主键**，由于每次插入主键的索引值都是随机的，因此**每次插入新的数据时，就可能会插入到现有数据页中间的某个位置，这将不得不移动其它数据来满足新数据的插入，甚至需要从一个页面复制数据到另外一个页面**，我们通常将这种情况称为**页分裂**，**页分裂还有可能会造成大量的内存碎片，导致索引结构不紧凑，从而影响查询效率**

   

5. 索引列最好设置`NOT NULL`约束: 索引列存在 NULL 就会导致优化器在做索引选择的时候更加复杂，更加难以优化,且`NULL` 值是一个没意义的值，但是它会占用物理空间

6. 防止索引失效：先简单说一下，发生索引失效的情况：

   - 当我们使用左或者左右模糊匹配的时候，也就是 `like %xx` 或者 `like %xx%`这两种方式都会造成索引失效；
   - 当我们在查询条件中对索引列做了计算、函数、类型转换操作，这些情况下都会造成索引失效；
   - 联合索引要能正确使用需要遵循最左匹配原则，也就是按照最左优先的方式进行索引的匹配，否则就会导致索引失效；
   - **在 `WHERE` 子句中**，**如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效**









### 什么时候适用/不适用索引？

适用索引的： 

- 字段有唯一性限制的，比如商品编码；
- 经常用于 `WHERE` 查询条件的字段，这样能够提高整个表的查询速度，如果查询条件不是一个字段，可以建立联合索引；
- 经常用于 `GROUP BY` 和 `ORDER BY` 的字段，这样在查询的时候就不需要再去做一次排序了，因为我们都已经知道了建立索引之后在 B+Tree 中的记录都是排序好的
- 大表的查询优化： 对于大型表，使用索引可以极大地提高查询性能，因为它们可以减少需要扫描的数据量。

不适用的情况：

- **经常更新的字段不用创建索引**，比如不要对电商项目的用户余额建立索引，因为索引字段频繁修改，由于要维护 B+Tree的有序性，那么就需要频繁的重建索引，这个过程是会影响数据库性能；
- `WHERE` 条件，`GROUP BY`，`ORDER BY` 里用不到的字段，索引的价值是快速定位，如果起不到定位的字段通常是不需要创建索引的，因为索引是会占用物理空间的；
- 字段中存在大量重复数据，不需要创建索引，比如性别字段，只有男女，如果数据库表中，男女的记录分布均匀，那么无论搜索哪个值都可能得到一半的数据。在这些情况下，还不如不要索引，**因为 `MySQL` 还有一个查询优化器，查询优化器发现某个值出现在表的数据行中的百分比很高的时候，它一般会忽略索引，进行全表扫描**；
- 表数据太少的时候，不需要创建索引
- 小表： 对于小型表，索引可能不会带来明显的性能提升，甚至可能会导致性能下降，因为额外的索引可能增加了写操作的开销。







## 事务

 `MySQL` 原生的 `MyISAM` 引擎就不支持事务,我们常见的 `InnoDB` 引擎它是支持事务的



### ACID

**原子性（Atomicity）**：原子性确保**一个事务**中的所有操作要么全部成功完成，要么全部回滚到事务开始前的状态。事务是一个不可分割的单元，要么全部执行，要么完全不执行，考虑一个转账操作的事务，包括从一个账户扣款和向另一个账户存款。原子性要求如果任一部分操作失败，整个事务都应回滚，不应有部分转账成功或失败的情况发生



**一致性（Consistency）**：是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态。比如，用户 A 和用户 B 在银行分别有 800 元和 600 元，总共 1400 元，用户 A 给用户 B 转账 200 元，分为两个步骤，从 A 的账户扣除 200 元和对 B 的账户增加 200 元。一致性就是要求上述步骤操作后，最后的结果是用户 A 还有 600 元，用户 B 有 800 元，总共 1400 元，而不会出现用户 A 扣除了 200 元，但用户 B 未增加的情况（该情况，用户 A 和 B 均为 600 元，总共 1200 元）

**隔离性（Isolation）**：数据库允许多个并发事务同时对其数据进行读写和修改的能力，**隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致**，**因为多个事务同时使用相同的数据时，不会相互干扰，每个事务都有一个完整的数据空间，对其他并发事务是隔离的**

**持久性（Durability）**：持久性确保一旦事务提交`commit`，其**对数据库的改变将是永久性的，即使在系统故障的情况下也是如此**。已提交的事务的结果将被写入永久存储介质（如磁盘），以便在系统故障后可以恢复



InnoDB 引擎通过什么技术来保证事务的这四个特性的呢？

- 持久性是通过 `redo log` （重做日志）来保证的；
- 原子性是通过 `undo log`（回滚日志） 来保证的；
- 隔离性是通过 `MVCC`（多版本并发控制） 或锁机制来保证的；
- 一致性则是通过持久性+原子性+隔离性来保证；





### 并行事务问题+隔离级别

1、脏读(一个事务读取到了另一个事务未提交修改的数据)

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E8%84%8F%E8%AF%BB.webp" style="zoom:80%;" />

因为事务 A 是还没提交事务的，也就是它随时可能发生回滚操作，**如果在上面这种情况事务 A 发生了回滚，那么事务 B 刚才得到的数据就是过期的数据，这种现象就被称为脏读**

事务A在未提交之前，读到了其他事务未提交的数据了！



2、不可重复读

**在一个事务内多次读取同一个数据**，如果出现前后两次读到的数据不一样的情况，就意味着发生了「不可重复读」现象，假设有 A 和 B 这两个事务同时在处理，事务 A 先开始从数据库中读取小林的余额数据，然后继续执行代码逻辑处理，**在这过程中如果事务 B 更新了这条数据，并提交了事务，那么当事务 A 再次读取该数据时，就会发现前后两次读到的数据是不一致的，这种现象就被称为不可重复读**

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E4%B8%8D%E5%8F%AF%E9%87%8D%E5%A4%8D%E8%AF%BB.webp" style="zoom:80%;" />

事务A在未提交之前，读到了其他事务提交的数据了！





3、幻读

**在一个事务内多次查询**某个符合查询条件的「记录数量」，如果出现前后两次查询到的记录数量不一样的情况，就意味着发生了「幻读」现象

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E5%B9%BB%E8%AF%BB.webp" style="zoom:80%;" />



针对以上三种现象，SQL 标准提出了四种隔离级别来规避这些现象，隔离级别越高，性能效率就越低

这四个隔离级别如下：

- **读未提交（read uncommitted）**指一个事务还没提交时，它做的变更就能被其他事务看到(对应脏读)；
- **读提交（read committed）**指一个事务提交之后，它做的变更才能被其他事务看到，未提交的数据其他事务是看不到的(解决了脏读，但是没有解决不可重复读)；
- **可重复读（repeatable read）**，指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，**MySQL InnoDB 引擎的默认隔离级别**(解决了可重复读，**很大程度上解决了幻读**)；
- **串行化（serializable）**；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；



**如何解决幻读？**



**`MySQL` 并不会使用「串行化」隔离级别来避免幻读现象的发生**，因为使用「串行化」隔离级别会影响性能，`Innodb`默认隔离级别「可重复读」避免幻读的解决方案有两种：

- 针对**快照读**（普通 `select` 语句），是**通过 MVCC 方式解决了幻读**，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题

- 针对**当前读**（`select` ... `for update` 、`select .... for share`语句），是**通过 `next-key lock`（记录锁+间隙锁）方式解决了幻读**，因为当执行 `select ... for update` 语句的时候，会加上 `next-key lock`，如果有其他事务在 `next-key lock` 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题

  > `SELECT FOR SHARE` 和 `SELECT IN SHARE MODE` 都是用于查询时设置共享锁(阻塞写操作)的方式，它们都会阻塞其他事务的写操作，但不会阻塞其他事务的读操作

 







### MVCC :astonished:

`MVCC` = 隐式列属性 + `undo log`版本链(同一行记录在不同时间点上的`Undo Log`形成的链式结构) + `ReadView`



**隐式列：**

首先来看看一行记录的真实字段有哪些

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E8%AE%B0%E5%BD%95%E7%9A%84%E7%9C%9F%E5%AE%9E%E6%95%B0%E6%8D%AE.webp)

- `row_id`

如果我们建表的时候指定了主键或者唯一约束列，那么就没有 row_id 隐藏字段了。如果既没有指定主键，又没有唯一约束，那么 InnoDB 就会为记录添加 row_id 隐藏字段，`row_id`不是必需的

- `trx_id`

事务id，表示这个数据是由哪个**最新**事务操作过的， `trx_id`是必需的

- `roll_pointer`

指向这条记录上一个版本的指针，`roll_pointer` 是必需的

假设在账户余额表插入一条小林余额为 100 万的记录，然后我把这两个隐藏列也画出来，该记录的整个示意图如下：![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E9%9A%90%E5%A3%AB%E5%88%97.webp)

对于使用 InnoDB 存储引擎的数据库表，它的聚簇索引记录中都包含下面两个隐藏列：

- `trx_id`，当一个事务对某条聚簇索引记录进行改动时(因为一旦对某条记录做了修改，存储在聚簇索引B+树叶子节点的数据肯定也会变更)，就会**把该事务的事务 id 记录在 trx_id 隐藏列里**；
- `roll_pointer`，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后**这个隐藏列是个指针，指向每一个旧版本记录**，于是就可以通过它找到修改前的记录





**Read-View:**

**Read-View是"快照读"SQL执行时MVCC提取数据的依据**，快照读就是普通的select语句，当前读指的是执行下列sql语句时进行数据读取(此时使用next-key lock)的方式：

Insert、Update、Delete、Select... for update、Select... lock in share mode 

再来看看`Read-View`

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/readview%E7%BB%93%E6%9E%84.drawio.webp" style="zoom:67%;" />

每个Read View 有四个重要的字段：

- `m_ids` ：指的是在创建 Read View 时，当前数据库中「活跃事务」的**事务 id 列表**，注意是一个列表，**“活跃事务”指的就是，启动了但还没提交的事务**
- `min_trx_id` ：指的是在创建 Read View 时，当前数据库中「活跃事务」中事务 **id 最小的事务**，也就是 m_ids 的最小值
- `max_trx_id` ：这个并不是 m_ids 的最大值，而是**创建 Read View 时当前数据库中应该给下一个事务的 id 值**，也就是**全局事务中最大的事务 id 值 + 1**；
- `creator_trx_id` ：指的是**创建该 Read View 的事务的事务 id**



每次快照读执行时会生成一个`Read-View` 

在创建 `Read View` 后，我们可以将记录中的 `trx_id` 划分这三种情况：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/ReadView.drawio.webp)

当一个事务去访问一条记录的时候，除了自己的更新记录总是可见之外，还有这几种情况：

- 如果该记录的 trx_id 值小于 Read View 中的 `min_trx_id` 值，表示这个版本的记录是**在创建 Read View 前已经提交的事务生成的**，所以该版本的记录对当前事务**可见**
- 如果该记录的 trx_id 值**大于等于** Read View 中的 `max_trx_id` 值，表示这个版本的记录是**在创建 Read View 后才启动的事务生成的**，所以该版本的记录对当前事务**不可见**
- 如果该记录的 `trx_id` 值在 Read View 的 `min_trx_id` 和 `max_trx_id` 之间，需要判断 trx_id 是否在 m_ids 列表中:
  - 如果记录的 trx_id **在** `m_ids` 列表中，表示生成该版本记录的活跃事务依然活跃着（**还没提交事务**），所以该版本的记录对当前事务**不可见**
  - 如果记录的 trx_id **不在** `m_ids`列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务**可见**



**一旦出现了不可见的情况，就沿`undolog`版本链回退到前一版本的行记录，然后再用前一个版本的`trx_id`再次和`ReadView`做比对**







`Innodb`引擎下默认就可以解决不可重复读和幻读(一定程度上)，下面来详细介绍一下：

1、如下图所示，不同的事务隔离级别会导致select1+select2语句的结果不一致：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE1.png)



该例子下基于`UNDO-LOG`的版本链如下所示：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE2.png)

注意：无论`Update`操作是否提交都将被记录到`undo-log`版本链中，且`undo-log`版本链用完后不是立即删除，`Mysql`确保版本链数据不再被"引用"后才会进行删除



2、来看一下读已提交(RC)级别下,两次快照读各生成的`Read-View`：





3、再结合`undo-log`版本链和`Read-View`分析一下快照读的结果：

第一次快照读的结果：先用`trx_id`为2的版本做比对，发现比较不出结果后，再沿`undolog`链表遍历回退到前一个版本，然后再进行比较

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/mvcc1.png)





第二次快照读的结果：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/mvcc2.png)



**即每次比较时，从`undo log`版本链的最顶端和当前快照读生成的Read-View视图来进行一一比对(比对规则在图中)，如果比对失败则向下遍历`undo log`版本链，直至比对成功**







**而对于可重复读RR隔离级别，仅在第一次执行快照读时生成Read-View,后续快照读会复用！**

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/mvcc3.png)

即在RR级别下，事务D第二次快照读时生成的Read-View直接复用了上一次快照读所生成的，而undo-log版本链也没有发生变化(没有其他事务进行更新操作)，因此解决了不可重复读





再来看看RR级别下发生幻读的例子：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E5%B9%BB%E8%AF%BB.png)



**总结：**

- **RC级别下：每次快照读均会生成 `Read-View`(因此会导致不可重复读！！！)**
- RR级别下：连续多次快照读，`Read-View` 会产生复用，没有不可重复读问题
- RR级别下：当两次快照读之间存在当前读，`Read-View` 会重新生成，导致产生幻读
- RR级别下： 针对第三条可能产生的幻读问题，可以通过当前读(`select for update`)来对记录加`next-key Lock`(记录锁+间隙锁)，即**尽量在开启事务之后，马上执行 `select ... for update` 这类当前读的语句，因为它会对记录加 `next-key lock`，从而避免其他事务插入一条新记录**















## 锁



根据加锁范围，可以分成**全局锁、表级锁和行锁**三类

### 全局锁

```sql
flush tables with read lock  #1
set global readonly=true #2
```

执行后，**整个数据库就处于只读状态了**,任何对数据的增删改、对表结构的操作都会被阻塞

全局锁的典型使用场景是，做全库逻辑备份（`mysqldump`——用于备份整个数据库的逻辑结构和数据。它是通过导出数据库中的数据和对象定义语句来创建备份，备份的是sql语句），备份期间会造成业务停滞

既然要全库只读，**为什么不使用 `set global readonly=true` 的方式呢**？确实 `readonly` 方式也可以让全库进入只读状态，但还是建议用 `FTWRL` 方式，主要有几个原因： 

一是，在有些系统中，`readonly` 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 `global` 变量的方式影响面更大

二是，在异常处理机制上有差异。如果执行`FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁`，整个库回到可以正常更新的状态。而将整个库设置为 `readonly` 之后，如果客户端发生异常，则数据库就会一直保持 `readonly` 状态，这样会导致整个库长时间处于不可写状态，风险较高

三是，`readonly` 对`super`用户权限无效

业务的更新不只是增删改数据（DML)，还有可能是加字段等修改表结构的操作（DDL），不论是哪种方法，一个库被全局锁上以后，你要对里面任何一个表做加字段操作，都是会被锁住的



### 表级锁

MySQL 里面表级别的锁有这几种：

- 表锁；
- 元数据锁（MDL）；
- 意向锁；
- AUTO-INC 锁；



1、表锁

如果我们想对学生表（t_student）加表锁，可以使用下面的命令：

```sql
//表级别的共享锁，也就是读锁；
lock tables t_student read;   

//表级别的独占锁，也就是写锁；
lock tables t_stuent write;

```

如果本线程对学生表加了「共享表锁」，那么本线程接下来如果要对学生表执行写操作的语句，是会被阻塞的，当然其他线程对学生表进行写操作时也会被阻塞，直到锁被释放(**读写互斥**)



2、元数据锁(`Meta Data Lock`)

当我们对数据库表进行操作时，会自动默认地给这个表加上 MDL：

- 对一张表进行 `CRUD` 操作时，加的是 **MDL 读锁**(读锁之间不互斥，为了保证多个线程同时crud操作不阻塞)；
- 对一张表做结构变更操作的时候，加的是 **MDL 写锁**；

MDL 是为了保证当用户对表执行 CRUD 操作时，防止其他线程对这个表结构做了变更

当有线程在执行 `select` 语句（ 加 MDL 读锁）的期间，如果有其他线程要更改该表的结构（ 申请 MDL 写锁），那么将会被阻塞，直到执行完 `select` 语句（ 释放 MDL 读锁）。

反之，当有线程对表结构进行变更（ 加 MDL 写锁）的期间，如果有其他线程执行了 `CRUD` 操作（ 申请 MDL 读锁），那么就会被阻塞，直到表结构变更完成（ 释放 MDL 写锁）、或其他线程想要修改表结构时(申请MDL写锁)同样会被阻塞

- MDL 是在事务提交后才会释放，这意味着**事务执行期间，MDL 是一直持有的**

- 申请 MDL 锁的操作会形成一个队列，队列中**写锁获取优先级高于读锁**，一旦出现 MDL 写锁等待，会阻塞后续该表的所有 CRUD 操作







3、意向锁

- 在使用 InnoDB 引擎的表里对**某些记录**加上「共享锁」之前，需**要先在表级别加**上一个「**意向共享锁**」；
- 在使用 InnoDB 引擎的表里对某些纪录加上「独占锁」之前，需**要先在表级别加**上一个「**意向独占锁**」；

也就是，当执行插入、更新、删除操作，需要先对表加上「意向独占锁」，然后对该记录加独占锁

(即加行锁前要先加一个意向表锁)

而普通的 `select` 是**不会加行级锁**的，普通的 `select` 语句是利用 `MVCC` 实现一致性读，是无锁的

不过，`select` 也是可以对记录加共享锁和独占锁的，具体方式如下：

```sql
//先在表上加上意向共享锁，然后对读取的记录加共享锁  这里的共享锁是怎么实现的？
select ... lock in share mode;

//先表上加上意向独占锁，然后对读取的记录加独占锁(Next key lock)
select ... for update;
```

意向共享锁和意向独占锁是表级锁，不会和**行级的共享锁和独占锁发生冲突**，而且**意向锁之间也不会发生冲突**，只会和共享表锁（`lock tables ... read`）和独占表锁（`lock tables ... write`）发生冲突。

**意向锁的目的是为了快速判断表里是否有记录被加锁:**

有了「意向锁」，由于在对记录加独占锁前，先会加上表级别的意向独占锁，**那么在加「独占表锁」时，直接查该表是否有意向独占锁，如果有就意味着表里已经有记录被加了独占锁，这样就不用去遍历表里的记录**







4、 Auto-INC锁

表里的主键通常都会设置成自增的，这是通过对主键字段声明 `AUTO_INCREMENT` 属性实现的

**在插入数据时，会加一个表级别的 AUTO-INC 锁**，然后为被 `AUTO_INCREMENT` 修饰的字段赋值递增的值，等插入语句执行完成后，才会把 AUTO-INC 锁释放掉。那么，一个事务在持有 `AUTO-INC` 锁的过程中，其他事务的如果要向该表插入语句都会被阻塞，从而保证插入数据时，被 `AUTO_INCREMENT` 修饰的字段的值是连续递增的

但是， AUTO-INC 锁再对大量数据进行插入的时候，会影响插入性能，因为另一个事务中的插入会被阻塞(其他事务要等待所有数据全部插入完成后才能继续操作，因此后面引出来轻量级锁，插入新记录的事务在申请到主键后就可以释放该锁，不用等到整个插入语句完成)



在 MySQL 5.1.22 版本开始，InnoDB 存储引擎提供了一种**轻量级的锁**来实现自增：

一样也是在插入数据的时候，会为被 `AUTO_INCREMENT` 修饰的字段加上轻量级锁，**然后给该字段赋值一个自增的值，就把这个轻量级锁释放了，而不需要等待整个插入语句执行完后才释放锁**

InnoDB 存储引擎提供了个 `innodb_autoinc_lock_mode` 的系统变量，是用来控制选择用 AUTO-INC 锁，还是轻量级的锁

- 当 `innodb_autoinc_lock_mode` = 0，就采用 `AUTO-INC` 锁，语句执行结束后才释放锁；
- 当 `innodb_autoinc_lock_mode` = 2，**就采用轻量级锁，申请自增主键后就释放锁，并不需要等语句执行后才释放。**
- 当 `innodb_autoinc_lock_mode` = 1：
  - 普通 insert 语句，自增锁在申请到自增主键值之后就马上释放；
  - 类似 insert … select 这样的批量插入数据的语句，自增锁还是要等每条sql语句结束后才被释放；





### 行级锁 :imp:

`Innodb`不同隔离级别下，行级锁的种类是不同的:

在读已提交隔离级别下，行级锁的种类只有记录锁，也就是仅仅把一条记录锁上。

在可重复读隔离级别下，行级锁的种类除了有记录锁，还有间隙锁（目的是为了避免幻读）

在可串行化隔离级别下，使用记录锁和间隙锁，类似于可重复读隔离级别。但是，**串行化隔离级别会在读取范围内的所有记录和间隙上设置共享锁(此处是行锁)**，阻止其他事务插入、修改或删除范围内的任何记录



#### Record Lock X锁

当一个事务执行了下面这条语句：

```sql
mysql > begin;
mysql > select * from t_test where id = 1 for update; #加了排他锁
mysql > select * from t_test where id = 1 lock in share mode ; #加了共享锁
```

第 2 行就是对 `t_test` 表中主键 id 为 1 的这条记录加上 X 型的记录锁，这样其他事务就无法对这条记录进行修改了

`Record Lock` 是有 S 锁和 X 锁之分的：

- 当一个事务对一条记录加了 S 型记录锁后，其他事务也可以继续对该记录加 S 型记录锁（S 型与 S 锁兼容），但是不可以对该记录加 X 型记录锁（S 型与 X 锁不兼容）;
- 当一个事务对一条记录加了 X 型记录锁后，其他事务既不可以对该记录加 S 型记录锁（S 型与 X 锁不兼容），也不可以对该记录加 X 型记录锁（X 型与 X 锁不兼容）







#### Gap Lock S锁

`Gap Lock`间隙锁只存在于**可重复读**隔离级别，目的是为了解决可重复读隔离级别下幻读的现象：

假设表中有一个范围 id 为（3，5）间隙锁，那么其他事务就无法插入 id = 4 这条记录了，这样就有效的防止幻读现象的发生

间隙锁虽然存在 X 型间隙锁和 S 型间隙锁，但是并没有什么区别，**间隙锁之间是兼容的，即两个事务可以同时持有包含共同间隙范围的间隙锁，并不存在互斥关系，因为间隙锁的目的是防止插入幻影记录而提出的**



与**插入意向锁**的区别：

一个事务在插入一条记录的时候，需要判断插入位置是否已被其他事务加了间隙锁，如果有的话，插入操作就会发生**阻塞**，直到拥有间隙锁的那个事务提交为止（释放间隙锁的时刻），在此期间会生成一个**插入意向锁**，表明有事务想在某个区间插入新记录，但是**现在处于等待状态**

插入意向锁名字虽然有意向锁，但是它并**不是意向锁(表锁)，它是一种特殊的间隙锁，属于行级别锁**









#### Next-Key Lock X锁+S锁

`Next-Key Lock` 称为临界锁，是 `Record Lock` + `Gap Lock` 的组合，锁定一个范围，并且锁定记录本身

假设，表中有一个范围 id 为（3，5] 的 `next-key lock`，那么其他事务既不能插入 id = 4 记录，也不能修改 id = 5 这条记录

**`next-key lock` 是包含间隙锁+记录锁的，如果一个事务获取了 X 型的 `next-key lock`，那么另外一个事务在获取相同范围的 X 型的 `next-key lock` 时，是会被阻塞的**



行级锁加锁的对象是**索引**，加锁的基本单位是 `next-key lock`，它是由记录锁和间隙锁组合而成的，**`next-key lock` 是前开后闭区间，而间隙锁是前开后开区间**,因为查询语句扫描的 B+ 树是聚簇索引树，即主键索引树，所以是对主键索引加锁。将对应记录的主键索引加 记录锁后，就意味着其他事务无法对该记录进行更新和删除操作了

**在能使用记录锁或者间隙锁就能避免幻读现象的场景下， `next-key lock` 就会退化成记录锁或间隙锁**









`Next-key lock` 实际上是一个范围锁，用于保护索引键范围内的数据。它在 InnoDB 的索引记录和间隙之间创建锁定范围。下面是 `Next-key lock` 的行为：

1. 对于存在的索引记录（行级锁）：
   - 当使用共享锁时，获取共享锁以读取数据。
   - 当使用排他锁时，获取排他锁以修改数据。
2. 对于不存在的索引记录（间隙锁）：
   - 当使用共享锁时，获取间隙共享锁，阻止其他事务插入具有相同索引值的新记录。
   - 当使用排他锁时，获取间隙排他锁，阻止其他事务插入具有相同索引值的新记录，也阻止其他事务修改具有相同索引值的记录。

因此，`Next-key lock` 是一种组合了共享锁和排他锁的锁类型









>  什么时候加`Next-Key Lock`呢？

在InnoDB中，当执行以下类型的SQL语句时，会隐式地加上**Next-Key Lock**：

1. `UPDATE`语句：当使用`UPDATE`语句更新表中的行时，InnoDB会在更新期间为被修改的行加上`Next-Key Lock`。这样可以保证并发事务的一致性，并防止其他事务在读取或修改被更新的行时发生冲突。
2. `DELETE`语句：执行`DELETE`语句删除行时，InnoDB会为要删除的行加上`Next-Key Lock`。这样可以防止其他事务在删除操作进行期间对这些行进行读取或修改。
3. `SELECT`语句（使用WHERE子句）：当使用`SELECT`语句并带有WHERE子句时，InnoDB会为满足WHERE条件的行加上`Next-Key Lock`。这样可以避免其他事务在读取或修改这些行时引发冲突(**但是会涉及到锁的退化**)







#### 锁退化场景分析

记住一个前提：锁退化是为了减少锁的粒度，但是退化必须要保证不发生幻读！

<img src="https://segmentfault.com/img/remote/1460000040129112/view" alt="preview" style="zoom:50%;" />





**1、唯一索引等值查询**

当我们用唯一索引进行等值查询的时候，查询的记录存不存在，加锁的规则也会不同：

- 当查询的记录是「存在」的，在索引树上定位到这一条记录后，将该记录的索引中的 `next-key lock` 会**退化成「记录锁」`Record Lock`**
- 当查询的记录是「不存在」的，在索引树找到第一条大于该查询记录的记录后，将该记录的索引中的 `next-key lock` 会**退化成「间隙锁」 `Gap Lock`**

假设事务 A 执行了这条等值查询语句，查询的记录**「存在」**于表中:

```sql
mysql> begin;
Query OK, 0 rows affected (0.00 sec)

mysql> select * from user where id = 1 for update;
+----+--------+-----+
| id | name   | age |
+----+--------+-----+
|  1 | 路飞   |  19 |
+----+--------+-----+
1 row in set (0.02 sec)
```

那么，事务 A 会为 id 为 1 的这条记录就会加上 **X 型的记录锁**

因为在唯一索引等值查询并且查询记录存在的场景下，仅靠记录锁也能避免幻读的问题

- 由于主键具有唯一性，所以**其他事务插入 id = 1 的时候，会因为主键冲突，导致无法插入 id = 1 的新记录**。这样事务 A 在多次查询 id = 1 的记录的时候，不会出现前后两次查询的结果集不同，也就避免了幻读的问题。

- 由于对 id = 1 加了记录锁，**其他事务无法删除该记录**，这样事务 A 在多次查询 id = 1 的记录的时候，不会出现前后两次查询的结果集不同，也就避免了幻读的问题









假设事务 A 执行了这条等值查询语句，查询的记录**「不存在」**于表中:

```sql
mysql> begin;
Query OK, 0 rows affected (0.00 sec)

mysql> select * from user where id = 2 for update;
Empty set (0.03 sec)
```

接下来，通过 `select * from performance_schema.data_locks\G;` 这条语句，查看事务执行 SQL 过程中加了什么锁

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E4%BA%8B%E5%8A%A1a%E5%88%86%E6%9E%901.webp" style="zoom: 50%;" />

**此时事务 A 在 id = 5 记录的主键索引上加的是间隙锁，锁住的范围是 (1, 5)**

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%E9%97%B4%E9%9A%99%E9%94%81.drawio.webp" style="zoom:67%;" />

接下来，如果有其他事务插入 id 值为 2、3、4 这一些记录的话，这些插入语句都会发生阻塞

注意，如果其他事务插入的 id = 1 或者 id = 5 的记录话，并不会发生阻塞，而是报主键冲突的错误，因为表中已经存在 id = 1 和 id = 5 的记录了

> 间隙锁的范围`(1, 5)` ，是怎么确定的？

根据我的经验，如果 `LOCK_MODE` 是 next-key 锁或者间隙锁，那么 LOCK_DATA 就表示锁的范围「右边界」，此次的事务 A 的 LOCK_DATA 是 5

然后锁范围的**「左边界」是表中 id 为 5 的上一条记录的 id 值**，即 1

因此，间隙锁的范围为`(1, 5)`

> 为什么唯一索引等值查询并且查询记录「不存在」的场景下，在索引树找到第一条大于该查询记录的记录后，要将该记录的索引中的 next-key lock 会退化成「间隙锁」？

原因就是在唯一索引等值查询并且查询记录不存在的场景下，**仅靠间隙锁就能避免幻读的问题**。

- 为什么 id = 5 记录上的主键索引的锁不可以是 next-key lock？如果是 next-key lock，就意味着其他事务无法删除 id = 5 这条记录，但是这次的案例是查询 id = 2 的记录，只要保证前后两次查询 id = 2 的结果集相同，就能避免幻读的问题了，所以即使 id =5 被删除，也不会有什么影响，那就没必须加 next-key lock，因此**只需要在 id = 5 加间隙锁，避免其他事务插入 id = 2 的新记录**就行了。
- 为什么不可以针对不存在的记录加记录锁？**锁是加在索引上的**，而这个场景下查询的记录是不存在的，自然就没办法锁住这条不存在的记录





2、唯一索引范围查询 (未完待续。。。。)





3、非唯一索引等值查询

当我们用非唯一索引进行等值查询的时候，**因为存在两个索引，一个是主键索引，一个是非唯一索引（二级索引），所以在加锁时，同时会对这两个索引都加锁，但是对主键索引加锁的时候，只有满足查询条件的记录才会对它们的主键索引加锁**





针对非唯一索引等值查询时，查询的记录存不存在，加锁的规则也会不同：

- 当查询的记录「存在」时，由于不是唯一索引，所以肯定存在索引值相同的记录，于是**非唯一索引等值查询的过程是一个扫描的过程，直到扫描到第一个不符合条件的二级索引记录就停止扫描，然后在扫描的过程中，对扫描到的二级索引记录加的是 next-key 锁，而对于第一个不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。同时，在符合查询条件的记录的主键索引上加记录锁**。
- 当查询的记录「不存在」时，**扫描到第一条不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。因为不存在满足查询条件的记录，所以不会对主键索引加锁**。





或者直接看这篇文章吧，应该足够应付面试了：

https://segmentfault.com/a/1190000040129107



### 死锁问题

#### Mysql下如何产生死锁的？

**Innodb 引擎为了解决「可重复读」隔离级别下的幻读问题，就引出了 next-key 锁**，它是记录锁和间隙锁的组合

普通的 select 语句是不会对记录加锁的，因为它是通过 MVCC 的机制实现的快照读，如果要在查询时对记录加行锁，可以使用下面这两个方式：

```sql
begin;
//对读取的记录加共享锁
select ... lock in share mode;
commit; //锁释放

begin;
//对读取的记录加排他锁
select ... for update;
commit; //锁释放
```

行锁的释放时机是在事务提交（commit）后，锁就会被释放，并不是一条语句执行完就释放行锁







再来看一个死锁的示例：

1、首先建了一张订单表，其中 id 字段为主键索引，order_no 字段普通索引，也就是非唯一索引：

```sql
CREATE TABLE `t_order` (
  `id` int NOT NULL AUTO_INCREMENT,
  `order_no` int DEFAULT NULL,
  `create_date` datetime DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `index_order` (`order_no`) USING BTREE
) ENGINE=InnoDB ;
```

然后新增几条记录：

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/54fc00f9f87a60ab7b5ba92d824a892d.webp" style="zoom:50%;" />

2、事务A、B先后执行以下操作：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E6%AD%BB%E9%94%81%E5%AE%9E%E4%BE%8B.webp)

事务 A 在执行下面这条语句的时候：

```sql
select id from t_order where order_no = 1007 for update;
```

我们可以通过 `select * from performance_schema.data_locks\G;` 这条语句，查看事务执行 SQL 过程中加了什么锁

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E6%AD%BB%E9%94%811.webp" style="zoom:67%;" />

从上图可以看到，共加了两个锁，分别是：

- 表锁：X 类型的意向锁；
- 行锁：X 类型的间隙锁；

这里我们重点关注行锁，图中 LOCK_TYPE 中的 RECORD 表示行级锁，而不是记录锁的意思，通过 LOCK_MODE 可以确认是 next-key 锁，还是间隙锁，还是记录锁：

- 如果 LOCK_MODE 为 `X`，说明是 X 型的 next-key 锁；
- 如果 LOCK_MODE 为 `X, REC_NOT_GAP`，说明是 X 型的记录锁；
- 如果 LOCK_MODE 为 `X, GAP`，说明是 X 型的间隙锁；



**因此，此时事务 A 在二级索引（INDEX_NAME : index_order）上加的是 X 型的 next-key 锁，锁范围是`(1006, +∞]`**

根据经验，如果 LOCK_MODE 是 next-key 锁或者间隙锁，那么 LOCK_DATA 就表示锁的范围最右值，此次的事务 A 的 LOCK_DATA 是 supremum pseudo-record，表示的是 +∞。然后锁范围的最左值是 t_order 表中最后一个记录的 index_order 的值，也就是 1006。因此，next-key 锁的范围 (1006, +∞]

+

因此当事务 B 往事务 A的`next-key` 锁的范围 (1006, +∞] 里插入 id = 1008 的记录就会被锁住：

```sql
Insert into t_order (order_no, create_date) values (1008, now());
```

因为当我们执行以下插入语句时，会在插入间隙上获取插入意向锁，而插入意向锁与间隙锁是冲突的，所以当其它事务持有该间隙的间隙锁时，需要等待其它事务释放间隙锁之后，才能获取到插入意向锁。而间隙锁与间隙锁之间是兼容的，所以所以两个事务中 `select ... for update` 语句并不会相互影响



案例中的事务 A 和事务 B 在执行完后 `select ... for update` 语句后都持有范围为`(1006,+∞]`的`next-key` 锁，而接下来的插入操作为了获取到插入意向锁，都在等待对方事务的间隙锁释放，于是就造成了循环等待，导致死锁



#### 如何避免死锁？

在数据库层面，有两种策略通过「打破循环等待条件」来解除死锁状态：

- **设置事务等待锁的超时时间**：**当一个事务的等待时间超过该值后，就对这个事务进行`rollback`回滚，于是锁就释放了**，另一个事务就可以继续执行了。在 `InnoDB` 中，参数 `innodb_lock_wait_timeout` 是用来设置超时时间的，默认值时 50 秒
- **开启主动死锁检测**。主动死锁检测在发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 `innodb_deadlock_detect` 设置为 on，表示开启这个逻辑，默认就开启











### 一条sql语句执行时的加锁情况









## 日志

首先要知道：

- **undo log（回滚日志）**：是 `Innodb` 存储引擎层生成的日志，实现了事务中的**原子性**，主要**用于事务回滚和 MVCC**；
- **redo log（重做日志）**：是 `Innodb` 存储引擎层生成的日志，实现了事务中的**持久性**，主要**用于掉电等故障恢复**，属于物理日志；
- **bin log（归档日志）**：是 `Server` 层生成的日志，主要**用于数据备份和主从复制**



然后我们需要重点关注四个问题：

1. 每个日志什么时候生成的？

2. 存放在哪里？

3. 以何种格式存放？
4. 什么时候刷盘？



### undo log

我们在执行执行一条“增删改”语句的时候，虽然没有输入 `begin` 开启事务和 `commit` 提交事务，但是 MySQL 会**隐式开启事务**来执行“增删改”语句的(`autocommit`参数)，执行完就自动提交事务

如果我们每次在事务执行过程中，都记录下回滚时需要的信息到一个日志里，那么在事务执行中途发生了 MySQL 崩溃后，就不用担心无法回滚到事务之前的数据，实现这一机制就是 **undo log（回滚日志），它保证了事务的 [ACID 特性 (opens new window)](https://xiaolincoding.com/mysql/transaction/mvcc.html#事务有哪些特性)中的原子性（Atomicity）**

在事务没提交之前，`MySQL` 会先记录更新前的数据到 `undo log` 日志文件里面：

每当 `InnoDB` 引擎对一条记录进行操作（修改、删除、新增）时，要把回滚时需要的信息都记录到 `undo log` 里，比如：

- 在**插入**一条记录时，要把这条记录的主键值记下来，这样之后回滚时只需要把这个主键值对应的记录**删掉**就好了；
- 在**删除**一条记录时，要把这条记录中的内容都记下来，这样之后回滚时再把由这些内容组成的记录**插入**到表中就好了；
- 在**更新**一条记录时，要把被更新的列的旧值记下来，这样之后回滚时再把这些列**更新为旧值**就行了

一条记录的每一次更新操作产生的 `undo log` 格式都有一个 `roll_pointer` 指针和一个 `trx_id` 事务id：

- 通过 `trx_id` 可以知道该记录最新是被哪个事务修改的；
- 通过 `roll_pointer` 指针可以将这些 `undo log` 串成一个链表，这个链表就被称为版本链；

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E7%89%88%E6%9C%AC%E9%93%BE.webp)

> Undo Log是用于实现事务的回滚操作和MVCC（多版本并发控制）的一种日志机制。它记录了事务对数据行所做的修改操作的详细信息，包括旧值、修改类型等。Undo Log使用回滚段（Rollback Segment）的结构来存储撤销日志的信息。
>
> `Roll Pointer`是一个指针，**指向当前事务的回滚段的起始位置**，它是为了管理和跟踪Undo Log的读取和回滚操作而引入的。每个事务在开始时都会获得一个唯一的`Roll Pointer`，用于标识该事务在Undo Log中的位置。
>
> Undo Log和Roll Pointer之间的关系如下：
>
> - 当事务对数据行进行修改时，Undo Log会记录该修改的详细信息，并将相应的Undo Log条目插入到回滚段中。
> - Roll Pointer会指向回滚段中当前事务的起始位置，用于**指示当前记录的最新版本在Undo Log中的位置。**
> - 在事务进行回滚操作时，Roll Pointer会根据需要向前移动，以选择合适的Undo Log条目进行回滚操作。回滚操作会根据Roll Pointer指示的位置逆向执行Undo Log中记录的修改操作，将数据恢复到事务开始前的状态。
> - 当事务提交后，Roll Pointer将被更新，指向下一个可用的位置，用于下一个事务的Undo Log记录。



下图为`UPDATE`操作对应的undo日志结构：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/trx_undo_upd_exist_rec_format.jpg)



总结 undo log 的两大作用：

- **实现事务回滚，保障事务的原子性**：事务处理过程中，如果出现了错误或者用户执行了 ROLLBACK 语句，MySQL 可以利用 undo log 中的历史数据将数据恢复到事务开始之前的状态
- **实现 MVCC（多版本并发控制）关键因素之一**：MVCC 是通过 ReadView + undo log 实现的。undo log 为每条记录保存多份历史数据，MySQL 在执行快照读（普通 select 语句）的时候，会根据事务的 Read View 里的信息，顺着 undo log 的版本链找到满足其可见性的记录



> undo log 是如何刷盘（持久化到磁盘）的？
>



开启事务后，InnoDB 层更新记录前，首先要记录相应的 `undo log`，如果是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 `undo log`，undo log 会写入 Buffer Pool 中的 Undo 页

**对 Undo 页的修改也都会记录到 redo log。redo log 会每秒刷盘，提交事务时也会刷盘，数据页和 undo 页都是靠这个机制保证持久化的**











### redo log



`redo log` 是物理日志，记录了某个数据页做了什么修改，比如**对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新**，每当执行一个事务就会产生这样的一条或者多条物理日志



> 那么为什么需要`redo log`?  从两点来答



(1) 事务的四大特性里面有一个是 **持久性** ，具体来说就是**只要事务提交成功，那么对数据库做的修改就被永久保存下来了，不可能因为任何原因再回到原来的状态** 。那么 `mysql`是如何保证持久性的呢？最简单的做法是在每次事务提交的时候，将该事务涉及修改的数据页全部刷新到磁盘中。但是这么做会有严重的性能问题，主要体现在两个方面：

1. 因为 `Innodb `是以 `页 `为单位进行磁盘交互的，而一个事务很可能只修改一个数据页里面的几个字节，这个时候将完整的数据页刷到磁盘的话，太浪费资源了！
2. 一个事务可能涉及修改多个数据页，并且这些数据页在物理上并不连续，使用随机I/O写入性能太差！

因此 `mysql `设计了 `redo log `， **具体来说就是只记录事务对数据页做了哪些修改**，这样就能完美地解决性能问题了(相对而言文件更小并且是顺序IO)，同时让数据库有了`crash-safe`的能力



(2) 将写操作从「随机写」变成了「顺序写」，提升 MySQL 写入磁盘的性能:

- redo log buffer 写入到磁盘中的`redo log group`中的 `ib_logfile0/1`文件中，采用的是循环写
- 而持久化数据时需要先找到该数据页的位置，然后遍历页内链表，使用的是随机写





当执行一个更新操作时

1. 首先从磁盘中读取相应的数据页到内存`Buffer Pool`中
2. 然后更新内存中的数据，**并标记该内存中的数据页为脏页(Flush链表)**
3. 然后记录`redo log`日志(相应的 `Redo Log` 条目会很快地被写入到磁盘中的`redo log`文件中)，实际上`redo log` 也有自己的缓存—— **`redo log buffer`**，每当产生一条 `redo log` 时，会先写入到 `redo log buffer`，后续再持久化到磁盘(事务提交后redo log先刷盘到redo log group中)
4. 随后InnoDB 引擎在适当的时候由后台线程将缓存在 Buffer Pool 的脏页刷新到磁盘里

> - 即在事务提交时，只要先将 redo log 持久化到磁盘即可，可以不需要等到将缓存在 Buffer Pool 里的脏页数据持久化到磁盘
>
> - 当系统崩溃时，虽然脏页数据没有持久化，但是 redo log 已经持久化，接着 MySQL 重启后，可以根据 redo log 的内容，将所有数据恢复到最新的状态
>
> - **不仅redo log要先刷盘，数据也要写入磁盘！！** 两者区别在于：
>
>   写入 redo log 的方式使用了追加操作， 所以磁盘操作是**顺序写**，而写入数据需要先找到写入位置，然后才写到磁盘，所以磁盘操作是**随机写**。
>
>   磁盘的「顺序写 」比「随机写」 高效的多，因此 redo log 写入磁盘的开销更小。
>
>   这是 WAL 技术的另外一个优点：**MySQL 的写操作从磁盘的「随机写」变成了「顺序写」**，提升语句的执行性能。













**question1**：  **`redo log` 和 `binlog` 有什么区别？**

*1、适用对象不同：*

- binlog 是 MySQL 的 Server 层实现的日志，所有存储引擎都可以使用；
- redo log 是 Innodb 存储引擎实现的日志；

*2、文件格式不同：*

- binlog 有 3 种格式类型，分别是 STATEMENT（默认格式）、ROW、 MIXED，区别如下：
  - STATEMENT：每一条修改数据的 SQL 都会被记录到 `binlog` 中（相当于记录了逻辑操作，所以针对这种格式， `binlog` 可以称为逻辑日志），主从复制中 slave 端再根据 SQL 语句重现。但 STATEMENT 有动态函数的问题，比如你用了 uuid 或者 now 这些函数，你在主库上执行的结果并不是你在从库执行的结果，这种随时在变的函数会导致复制的数据不一致；
  - ROW：记录行数据最终被修改成什么样了（这种格式的日志，就不能称为逻辑日志了），不会出现 STATEMENT 下动态函数的问题。但 **ROW 的缺点是每行数据的变化结果都会被记录，比如执行批量 update 语句，更新多少行数据就会产生多少条记录，使 binlog 文件过大，而在 STATEMENT 格式下每次的更新只会记录一个 update 类型的sql语句而已**；
  - MIXED：包含了 STATEMENT 和 ROW 模式，它会根据不同的情况自动使用 ROW 模式和 STATEMENT 模式；
- redo log 是物理日志，记录的是在某个数据页做了什么修改，比如对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新；



> `binlog`中的`row`格式和`statement`格式的区别是什么?

假设有一个表格 `employees`，其中有以下记录：

| id   | name  | salary |
| ---- | ----- | ------ |
| 1    | John  | 50000  |
| 2    | Alice | 60000  |
| 3    | Bob   | 55000  |

如果进行一个 `UPDATE` 操作：

```SQL
UPDATE employees SET salary = 58000 WHERE id = 2;
```

在 `binlog` 中以 `row` 格式记录的话，会记录这样的信息：

| Event Type | Table Name | Row Data (after change) |
| ---------- | ---------- | ----------------------- |
| UPDATE     | employees  | (2, Alice, 58000)       |

这表示进行了一次 UPDATE 操作，修改了 `id` 为 2 的员工的薪水为 58000。记录的是修改后的数据 `(2, Alice, 58000)`



现在我们执行一个 `UPDATE` 语句，将所有员工的薪水增加10%：但是这次使用的是`statement`格式存储的binlog:

```sql
UPDATE employees SET salary = salary * 1.1;
```

在 `binlog` 中以 `statement` 格式记录的话，会记录这样的信息：

| Event Type | SQL Statement                               |
| ---------- | ------------------------------------------- |
| UPDATE     | UPDATE employees SET salary = salary * 1.1; |









*3、写入方式不同：*

- binlog 是**追加写**，**写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志。**
- redo log 是循环写，日志空间大小是固定，全部写满就从头开始，保存未被刷入磁盘的脏页日志



*4、用途不同：*

- binlog 用于备份恢复、**主从复制**(slave节点重放master节点传来的binlog)；
- redo log 用于掉电等故障恢复







**question2**：  **`redo log` 何时刷盘？**



> 前提：
>
> 1. 当事务执行 UPDATE、INSERT 或 DELETE 等修改数据的操作时，这些更改操作不会直接写入磁盘上的数据文件，而是首先写入 `Redo Log Buffer` 中。这样做是为了提高性能，避免频繁的磁盘写入
>
>    
>
> 2. 在事务提交时，`Redo Log Buffer` 中的 redo 信息将被刷新到 `Redo Log` 文件组中的一个 redo log 文件中，然后才会更新磁盘上的数据文件。



缓存在 `redo log buffer` 里的 `redo log` 还是在内存中，它什么时候刷新到磁盘？

主要有下面几个时机：

- MySQL 正常关闭时；
- 当 **redo log buffer 中记录的写入量大于 redo log buffer 内存空间的一半时**，会触发落盘(落盘到`redo log group`中的某一个文件)；
- InnoDB 的**后台线程每隔 1 秒，将 `redo log buffer` 持久化到磁盘中的`redo log group`文件**中；
- **每次事务提交**时都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘（这个策略可由 `innodb_flush_log_at_trx_commit` 参数控制





**question3：  `redo log` 文件写满了怎么办？**

 InnoDB 存储引擎有 1 个 `redo log Group`,「重做日志文件组」由有 2 个 redo log 文件组成，这两个 redo 日志的文件名叫 ：`ib_logfile0` 和 `ib_logfile1` ,每个 redo log File 的大小是固定且一致的，假设每个 redo log File 设置的上限是 1 GB，那么总共就可以记录 2GB 的操作

重做日志文件组(**位于磁盘中** ❗❗❗ )是以**循环写**的方式工作的，从头开始写，写到末尾就又回到开头，所以 InnoDB 存储引擎会先写 ib_logfile0 文件，当 ib_logfile0 文件被写满的时候，会切换至 ib_logfile1 文件，当 ib_logfile1 文件也被写满时，会切换回 ib_logfile0 文件

redo log 是循环写的方式，相当于一个环形，InnoDB 用 `write pos` 表示 redo log 当前记录写到的位置，用 checkpoint 表示当前要擦除的位置，如下图：

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/checkpoint.webp" style="zoom:50%;" />



- write pos 和 checkpoint 的移动都是顺时针方向；
- write pos ～ checkpoint 之间的部分（图中的红色部分），用来记录新的更新操作；
- check point ～ write pos 之间的部分（图中蓝色部分）：**待落盘的脏数据页记录；**

如果 write pos 追上了 checkpoint，就意味着 **redo log 文件满了，这时 MySQL 不能再执行新的更新操作，也就是说 MySQL 会被阻塞**，此时**会停下来将 Buffer Pool 中的脏页刷新到磁盘中，然后标记 redo log 哪些记录可以被擦除，接着对旧的 redo log 记录进行擦除，等擦除完旧记录腾出了空间，checkpoint 就会往后移动（图中顺时针）**，然后 MySQL 恢复正常运行，继续执行新的更新操作

所以，一次 checkpoint 的过程就是脏页刷新到磁盘中变成干净页，然后标记 redo log 哪些记录可以被覆盖的过程













### bin log

MySQL 在完成一条更新操作后，`Server` 层还会生成一条 `binlog`(**redo log是在事务进行中每执行一条增删改操作后，先记录对应的redo log到buffer pool中的redo log buffer里，后续再刷盘**)，等之后事务提交的时候，会将该事物执行过程中产生的所有 `binlog` 统一写入 `binlog` 文件

MySQL的Binlog（二进制日志）和Redo Log（重做日志）是两种不同的日志机制，用于不同的目的，并在MySQL中扮演不同的角色。

1. Binlog（二进制日志）：
   - Binlog是MySQL的主要日志，用于记录对数据库进行的修改操作，如INSERT、UPDATE、DELETE等
   - Binlog通常用于实现数据复制（replication）和恢复（recovery）操作。它可以被其他MySQL实例（如从服务器）读取和应用，以保持数据的一致性和复制更新操作
   - Binlog是**逻辑日志(仅仅在statement格式下)**，它记录的是SQL语句的逻辑操作，而不是物理操作
   
2. Redo Log（重做日志）：
   - Redo Log是Innodb的事务日志，用于记录数据库的物理修改操作，如数据页的插入、更新和删除操作
   - Redo Log以循环写（circular write）的方式记录，是一个持久的、顺序追加的日志文件
   - Redo Log的目的是为了确保在系统崩溃或意外断电等情况下，可以将尚未持久化到磁盘的事务修改重新应用，保持数据的一致性
   - Redo Log是**物理日志**，它记录的是innodb引擎层面的物理修改操作，以便在崩溃恢复时重新执行这些操作，保证事务的持久性
   
   

> 逻辑日志是指MySQL中的二进制日志（binary log）。它是MySQL服务器将所有修改数据的操作记录下来的一种方式。逻辑日志以一种通用的、与具体存储引擎无关的格式记录了数据库的逻辑操作，如插入（INSERT）、更新（UPDATE）、删除（DELETE）等。**逻辑日志记录的是SQL语句的逻辑内容(同样是只是在statement格式下)**，而不是具体的物理修改
>
> 
>
> 物理日志它记录了对数据库中数据进行物理修改的详细信息。物理日志以一种与具体存储引擎相关的格式记录了数据库的物理操作，如在磁盘上的页或块中进行的插入、更新和删除。物理日志记录了具体的修改，而不仅仅是SQL语句的逻辑内容，**例如redo log就记录了对innodb中的表空间内的哪个区中的哪个页内的多少偏移量位置处做了XXX修改**



[小林Coding上对binlog和redo log的区别总结:](https://xiaolincoding.com/mysql/log/how_update.html#redo-log-%E5%92%8C-binlog-%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB)

*1、适用对象不同：*

- binlog 是 MySQL 的 Server 层实现的日志，所有存储引擎都可以使用；
- redo log 是 Innodb 存储引擎实现的日志；

*2、文件格式不同：*

- binlog 有 3 种格式类型，分别是 STATEMENT（默认格式）、ROW、 MIXED，区别如下：
  - 基于语句（Statement-Based）格式：
    - **记录的是执行的SQL语句本身**，例如INSERT、UPDATE、DELETE等(只记录修改数据的sql)。
    - 较为简洁，日志文件相对较小。
    - 主要复制的是SQL语句，从服务器在重放时会执行相同的SQL语句来达到数据一致性。
    - 可能存在非确定性的结果，因为某些操作可能依赖于随机因素或系统状态。
  - 基于行（Row-Based）格式：
    - 记录的是对数据行的具体修改，例如将某一行改为什么值
    - 不记录每条sql语句的上下文信息，仅需记录哪条数据被修改了 
  - 混合（Mixed）格式：
    - 是基于sql语句格式和基于行格式的组合
    - 在MySQL中是默认的二进制日志格式
    - 根据具体的操作选择使用基于语句格式还是基于行格式进行记录
    - 大多数情况下使用基于语句格式，但对于某些特殊的操作会切换到基于行格式
    - 既可以复制SQL语句，又可以复制具体的数据行修改操作



- redo log 是物理日志，记录的是在某个数据页做了什么修改，比如对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新；

*3、写入方式不同：*

- bin log 是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志
- redo log 是循环写，日志空间大小是固定，全部写满就从头开始，保存未被刷入磁盘的脏页日志

*4、用途不同：*

- bin log 用于备份恢复、主从复制；
- redo log 用于掉电等故障恢复。







> 如果不小心整个数据库的数据被删除了，能使用 redo log 文件恢复数据吗？

不可以使用 redo log 文件恢复，只能使用 binlog 文件恢复

**因为 redo log 文件是循环写，是会边写边擦除日志的，只记录未被刷入磁盘的数据的物理日志，已经刷入磁盘的数据都会从 redo log 文件里擦除**

binlog 文件保存的是全量的日志，也就是保存了所有数据变更的情况，理论上只要记录在 binlog 上的数据，都可以恢复，所以如果不小心整个数据库的数据被删除了，得用 binlog 文件恢复数据









> **binlog 何时刷盘？**

事务执行过程中，先把日志写到 `binlog cache`（MySQL 给每个线程分配了一片内存用于缓冲 `binlog` ），事务提交的时候，再把 `binlog cache` 写到 `binlog` 文件中，并清空 `binlog cache`

虽然每个线程有自己 `binlog cache`，但是最终都写到同一个 `binlog` 文件：![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/binlogcache.drawio.webp)



- 图中的 `write`，指的就是指把日志写入到 `binlog` 文件(位于内存中)，但是**并没有把数据持久化到磁盘，因为数据还缓存在文件系统的 `page cache` 里**，`write` 的写入速度还是比较快的，因为不涉及磁盘 I/O。
- 图中的 fsync(用于将缓冲区中的数据强制写入磁盘)，才是将`binlog`数据持久化到磁盘的操作，这里就会涉及磁盘 I/O，所以频繁的 fsync 会导致磁盘的 I/O 升高



MySQL提供一个 sync_binlog 参数来控制数据库的 binlog 刷到磁盘上的频率：

- sync_binlog = 0 的时候，表示每次提交事务都只 write，不 fsync，后续交由操作系统决定何时将数据持久化到磁盘；
- sync_binlog = 1 的时候，表示每次提交事务都会 write，然后马上执行 fsync；
- sync_binlog =N(N>1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。









### 主从复制

MySQL 的主从复制依赖于 binlog ，也就是记录 MySQL 上的所有变化并以二进制形式保存在磁盘上。复制的过程就是将 binlog 中的数据从主库传输到从库上

这个过程一般是**异步**的，也就是主库上执行事务操作的线程不会等待复制 binlog 的线程同步完成

MySQL 集群的主从复制过程梳理成 3 个阶段：

- **写入 Binlog**：主库提交事务后 写binlog 日志(write `binlog cache`)，并更新本地存储数据(`fsync`写入磁盘)
- **同步 Binlog**：主库后台启动一个`log dump`线程，把 binlog 复制到所有从库上，每个从库把 binlog 写到暂存日志**`relay log`**中(从库上启动IO线程完成这些操作)
- **回放 Binlog**：从库最后启动一个 SQL 线程来回放 binlog (在数据库中执行事务日志（Binary Log）的内容)，并更新其各自存储引擎中的数据

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E8%BF%87%E7%A8%8B.drawio.webp)

具体详细过程如下：

- MySQL 主库在收到客户端提交事务的请求之后，会先写入 binlog，再提交事务，更新存储引擎中的数据，事务提交完成后，返回给客户端“操作成功”的响应
- 从库会创建一个专门的 I/O 线程，连接主库的 `log dump` 线程，来接收主库的 binlog 日志，**再把 binlog 信息写入 `relay log` 的中继日志里**，再返回给主库“复制成功”的响应
- 从库会创建一个用于回放 binlog 的线程(SQL线程)，去读 `relay log` 中继日志，然后回放 binlog 更新存储引擎中的数据，最终实现主从的数据一致性





`Relay log`的作用有以下几点：

1. 数据传递：主数据库服务器将二进制日志（Binary Log）中的更改操作传输给从数据库服务器。从数据库服务器接收到这些更改操作后，将其记录到 Relay Log 中。
2. 重放操作：从数据库
服务器根据 Relay Log 中的记录，按照相同的顺序重新执行主数据库服务器上的更改操作，这样可以确保从数据库服务器上的数据与主数据库服务器保持一致。
3. 容错恢复：如果从数据库服务器发生故障或断开连接，并重新连接到主数据库服务器，Relay Log 可以用来恢复丢失的更改操作。**从数据库服务器可以根据 Relay Log 中的记录，从上次断开连接的位置继续进行复制**，以确保数据的完整性。
4. **延迟复制**：Relay Log 还可以用于实现主从复制的延迟。 通过在从数据库服务器上保留 Relay Log 的一部分，可以延迟从数据库服务器执行主数据库服务器上的更改操作，从而实现数据复制的延迟效果。



其实主要就是起了缓冲的作用,类似消息队列中的`Broker`

> 关于**延迟复制**：在 MySQL 中，延迟复制是指从数据库服务器在主从复制中故意延迟应用主数据库服务器上的更改操作。延迟复制可以在从服务器上引入一定的时间延迟，使从服务器的数据变更相对于主服务器有一定的滞后。延迟复制的目的有几个可能的原因：
>
> 1. 故障恢复：如果在主服务器上发生了误操作、错误的数据更改或者数据损坏，通过延迟复制，可以提供一定的时间窗口来检测问题并采取必要的措施，例如中止复制或还原到较早的时间点。
> 2. 数据验证：延迟复制可以提供额外的时间来验证主服务器上的更改操作，以确保数据的正确性。在某些情况下，这可以用于检测主服务器上的错误操作或数据冲突。
> 3. 负载控制：延迟复制可以在从服务器上引入一定的延迟，从而减轻从服务器的负载。这对于大型复制环境或者从服务器上同时执行其他重要任务的情况下很有用





**MySQL 主从复制有哪些模型？**

主要有三种：

- **同步复制**：MySQL 主库提交事务的线程要等待所有从库的复制成功响应，才返回客户端结果。这种方式在实际项目中，基本上没法用，原因有两个：一是性能很差，因为要复制到所有节点才返回响应；二是可用性也很差，主库和所有从库任何一个数据库出问题，都会影响业务。
- **异步复制**（默认模型）：MySQL 主库提交事务的线程并不会等待 binlog 同步到各从库，就返回客户端结果。这种模式一旦主库宕机，数据就会发生丢失。
- **半同步复制**：MySQL 5.7 版本之后增加的一种复制方式，介于两者之间，事务线程不用等待所有的从库复制成功响应，只要一部分复制成功响应回来就行，比如一主二从的集群，只要数据成功复制到任意一个从库上，主库的事务线程就可以返回给客户端。这种**半同步复制的方式，兼顾了异步复制和同步复制的优点，即使出现主库宕机，至少还有一个从库有最新的数据，不存在数据丢失的风险**











### Buffer Pool

`Innodb` 存储引擎设计了一个**缓冲池（Buffer Pool）**,来替代`Server`层中的查询缓存(比较鸡肋，一旦涉及到`update`等操作查询缓存就会失效)，`Buffer Pool`（缓冲池）是在内存中的一个重要组件。在`InnoDB`存储引擎中，`Buffer Pool`是一个用于缓存数据库表数据和索引的内存区域

有了 `Buffer Pool` 后：

- 当读取数据时，如果数据存在于 `Buffer Pool` 中，客户端就会直接读取 `Buffer Pool` 中的数据，否则再去磁盘中读取
- 当修改数据时，如果数据存在于 `Buffer Pool` 中，那直接修改 `Buffer Pool` 中数据所在的页，然后将其页设置为脏页（该页的内存数据和磁盘上的数据已经不一致），**为了减少磁盘I/O**，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘



`InnoDB` 会把存储的数据划分为若干个「页」，以页作为磁盘和内存交互的基本单位，一个页的默认大小为 16KB。因此，`Buffer Pool` **同样需要按「页」来划分**

在 MySQL 启动的时候，**`InnoDB` 会为 `Buffer Pool` 申请一片连续的内存空间，然后按照默认的`16KB`的大小划分出一个个的页(对应Innodb中页的大小)， `Buffer Pool` 中的页就叫做缓存页**。此时这些缓存页都是空闲的，之后随着程序的运行，才会有磁盘上的页被缓存到 `Buffer Pool` 中

`Buffer Pool` 除了缓存「索引页」和「数据页」，还包括了 Undo 页，插入缓存、自适应哈希索引、锁信息等等：

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/bufferpool%E5%86%85%E5%AE%B9.drawio.webp" style="zoom: 67%;" />



在开启事务后，`InnoDB` 层更新记录前，首先要记录相应的 `undo log`(如果是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 `undo log`)，`undo log` 会写入 `Buffer Pool` 中的 `Undo` 页面

当我们查询一条记录时，InnoDB 是会把整个页的数据加载到 Buffer Pool 中，将页加载到 Buffer Pool 后，再通过页里的「页目录」去定位到某条具体的记录(分组外二分查找，分组内顺序遍历)







(1) Free 链表： Buffer Pool 是一片连续的内存空间，当 MySQL 运行一段时间后，这片连续的内存空间中的缓存页既有空闲的，也有被使用的。那当我们从磁盘读取数据的时候，总不能通过遍历这一片连续的内存空间来找到空闲的缓存页吧，这样效率太低了。所以，**为了能够快速找到空闲的缓存页，可以使用链表结构，将空闲缓存页的「控制块」作为链表的节点，这个链表称为 Free 链表（空闲链表）**



(2)Flush 链表： 更新数据的时候，不需要每次都要写入磁盘，而是将 Buffer Pool 对应的缓存页标记为**脏页**，然后再由后台线程将脏页写入到磁盘。那为了能快速知道哪些缓存页是脏的，于是就设计出 **Flush 链表**,它跟 Free 链表类似的，链表的节点也是控制块，**区别在于 Flush 链表的元素都是脏页**



(3)LRU 链表：Buffer Pool 的大小是有限的，对于一些频繁访问的数据我们希望可以一直留在 Buffer Pool 中，而一些很少访问的数据希望可以在某些时机可以淘汰掉，从而保证 Buffer Pool 不会因为满了而导致无法再缓存新的数据，同时还能保证常用数据留在 Buffer Pool 中，因此对于Clean Page和Dirty Page都需要使用LRU链表来连接





即 Buffer Pool 里有三种数据页和链表来管理数据:

- Free Page（空闲页），表示此页还未被缓存标记，位于 `Free` 链表；
- Clean Page（干净页），表示此页已被使用(已经有对应的数据页从磁盘加入至该页)，但是页面未发生修改，位于`LRU` 链表;
- Dirty Page（脏页），表示此页「已被使用」且「已经被修改」，其数据和磁盘上的数据已经不一致。当脏页上的数据写入磁盘后，内存数据和磁盘数据一致，那么该页就变成了干净页。脏页同时存在于 `LRU` 链表和 **`Flush` 链表**







> **WAL技术：**

`Buffer Pool` 是基于内存的，而内存总是不可靠，万一断电重启，还没来得及**落盘**的脏页数据就会丢失

为了防止断电导致数据丢失的问题，当有一条记录需要更新的时候，`InnoDB` 引擎就会先更新内存（同时标记为脏页），然后将本次对这个页的修改以 `redo log` 的形式记录下来，**这个时候更新就算完成了**

后续，`InnoDB` 引擎会在适当的时候，由**后台线程将缓存在 `Buffer Pool` 的脏页刷新到磁盘里**，这就是 **WAL （Write-Ahead Logging）技术**

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/wal.webp" style="zoom:67%;" />

在事务提交时，只要先将 redo log 持久化到磁盘即可，可以不需要等到将缓存在 Buffer Pool 里的脏页数据持久化到磁盘。这样当系统崩溃时，虽然脏页数据没有持久化，但是 redo log 已经持久化，接着 MySQL 重启后，可以根据 redo log 的内容，将所有数据恢复到最新的状态



> **脏页什么时候会被刷入磁盘?**

引入了 Buffer Pool 后，当修改数据时，首先是修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页，但是磁盘中还是原数据。因此，脏页需要被刷入磁盘，保证缓存和磁盘数据一致，但是若每次修改数据都刷入磁盘，则性能会很差，因此一般都会在一定时机进行批量刷盘下面几种情况会触发脏页的刷新：

- 当 redo log 日志(位于磁盘上)满了的情况下，会主动触发脏页刷新到磁盘；
- Buffer Pool 空间不足时，需要将一部分数据页淘汰掉，如果淘汰的是脏页，需要先将脏页同步到磁盘；
- MySQL 认为空闲时，后台线程会定期将适量的脏页刷入到磁盘；
- MySQL 正常关闭之前，会把所有的脏页刷入到磁盘；





### 一条sql语句执行时的日志变化

具体更新一条记录 `UPDATE t_user SET name = 'xiaolin' WHERE id = 1;` 的流程如下:

1. 执行器负责具体执行，会调用存储引擎的接口，通过主键索引树搜索获取 id = 1 这一行记录：
   - 如果 id=1 这一行所在的数据页本来就在 buffer pool 中，就直接返回给执行器更新；
   - 如果记录不在 buffer pool，将数据页从磁盘读入到 buffer pool，返回记录给执行器(涉及到在B+树上及每个数据页内部 槽的二分查询、组内部的链表遍历)。
2. 执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样：
   - 如果一样的话就不进行后续更新流程；
   - 如果不一样的话就把更新前的记录和更新后的记录都当作参数传给 InnoDB 层，让 InnoDB 真正的执行更新记录的操作；
3. 开启事务， InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面，不过在内存修改该 Undo 页面后，需要记录对应的 redo log
4. InnoDB 层开始更新记录，会先更新内存（同时标记为脏页），然后将记录写到 redo log 里面，这个时候更新就算完成了。为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。这就是 **WAL 技术**，MySQL 的写操作并不是立刻写到磁盘上，而是先写 redo 日志，然后在合适的时间再将修改的行数据写到磁盘上
6. 在一条更新语句执行完成后，Server层开始记录该语句对应的 binlog，此时记录的 binlog 会被保存到 binlog cache，并没有刷新到硬盘上的 binlog 文件，在事务提交时才会统一将该事务运行过程中的所有 binlog 刷新到硬盘









# Redis





## Redis线程模型



**`Redis` 单线程指的是「接收客户端请求->解析请求 ->进行数据读写等操作->发送数据给客户端」这个过程是由一个线程（主线程）来完成的**，这也是我们常说 `Redis` 是单线程的原因

但是，**`Redis` 程序并不是单线程的**，`Redis` 在启动的时候，是会**启动后台线程**（`BIO`）的：

- **`Redis` 在 2.6 版本**，会启动 2 个后台线程，分别处理关闭文件、AOF 刷盘这两个任务；
- **`Redis` 在 4.0 版本之后**，新增了一个新的后台线程，用来异步释放 `Redis` 内存，也就是 `lazyfree` 线程。例如执行 unlink key / flushdb async / flushall async 等命令，会把这些删除操作交给后台线程来执行，好处是不会导致 Redis 主线程卡顿。因此，当我们要删除一个大 key 的时候，不要使用 del 命令删除，因为 del 是在主线程处理的，这样会导致 `Redis` 主线程卡顿，因此我们应该**使用 unlink 命令来异步删除大key**

之所以 `Redis` 为「**关闭文件、AOF 刷盘、释放内存**」这些任务创建单独的线程来处理，是因为这些任务的操作都是很耗时的，如果把这些任务都放在主线程来处理，那么 `Redis` 主线程就很容易发生阻塞，这样就无法处理后续的请求了

后台线程相当于一个消费者，生产者把耗时任务丢到任务队列中，消费者（BIO）不停轮询这个队列，拿出任务就去执行对应的方法即可

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E5%90%8E%E5%8F%B0%E7%BA%BF%E7%A8%8B.webp" style="zoom:67%;" />

关闭文件、AOF 刷盘、释放内存这三个任务都有各自的任务队列：

- BIO_CLOSE_FILE，关闭文件任务队列：当队列有任务后，后台线程会调用 close(fd) ，将文件关闭；
- BIO_AOF_FSYNC，AOF刷盘任务队列：当 AOF 日志配置成 everysec 选项后，主线程会把 AOF 写日志操作封装成一个任务，也放到队列中。当发现队列有任务后，后台线程会调用 fsync(fd)，将 AOF 文件刷盘，
- BIO_LAZY_FREE，lazy free 任务队列：当队列有任务后，后台线程会 `free(obj)` 释放对象 / `free(dict)` 删除数据库所有对象 / `free(skiplist)` 释放跳表对象





### 单线程模型

Redis 6.0 版本之前的单线程模式如下图：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/redis%E5%8D%95%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B.drawio.webp)





**由于文件事件处理器（file event handler）是单线程方式运行的，所以我们一般都说 Redis 是单线程模型**

> `epoll()`是一种高性能的I/O多路复用机制，用于处理大量并发连接的情况,`epoll()`系统调用提供了一种非阻塞的I/O模型，可以监视多个文件描述符的状态并且在这些文件描述符就绪时通知应用程序进行相应的读写操作
>
> `epoll()`的用法如下：
>
> 1. 创建`epoll`实例：首先，需要通过`epoll_create()`系统调用创建一个`epoll`实例，该实例会返回一个文件描述符，用于标识这个`epoll`实例。
> 2. 添加文件描述符到`epoll`：**使用`epoll_ctl()`系统调用将需要监视的文件描述符添加到`epoll`实例中**(监听Channel)，可以通过设置事件类型（例如可读事件、可写事件等）来指定监视的事件。
> 3. 等待事件就绪：使用`epoll_wait()`系统调用等待文件描述符的事件就绪。**当有一个或多个文件描述符的事件就绪时，`epoll_wait()`会阻塞，并返回就绪的文件描述符以及对应的事件类型**。
> 4. 处理事件**：一旦`epoll_wait()`返回有就绪的文件描述符，应用程序可以通过读取或写入数据来处理这些事件**。
>
> 使用`epoll()`的优势在于它避免了传统的阻塞式I/O模型中的大量线程阻塞等待，从而减少了线程的创建和销毁开销。它可以同时监视大量的文件描述符，提高了系统的并发性能和吞吐量。因此，对于高并发的网络编程，`epoll()`是一种高效的I/O多路复用机制
>
> 
>
> 
>
> 其与`poll()`的对比：
>
> 1. 事件注册：
>    - `poll()`使用`pollfd`结构来注册文件描述符和事件，并通过`poll()`系统调用等待事件就绪
>    - `epoll()`使用`epoll_event`结构来注册文件描述符和事件，并**通过`epoll_wait()`系统调用等待事件就绪**
> 2. 数据结构：
>    - `poll()`使用线性数组来存储注册的文件描述符和事件，需要遍历整个数组来查找就绪的文件描述符，导致性能下降。
>    - `epoll()`使用红黑树来存储文件描述符，并使用双链表来存储就绪的文件描述符，可以快速查找和处理就绪事件。
> 3. 文件描述符数量限制：
>    - `poll()`将所有的文件描述符都存储在一个数组中，因此有一个最大文件描述符数量限制（通常是1024）。
>    - `epoll()`使用红黑树来存储文件描述符，并没有这个限制，可以支持更多的文件描述符。
>
> 综上所述，`epoll()`相比`poll()`在处理大量并发连接时有更高的性能优势，并且没有文件描述符数量的限制。



上图中的蓝色部分是一个事件循环(无限循环，在循环中等待并处理事件的到来)，是由主线程负责的，可以看到网络 I/O 和命令处理都是单线程。 `Redis` 初始化的时候，会做下面这几件事情：

- 首先，调用 `epoll_create()` 创建一个 `epoll` 对象和调用 `socket()` 创建一个服务端 `socket`(ip+port)
- 然后，调用 `bind()` **将套接字绑定到指定的IP地址和端口号上**，同时调用 `listen()` 进入监听状态，等待客户端的连接请求；
- 然后，将调用 `epoll_ctl()` 将 `listen socket` 加入到 `epoll`实例中，同时**注册「连接事件」处理函数**(即该监听`socket`负责处理连接应答)



`Redis` 基于 `Reactor` 模式开发了自己的网络事件处理器：这个处理器被称为文件事件处理器（`file event handler`）

**文件事件处理器使用 I/O 多路复用（`multiplexing`）程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器**

当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关 闭（close）等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。

虽然文件事件处理器以单线程方式运行，但通过使用 I/O 多路复用程序来监听多个套接字，文件事件处理器既实现了高性能的网络通信模型，又可以很好地与 Redis 服务器中其他同样以单线程方式运行的模块进行对接，这保持了 Redis 内部单线程设计的简单性

文件事件处理器（`file event handler`）主要是包含 4 个部分：

- 多个 `socket`（客户端连接）
- IO 多路复用程序（支持多个客户端连接的关键）
- 文件事件分派器（将 `socket` 关联到相应的事件处理器）
- 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）



初始化完后，主线程就进入到一个**事件无限循环函数`EventLoop`**，主要会做以下事情：

- 首先，先调用**处理发送队列函数**，看发送队列里是否有任务，如果有发送任务，则通过 `write` 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发送完，就会注册写事件处理函数，等待 `epoll_wait` 发现可写后再处理 
- 接着，调用 `epoll_wait` 函数等待事件的到来：
  - 如果是**连接事件**到来，则会调用**连接事件处理函数**，该函数会做这些事情：调用 `accpet` 获取已连接的 `socket` -> 调用 `epoll_ctl` 将已连接的 `socket` 加入到 `epoll` -> 注册「读事件」处理函数(将请求连接的客户端Socket方的**文件描述符**加入到`epoll`实例中)；
  - 如果是**读事件**到来，则会调用**读事件处理函数**，该函数会做这些事情：调用 `read` 获取客户端发送的数据 -> 解析命令 -> 处理命令 -> 将客户端对象添加到发送队列 -> 将执行结果写到发送缓存区等待发送；
  - 如果是**写事件**到来，则会调用**写事件处理函数**，该函数会做这些事情：通过 `write` 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发送完，就会继续注册写事件处理函数，等待 `epoll_wait` 发现可写后再处理





### Redis单线程为什么快？

之所以 Redis 采用单线程（网络 I/O 和执行命令）那么快，有如下几个原因：

- 纯内存操作：Redis 的大部分操作**都在内存中完成**，并且采用了高效的数据结构，因此 **Redis 瓶颈可能是机器的内存或者网络带宽，而并非 CPU**，既然 CPU 不是瓶颈，那么自然就采用单线程的解决方案了；
- 避免了线程切换开销：Redis 采用单线程模型可以**避免了多线程之间的竞争**，**省去了多线程切换带来的时间和性能上的开销**，而且不涉及线程同步及锁的竞争；
- Redis 采用了 **I/O 多路复用机制**处理大量的客户端 Socket 请求，IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听 Socket 和已连接 Socket。内核会一直监听这些 Socket 上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果；
- **非持久化特性：Redis默认情况下不进行数据持久化**，只将数据保存在内存中，不需要进行频繁的磁盘读写，提高了读写性能；





### 多线程模型

虽然 Redis 的主要工作（**网络 I/O 和执行命令**）一直是单线程模型，但是**在 Redis 6.0 版本之后，也采用了多个 I/O 线程来处理网络请求**，**这是因为随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 I/O 的处理上**

为了提高网络 I/O 的并行度，Redis 6.0 对于网络 I/O 采用多线程来处理。**但是对于命令的执行，Redis 仍然使用单线程来处理，所以不要误解** **Redis 由多线程同时执行命令**

Redis 6.0 版本支持的 I/O 多线程特性，默认情况下 I/O 多线程只针对发送响应数据（`write client socket`），并不会以多线程的方式处理读请求（`read client socket`）。要想开启多线程处理客户端读请求，就需要把 Redis.conf 配置文件中的 io-threads-do-reads 配置项设为 yes。

```conf
//读请求也使用io多线程
io-threads-do-reads yes 
```

同时， Redis.conf 配置文件中提供了 IO 多线程个数的配置项。

```conf
// io-threads N，表示启用 N-1 个 I/O 多线程（主线程也算一个 I/O 线程）
io-threads 4 
```



因此， Redis 6.0 版本之后，Redis 在启动的时候，默认情况下会**额外创建 6 个线程**（*这里的线程数不包括主线程*）：

- Redis-server ： Redis的主线程，主要负责执行命令；
- bio_close_file、bio_aof_fsync、bio_lazy_free：三个后台线程，分别异步处理关闭文件任务、AOF刷盘任务、释放内存任务；
- io_thd_1、io_thd_2、io_thd_3：三个 I/O 线程，io-threads 默认是 4 ，所以会启动 3（4-1）个 I/O 多线程，用来分担 Redis 网络 I/O 的压力



















## 基本数据类型

总览：

Redis 提供了丰富的数据类型，常见的有五种数据类型：**String（字符串），Hash（哈希），List（列表），Set（集合）、Zset（有序集合）** `Redis` 五种数据类型的应用场景：

- String 类型的应用场景：**缓存对象**、常规计数、**分布式锁**、**共享 session 信息**
- List 类型的应用场景：**消息队列**（但是有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等
- Hash 类型**：缓存对象**、购物车等
- Set 类型：聚合计算（并集、交集、差集）场景，比如**点赞**、**共同关注**、抽奖活动等
- Zset 类型：排序场景，比如**排行榜**、电话和姓名排序等

Redis 后续版本又支持四种数据类型，它们的应用场景如下：

- BitMap（2.2 版新增）：二值状态统计的场景，比如签到、判断用户登陆状态、连续签到用户总数等；
- HyperLogLog（2.8 版新增）：海量数据基数统计的场景，比如百万级网页 UV 计数等；
- GEO（3.2 版新增）：存储地理位置信息的场景，比如滴滴叫车；
- Stream（5.0 版新增）：消息队列，相比于基于 List 类型实现的消息队列，有这两个特有的特性：**自动生成全局唯一性消息ID**，支持**以消费组形式消费数据**









### String

`String` 类型的底层的数据结构实现主要是  `SDS`（简单动态字符串）

- **SDS 不仅可以保存文本数据，还可以保存二进制数据**。SDS 的所有 API 都会以处理二进制的方式来处理 SDS 存放在 `buf[]` 数组里的数据。所以 SDS 不光能存放文本数据，而且能保存图片、音频、视频、压缩文件这样的二进制数据
- **SDS 获取字符串长度的时间复杂度是 O(1)** 因为 C 语言的字符串并不记录自身长度，所以获取长度的复杂度为 O(n)；而 `SDS`对应的结构体里用 `len` 属性记录了字符串长度，所以复杂度为 `O(1)`





> **什么是SDS?**

Redis没有直接使用C语言传统的字符串表示(以空字符结尾的字符数组)，而是使用了`SDS`，SDS的底层实现是一个结构体，它包含三个字段：

1. `len`：一个整数类型的字段，用于**记录SDS中保存的字符串的长度**。这个字段表示了SDS中实际保存的字符数量，不包括结尾的空字符'\0'。
2. `free`：一个整数类型的字段，表示SDS中未使用的字节数量。这个字段用于在SDS扩展时记录可用的未使用空间大小。
3. `buf`：一个字节数组，用于存储实际的字符串数据。SDS中的字符数据存储在这个缓冲区中。

```c
struct sdshdr {
    int len;        // 字符串的实际长度
    int free;       // 未使用的空间大小
    char buf[];     // 字符串数据
};
```

SDS的实现使用了C语言的**柔性数组**（flexible array member——可变长度+动态内存分配）特性，`buf`字段可以动态地根据实际需要分配内存空间。这使得SDS可以根据字符串的长度**动态调整**自己的大小，从而节省内存并提高效率。

SDS的动态调整大小操作主要包括：

1. 在字符串长度增加时，SDS会自动分配更多的内存空间，以适应新的长度，并更新`free`字段的值。
2. 在字符串长度减小时，SDS会自动回收多余的内存空间，并更新`free`字段的值。

通过这种方式，SDS可以灵活地管理内存，避免了频繁的内存重新分配操作，提高了性能并减少了内存碎片的产生。





>  SDS如何实现动态扩展？

当SDS需要扩展（增加长度）以容纳更多的字符时，它会执行以下步骤来动态调整大小：

1. 计算新的长度：首先，SDS会根据需要添加的字符数计算出新的长度。新的长度等于当前字符串长度加上要添加的字符数。
2. 检查是否需要扩展：SDS会检查是否有足够的未使用空间（`free`字段的值）来容纳新的字符。如果有足够的未使用空间，那么无需进行扩展操作。
3. 扩展内存：如果没有足够的未使用空间，SDS就需要进行扩展操作。它会根据需要的新长度，重新分配一块更大的内存区域来容纳新的字符数据。
4. 复制数据：在分配新的内存区域后，SDS会将原有的字符串数据复制到新的内存区域中。
5. 更新长度和未使用空间：完成数据复制后，SDS会更新`len`字段为新的长度，并且计算新的未使用空间大小，然后更新`free`字段的值。



来看一个例子就知道了,首先，我们创建一个空的String类型的键，键名为"my_string"：

```shell
SET my_string ""
```

此时，Redis会创建一个空的SDS对象来存储空字符串

然后，我们对该键进行字符串的追加操作，向"my_string"键中追加10个字符的字符串：

```shell
APPEND my_string "HelloWorld!"
```

由于"my_string"键中当前的SDS对象空间较小，无法容纳10个字符的字符串，所以SDS会进行动态扩展。它会重新分配一个更大的内存空间，将原有的数据"Hello"复制到新的内存区域，并将字符串"World!"追加到新的内存空间中。此时，SDS的结构可能类似于下面：

```shell
+--------+--------+----------------------------+
|  len   |  free  |          buf (数据区)       |
+--------+--------+----------------------------+
|   10   |   2    |  "Hello"World!" (新数据区)  |
+--------+--------+----------------------------+
```

接着，我们再对"my_string"键进行设置操作，将一个长度为15的新字符串赋值给它：

```shell
SET my_string "This is a new string!"
```

由于新字符串的长度为15，超过了原有SDS的长度10，SDS需要进行动态扩展。它会重新分配一个足够大的内存空间，将新字符串复制到新的内存区域，并更新SDS的长度和未使用空间字段。此时，SDS的结构可能类似于下面：

```shell
+--------+--------+---------------------------+
|  len   |  free  |       buf (新数据区)       |
+--------+--------+---------------------------+
|   21   |   5    |  "This is a new string!"  |
+--------+--------+---------------------------+
```





**应用场景:**

（1）String常用来缓存对象,有以下两种方式：

直接缓存整个对象的JSON，`SET user:1 '{"name":"xiaolin", "age":18}'`

采用将 key 进行分离为 user:ID:属性，采用 `MSET`(**Mutil-Set**) 存储，用 `MGET` 获取各属性值，命令例子： `MSET user:1:name xiaolin   user:1:age 18 `

示例：使用`Redisson`来缓存对象：

```java
config.useSingleServer().setAddress("redis://localhost:6379"); 
// 替换成实际的Redis地址和端口
       RedissonClient redisson = Redisson.create(config);
        // 创建一个用户信息对象
        UserInfo user = new UserInfo();
        user.setId("1");
        user.setName("John Doe");
        user.setAge(30);

        // 将用户信息对象存储到Redis缓存中，每个用户对象对应一个Bucket
        RBucket<UserInfo> bucket = redisson.getBucket("user:" + user.getId());
        bucket.set(user);
        
                // 从Redis缓存中获取用户信息对象
        UserInfo cachedUser = bucket.get();
        
        
        
        // 关闭Redisson客户端
        redisson.shutdown();
```

`Redisson`中设置`Bucket`的方法：

```
  @Override
    public <V> RBucket<V> getBucket(String name) {
        return new RedissonBucket<V>(connectionManager.getCommandExecutor(), name);
    }
```







（2）常规计数：因为 Redis 处理命令是单线程，所以执行命令的过程是原子的。因此 String 数据类型适合计数场景，比如计算访问次数、点赞、转发、库存数量





（3）**分布式锁**：SET 命令有个 NX 参数可以实现「key不存在才插入」，可以用它来实现分布式锁：

- 如果 key 不存在，则显示插入成功，可以用来表示加锁成功；
- 如果 key 存在，则会显示插入失败，可以用来表示加锁失败。

一般而言，还会对分布式锁加上过期时间，分布式锁的命令如下：

```shell
SET lock_key unique_value NX PX 10000
```

- lock_key 就是 key 键；
- unique_value 是客户端生成的唯一的标识；
- NX 代表只在 lock_key 不存在时，才对 lock_key 进行设置操作；
- PX 10000 表示设置 lock_key 的过期时间为 10s，这是为了避免客户端发生异常而无法释放锁



而解锁的过程就是将 `lock_key` 键删除，但不能乱删，要**保证执行删锁操作的客户端就是加锁的客户端**。所以解锁的时候，我们要先判断锁的 `unique_value` 是否为加锁客户端，是的话，才将 `lock_key` 键删除

可以看到，解锁是有两个操作，这时就需要 **Lua 脚本**来保证解锁的原子性(参考[Lua脚本实现分布式锁](https://www.cnblogs.com/niceyoo/p/13711149.html))，因为 Redis 在执行 Lua 脚本时，可以以原子性的方式执行，保证了锁释放操作的原子性：

```lua
// 释放锁时，先比较 unique_value 是否相等，避免锁的误释放
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end

//lua脚本示例
```

这样一来，就通过使用 SET 命令和 Lua 脚本在 Redis 单节点上完成了分布式锁的加锁和解锁



> 为什么Redis执行lua脚本的时候可以保证原子性？
>
>  
>
> 在Redis中，Lua脚本能够保证原子性的主要原因还是**Redis采用了单线程**执行模型。也就是说，当Redis执行Lua脚本时，Redis**会把Lua脚本作为一个整体并把它当作一个任务加入到一个队列中**，然后单线程按照队列的顺序依次执行这些任务，**在执行过程中Lua脚本是不会被其他命令或请求打断**，因此可以保证每个任务的执行都是原子性的





(4) **共享 `Session` 信息**: 通常我们在开发后台管理系统时，会使用 `Session` 来保存用户的会话(登录)状态，这些 `Session` 信息会被保存在服务器端，但这只适用于单系统应用，如果是分布式系统此模式将不再适用。例如用户一的 `Session` 信息被存储在服务器一，但第二次访问时用户一被分配到服务器二，这个时候服务器并没有用户一的 `Session` 信息，就会出现**需要重复登录**的问题，问题在于分布式系统每次会把请求随机分配到不同的服务器，因此，我们需要**借助 `Redis` 对这些 `Session` 信息进行统一的存储和管理，这样无论请求发送到那台服务器，服务器都会去同一个 `Redis` 获取相关的 `Session` 信息**，这样就解决了分布式系统下 `Session` 存储的问题

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/session%E5%85%B1%E4%BA%AB.png)







### List



**底层实现：**

旧版本下 使用 `ziplist`+`linkedlist`

- 如果列表的元素个数小于 `512` 个（默认值，可由 `list-max-ziplist-entries` 配置），列表每个元素的值都小于 `64` 字节（默认值，可由 `list-max-ziplist-value` 配置），Redis 会使用**压缩列表**作为 List 类型的底层数据结构；
- 如果列表的元素不满足上面的条件，Redis 会使用**双向链表**作为 List 类型的底层数据结构；

新版本下 **在 Redis 3.2 版本之后，List 数据类型底层数据结构就只由 `quicklist` 实现了，替代了双向链表和压缩列表**







常用命令如下：

```shell
# 将一个或多个值value插入到key列表的表头(最左边)，最后的值在最前面
LPUSH key value [value ...] 
# 将一个或多个值value插入到key列表的表尾(最右边)
RPUSH key value [value ...]
# 返回列表key中指定区间内的元素，区间以偏移量start和stop指定，从0开始
LRANGE key start stop
```



例如操作`player`这个`list`:

```shell
127.0.0.1:6379> lpush player   cadian teses jabbi siush
(integer) 4
127.0.0.1:6379> rpush player stavn 
(integer) 5
```



结果如下所示：

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/player_list.png" style="zoom: 80%;" />









**应用场景:**

（1）消息队列：消息队列在存取消息时，必须要满足三个需求，分别是**消息保序、处理重复的消息和保证消息可靠性**。Redis 的 List 和 Stream 两种数据类型，就可以满足消息队列的这三个需求。List 可以使用 LPUSH + RPOP （或者反过来，RPUSH+LPOP）命令实现消息队列：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/list%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97.jpg)

不过，在消费者读取数据时，有一个潜在的性能风险点：
**在生产者往 List 中写入数据时，List 并不会主动地通知消费者有新消息写入，如果消费者想要及时处理消息，就需要在程序中不停地调用 `RPOP` 命令**（比如使用一个while(1)循环）。如果有新消息写入，RPOP命令就会返回结果，否则，RPOP命令返回空值，再继续循环。所以，即使没有新消息写入List，消费者也要不停地调用 RPOP 命令，这就会导致消费者程序的 CPU 一直消耗在执行 RPOP 命令上，带来不必要的性能损失，为了解决这个问题，Redis提供了 BRPOP(`Blocking Right Pop`) 命令。**BRPOP命令也称为阻塞式读取(阻塞市等待期间线程不消耗CPU资源的)，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列，再开始读取新数据**。和消费者程序自己不停地调用RPOP命令相比，这种方式能节省CPU开销

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/BRpop%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97.jpg)

同时消费者要实现重复消息的判断，这需要2个方面的要求：

- 每个消息都有一个全局的 ID
- 消费者要记录已经处理过的消息的 ID。当收到一条消息后，消费者程序就可以对比收到的消息 ID 和记录的已处理过的消息 ID，来判断当前收到的消息有没有经过处理。如果已经处理过，那么，消费者程序就不再进行处理了

但是 **List 并不会为每个消息生成 ID 号，所以我们需要自行为每个消息生成一个全局唯一ID**，生成之后，我们在用 LPUSH 命令把消息插入 List 时，需要在消息中包含这个全局唯一 ID。例如，执行以下命令，就把一条全局 ID 为 111000102、库存量为 99 的消息插入了消息队列：

```shell
> LPUSH mq "111000102:stock:99"
(integer) 1
```

基于 List 类型的消息队列，满足消息队列的三大需求（消息保序、处理重复的消息和保证消息可靠性）

- 消息保序：使用 LPUSH + RPOP；
- 阻塞读取：使用 BRPOP；
- 重复消息处理：生产者自行实现全局唯一 ID；
- 消息的可靠性：使用 BRPOP、LPUSH







> List 作为消息队列有什么缺陷？

**List 不支持多个消费者消费同一条消息**，因为一旦消费者拉取一条消息后，这条消息就从 List 中删除了，无法被其它消费者再次消费。要实现一条消息可以被多个消费者消费，那么就要将多个消费者组成一个消费组，使得多个消费者可以消费同一条消息(让一条消息转发至对应的组内，组内所有成员都可以收到消息)，但是 **List 类型并不支持消费组的实现**(实际上是发布订阅模式)。



 Redis 从 5.0 版本开始提供的 Stream 数据类型了，Stream 同样能够满足消息队列的三大需求，而且它还支持「消费组」形式的消息读取。

### Hash

Hash 是一个键值对（key - value）集合，其中 value 的形式如： `value=[{field1，value1}，...{fieldN，valueN}]`。Hash 特别适合用于存储对象,Hash 与 String 对象的区别如下图所示:![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/hash-string-difference.jpg)


常用命令如下：

```shell
SET user '{"name":"harrykane", "age":29}'   #String类型 Json存储User对象

HMSET user1   name harrykane age 30            #Hash存储Player对象,key为实体类名，field-value为键值对

### 可以使用如下命令，将用户对象的信息存储到 Hash 类型
HMSET uid:1 name Tom age 15
HMSET uid:2 name Jerry age 13
HMSET uid:3 name David age 20

#获取uid为1对象操作如下：
HGETALL  uid:1
1) "name"
2) "Tom"
3) "age"
4) "15"
```

上面介绍到String + Json也是存储对象的一种方式，那么存储对象时，那么到底用 String + json 还是用 Hash 呢？实际上一般对象用String + Json 存储，对象中某些频繁变化的属性可以考虑抽出来用 Hash 类型存储(因为String用的SDS动态字符串)



### Set&Zset

Set 类型是一个无序并唯一的键值集合，它的存储顺序不会按照插入的先后顺序进行存储,Set 类型和 List 类型的区别如下：

- List 可以存储重复元素，**Set 只能存储非重复元素**；
- List 是按照元素的先后顺序存储元素的，而 Set 则是无序方式存储元素的



内部实现：

Set 类型的底层数据结构是由**哈希表或整数集合**实现的：

- 如果集合中的元素都是整数且元素个数小于 `512` （默认值，`set-maxintset-entries`配置）个，Redis 会使用**整数集合**作为 Set 类型的底层数据结构；
- 如果集合中的元素不满足上面条件，则 Redis 使用**哈希表**作为 Set 类型的底层数据结构





Set 类型比较适合用来数据去重和保障数据的唯一性,例如点赞,Set 类型可以保证一个用户只能点一个赞；Set 类型同时支持交集运算，所以可以用来计算共同关注的好友、公众号等



1.计算点赞量

Set 类型可以保证一个用户只能点一个赞，这里举例子一个场景，key 是文章id，value 是用户id,

- 查看文章article2有哪些用户点赞了(每个用户只能点一次赞)：

```shell
127.0.0.1:6379> SADD article2 user1 user2 user3 user4
(integer) 4
```

- 查看哪些用户给article2和article1均点了赞(计算交集)：

```shell
127.0.0.1:6379> SINTER article2  article1 
1) "user3"
2) "user2"
3) "user1"
```







`Zset` 类型（也称`SortedSet`）相比于 Set 类型多了一个排序属性 score（分值），对于有序集合 `Zset` 来说，每个存储元素相当于有两个值组成的，一个是有序集合的元素值，一个是排序值。有序集合保留了集合不能有重复成员的特性（分值可以重复），但不同的是**有序集合中的元素可以排序**:

![Zset](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/zset.jpg)



内部实现：

`Zset` 类型的底层数据结构是由**压缩列表或跳表**实现的：

- 如果有序集合的元素个数小于 `128` 个，并且每个元素的值小于 `64` 字节时，Redis 会使用**压缩列表**作为 Zset 类型的底层数据结构；
- 如果有序集合的元素不满足上面的条件，Redis 会使用**跳表**作为 Zset 类型的底层数据结构；



Zset 类型（Sorted Set，有序集合） 可以**根据元素的权重**来排序，可以自己来决定每个元素的权重值。比如说，我们可以根据元素插入 Sorted Set 的时间确定权重值，先插入的元素权重小，后插入的元素权重大,在面对需要展示最新列表、排行榜等场景时，如果数据更新频繁或者需要分页显示，可以优先考虑使用 Sorted Set,有序集合比较典型的使用场景就是排行榜。例如学生成绩的排名榜、游戏积分排行榜、视频播放排名、电商系统中商品的销量排名等。

以博文点赞排名为例，小林发表了五篇博文，分别获得赞为 200、40、100、50、150

```shell
# 往有序集合key中加入带分值元素
ZADD key score member [[score member]...] 

# arcticle:1 文章获得了200个赞
> ZADD user:xiaolin:ranking 200 arcticle:1
(integer) 1
# arcticle:2 文章获得了40个赞
> ZADD user:xiaolin:ranking 40 arcticle:2
(integer) 1
# arcticle:3 文章获得了100个赞
> ZADD user:xiaolin:ranking 100 arcticle:3
(integer) 1
# arcticle:4 文章获得了50个赞
> ZADD user:xiaolin:ranking 50 arcticle:4
(integer) 1
# arcticle:5 文章获得了150个赞
> ZADD user:xiaolin:ranking 150 arcticle:5
(integer) 1
```

获取小林文章赞数最多的 3 篇文章，可以使用 ZREVRANGE 命令（倒序获取有序集合 key 从start下标到stop下标的元素）：

```shell
# WITHSCORES 表示把 score 也显示出来
> ZREVRANGE user:xiaolin:ranking 0 2 WITHSCORES
1) "arcticle:1"
2) "200"
3) "arcticle:5"
4) "150"
5) "arcticle:3"
6) "100"
```



比如用来统计一个学生的成绩排名：

```shell
127.0.0.1:6379> ZADD  kane 155 course1 165 course2  250 course3 55 course4 100 course5
(integer) 5

#获取该学生成绩最高的三门课
127.0.0.1:6379> zrevrange kane 0 2 withscores
1) "course3"
2) "250"
3) "course2"
4) "165"
5) "course1"
6) "155"
```





### BitMap

位图，是一串连续的二进制数组（0和1），可以通过偏移量（offset）定位元素。`BitMap`通过最小的单位bit来进行`0|1`的设置，表示某个元素的值或者状态，`BitMap`特别适合一些数据量大且使用**二值统计的场景**



**内部实现：**

Bitmap 本身是用 String 类型作为底层数据结构实现的一种统计二值状态的数据类型

String 类型是会保存为二进制的字节数组，所以，Redis 就把字节数组的每个 bit 位利用起来，用来表示一个元素的二值状态，你可以把 Bitmap 看作是一个 bit 数组



**应用场景：**

1. 用户在线状态：可以使用Bitmap来跟踪用户的在线状态。每个位代表一个用户，如果用户在线则设置为1，离线则设置为0
2. 布隆过滤器（Bloom Filter）：Bitmap是**布隆过滤器**的基本实现之一。可以**使用Bitmap来快速判断某个元素是否在集合中，虽然有一定的误判率**，但是在处理大规模数据时，性能非常高效





来看几个例子吧：

(1) 在签到打卡的场景中，我们只用记录签到（1）或未签到（0），所以它就是非常典型的二值状态。签到统计时，每个用户一天的签到用 1 个 bit 位就能表示，一个月（假设是 31 天）的签到情况用 31 个 bit 位就可以，而一年的签到也只需要用 365 个 bit 位，根本不用太复杂的集合类型。假设我们要统计id为100的用户在2023年6月的签到情况，可以按照下面步骤来进行：

```shell
# 用户ID为1001，在1月1日、1月5日和1月20日签到
SETBIT user_signins:1001 1 1
SETBIT user_signins:1001 5 1
SETBIT user_signins:1001 20 1

```

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/bitmap.png" style="zoom:67%;" />

可以看到第1位、第5位、第20位已经被置为1了





(2)判断用户是否在线



假如我们要判断 ID = 10086 的用户的登陆情况：

第一步，执行以下指令，表示用户已登录

```shell
SETBIT login_status 10086 1
```

第二步，检查该用户是否登陆，返回值 1 表示已登录

```shell
GETBIT login_status 10086
```

第三步，登出，将 offset 对应的 value 设置成 0

```shell
SETBIT login_status 10086 0
```







### Stream

Redis Stream 是 Redis 5.0 版本新增加的数据类型，Redis 专门为消息队列设计的数据类型。

在 Redis 5.0 Stream 没出来之前，消息队列的实现方式都有着各自的缺陷，例如：

- 发布订阅模式，不能持久化也就无法可靠的保存消息，并且对于离线重连的客户端不能读取历史消息的缺陷；
- List 实现消息队列的方式不能重复消费，一个消息消费完就会被删除，而且**生产者需要自行实现全局唯一 ID**。

基于以上问题，Redis 5.0 便推出了 Stream 类型也是此版本最重要的功能，用于完美地实现消息队列，它支持消息的持久化、支持自动生成全局唯一 ID、支持 ack 确认消息的模式、支持消费组模式等，让消息队列更加的稳定和可靠





#### 消息队列

Stream 可以使用 **`XGROUP` 创建消费组**，创建消费组之后，Stream 可以使用 `XREADGROUP` 命令让消费组内的消费者读取消息,创建两个消费组，这两个消费组消费的消息队列是 `mymq`，都指定从第一条消息开始读取：

```shell
# 创建一个名为 group1 的消费组，0-0 表示从第一条消息开始读取。
> XGROUP CREATE mymq group1 0-0
OK
# 创建一个名为 group2 的消费组，0-0 表示从第一条消息开始读取。
> XGROUP CREATE mymq group2 0-0
OK
```

消息队列中的**某一条消息**一旦被消费组里的一个消费者读取了，就不能再被该消费组内的其他消费者读取了，即同一个消费组里的消费者不能消费同一条消息，但是，**不同消费组的消费者可以消费同一条消息（但是有前提条件，创建消息组的时候，不同消费组指定了相同位置开始读取消息**:

```shell
127.0.0.1:6379> xadd  mymq *  name xiaolin
"1679378689141-0"
127.0.0.1:6379> XGROUP CREATE mymq group1 0-0
OK
127.0.0.1:6379>  XGROUP CREATE mymq group2 0-0
OK
127.0.0.1:6379> XREADGROUP GROUP group1 consumer1 STREAMS mymq >
1) 1) "mymq"
   2) 1) 1) "1679378689141-0"
         2) 1) "name"
            2) "xiaolin"
127.0.0.1:6379> XREADGROUP GROUP group1 consumer1 STREAMS mymq >
(nil)
127.0.0.1:6379> XREADGROUP GROUP group1 consumer2 STREAMS mymq >
(nil)
127.0.0.1:6379> XREADGROUP GROUP group2 consumer1 STREAMS mymq >
1) 1) "mymq"
   2) 1) 1) "1679378689141-0"
         2) 1) "name"
            2) "xiaolin"

```

使用消费组的目的是让组内的多个消费者共同分担读取消息，所以，我们通常会让每个消费者读取部分消息，从而实现消息读取负载在多个消费者间是均衡分布的，如下所示：

```shell
##再次添加四条消息，这样mymq中一共有5条消息

127.0.0.1:6379> XADD mymq *  player kane
"1679378913264-0"
127.0.0.1:6379> XADD mymq *  age 30
"1679378922998-0"
127.0.0.1:6379> XADD mymq *  club  spurs
"1679378928773-0"
127.0.0.1:6379> XADD mymq *  number   9
"1679378936160-0"

##设置三个消费者组，观察其读取消息的情况：

127.0.0.1:6379>  XREADGROUP GROUP group2 consumer1 COUNT 1 STREAMS mymq >
1) 1) "mymq"
   2) 1) 1) "1679378913264-0"
         2) 1) "player"
            2) "kane"
127.0.0.1:6379>  XREADGROUP GROUP group1 consumer1 COUNT 1 STREAMS mymq >
1) 1) "mymq"
   2) 1) 1) "1679378913264-0"
         2) 1) "player"
            2) "kane"
127.0.0.1:6379>  XREADGROUP GROUP group3 consumer1 COUNT 1 STREAMS mymq >
1) 1) "mymq"
   2) 1) 1) "1679378689141-0"
         2) 1) "name"
            2) "xiaolin"
127.0.0.1:6379>  XREADGROUP GROUP group3 consumer2 COUNT 1 STREAMS mymq >
1) 1) "mymq"
   2) 1) 1) "1679378913264-0"
         2) 1) "player"
            2) "kane"
127.0.0.1:6379>  XREADGROUP GROUP group3 consumer3 COUNT 1 STREAMS mymq >
1) 1) "mymq"
   2) 1) 1) "1679378922998-0"
         2) 1) "age"
            2) "30"
127.0.0.1:6379>  XREADGROUP GROUP group3 consumer4 COUNT 1 STREAMS mymq >
1) 1) "mymq"
   2) 1) 1) "1679378928773-0"
         2) 1) "club"
            2) "spurs"
127.0.0.1:6379>  XREADGROUP GROUP group3 consumer5 COUNT 1 STREAMS mymq >
1) 1) "mymq"
   2) 1) 1) "1679378936160-0"
         2) 1) "number"
            2) "9"
127.0.0.1:6379>  XREADGROUP GROUP group3 consumer6 COUNT 1 STREAMS mymq >
(nil)
127.0.0.1:6379> 

```

再次验证了同一条消息只能被一个消费者组里的一个消费者consumer所读取，但是可以被不同消费者组的多个消费者所读取，并且，一个队列中的所有消息会被一个消费者组里的所有消费者均匀分配（组内的多个消费者共同分担读取消息，所以，我们通常会让每个消费者读取部分消息，从而实现消息读取负载在多个消费者间是均衡分布的）

> 基于 Stream 实现的消息队列，如何保证消费者在发生故障或宕机再次重启后，仍然可以读取未处理完的消息？

Streams 会自动使用内部队列（也称为 `PENDING List`）留存消费组里每个消费者读取的消息，直到消费者使用 `XACK` 命令通知 Stream“消息已经处理完成”。**消息确认**增加了消息的可靠性，一般在业务处理完成之后，需要执行 `XACK `确认消息已经被消费完成

![Stream-Ack](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E6%B6%88%E6%81%AF%E7%A1%AE%E8%AE%A4.jpg)

如果消费者没有成功处理消息，它就不会给 `Streams` 发送 `XACK` 命令，消息仍然会留存。此时，**消费者可以在重启后，用 `XPENDING` 命令查看已读取、但尚未确认处理完成的消息**，查看 `group2` 中各个消费者**已读取、但尚未确认**的消息个数命令如下：

```shell
127.0.0.1:6379> XPENDING mymq group2
1) (integer) 3
2) "1654254953808-0"  # 表示 group2 中所有消费者读取的消息最小 ID
3) "1654256271337-0"  # 表示 group2 中所有消费者读取的消息最大 ID
4) 1) 1) "consumer1"
      2) "1"
   2) 1) "consumer2"
      2) "1"
   3) 1) "consumer3"
      2) "1"
```





> Redis 基于 Stream 消息队列与专业的消息队列有哪些差距？

1. Redis Stream 消息会丢失吗

- Redis 生产者会不会丢消息？生产者会不会丢消息，取决于生产者对于异常情况的处理是否合理。 **从消息被生产出来，然后提交给 MQ 的过程中，只要能正常收到 （ MQ 中间件） 的 ACK 确认响应，就表示发送成功**，所以只要处理好返回值和异常，如果返回异常则进行消息重发，那么这个阶段是不会出现消息丢失的。

- Redis 消费者会不会丢消息？不会，**因为 Stream （ MQ 中间件）会自动使用内部队列（也称为 PENDING List）留存消费组里每个消费者读取的消息**，**但是未被确认的消息**。消费者可以在重启后，用 XPENDING 命令查看已读取、但尚未确认处理完成的消息。**等到消费者执行完业务逻辑后，再发送消费确认 XACK 命令，也能保证消息的不丢失**

- Redis 消息中间件会不会丢消息？会，Redis 在以下 2 个场景下，都会导致数据丢失：

  - AOF 持久化配置为每秒写盘，但这个写盘过程是异步的，Redis 宕机时会存在数据丢失的可能

  - 主从复制也是异步的，[主从切换时，也存在丢失数据的可能 ](https://xiaolincoding.com/redis/cluster/master_slave_replication.html#redis-主从切换如何减少数据丢失)

Redis 在队列中间件环节无法保证消息不丢。像 `RabbitMQ` 或 `Kafka` 这类专业的队列中间件，在使用时是部署一个集群，生产者在发布消息时，队列中间件通常会写「多个节点」，也就是有多个副本，这样一来，即便其中一个节点挂了，也能保证集群的数据不丢失





*2. Redis Stream 消息可堆积吗？* (主要原因 Redis是基于内存存储的)

Redis 的数据都存储在内存中，这就意味着一旦发生消息积压，则会导致 Redis 的内存持续增长，如果超过机器内存上限，就会面临 `OOM` 的风险。所以 Redis 的 Stream 提供了可以指定队列最大长度的功能。当指定队列最大长度时，队列长度超过上限后，旧消息会被删除，只保留固定长度的新消息。这么来看，Stream 在消息积压时，如果指定了最大长度，还是有可能丢失消息的。但 Kafka、RabbitMQ 专业的消息队列它们的数据都是存储在磁盘上，当消息积压时，无非就是多占用一些磁盘空间







## 持久化



### AOF

Redis 写入 AOF 日志的过程，如下图：

<img src="https://cdn.xiaolincoding.com//mysql/other/4eeef4dd1bedd2ffe0b84d4eaa0dbdea.png" alt="img" style="zoom:50%;" />



1. Redis 执行完写操作命令后，会将命令追加到 `server.aof_buf` 缓冲区；
2. 然后通过 write() 系统调用，将 aof_buf 缓冲区的数据写入到 AOF 文件，此时数据并没有写入到硬盘，而是拷贝到了内核缓冲区 page cache，等待内核将数据写入硬盘；
3. 具体内核缓冲区的数据什么时候写入到硬盘，由内核决定。

Redis 提供了 3 种写回硬盘的策略，控制的就是上面说的第三步的过程。

在 `redis.conf` 配置文件中的 `appendfsync` 配置项可以有以下 3 种参数可填：

- **Always**，这个单词的意思是「总是」，所以它的意思是每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘；
- **Everysec**，这个单词的意思是「每秒」，所以它的意思是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘；(**折中方式，允许最多一秒的数据丢失**)
- **No**，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘

深入到源码后，你就会发现这三种策略只是在控制 `fsync()` 函数的调用时机。

> `fsync()`函数是用于将缓冲区数据同步写入磁盘的系统调用

当应用程序向文件写入数据时，内核通常先将数据复制到内核缓冲区中，然后排入队列，然后由内核决定何时写入硬盘。

- Always 策略就是每次写入 AOF 文件数据后，就执行 fsync() 函数；

- Everysec 策略就会创建一个异步任务来执行 fsync() 函数；

- No 策略就是永不执行 fsync() 函数;



`AOF`的刷盘非常类似`BinLog`的刷盘



#### AOF重写

Redis 为了避免 AOF 文件越写越大，提供了 **AOF 重写机制**，**当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制(注意触发时机！！！)**，来压缩 AOF 文件。AOF 重写机制是**在重写时，读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到「新的 AOF 文件」**，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/aof%E9%87%8D%E5%86%99.jpg)

在使用重写机制后，就会读取 name 最新的 value（键值对） ，然后用一条 「set name xiaolincoding」命令记录到新的 AOF 文件，之前的第一个命令就没有必要记录了，因为它属于「历史」命令，没有作用了。这样一来，一个键值对在重写日志中只用一条命令就行了。重写机制的妙处在于，尽管某个键值对被多条写命令反复修改，**最终也只需要根据这个「键值对」当前的最新状态，然后用一条命令去记录键值对**，代替之前记录这个键值对的多条命令，这样就减少了 AOF 文件中的命令数量

Redis 的**重写 AOF 过程是由后台子进程 `bgrewriteaof`来完成的**

- 子进程进行 AOF 重写期间，主进程可以继续处理命令请求，从而避免阻塞主进程；
- 子进程带有主进程的数据副本（*数据副本怎么产生的后面会说*），这里使用子进程而不是线程，因为如果是使用线程，多线程之间会共享内存，那么在修改共享内存数据的时候，需要通过加锁来保证数据的安全，而这样就会降低性能。而使用子进程，创建子进程时，父子进程是共享内存数据的，不过这个共享的内存只能以只读的方式，而当父子进程任意一方修改了该共享内存，就会发生**「写入时复制」**，于是父子进程就有了独立的数据副本，就不用加锁来保证数据安全。



触发重写机制后，主进程就会创建重写 AOF 的子进程`bgrewriteaof`，此时父子进程共享物理内存，重写子进程只会对这个内存进行只读，重写 AOF 子进程会读取内存数据库里的所有数据，**并逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志（新的 AOF 文件）**

**但是子进程重写过程中，主进程依然可以正常处理命令**

如果此时**主进程修改了已经存在 key-value，就会发生写入时复制，注意这里只会复制主进程修改的物理内存数据，没修改的那部分物理内存还是与子进程共享的**。



> `bigkey`对`AOF`与`RDB`的影响？

所以如果这个阶段修改的是一个 bigkey，也就是数据量比较大的 key-value 的时候，这时复制的物理内存数据的过程就会比较耗时，有阻塞主进程的风险

:question:  再解释一下：对于AOF，最开始会`fork`出一个用于AOF重写的子进程，让该子进程也指向了父进程指向的内存空间；对于RDB持久化，如果使用`bgsave`命令，同样也会`fork`出一个子进程来执行操作。

一旦父进程收到了写操作命令，就会新复制出来一片内存区域(此时和子进程指向的就不是同一片内存区域了)，并在该新内存区域上进行写操作，这样就影响不到子进程进行`aof`重写/`bgsave`进行`rdb`持久化

如果创建完子进程后，**父进程对共享内存中的大 Key 进行了修改，那么内核就会发生写入时复制，会把物理内存复制一份，由于大 Key 占用的物理内存是比较大的，那么在复制物理内存这一过程中，也是比较耗时的，于是父进程（主线程）就会发生阻塞**。

所以，有两个阶段会导致阻塞父进程：

- 创建子进程的途中，**由于要复制父进程的页表等数据结构，阻塞的时间跟页表的大小有关，页表越大，阻塞的时间也越长**；
- 创建完子进程后，如果子进程或者父进程修改了共享数据，就会发生写时复制，这期间会拷贝物理内存，如果内存越大，自然阻塞的时间也越长；









### RDB

RDB 快照就是记录某一个瞬间的内存数据，记录的是**实际数据**(二进制文件，因此可能比较大)，而 AOF 文件记录的是命令操作的日志，而不是实际的数据，故在 Redis 恢复数据时， RDB 恢复数据的效率会比 AOF 高些，因为直接将 RDB 文件读入内存就可以，不需要像 AOF 那样还需要额外执行操作命令的步骤才能恢复数据，Redis 提供了两个命令来生成 RDB 文件，分别是 `save` 和 `bgsave`，他们的区别就在于是否在「主线程」里执行：

- 执行了 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，**会阻塞主线程**；
- 执行了 `bgsave` 命令，会**创建一个子进程**来生成 RDB 文件，这样可以**避免主线程的阻塞**；



> 执行快照时，数据可以被修改吗？

在子进程执行 `bgsave` 过程中，Redis主线程依然**可以继续处理操作命令**的，也就是说数据是能被修改的，这依赖于**写入时复制**（`Copy On Write`）:



执行 bgsave 命令的时候，会通过 `fork()` 创建子进程，此时子进程和父进程是共享同一片内存数据的，因为创建子进程的时候，会复制父进程的页表，但是页表指向的物理内存还是一个。

<img src="https://cdn.xiaolincoding.com//mysql/other/c34a9d1f58d602ff1fe8601f7270baa7.png" alt="图片" style="zoom:67%;" />

只有在发生修改内存数据的情况时，物理内存才会被复制一份。

<img src="https://cdn.xiaolincoding.com//mysql/other/ebd620db8a1af66fbeb8f4d4ef6adc68.png" alt="图片" style="zoom:67%;" />





执行 `bgsave` 命令的时候，会通过 `fork()` 创建子进程，此时子进程和父进程是共享同一片内存数据的，由于共享父进程的所有内存数据，于是就可以直接读取主线程（父进程）里的内存数据，并将数据写入到 RDB 文件

1. 当主线程（父进程）对这些共享的内存数据也都是只读操作，那么，主线程（父进程）和 bgsave 子进程相互不影响
2. 但是，如果主线程（父进程）要**修改共享数据里的某一块数据**时，就会发生写入时复制，于是这块数据的**物理内存就会被复制一份**，然后**主线程在这个数据副本（进行修改操作）**。与此同时，**bgsave 子进程可以继续把原来的数据写入到 RDB 文件**，**这种情况下RDB 快照保存的是原本的内存数据**，而主线程刚修改的数据，是没办法在这一时间写入 RDB 文件的，只能交由下一次的 bgsave 快照



所以 Redis 在使用 bgsave 快照过程中，如果主线程修改了内存数据，不管是否是共享的内存数据，RDB 快照都无法写入主线程刚修改的数据，因为此时主线程（父进程）的内存数据和子进程的内存数据已经分离了，子进程写入到 RDB 文件的内存数据只能是原本的内存数据。





### 混合持久化

将 RDB 和 AOF 合体使用，这个方法是在 Redis 4.0 提出的，该方法叫**混合使用 AOF 日志和内存快照**，也叫混合持久化。如果想要开启混合持久化功能，可以在 Redis 配置文件将下面这个配置项设置成 yes：

```shell
aof-use-rdb-preamble yes
```

当开启了混合持久化时，在 AOF 重写日志时，`fork` 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。

也就是说，使用了混合持久化，AOF 文件的**前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据**。



这样的好处在于重启 Redis 加载数据的时候，由于前半部分是 RDB 内容，这样**加载的时候速度会很快**。加载完 RDB 的内容后，才会加载后半部分的 AOF 内容，这里的内容是 Redis 后台子进程重写 AOF 期间，主线程处理的操作命令(此时发生了写入时复制)，可以使得**数据更少的丢失**









## 高可用

> 补充： Redis删除策略、内存淘汰策略

定时删除策略的做法是，**在设置 key 的过期时间时，同时创建一个定时事件，当时间到达时，由事件处理器自动执行 key 的删除操作**

惰性删除策略的做法是，**不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key**

定期删除策略的做法是，**每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key**

Redis 使用的过期删除策略是「惰性删除+定期删除」，删除的对象是已过期的 key。

内存淘汰策略是解决内存过大的问题，当 Redis 的运行内存超过最大运行内存时，就会触发内存淘汰策略（前面说的过期删除策略，是删除已过期的 key，而当 Redis 的运行内存已经超过 Redis 设置的最大内存之后，则会使用内存淘汰策略删除符合条件的 key，以此来保障 Redis 高效的运行）



### 主从复制

主从复制模式下：主服务器可以进行读写操作，当发生写操作时自动将写操作同步给从服务器，而从服务器一般是只读，并接受主服务器同步过来写操作命令，然后执行这条命令

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6.jpg)

可以使用 `replicaof`（Redis 5.0 之前使用 slaveof）命令形成主服务器和从服务器的关系

比如，现在有服务器 A 和 服务器 B，我们在服务器 B 上执行下面这条命令：

```shell
# 服务器 B 执行这条命令
replicaof <服务器 A 的 IP 地址> <服务器 A 的 Redis 端口号>
```

主从服务器间的第一次同步的过程可分为三个阶段：

- 第一阶段是建立连接、协商同步；

  从服务器就会给主服务器发送 `psync` 命令，表示要进行数据同步。

  psync 命令包含两个参数，分别是**主服务器的 runID** 和**复制进度 offset**。

  - runID，每个 Redis 服务器在启动时都会自动生产一个随机的 ID 来唯一标识自己。当从服务器和主服务器第一次同步时，因为不知道主服务器的 run ID，所以将其设置为 "?"。
  - offset，表示复制的进度，第一次同步时，其值为 -1。

  主服务器收到 psync 命令后，会用 `FULLRESYNC` 作为响应命令返回给对方。

  并且这个响应命令会带上两个参数：主服务器的 runID 和主服务器目前的复制进度 offset。从服务器收到响应后，会记录这两个值。

  FULLRESYNC 响应命令的意图是采用**全量复制**的方式，也就是主服务器会把所有的数据都同步给从服务器





- 第二阶段是主服务器同步数据给从服务器（主服务器会执行 bgsave 命令来生成 RDB 文件，然后把文件发送给从服务器）

  有一点要注意，主服务器生成 RDB 这个过程是不会阻塞主线程的，因为 bgsave 命令是fork了一个子进程来做生成 RDB 文件的工作，是异步工作的，这样 Redis 依然可以正常处理命令。但是，**这期间的写操作命令并没有记录到刚刚生成的 RDB 文件中，这时主从服务器间的数据就不一致了**

  

  为了保证主从服务器的数据一致性，**主服务器在下面这三个时间间隙中将收到的写操作命令，写入到 `replication buffer` 缓冲区里**：

  - 主服务器生成 RDB 文件期间；
  - 主服务器发送 RDB 文件给从服务器期间；
  - 「从服务器」加载 RDB 文件期间；



- 第三阶段是主服务器发送新写操作命令给从服务器

  从服务器收到 RDB 文件后，丢弃所有旧数据，将 RDB 数据载入到内存。完成 RDB 的载入后，会回复一个ACK确认消息给主服务器。接着，主服务器将 `replication buffer` 缓冲区里所记录的写操作命令发送给从服务器，从服务器执行来自主服务器 `replication buffer` 缓冲区里发来的命令，这时主从服务器的数据就一致了。



> Replication Buffer用于暂时保存主节点发送给从节点的数据，包括命令和数据更新。主节点发送数据的速率可能快于从节点接收和执行数据的速率，这可能导致从节点丢失部分数据，尤其在网络传输过程中出现延迟或网络抖动时。为了避免数据丢失，Redis使用Replication Buffer来暂存主节点发送的数据
>
> 
>
> 当从节点准备好接收新的数据时，它会从Replication Buffer中获取数据并应用到自己的数据集中，从而保持与主节点的数据同步。一旦数据在从节点执行成功，从节点会向主节点发送确认，表示已经接收并处理了数据





主从服务器在完成第一次同步后，双方之间就会维护一个 TCP 连接，后续主服务器可以通过这个连接继续将写操作命令传播给从服务器，然后从服务器执行该命令，使得与主服务器的数据库状态相同。而且这个连接是长连接的，目的是避免频繁的 TCP 连接和断开带来的性能开销。上面的这个过程被称为**基于长连接的命令传播**，通过这种方式来保证第一次同步后的主从服务器的数据一致性





主从复制共有三种模式：**全量复制、基于长连接的命令传播、增量复制**

主从服务器第一次同步的时候，就是采用全量复制，此时主服务器会两个耗时的地方，分别是生成 RDB 文件和传输 RDB 文件。为了避免过多的从服务器和主服务器进行全量复制，可以把一部分从服务器升级为「经理角色」，让它也有自己的从服务器，通过这样可以分摊主服务器的压力

第一次同步完成后，主从服务器都会维护着一个长连接，主服务器在接收到写操作命令后，就会通过这个连接将写命令传播给从服务器，来保证主从服务器的数据一致性

如果遇到网络断开又恢复后，主服务器会采用**增量复制**的方式继续同步，也就是说只会把网络断开期间主服务器接收到的写操作命令，同步给从服务器



重点来看看增量复制：

从 Redis 2.8 开始，网络断开又恢复后，主从服务器会采用**增量复制**的方式继续同步，也就是只会把网络断开期间主服务器接收到的写操作命令，同步给从服务器。

<img src="https://cdn.xiaolincoding.com//mysql/other/e081b470870daeb763062bb873a4477e.png" alt="图片" style="zoom: 67%;" />



主要有三个步骤：

- 从服务器在恢复网络后，会发送 psync 命令给主服务器，此时的 psync 命令里的 offset 参数不是 -1(**因为不是第一次同步了!!!**)
- 主服务器收到该命令后，然后用 CONTINUE 响应命令告诉从服务器接下来采用增量复制的方式同步数据
- 然后主服务将主从服务器断线期间，所执行的写命令发送给从服务器，然后从服务器执行这些命令

那么关键的问题来了，**主服务器怎么知道要将哪些增量数据发送给从服务器呢？**









### 哨兵

**哨兵有两项任务：判定主节点宕机下线+投票选出leader**



**哨兵（`Sentinel`）机制**，它的作用是实现**主从节点故障转移**。它会监测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端，**哨兵其实是一个运行在特殊模式下的 Redis 进程，所以它也是一个节点**。从“哨兵”这个名字也可以看得出来，它相当于是“观察者节点”，观察的对象是主从节点

> 如何判断主节点真的故障了？   由哨兵投票决定

哨兵会每隔 1 秒给**所有主从节点**发送 `PING` 命令，当主从节点收到 `PING` 命令后，会发送一个响应命令给哨兵，这样就可以判断它们是否在正常运行，哨兵在部署的时候不会只部署一个节点，而是用多个节点部署成**哨兵集群**，当一个哨兵判断主节点为「主观下线」后，就会向其他哨兵发起命令，其他哨兵收到这个命令后，就会根据自身和主节点的网络状况，做出**赞成投票或者拒绝投票**的响应，当这个哨兵的赞同票数达到哨兵配置文件中的 `quorum `配置项设定的值后，这时主节点就会被该哨兵标记为「客观下线」，并准备执行主从节点切换





(例如，现在有 3 个哨兵，`quorum` 配置的是 2，那么一个哨兵需要 2 张赞成票，就可以标记主节点为“客观下线”了。**这 2 张赞成票包括哨兵自己的一张赞成票和另外两个哨兵的赞成票**。`quorum` 的值一般设置为哨兵个数的二分之一加1，例如 3 个哨兵就设置 2)







哪个哨兵节点判断主节点为「客观下线」，这个哨兵节点就是候选者，所谓的候选者就是想当 `Leader` 的哨兵。

举个例子，假设有三个哨兵。当哨兵 B 先判断到主节点「主观下线后」，就会给其他实例发送 is-master-down-by-addr 命令。接着，其他哨兵会根据自己和主节点的网络连接情况，做出赞成投票或者拒绝投票的响应。

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/sentinel.jpg" style="zoom: 50%;" />

- 单个哨兵判定一个主节点下线 ，这种判定被称为主观下线
- 整个哨兵集群在经过投票判断后判定该主节点下线，这种判定称为**客观下线**



> 谁来进行故障转移？ 谁来当选新的主节点？



**哪个哨兵节点判断主节点为「客观下线」，这个哨兵节点就是候选者**，所谓的候选者就是想当 leader 的哨兵

举个例子，假设有三个哨兵。当哨兵 B 先判断到主节点「主观下线后」，就会给其他实例发送 is-master-down-by-addr 命令。接着，其他哨兵会根据自己和主节点的网络连接情况，做出赞成投票或者拒绝投票的响应



执行切换之前还需要在哨兵集群中选出一个 `leader`（标记客观下线的哨兵向其他哨兵发起投票，询问是否可以当选`leader`），让 `leader` 来进行切换操作

候选者会向其他哨兵发送命令，表明希望成为 `leader` 来执行主从切换，并让所有其他哨兵对它进行投票。

每个哨兵只有一次投票机会，如果用完后就不能参与投票了，可以投给自己或投给别人，但是只有候选者才能把票投给自己。

那么在投票过程中，任何一个「候选者」，要满足两个条件：

- 第一，拿到半数以上的赞成票；
- 第二，拿到的票数同时还需要大于等于哨兵配置文件中的 `quorum` 值



举个例子，假设哨兵节点有 3 个，`quorum` 设置为 2，那么任何一个想成为 `leader` 的哨兵只要拿到 2 张赞成票，就可以选举成功了(**加上自己的一票**)。如果没有满足条件，就需要重新进行选举



> 为什么哨兵节点至少要有 3 个？

如果哨兵集群中只有 2 个哨兵节点，此时如果一个哨兵想要成功成为 Leader，必须获得 2 票，而不是 1 票。

所以，如果哨兵集群中有个哨兵挂掉了，那么就只剩一个哨兵了，如果这个哨兵想要成为 Leader，这时票数就没办法达到 2 票，就无法成功成为 Leader，这时是无法进行主从节点切换的。

因此，通常我们至少会配置 3 个哨兵节点。这时，如果哨兵集群中有个哨兵挂掉了，那么还剩下两个个哨兵，如果这个哨兵想要成为 Leader，这时还是有机会达到 2 票的，所以还是可以选举成功的，不会导致无法进行主从节点切换。



再说一个问题，Redis 1 主 4 从，5 个哨兵 ，quorum 设置为 3，如果 2 个哨兵故障，当主节点宕机时，哨兵能否判断主节点“客观下线”？主从能否自动切换？

- **哨兵集群可以判定主节点“客观下线”**。哨兵集群还剩下 3 个哨兵，当一个哨兵判断主节点“主观下线”后，询问另外 2 个哨兵后，有可能能拿到 3 张赞同票，这时就达到了 quorum 的值，因此，哨兵集群可以判定主节点为“客观下线”。
- **哨兵集群可以完成主从切换**。当有个哨兵标记主节点为「客观下线」后，就会进行选举 Leader 的过程，因为此时哨兵集群还剩下 3 个哨兵，那么还是可以拿到半数以上（5/2+1=3）的票，而且也达到了 quorum 值，满足了选举 Leader 的两个条件， 所以就能选举成功，因此哨兵集群可以完成主从切换。

如果 quorum 设置为 2 ，并且如果有 3 个哨兵故障的话。此时哨兵集群还是可以判定主节点为“客观下线”，但是哨兵不能完成主从切换了，大家可以自己推演下。

如果 quorum 设置为 3，并且如果有 3 个哨兵故障的话，哨兵集群即不能判定主节点为“客观下线”，也不能完成主从切换了。

可以看到，quorum 为 2 的时候，并且如果有 3 个哨兵故障的话，虽然可以判定主节点为“客观下线”，但是不能完成主从切换，这样感觉「判定主节点为客观下线」这件事情白做了一样，既然这样，还不如不要做，quorum 为 3 的时候，就可以避免这种无用功。

所以，**quorum 的值建议设置为哨兵个数的二分之一加1**，例如 3 个哨兵就设置 2，5 个哨兵设置为 3，而且**哨兵节点的数量应该是奇数**。





总结：在`Redis`哨兵中，`quorum`值用于两个方面：

1. 判断节点客观下线时的quorum值：当哨兵节点检测到一个Redis节点不可用时，它会向其他哨兵节点发送投票请求，如果得到的投票数超过quorum值，就认为节点客观下线，并通知其他哨兵节点做出相同的判断。
2. 选举leader时的quorum值：当Redis主节点失效时，哨兵节点会进行领导者选举，每个哨兵会对候选主节点进行投票，如果候选主节点得到的投票数超过quorum值，它将被选举为新的主节点。

通常情况下，判断节点客观下线时的quorum值和选举leader时的quorum值是一样的，都被设置为哨兵节点的大多数（majority），即(N/2) + 1，其中N是哨兵节点的数量。







> 主从故障转移操作包括哪些内容？

主从故障转移操作包含以下四个步骤：

- 第一步：在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点。
- 第二步：让已下线主节点属下的所有「从节点」修改复制目标，修改为复制「新主节点」；
- 第三步：将新主节点的 IP 地址和信息，通过「**发布者/订阅者机制**」通知给客户端(每个哨兵节点提供发布者/订阅者机制，客户端可以从哨兵订阅消息)；
- 第四步：继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E4%B8%BB%E4%BB%8E%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB.jpg)



1.选出新主节点  (和哨兵选举的意义不一样，这次选举是选举出新的主节点)

故障转移操作第一步要做的就是在已下线主节点属下的所有「从节点」中，挑选出一个状态良好、数据完整的从节点，然后向这个「从节点」发送 `SLAVEOF no one` 命令(晋升为新主节点)，将这个「从节点」转换为「主节点」

具体是怎么挑选的呢？

- 第一轮考察：哨兵首先会根据从节点的优先级来进行排序，优先级越高排名越靠前( `slave-priority` 配置项)，
- 第二轮考察：如果优先级相同，则查看复制的下标，哪个从「主节点」接收的复制数据多，哪个就靠前
- 第三轮考察：如果优先级和下标都相同，就选择从节点 ID 较小的那个





2.将从节点指向指向新的主节点

当新主节点出现之后，哨兵 leader 下一步要做的就是，让已下线主节点属下的所有「从节点」指向「新主节点」，这一动作可以通过向「从节点」发送 `SLAVEOF` 命令来实现。





3.通知客户的主节点已更换

每个哨兵节点提供发布者/订阅者机制，客户端可以从哨兵订阅消息。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E5%93%A8%E5%85%B5/%E5%93%A8%E5%85%B5%E9%A2%91%E9%81%93.webp" alt="img" style="zoom:50%;" />

客户端和哨兵建立连接后，客户端会订阅哨兵提供的频道。**主从切换完成后，哨兵就会向 `+switch-master` 频道发布新主节点的 IP 地址和端口的消息，这个时候客户端就可以收到这条信息，然后用这里面的新主节点的 IP 地址和端口进行通信了**





4.将旧主节点变为从节点

故障转移操作最后要做的是，继续监视旧主节点，当旧主节点重新上线时，哨兵集群就会向它发送 `SLAVEOF` 命令，让它成为新主节点的从节点











:grey_exclamation: :heavy_exclamation_mark: :exclamation: 最后总结一下：

 

哨兵一般是以集群的方式部署，至少需要 3 个哨兵节点，哨兵集群主要负责三件事情：**监控、选主、通知**。

哨兵节点通过 Redis 的发布者/订阅者机制，哨兵之间可以相互感知，相互连接，然后组成哨兵集群，同时哨兵又通过 INFO 命令，在主节点里获得了所有从节点连接信息，于是就能和从节点建立连接，并进行监控了。



*1、第一轮投票：判断主节点下线*

当哨兵集群中的某个哨兵判定主节点下线（主观下线）后，就会向其他哨兵发起命令，其他哨兵收到这个命令后，就会根据自身和主节点的网络状况，做出赞成投票或者拒绝投票的响应。

当这个哨兵的赞同票数达到哨兵配置文件中的 quorum 配置项设定的值后，这时主节点就会被该哨兵标记为「客观下线」。



*2、第二轮投票：选出哨兵leader*

某个哨兵判定主节点客观下线后，该哨兵就会发起投票，告诉其他哨兵，它想成为 leader，想成为 leader 的哨兵节点，要满足两个条件：

- 第一，拿到半数以上的赞成票；
- 第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。





*3、由哨兵 leader 进行主从故障转移*

选举出了哨兵 leader 后，就可以进行主从故障转移的过程了。该操作包含以下四个步骤：

- 第一步：在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点，选择的规则：
  - 过滤掉已经离线的从节点；
  - 过滤掉历史网络连接状态不好的从节点；
  - 将剩下的从节点，进行三轮考察：优先级、复制进度、ID 号。在每一轮考察过程中，如果找到了一个胜出的从节点，就将其作为新主节点。
- 第二步：让已下线主节点属下的所有「从节点」修改复制目标，修改为复制「新主节点」；
- 第三步：将新主节点的 IP 地址和信息，通过「发布者/订阅者机制」通知给客户端；
- 第四步：继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点；









### 集群



Redis 的哨兵模式虽然已经可以实现高可用，读写分离 ，但是存在几个方面的不足：

- 哨兵模式下每台 Redis 服务器都存储相同的数据，很浪费内存空间；数据量太大，主从同步时严重影响了master性能。
- 哨兵模式是中心化的集群实现方案，每个从机和主机的耦合度很高，master宕机到salve选举master恢复期间服务不可用。
- 哨兵模式始终只有一个Redis主机来接收和处理写请求，写操作还是受单机瓶颈影响，没有实现真正的分布式架构。



 Redis3.0 上加入了 `Cluster` 集群模式（Redis集群是去中心化的集群架构），同时实现了 Redis 的分布式存储（对数据进行**分片**，也就是说**每台 Redis 节点上存储不同的内容**）

`Redis Cluster`是一种服务器`Sharding`技术(分片和路由都是在服务端实现)，采用多主多从，每一个分区都是由一个Redis主机和多个从机组成，片区和片区之间是相互平行的。`Redis Cluster`集群采用了P2P的模式，完全去中心化



> 什么是服务器`Sharding`？
>
> 
>
> 当应用程序的数据量逐渐增大，单台服务器可能无法承载全部数据和负载。服务器`Sharding`技术将数据分成多个较小的数据集，每个数据集称为一个分片（`Shard`），并将每个分片存储在不同的服务器上。这样，每台服务器只需要处理其中一个或一部分分片的数据，从而有效地分散了负载和数据存储
>
> 
>
> 服务器`Sharding`技术的一些关键特点和优势包括：
>
> 1. 扩展性：通过将数据分布在多台服务器上，可以水平扩展系统，支持更大的数据量和更高的并发请求。
> 2. 性能：分片可以使查询和写入操作在多台服务器上并行执行，从而提高系统的响应性能。
> 3. 容错性：当一台服务器发生故障时，其他服务器上的分片仍然可用，保障系统的可用性。
> 4. 灵活性：可以根据需求动态添加或删除分片，以适应数据量的变化。
> 5. 数据隔离：将数据分片存储在不同的服务器上，可以提高数据的隔离性，减少单一故障点的风险。



![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E9%9B%86%E7%BE%A4.jpg)



这里的 6 台 redis节点两两之间并不是独立的，每个节点都会通过集群总线(cluster bus)与其他的节点进行通信（Gossip协议），Redis 集群有16384 个哈希槽，当我们存取key的时候，每个 key 通过 CRC16 校验后得到一个结果，把结果对 16384 取模，来决定放置哪个槽，集群的每个节点负责一部分hash槽，举个例子，比如当前集群有3个节点，那么：

- 节点 A 包含 0 到 5460 号哈希槽
- 节点 B 包含 5461 到 10922 号哈希槽
- 节点 C 包含 10923 到 16383 号哈希槽

使用哈希槽的好处就在于可以方便的添加或者移除节点，并且无论是添加删除或者修改某一个节点，都不会造成集群不可用的状态。当需要增加节点时，只需要把其他节点的某些哈希槽挪到新节点就可以了；当需要移除节点时，只需要把移除节点上的哈希槽挪到其他旧节点就行了



Cluster模式集群节点最小配置6个节点(3主3从，因为需要半数以上)，其中**主节点提供读写操作，从节点作为备用节点，不提供请求，只作为故障转移使用**



> Gossip协议是一种用于分布式系统中节点之间通信和信息传播的协议。它得名于"流言"（gossip）这个词，类比于节点之间像传播谣言一样相互交换信息的过程。Gossip协议是一种去中心化的、自组织的协议，没有单一的中央节点，所有节点平等参与信息传播。
>
> 在Gossip协议中**，每个节点都会周期性地选择几个邻居节点（通常称为伙伴节点），然后与这些伙伴节点交换信息**。信息可以是节点状态、数据、事件等。节点之间的信息传播是通过相互交换消息来实现的，一个节点接收到信息后会将其传播给其它节点，从而使得信息在整个系统中传播。
>
> Gossip协议有以下特点：
>
> 1. 随机性：Gossip协议中，节点选择伙伴节点的过程通常是随机的。这种随机性可以帮助信息更快地在整个系统中传播，避免信息聚集在某些节点上。
> 2. 治愈性：节点不断地与伙伴节点交换信息，将信息传播给其他节点。这种交换过程有点类似于传染病的传播，一旦一个节点收到信息，它就会将信息传播给其它节点，从而实现信息的快速传播和治愈。
> 3. 自适应性：Gossip协议是一种自适应的协议。节点之间根据实际的网络状态和负载情况来选择伙伴节点，这使得协议能够在不同的网络环境下进行适应和优化。

Redis集群采用无中心结构,它的特点如下：

1. 所有的redis节点彼此互联(PING-PONG机制),内部使用二进制协议优化传输速度和带宽
2. **节点的fail是通过集群中超过半数的节点检测失效时才生效**
3. 客户端与redis节点直连,不需要中间代理层。客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可





#### 故障转移

Redis集群通过ping/pong消息，实现故障发现。这个环境包括**主观下线和客观下线**：

**主观下线：** 某个节点认为另一个节点不可用，即下线状态，这个状态并不是终的故障判定，只能代表一个节点的意见，**可能存在误判情况**

**客观下线：** 指标记一个节点真正的下线，集群内多个节点都认为该节点不可用，从而达成共识的结果。如果是持有槽的主节点故障，需要为该节点进行故障转移（master-slave切换）

故障发现后，如果下线节点的是主节点，则需要在它的从节点中选一个替换它，以保证集群的高可用





## 缓存相关问题 :baby_chick:



![图片](https://cdn.xiaolincoding.com//mysql/other/061e2c04e0ebca3425dd75dd035b6b7b.png)





### 缓存穿透

缓存穿透是指用户不断请求**缓存和数据库中都没有的信息（查询一个根本不存在的数据！）**，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能DB就挂掉了，要是**有人利用不存在的key频繁攻击应用，如发起请求为id为“-1”的数据或id为特别大不存在的数据。就会导致数据库压力过大**

解决方案：

1. 接口层增加校验，如用户鉴权校验，id做基础校验，id<=0的直接拦截；
2. 从缓存查不到，在数据库中也查不到的数据，这时也可以将key-value写为key-null（比如一个请求查询id=-1，查不到数据库后照样将该值缓存到redis中：**redis中缓存一个key为-1，value为null的键值对**），同时必须设置缓存时间（防止万一以后真的添加了对应id的数据行，如果不设置过期时间直接走缓存就会返回一个null值），缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击；
3. [布隆过滤器][https://javaguide.cn/cs-basics/data-structure/bloom-filter.html]：bloomfilter就类似于一个hashset，用于快速判某个元素是否存在于集合中，其典型的应用场景就是快速判断一个key是否存在于某容器，不存在就直接返回。布隆过滤器的关键就在于hash算法和容器大小

>比如当某一个字符串存储要加入到布隆过滤器中时，该字符串首先由**多个哈希函数生成不同的哈希值**，然后将对应的位数组的下标设置为 1（当位数组初始化时，所有位置均为 0）。当第二次存储相同字符串时，因为先前的对应位置已设置为 1，所以很容易知道此值已经存在（去重非常方便）；
>
>如果我们需要判断某个字符串是否在布隆过滤器中时，只需要对给定字符串再次多次进行相同的哈希函数计算，得到值之后**判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。**
>
>
>
>当判断一个元素是否存在时，将该元素通过相同的哈希函数计算出位数组中的位置，如果所有位置上的位都为1，则说明元素可能存在于集合中；如果有任何一个位置的位为0，则说明元素肯定不存在于集合中。







### 缓存击穿

**缓存击穿是指大量并发访问同一个热点数据（缓存雪崩是多个数据）**时，当该热点数据缓存失效后同时请求数据库，瞬间耗尽数据库资源，导致数据库压力过大

解决方案：

1. 设置热点数据永远不过期
2. 仅对查询数据库的业务逻辑代码块来设置同步锁`synchronized(this)`

> 比如查询逻辑调用的service为PublishServiceImpl,由于在对应的ServiceImpl上设置了**@Service**注解，故该类的实例会被注入到Spring容器中，而Spring默认Bean为单例的（**Singleton**）,因此如果多个线程请求过来共享这一个实例，即共享这一个锁

3. **缓存预热：**在系统启动或者某个时间点，提前加载热门数据到缓存中，避免在高并发时大量请求访问缓存失效的数据









### 缓存雪崩

缓存雪崩是指缓存中大批数据一起过期，此时如果外来请求过多，使得大量请求直接查询数据库，导致数据库压力过大甚至宕机。和缓存击穿不同的是，**缓存击穿指并发查同一条数据，缓存雪崩是大量不同数据一起过期了**

解决方案：


1. 对缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。

2. 如果缓存数据库是分布式部署，将热点数据均匀分布在不同的缓存数据库中。

3. 使用`synchronized`同步锁控制查询数据库的线程（并发度很低）
4. 不用等到请求到来再去查询数据库时才存入缓存，可以提前将数据存入缓存中，后台通常有**定时任务将数据库中的数据存入缓存**









### 数据库与缓存一致性问题  

先抛结论：**在满足实时性的条件下，不存在两者完全保存一致的方案，只有最终一致性方案**

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/redis-shuju-yizhixing.png" style="zoom:67%;" />



**1、先写Mysql 再写Redis**

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/redis-shuju-yizhixing-1.png)



> 图解说明：
>
> - 这是一副时序图，描述请求的先后调用顺序、纵轴表示时间；
> - 橘黄色的线是请求 A，黑色的线是请求 B；
> - 橘黄色的文字，是 MySQL 和 Redis 最终不一致的数据；
> - 数据是从 10 更新为 11；

请求 A、B 都是先写 MySQL，然后再写 Redis，**在高并发情况下，如果请求 A 在写 Redis 时卡了一会，请求 B 已经依次完成数据的更新，就会出现图中的问题**





**2、先写Redis 再写Mysql**

   也会出现同样的问题

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/redis-shuju-yizhixing-2.png)

所以，**无论是「先更新数据库，再更新缓存」，还是「先更新缓存，再更新数据库」，这两个方案都存在并发问题，当两个请求并发更新同一条数据的时候，可能会出现缓存和数据库中的数据不一致的现象**





> 先更新数据库，还是先删除缓存？

考虑以下思路：**更新数据时，不更新缓存，而是删除缓存中的数据。然后到读取数据时，发现缓存中没了数据之后，再从数据库中读取数据，更新到缓存中**。这个策略是有名字的：**`Cache Aside`** ————旁路缓存策略：

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E6%97%81%E8%B7%AF%E7%BC%93%E5%AD%98.webp" style="zoom: 67%;" />

**写策略的步骤：**

- 更新数据库中的数据；
- 删除缓存中的数据

**读策略的步骤：**

- 如果读取的数据命中了缓存，则直接返回数据(这种情况**只可能是连续发生两次读请求**)；
- **如果读取的数据没有命中缓存，则从数据库中读取数据，然后将数据写入到缓存，并且返回给用户**



而针对写策略，到底该选择哪种顺序呢？

- 先删除缓存，再更新数据库；
- 先更新数据库，再删除缓存





**3、先删除Redis缓存、再写Mysql**

以用户表的场景来分析：

假设某个用户的年龄是 20，请求 A 要更新用户年龄为 21，所以它会删除缓存中的内容。这时，另一个请求 B 要读取这个用户的年龄，它**查询缓存发现未命中后，会从数据库中读取到年龄为 20，并且写入到缓存中**，然后请求 A 继续更改数据库，将用户的年龄更新为 21

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E5%85%88%E5%88%A0%E7%BC%93%E5%AD%98%20%E5%86%8D%E5%86%99redis.webp" style="zoom: 67%;" />

最终，该用户年龄在缓存中是 20（旧值），在数据库中是 21（新值），缓存和数据库的数据不一致

可以看到，**先删除缓存，再更新数据库，在「读 + 写」并发的时候，还是会出现缓存和数据库的数据不一致的问题**





#### 延迟双删

而针对「先删除缓存，再更新数据库」方案在「读 + 写」并发请求而造成缓存不一致的解决办法是「**延迟双删**」

延迟双删实现的伪代码如下：

```shell
#删除缓存
redis.delKey(X)
#更新数据库
db.update(X)
#睡眠
Thread.sleep(N)
#再删除缓存
redis.delKey(X)
```

即对于“先删除 Redis，再写 MySQL”，如果要解决最后的不一致问题，其实再对 Redis 重新删除即可，**这个也是大家常说的“缓存双删**：

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/redis-shuju-yizhixing-3.png" style="zoom:67%;" />



为了便于大家看图，对于蓝色的文字，“删除缓存 10”必须在“回写缓存10”后面，那如何才能保证一定是在后面呢？**网上给出的第一个方案是，让请求 A 的最后一次删除，等待 500ms**

对于这种方案，看看就行，风险不可控

**那有没有更好的方案呢，我建议异步串行化删除，即删除请求入队列**

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/redis-shuju-yizhixing-4.png" style="zoom:67%;" />

异步删除对线上业务无影响，串行化处理保障并发情况下正确删除













**4、先写Mysql、再删除Redis缓存**

继续用「读 + 写」请求的并发的场景来分析：

假如某个用户数据在缓存中不存在，请求 A 读取数据时从数据库中查询到年龄为 20，在未写入缓存中时另一个请求 B 更新数据。它更新数据库中的年龄为 21，并且清空缓存。这时请求 A 把从数据库中读到的年龄为 20 的数据写入到缓存中

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E5%85%88%E5%86%99mysql.webp" style="zoom:67%;" />

最终，该用户年龄在缓存中是 20（旧值），在数据库中是 21（新值），缓存和数据库数据不一致

从上面的理论上分析，先更新数据库，再删除缓存也是会出现数据不一致性的问题，**但是在实际中，这个问题出现的概率并不高**

**因为缓存的写入通常要远远快于数据库的写入**，所以**在实际中很难出现写请求 B 已经更新了数据库并且删除了缓存，读请求 A 才更新完缓存的情况(读请求A写缓存的速度一般要快于写请求B)**

而一旦请求 A 早于请求 B 删除缓存之前更新了缓存，那么接下来的请求就会因为缓存不命中而从数据库中重新读取数据，所以不会出现这种不一致的情况(**因为请求B已经把A更新的缓存数据给删掉了，后续的读请求需要重新读Mysql**)



所以，**「先更新数据库 + 再删除缓存」的方案，是可以一定程度上保证数据一致性的**



**缺点：**「先更新数据库，再删除缓存」的方案虽然保证了数据库与缓存的数据一致性，但是每次更新数据的时候，缓存的数据都会被删除，这样会对缓存的命中率带来影响

所以，**如果我们的业务对缓存命中率有很高的要求，我们可以采用「更新数据库 + 更新缓存」的方案，因为更新缓存并不会出现缓存未命中的情况**

但是这个方案前面我们也分析过，在两个更新请求并发执行的时候，会出现数据不一致的问题，因为更新数据库和更新缓存这两个操作是独立的，而我们又没有对操作做任何并发控制，那么当两个线程并发更新它们的话，就会因为写入顺序的不同造成数据的不一致。这里提供两种做法：

- 在更新缓存前先加个**分布式锁**，保证同一时间只运行一个请求更新缓存，就会不会产生并发问题了，当然引入了锁后，对于写入的性能就会带来影响
- 在更新完缓存时，给缓存加上较短的**过期时间**，这样即时出现缓存不一致的情况，缓存的数据也会很快过期，对业务还是能接受的







5、先写 MySQL，通过 Binlog，异步更新 Redis

这种方案，主要是监听 MySQL 的 Binlog，然后通过异步的方式，将数据更新到 Redis，这种方案有个前提，查询的请求，不会回写 Redis

![img](https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/mysql/redis-shuju-yizhixing-0da55874-8cf7-4c5a-995b-a0e6611bfac2.png)



这个方案，会保证 MySQL 和 Redis 的最终一致性，但是如果中途请求 B 需要查询数据，如果缓存无数据，就直接查 DB；如果缓存有数据，查询的数据也会存在不一致的情况。

**所以这个方案，是实现最终一致性的终极解决方案，但是不能保证实时性**





#### 方案比较

我们对比上面讨论的 6 种方案：

1. 先写 Redis，再写 MySQL

- **这种方案，我肯定不会用**，万一 DB 挂了，你把数据写到缓存，DB 无数据，这个是灾难性的；
- 我之前也见同学这么用过，如果写 DB 失败，对 Redis 进行逆操作，那如果逆操作失败呢，是不是还要搞个重试？

2. 先写 MySQL，再写 Redis

- **对于并发量、一致性要求不高的项目，很多就是这么用的**，我之前也经常这么搞，但是不建议这么做；
- 当 Redis 瞬间不可用的情况，需要报警出来，然后线下处理。

3. 先删除 Redis，再写 MySQL

- 这种方式，我还真没用过，**直接忽略吧。**

4. 先删除 Redis，再写 MySQL，再删除 Redis

- 这种方式虽然可行，但是**感觉好复杂**，还要搞个消息队列去异步删除 Redis。

5. 先写 MySQL，再删除 Redis

- **比较推荐这种方式**，删除 Redis 如果失败，可以再多重试几次，否则报警出来；
- 这个方案，是实时性中最好的方案，在一些高并发场景中，推荐这种。

6. 先写 MySQL，通过 Binlog，异步更新 Redis

- **对于异地容灾、数据汇总等，建议会用这种方式**，比如 binlog + kafka，数据的一致性也可以达到秒级；
- 纯粹的高并发场景，不建议用这种方案，比如抢购、秒杀等。

**个人结论：**

- **实时一致性方案**：采用“先写 MySQL，再删除 Redis”的策略，这种情况虽然也会存在两者不一致，但是需要满足的条件有点苛刻，**所以是满足实时性条件下，能尽量满足一致性的最优解。**
- **最终一致性方案**：采用“先写 MySQL，通过 Binlog，异步更新 Redis”，可以通过 Binlog，结合消息队列异步更新 Redis，**是最终一致性的最优解**





## 过期删除与内存淘汰策略





### 过期删除

每当对一个 key 设置了过期时间时，`Redis` 会把该 `key` 带上过期时间存储到一个**过期字典**（`expires dict`）中，也就是说「过期字典」保存了数据库中所有 key 的过期时间

当我们查询一个 key 时，`Redis` 首先检查该 `key` 是否存在于过期字典中：

- 如果不在，则正常读取键值(说明该key未设置过期时间)；
- 如果存在，则会获取该 key 的过期时间，然后与当前系统时间进行比对，如果比系统时间大，那就没有过期，否则判定该 key 已过期

过期字典存储在 `redisDb` 结构中，如下：

```c
typedef struct redisDb {
    dict *dict;    /* 数据库键空间，存放着所有的键值对 */
    dict *expires; /* 键的过期时间 */
    ....
} redisDb;
```

过期字典数据结构结构如下：

- 过期字典的 key 是一个指针，指向某个键对象；
- 过期字典的 value 是一个 long long 类型的整数，这个整数保存了 key 的过期时间；

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E8%BF%87%E6%9C%9F%E5%AD%97%E5%85%B8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.webp" style="zoom: 67%;" />







`Redis` 自带了**给缓存数据设置过期时间**的功能，比如：

```shell
127.0.0.1:6379> expire name 10 #   键 name在 10s 后过期
(integer) 1
127.0.0.1:6379> setex name 60 value # 数据在 60s 后过期 (setex:[key] + [ex]pire+[value])
OK
127.0.0.1:6379> ttl key # 查看数据还有多久过期
(integer) 56

```

`SETEX`命令是`Redis`中的一个用于设置带有过期时间的键值对的命令。它用于将指定的键设置为指定的值，并在一段时间后自动过期，命令格式：

```shell
SETEX key seconds value
```







`Redis` 使用的过期删除策略是「**惰性删除+定期删除**」这两种策略配合使用:

**惰性删除：**

惰性删除策略的做法是，**不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key**

惰性删除策略的**优点**：

- 因为每次访问时，才会检查 key 是否过期，所以此策略只会使用很少的系统资源，因此，惰性删除策略对 CPU 时间最友好。

惰性删除策略的**缺点**：

- 如果一个 key 已经过期，而这个 key 又仍然保留在数据库中，那么只要这个过期 key 一直没有被访问，它所占用的内存就不会释放，造成了一定的内存空间浪费。所以，惰性删除策略对内存不友好



Redis 的惰性删除策略由 db.c 文件中的 `expireIfNeeded` 函数实现，代码如下：

```c
int expireIfNeeded(redisDb *db, robj *key) {
    // 判断 key 是否过期 未过期则直接返回
    if (!keyIsExpired(db,key)) return 0;  
    ....
    /* 删除过期键 */
    ....
    
    // 如果 server.lazyfree_lazy_expire 为 1 表示异步删除，反之同步删除；
    return server.lazyfree_lazy_expire ? dbAsyncDelete(db,key) :
                                         dbSyncDelete(db,key);
}
```

(`lazy_free`是一种延迟释放内存的机制,具体来说，当Redis删除一个键值对时，它会将该键值对的内存标记为"待释放"，但并不立即释放它。相反，Redis会将这些待释放的内存块添加到一个专门的列表中，该列表称为"`lazyfree list`")，然后通过后台`lazy-free`线程来删除过期的key

Redis 在访问或者修改 key 之前，都会调用 `expireIfNeeded` 函数对其进行检查，检查 key 是否过期：

- 如果过期，则删除该 key，至于选择异步删除，还是选择同步删除，根据 `lazyfree_lazy_expire` 参数配置决定（Redis 4.0版本开始提供参数），然后返回 null 客户端；
- 如果没有过期，不做任何处理，然后返回正常的键值对给客户端；







**定期删除:**

**每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。**

Redis 的定期删除的流程：

1. 从过期字典中随机抽取 20 个 key；
2. 检查这 20 个 key 是否过期，并删除已过期的 key；
3. 如果本轮检查的已过期 key 的数量，超过 5 个（20/4），也就是「已过期 key 的数量」占比「随机抽取 key 的数量」大于 25%，则继续重复步骤 1；如果已过期的 key 比例小于 25%，则停止继续删除过期 key，然后等待下一轮再检查

可以看到，定期删除是一个循环的流程。那 Redis 为了保证定期删除不会出现循环过度，导致线程卡死现象，为此增加了定期删除循环流程的时间上限，默认不会超过 25ms(也就是说每次`check key`之前要先判断当前循环时间是否超出设置的时间上限，超出直接跳出循环)



定期删除策略的**优点**：

- 通过限制删除操作执行的时长和频率，来减少删除操作对 CPU 的影响，**而且删除一部分过期的数据减少了过期键对内存空间的无效占用(主要)**

定期删除策略的**缺点**：

- 难以确定删除操作执行的时长和频率。**如果执行的太频繁，就会对 CPU 不友好；如果执行的太少，那又和惰性删除一样了，过期 key 占用的内存不会及时得到释放**

可以看到，惰性删除策略和定期删除策略都有各自的优点，所以 **Redis 选择「惰性删除+定期删除」这两种策略配合使用**，以求在合理使用 CPU 时间和避免内存浪费之间取得平衡





> **Redis 持久化时，对过期键会如何处理的？**

Redis 持久化文件有两种格式：RDB（Redis Database）和 AOF（Append Only File），下面我们分别来看过期键在这两种格式中的呈现状态。

RDB 文件分为两个阶段，RDB 文件生成阶段和加载阶段

- **RDB 文件生成阶段**：从内存状态持久化成 RDB（文件）的时候，会对 key 进行过期检查，**过期的键「不会」被保存到新的 RDB 文件中**，因此 Redis 中的过期键不会对生成新 RDB 文件产生任何影响
- RDB 加载阶段：RDB 加载阶段时，要看服务器是主服务器还是从服务器，分别对应以下两种情况：
  - **如果 Redis 是「主服务器」运行模式的话，在载入 RDB 文件时，程序会对文件中保存的键进行检查，过期键「不会」被载入到数据库中**。所以过期键不会对载入 RDB 文件的主服务器造成影响；
  - **如果 Redis 是「从服务器」运行模式的话，在载入 RDB 文件时，不论键是否过期都会被载入到数据库中**。**但由于主从服务器在进行数据同步时，从服务器的数据会被清空。所以一般来说，过期键对载入 RDB 文件的从服务器也不会造成影响**

AOF 文件分为两个阶段，AOF 文件写入阶段和 AOF 重写(`ReWrite`)阶段

- **AOF 文件写入阶段**：当 Redis 以 AOF 模式持久化时，**如果数据库某个过期键还没被删除，那么 AOF 文件会保留此过期键，当此过期键被删除后，Redis 会向 AOF 文件追加一条 DEL 命令来显式地删除该键值**
- **AOF 重写阶段**：执行 AOF 重写时，会对 Redis 中的键值对进行检查，**已过期的键不会被保存到重写后的 AOF 文件中**，因此不会对 AOF 重写造成任何影响









### 内存淘汰

前面说的过期删除策略，是删除已过期的 key，而当 Redis 的运行内存已经超过 Redis 设置的最大内存阈值之后，则会使用内存淘汰策略删除符合条件的 key，以此来保障 Redis 高效的运行



在配置文件 `redis.conf` 中，可以**通过参数 `maxmemory <bytes>` 来设定最大运行内存**，只有在 Redis 的运行内存达到了我们设置的最大运行内存，才会触发内存淘汰策略，不同位数的操作系统，`maxmemory` 的默认值是不同的：

- 在 64 位操作系统中，`maxmemory` 的默认值是 0，表示没有内存大小限制，那么不管用户存放多少数据到 Redis 中，Redis 也不会对可用内存进行检查，直到 Redis 实例因内存不足而崩溃也无作为
- 在 32 位操作系统中，`maxmemory` 的默认值是 3G，因为 32 位的机器最大只支持 4GB 的内存，而系统本身就需要一定的内存资源来支持运行，所以 32 位操作系统限制最大 3 GB 的可用内存是非常合理的，这样可以避免因为内存不足而导致 Redis 实例崩溃



> **内存淘汰策略有哪些？**

Redis 内存淘汰策略共有八种，这八种策略大体分为「不进行数据淘汰」和「进行数据淘汰」两类策略

*1、不进行数据淘汰的策略*

**`noeviction`**（Redis3.0之后，默认的内存淘汰策略） ：它表示当运行内存超过最大设置内存时，不淘汰任何数据，这时如果有新的数据写入，则会触发 `OOM`，但是**如果没有数据写入的话，只是单纯的查询或者删除操作的话，还是可以正常工作**

*2、进行数据淘汰的策略*

针对「进行数据淘汰」这一类策略，又可以细分为「**在设置了过期时间的数据中进行淘汰**」和「**在所有数据范围内进行淘汰**」这两类策略。

在设置了过期时间的数据中进行淘汰：

- **volatile-random**：随机淘汰设置了过期时间的任意键值；
- **volatile-ttl**：优先淘汰更早过期的键值。
- **volatile-lru**(Redis3.0前默认的内存淘汰策略):淘汰所有设置了过期时间的键值中，最长时间未被使用的键值；
- **volatile-lfu**(Redis4.0后新增内存淘汰策略):淘汰所有设置了过期时间的键值中，最少使用的键值；

在所有数据范围内进行淘汰：

- **allkeys-random**：随机淘汰任意键值;
- **allkeys-lru**：淘汰整个键值中最久未使用的键值；
- **allkeys-lfu**（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值。

使用 `config get maxmemory-policy` 命令，来查看当前 Redis 的内存淘汰策略，命令如下：

```shell
127.0.0.1:6379> config get maxmemory-policy
1) "maxmemory-policy"
2) "noeviction"
```

可以看出，当前 Redis 使用的是 `noeviction` 类型的内存淘汰策略，它是 Redis 3.0 之后默认使用的内存淘汰策略，表示当运行内存超过最大设置内存时，不淘汰任何数据，但新增操作会报错





### LRU & LFU :astonished:



**LRU：**

传统 LRU 算法的实现是基于「**双向链表**」结构，链表中的元素按照操作顺序从前往后排列，最新操作的键会被移动到表头，当需要内存淘汰时，只需要删除链表尾部的元素即可，因为链表尾部的元素就代表最久未被使用的元素。

Redis 并没有使用这样的方式实现 LRU 算法，因为传统的 LRU 算法存在两个问题：

- 需要用链表管理所有的缓存数据，这会带来额外的空间开销；
- 当有数据被访问时，需要在链表上把该数据移动到头端，如果有大量数据被访问，就会带来很多链表移动操作，会很耗时，进而会降低 Redis 缓存性能



Redis 实现的是一种**近似 LRU 算法**，目的是为了更好的节约内存，它的**实现方式是在 Redis 的对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间**

当 Redis 进行内存淘汰时，会使用**随机采样的方式来淘汰数据**，它是随机取 5 个值（此值可配置），然后**淘汰最久没有使用的那个**

Redis 实现的 LRU 算法的优点：

- 不用为所有的数据维护一个大链表，节省了空间占用；
- 不用在每次数据访问时都移动链表项，提升了缓存的性能；



但是 LRU 算法有一个问题，**无法解决缓存污染问题**，比如应用一次读取了大量的数据，而这些数据只会被读取这一次，那么这些数据会留存在 Redis 缓存中很长一段时间(`因为读取的这些数据的最后访问时间字段都会被更新`)，这就造成了缓存污染







**LFU：**

LFU 全称是 Least Frequently Used 翻译为**最近最不常用的**，LFU 算法是根据数据访问次数来淘汰数据的,所以LFU 算法会记录每个数据的访问次数。当一个数据被再次访问时，就会增加该数据的访问次数。这样就解决了偶尔被访问一次之后，数据留存在缓存中很长一段时间的问题，相比于 LRU 算法也更合理一些，传统LFU算法实现思路如下：

- 使用一个有序集合（Sorted Set）来实现存储数据
- 在有序集合中，键是数据，值是数据的访问频率计数
- 每次访问一个键，会将该键的访问频率计数加一，并更新有序集合中的值
- 当需要淘汰数据时，会从有序集合中选择访问频率最低的数据进行淘汰

而在Redis中，LFU 算法相比于 LRU 算法的实现，多记录了「数据的访问频次」的信息。Redis 对象的结构如下：

```c
typedef struct redisObject {
    ...
      
    // 24 bits，用于记录对象的访问信息
    unsigned lru:24;  
    ...
} robj;
```

**在 LRU 算法中**，Redis 对象头的 24 bits 的 lru 字段是**用来记录 key 的访问时间戳**，因此在 LRU 模式下，Redis可以根据对象头中的 lru 字段记录的值，来比较最后一次 key 的访问时间长，从而淘汰最久未被使用的 key

**在 LFU 算法中**，Redis对象头的 24 bits 的 lru 字段被分成两段来存储，**高 16bit 存储 ldt(`Last Decrement Time`)，低 8bit 存储 logc(`Logistic Counter`)**

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/lru%E5%AD%97%E6%AE%B5.webp)

- ldt 是用来记录 key 的访问时间戳；
- logc 是用来记录 key 的访问频次，它的值越小表示使用频率越低，越容易淘汰，每个新加入的 key 的logc 初始值为 5
- logc 并不是单纯的访问次数，而是访问频次（访问频率），因为 **logc 会随时间推移而衰减的**

在每次 key 被访问时，会先对 logc 做一个衰减操作，衰减的值跟前后访问时间的差距有关系，如果上一次访问的时间与这一次访问的时间差距很大，那么衰减的值就越大，这样实现的 LFU 算法是根据**访问频率**来淘汰数据的，而不只是访问次数。访问频率需要考虑 key 的访问是多长时间段内发生的。key 的先前访问距离当前时间越长，那么这个 key 的访问频率相应地也就会降低，这样被淘汰的概率也会更大

对 logc 做完衰减操作后，就开始对 logc 进行增加操作，**增加操作并不是单纯的 + 1，而是根据概率增加，如果 logc 越大的 key，它的 logc 就越难再增加**



**总结：**即先减后加，减的程度和上次访问时间差距有关，加的程度和当前logc值有关







## 分布式锁





### Redisson



> 来看一个实际场景引入：微服务项目中，一个微服务通常会有多个实例在运行(用户请求到来时涉及到路由负载均衡)，打到一个特定实例上的多个线程请求，针对这一个实例(单个`jvm`进程)使用同步锁`synchronized`是可以实现这些线程的同步操作的，但是如果想要在多个实例(多个`jvm`进程)上实现所有线程请求的同步，这就涉及到了分布式锁，本项目中使用`Redisson`来实现分布式锁，先来看看业务场景
>
> 选课冲突处理：当多个学生同时选择某门课程时，可能发生选课冲突。为了避免冲突，可以使用分布式锁来确保同时只有一个学生能够成功选取该课程



然后我们再来讲一下优化的过程

(1) 使用setnx命令，设置过期时间但是过期时间不好确定(取决于业务)，问题有两点：

- 设置的过期时间较短：让key到期后自动释放，可能当前线程操作未完成锁就被释放；

- 手动删除：每次当前线程执行完后在finally中手动释放锁(`del key`),但是由于锁已经过期，锁当前被别人占用，此时再删除就删掉的是其他线程持有的锁了

  

(2) 依旧使用setnx命令，不设置过期时间，由当前线程执行完操作后判断锁是否还是之前所设置的，是的话再手动删除

这种方式也存在问题，因为**判断锁与释放锁的代码不是一个原子性操作，多线程场景下CPU是基于时间片轮转调度的，假如当前线程判断现在的锁是它所设置的``<K,V>=<"lock",01>`，但是马上让出了时间片给线程2，且此时锁失效，线程2判断到锁失效故执行`setnx`命令设置为(`<K,V>=<"lock",02>`)，然后再次让出时间片给线程1，此时线程1执行删除锁命令就把线程2的锁给删掉了**！！

```java
finally{
    if(redis.call("get","lock")=="01")
    {
        释放锁： redis.call("del","lock");
    }
}
```

(3) 解决以上原子性问题的办法是基于lua脚本，lua脚本在执行上述操作时可以保证原子性，但是也存在问题，**因为如果当前实例突然崩溃，`finally`中的代码没有执行呢**?由于没有设置过期时间，这个锁就永远不会被释放掉！！

这里给出基于`setnx`的分布式锁实现：

```java
//通过setnx实现分布式锁  2.0
public CoursePublish getCoursePublishCache2(Long courseId){

    //先从缓存中查询
    String jsonString = (String) redisTemplate.opsForValue().get("course:" + courseId);
    if(StringUtils.isNotEmpty(jsonString)){
        //System.out.println("========从缓存中查询===========");
        //将json转成对象返回
        CoursePublish coursePublish = JSON.parseObject(jsonString, CoursePublish.class);
        return coursePublish;
    }else{
        //使用setnx向redis设置一个key，谁设置成功谁拿到了分布式锁
        Boolean lock001 = redisTemplate.opsForValue().setIfAbsent("lock001", "001");
        if(lock001){
            //获取锁这个人去执行这里边的代码
        }
        synchronized (this){
            //再次从缓存中查询一下
            jsonString = (String) redisTemplate.opsForValue().get("course:" + courseId);
            if(StringUtils.isNotEmpty(jsonString)){
                //将json转成对象返回
                CoursePublish coursePublish = JSON.parseObject(jsonString, CoursePublish.class);
                return coursePublish;
            }
            System.out.println("从数据库查询...");
            //如果缓存中没有，要从数据库查询
            CoursePublish coursePublish = coursePublishMapper.selectById(courseId);
            //将从数据库查询到的数据存入缓存
            redisTemplate.opsForValue().set("course:" + courseId,JSON.toJSONString(coursePublish),300, TimeUnit.SECONDS);

            return coursePublish ;
        }
    }
}
```



(4) 基于`redisson`实现，`redisson`分布式锁优势如下：

- 将多个`redis`操作lua脚本作为整体提交，保证性能的同时保证整体原子性

- 看门狗自动延续锁生命周期，防止未处理完锁过期问题，但是同时造成了阻塞，甚至锁死

- 实现了自旋锁 ：发现锁被占用后`get ttl`进行`while true`对应的时间

- 实现了重入锁 ：发现锁后再看一下`clientid`是不是自己，如果是+1

```java
//解决缓存击穿，使用Redission实现分布式锁 3.0
public CoursePublish getCoursePublishCache(Long courseId){
    //先从缓存中查询
    String jsonString = (String) redisTemplate.opsForValue().get("course:" + courseId);
    if(StringUtils.isNotEmpty(jsonString)){
        System.out.println("========从缓存中查询===========");
        //将json转成对象返回
        CoursePublish coursePublish = JSON.parseObject(jsonString, CoursePublish.class);
        return coursePublish;
    }else{
        //使用setnx向redis设置一个key，谁设置成功谁拿到了锁
        // Boolean lock001 = redisTemplate.opsForValue().setIfAbsent("lock001", "001",300,TimeUnit.SECONDS);
        //使用redisson获取锁
        RLock lock = redissonClient.getLock("coursequery:" + courseId);  //为每个course都设置锁
        //获取分布式锁
        lock.lock();
        //拿到锁的才会执行try finally代码块
        try{
            //   Thread.sleep(35000);
            //再次从缓存中查询一下
            jsonString = (String) redisTemplate.opsForValue().get("course:" + courseId);
            if(StringUtils.isNotEmpty(jsonString)){
                //将json转成对象返回
                CoursePublish coursePublish = JSON.parseObject(jsonString, CoursePublish.class);
                return coursePublish;
            }
            System.out.println("从数据库查询...");
            //如果缓存中没有，要从数据库查询
            CoursePublish coursePublish = coursePublishMapper.selectById(courseId);
            //将从数据库查询到的数据存入缓存 ,缓存中设置Key为 "course:id"
            redisTemplate.opsForValue().set("course:" + courseId,JSON.toJSONString(coursePublish),300, TimeUnit.SECONDS);
            return coursePublish ;
        }finally {
            //释放锁 不管过不过期 业务完成后还是必须手动释放
            lock.unlock();  // redisson解锁方法内部封装了lua脚本保证原子性
        }
    }
}
```



再考虑一个问题，虽然`Redisson`解决了锁过期时间无法确定的问题(通过后台`WatchDog`线程实现锁自动续期)，但是假如当前线程出现异常并没有执行`finally`代码块中的`unlock()`方法，这和之前`setnx`命令实现分布式锁出现的问题一样。我们来看看`redisson`源码是如何保证锁一定会被释放的：

```java
// 锁释放，调用unlockAsync(Thread.currentThread().getId()) 方法来异步执行锁的释放操作
public void unlock() {
    try {
        get(unlockAsync(Thread.currentThread().getId()));
    } catch (RedisException e) {
        if (e.getCause() instanceof IllegalMonitorStateException) {
            throw (IllegalMonitorStateException) e.getCause();
        } else {
            throw e;
        }
    }
}

// 进入 unlockAsync(Thread.currentThread().getId()) 方法 入参是当前线程的id
public RFuture<Void> unlockAsync(long threadId) {
    RPromise<Void> result = new RedissonPromise<Void>();
    //执行lua脚本 删除key
    RFuture<Boolean> future = unlockInnerAsync(threadId);

    future.onComplete((opStatus, e) -> {
        // 无论执行lua脚本是否成功 执行cancelExpirationRenewal(threadId) 方法来删除EXPIRATION_RENEWAL_MAP中的缓存
        cancelExpirationRenewal(threadId); //停止锁的续期机制

        if (e != null) {
            result.tryFailure(e);
            return;
        }

        if (opStatus == null) {
            IllegalMonitorStateException cause = new IllegalMonitorStateException("attempt to unlock lock, not locked by current thread by node id: "
                    + id + " thread-id: " + threadId);
            result.tryFailure(cause);
            return;
        }

        result.trySuccess(null);
    });

    return result;
}

// 此方法会停止 watch dog 机制
/*
从 EXPIRATION_RENEWAL_MAP 中查找与当前锁关联的续期任务，
然后根据 threadId 来删除对应的线程标识，并检查是否还有其他线程在持有锁。
如果没有其他线程持有锁，就会取消续期任务并将其从 EXPIRATION_RENEWAL_MAP 中移除。
*/
void cancelExpirationRenewal(Long threadId) {
    ExpirationEntry task = EXPIRATION_RENEWAL_MAP.get(getEntryName());
    if (task == null) {
        return;
    }
    
    if (threadId != null) {
        task.removeThreadId(threadId);
    }

    if (threadId == null || task.hasNoThreads()) {
        Timeout timeout = task.getTimeout();
        if (timeout != null) {
            timeout.cancel();
        }
        EXPIRATION_RENEWAL_MAP.remove(getEntryName());
    }
}
```

释放锁的操作中 有一步操作是从 EXPIRATION_RENEWAL_MAP 中获取 `ExpirationEntry` 对象，然后将其remove，结合watch dog中的续期前的判断：

```java
EXPIRATION_RENEWAL_MAP.get(getEntryName());
if (ent == null) {
    return;
}
```

可以得出结论：如果释放锁操作本身异常了，watch dog 还会不停的续期吗？不会，因为无论释放锁操作是否成功，`EXPIRATION_RENEWAL_MAP`中的目标 `ExpirationEntry` 对象已经被移除了(因为线程异常退出了，在保存当前活跃线程的Map里也找不到了)，`watch dog`通过判断后就不会继续给锁续期了





来总结一下： :expressionless:

（1）基于`synchronized`的同步锁问题：

`synchronized`锁的是当前JVM，如果**多个JVM进程**同时访问一个接口，此时再使用同步锁是锁不住的：即一个同步锁程序只能保证同一个虚拟机中多个线程只有一个线程去查数据库，如果高并发情况下通过网关负载均衡转发给多个虚拟机，此时就会存在多个线程去查询数据库的情况，因为**同步锁（虚拟机内部的锁）无法跨虚拟机保证同步执行**





（2）基于`setnx`实现分布式锁的问题：

`SETNX` 命令是 Redis 中用于实现分布式锁的经典方案之一。它可以将一个指定的 key 设置为一个特定的值，只有当这个 key 不存在时才能设置成功，但是当多个JVM同时尝试获取同一个锁时，其中一个JVM进程获取成功后需要设置锁的过期时间，过期时间设置过小会导致当前请求还未处理完锁就被释放；时间设置过长又会导致资源浪费；而如果采取处理完请求后手动释放锁的方法，又会产生原子性问题：

```
if(缓存里有)
{
返回缓存里数据
}else{
获取分布式锁： set lock 01 NX
if(获取锁成功)
{
try{
查询数据库
}
finally{
# if(redis.call("get","lock")=="01"){
# 释放锁: redis.call("del","lock")
                }
           }
      }
}
```

可以看出redis在执行带`#`的两行代码时不能保证原子性，故需要通过`lua`脚本保证原子性：

解锁脚本的一个例子将类似于以下：

```lua
if redis.call("get",KEYS[1]) == ARGV[1]
then
    return redis.call("del",KEYS[1])
else
    return 0
end
```



**缺点1：**`setnx`锁最大的缺点就是它加锁时只作用在一个 Redis 节点上，即使 Redis 通过 Sentinel(哨岗、哨兵) 保证高可用，如果这个 master 节点由于某些原因发生了主从切换，那么就会出现锁丢失的情况，下面是个例子：

1. 在 Redis 的 master 节点上拿到了锁；
2. 但是这个加锁的 key 还没有同步到 slave 节点；
3. master 故障，发生故障转移，slave 节点升级为 master节点；
4. 上边 master 节点上的锁丢失

有的时候甚至不单单是锁丢失这么简单，新选出来的 master 节点可以重新获取同样的锁，出现一把锁被拿两次的场景。

锁被拿两次，也就不能满足安全性了...

实际上`Redisson`实现分布式锁也有类似问题(因为底层实现就是setnx)。。。

> 解决方案：`RedLock`算法，但是也存在争议  [Redis锁从面试连环炮聊到神仙打架](https://mp.weixin.qq.com/s?__biz=Mzg3NjU3NTkwMQ==&mid=2247505097&idx=1&sn=5c03cb769c4458350f4d4a321ad51f5a&source=41&poc_token=HH9_u2SjM7RlF6CSz2UMIAzVXLsAAOL1-Tqt9kNw)

**缺点2：**且使用`setnx`锁时要设置锁的过期时间，这个过期时间不好把握(`Redisson`使用看门狗机制解决)

**缺点3：**`SETNX` 命令创建的锁是不可重入的，即同一个客户端在持有锁期间无法再次获取锁，否则会出现死锁(`Redisson`支持可重入)





(3)基于Redisson实现分布式锁：

> 需要的前置知识：
>
> `HEXISTS` 是 Redis 数据库中的一个命令，用于检查指定哈希表（Hash）中是否存在指定字段（Field）；
>
> `PTTL` 是 Redis 数据库中的一个命令，用于获取指定键（Key）的剩余过期时间(毫秒)

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E7%9C%8B%E9%97%A8%E7%8B%97.png)



同时Redisson支持可重入锁：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E5%8F%AF%E9%87%8D%E5%85%A5.png)



Redisson的加锁机制如下图所示，线程去获取锁，获取成功则执行lua脚本，保存数据到redis数据库。如果获取失败: 一直通过while循环尝试获取锁(可自定义等待时间，超时后返回失败)，获取成功后，执行lua脚本，保存数据到redis：

![Redisson](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/redisson.jpg)

如果拿到分布式锁的节点宕机，且这个锁正好处于锁住的状态时，会出现锁死的状态，为了避免这种情况的发生，锁都会设置一个过期时间。这样也存在一个问题，加入一个线程拿到了锁设置了30s超时，在30s后这个线程还没有执行完毕，锁超时释放了，就会导致问题，Redisson给出了自己的答案，自动延期(Watch Dog)机制:

Redisson提供了一个监控锁的看门狗线程，它的作用是在Redisson实例被关闭前，不断的延长锁的有效期，也就是说，如果一个拿到锁的线程一直没有完成逻辑，那么看门狗会帮助线程不断的延长锁超时时间，锁不会因为超时而被释放。默认情况下，看门狗的续期时间是30s，也可以通过修改Config.lockWatchdogTimeout来另行指定







**`Redisson`实现分布式锁也有使用`setnx`分布式锁类似的问题，故引出后面的红锁算法**





### RedLock算法



分布式锁解决了**分布式系统中控制共享资源访问**的问题。与单体应用不同的是，分布式系统中竞争共享资源的最小粒度**从线程升级成了进程**，要了解`RedLock`算法，首先应该知道`Redisson`，`Redisson`提供了多样化的锁：

- 可重入锁（`Reentrant Lock`）：`Redisson`提供了`RLock`接口来实现可重入锁，常用的实现类是`RedissonReentrantLock`
- 红锁（`RedLock`）：`Redisson`提供了`RRedLock`接口来实现红锁，通过`RedissonRedLock`实现类来管理多个锁。
- 读写锁（`ReadWrite Lock`）：`Redisson`提供了`RReadWriteLock`接口来实现读写锁，通过`RedissonReadWriteLock`实现类来管理读写锁
- 信号量（`Semaphore`）：`Redisson`提供了`RSemaphore`接口来实现信号量，通过`RedissonSemaphore`实现类来管理信号量
- 闭锁（`CountDownLatch`）：`Redisson`提供了`RCountDownLatch`接口来实现闭锁，通过`RedissonCountDownLatch`实现类来管理闭锁



`RedLock`算法使用了多个独立的Redis实例来解决这个问题，它的基本思想是：

1. 选择多个独立的Redis实例（一般是5个）作为锁的持久化存储，这些实例应该分布在不同的物理节点上，以降低故障的概率。
2. 当客户端要获取锁时，它会在所有Redis实例上分别执行SETNX命令。如果至少有一半（即大多数）的Redis实例返回成功（即获取到了锁），则客户端认为自己获取到了锁。
3. 当客户端要释放锁时，它会在所有Redis实例上执行DEL命令，以确保锁被正确释放。





**在 Redis 的分布式环境中，我们假设有 N 个 Redis Master。这些节点完全互相独立，不存在主从复制或者其他集群协调机制。**

前面已经描述了在单点 Redis 下，怎么安全地获取和释放锁，我们确保将在 N 个实例上使用此方法获取和释放锁。

在下面的示例中，我们假设有 5 个完全独立的 Redis Master 节点，他们分别运行在 5 台服务器中，可以保证他们不会同时宕机

从官网上我们可以知道，一个客户端如果要获得锁，必须经过下面的五个步骤：

1. 获取当前Unix时间，以毫秒为单位。
2. 依次尝试从5个实例，使用相同的key和具有唯一性的value（例如UUID）获取锁。当向Redis请求获取锁时，客户端应该设置一个尝试从某个Redis实例获取锁的最大等待时间（超过这个时间，则立马询问下一个实例），这个超时时间应该小于锁的失效时间。例如你的锁自动失效时间为10秒，则超时时间应该在5-50毫秒之间。这样可以避免服务器端Redis已经挂掉的情况下，客户端还在死死地等待响应结果。如果服务器端没有在规定时间内响应，客户端应该尽快尝试去另外一个Redis实例请求获取锁。
3. 客户端使用当前时间减去开始获取锁时间（步骤1记录的时间）就得到获取锁消耗的时间。当且仅当从大多数（N/2+1，这里是3个节点）的Redis节点都取到锁，并且使用的总耗时小于锁失效时间时，锁才算获取成功。
4. 如果取到了锁，key的真正有效时间 = 有效时间（**获取锁时设置的key的自动超时时间） - 获取锁的总耗时（询问各个Redis实例的总耗时之和）**即步骤3计算的结果:下图中为9000毫秒
5. 如果因为某些原因，最终获取锁失败（即没有在至少 “N/2+1 ”个Redis实例取到锁或者“获取锁的总耗时”超过了“有效时间”），客户端应该在所有的Redis实例上进行解锁（即便某些Redis实例根本就没有加锁成功，这样可以防止某些节点获取到锁但是客户端没有得到响应而导致接下来的一段时间不能被重新获取锁）



![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/redlock5.png)



多个jvm进程尝试去修改redis中一个key  setnx   setnx设置成功的线程才能获得该锁，然后再去修改数据库中的票数，







## 数据丢失问题  :imp:



在主从切换过程中，产生数据丢失的情况有两种：

- 异步复制同步丢失
- 集群产生脑裂数据丢失



**1、异步复制丢失数据：**

对于 Redis 主节点与从节点之间的数据复制，是异步复制的，当客户端发送写请求给主节点的时候，客户端会返回 ok，接着主节点将写请求异步同步给各个从节点，**但是如果此时主节点还没来得及同步给从节点时发生了断电，那么主节点内存中的数据会丢失。** 



>  那么该如何解决异步复制导致的数据丢失问题呢？



对于服务器端：

Redis 配置里有一个参数 min-slaves-max-lag，表示一旦所有的从节点数据复制和同步的延迟都超过了 min-slaves-max-lag 定义的值，那么主节点就会拒绝接收任何请求

假设将 min-slaves-max-lag 配置为 10s 后，根据目前 master->slave 的复制速度，如果数据同步完成所需要时间超过10s，就会认为 master 未来宕机后损失的数据会很多，master 就拒绝写入新请求。这样就能将 master 和 slave 数据差控制在10s内，即使 master 宕机也只是这未复制的 10s 数据



对于客户端：

那么对于客户端，当客户端发现 master 不可写后，我们可以采取降级措施，将数据暂时写入本地缓存和磁盘中，在一段时间（等 master 恢复正常）后重新写入 master 来保证数据不丢失，也可以将数据写入消息队列，等 master 恢复正常，再隔一段时间去消费消息队列中的数据，让将数据重新写入 master







**2、集群脑裂丢失数据**

在 Redis 中，集群脑裂产生数据丢失的现象是怎样的呢？

在 Redis 主从架构中，部署方式一般是「一主多从」，主节点提供写操作，从节点提供读操作。

如果主节点的网络突然发生了问题，它与所有的从节点都失联了，但是此时的主节点和客户端的网络是正常的，这个客户端并不知道 Redis 内部已经出现了问题，还在向这个失联的主节点写数据（过程A），此时这些数据被主节点缓存到了缓冲区(`Replication Buffer`)里，因为主从节点之间的网络问题，这些数据都是无法同步给从节点的。

这时，哨兵也发现主节点失联了，它就认为主节点挂了（但实际上主节点正常运行，只是网络出问题了），于是哨兵就会在从节点中选举出一个 leader 作为主节点，这时集群就有两个主节点了 —— **脑裂出现了**

这时候网络突然好了，哨兵因为之前已经选举出一个新主节点了，它就会把旧主节点降级为从节点（A），然后从节点（A）会向新主节点请求数据同步，**因为第一次同步是全量同步的方式，此时的从节点（A）会清空掉自己本地的数据，然后再做全量同步。所以，之前客户端在过程 A 写入的数据就会丢失了，也就是集群产生脑裂数据丢失的问题**。

总结一句话就是：由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务节点。等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于会从节点会清空自己的数据，所以导致之前客户端写入的数据丢失了



>  那么如何解决集群脑裂现象导致的数据丢失问题呢？

在 Redis 的配置文件中有两个参数我们可以设置：

- min-slaves-to-write x，主节点必须要有**至少 x 个从节点连接**，如果小于这个数，主节点会禁止写数据。
- min-slaves-max-lag x，主从数据复制和同步的延迟**不能超过 x 秒**，如果主从同步的延迟超过 x 秒，主节点会禁止写数据。



这两个配置项组合后的要求是，**主节点连接的从节点中至少有 N 个从节点，「并且」主节点进行数据复制时，收到ACK 消息延迟不能超过 T 秒**，否则，主节点就不会再接收客户端的写请求了。





其实主要思路就是禁止再往宕机的主节点上执行写操作。。。。。。。







## Redis阻塞原因













# 计算机网络



## 从浏览器输入URL到网页显示，发生了什么？



1、浏览器首先要将URL解析为IP地址，解析域名就要用到DNS协议，**浏览器会先看自身有没有对这个域名的缓存，如果有，就直接返回**，如果没有，就去问操作系统，操作系统也会去看自己的缓存，如果有，就直接返回，**如果没有，再去 hosts 文件看，也没有**，**才会去问「本地 DNS 服务器」**，发起**DNS查询**，DNS查询分为两种方式：一种是递归查询，一种是迭代查询 



**递归**查询：客户端发一次请求，由各级DNS服务器依次降级查找，查找成功后直接返回给本地DNS服务器，本地DNS再返回给客户机，流程为 **客户端——>本地DNS服务器——根DNS服务器——>顶级DNS服务器——>权威DNS服务器——>查找成功！——>本地DNS服务器——>客户端**

比如 `www.server.com`，这里的句点代表了不同层次之间的**界限**。

在域名中，**越靠右**的位置表示其层级**越高**。实际上域名最后还有一个点，比如 `www.server.com.`，这个最后的一个点代表根域名。

也就是，`.` 根域是在最顶层，它的下一层就是 `.com` 顶级域，再下面是 `server.com`。

所以域名的层级关系类似一个树状结构：

- 根 DNS 服务器（.）
- 顶级域 DNS 服务器（.com）
- 权威 DNS 服务器（server.com）



![DNS 树状结构](https://github.com/amonstercat/PicGo/blob/main/dell/202403051753818.png?raw=true)

**迭代**查询：当根域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出所要查询的IP地址，要么告诉本地服务器：“你下一步应当向哪一个域名服务器进行查询”，然后让本地服务器进行后续的查询，**根域名服务器**通常是把自己知道的顶级域名服务器的IP地址告诉本地域名服务器，让本地域名服务器再向顶级域名服务器查询。**顶级域名服务器**在收到本地域名服务器的查询请求后，要么给出所要查询的IP地址，要么告诉本地服务器下一步应当向哪一个**权威域名服务器**进行查询。最后，知道所要解析的IP地址或找不到结果报错时，把这个结果返回给发起查询的主机



> DNS占用 **53** 号端口，同时使用 TCP 和 **UDP** 协议。DNS 在区域传输的时候使用 TCP 协议，其他时间使用 UDP 协议。另外当 DNS 查询超过 512 字节时，会使用 TCP 协议
>
> - 区域传输：DNS 服务器主从复制时，数据量很大，从服务器向主服务器查询更新数据，保证数据一致性
>
> 
>
> chatgpt上的解释：
>
> DNS查询通常使用UDP协议进行传输，原因如下：
>
> 1. **低延迟：** UDP是面向无连接的协议，它不需要在发送数据前建立连接，也不需要等待连接的确认。这使得DNS查询可以更快地发送和响应，减少了通信的延迟。
>2. **较小的数据包：** DNS查询通常非常小，只包含一个域名和查询类型，这样的小数据包在UDP中传输更加高效。
> 3. **简单性：** UDP是一种轻量级的协议，实现起来较为简单，适合用于快速响应的场景。
>
> 然而，由于UDP是面向无连接的协议，它在传输过程中不提供可靠性保证。这意味着，如果DNS查询丢失或出现错误，客户端不会得到通知，也不会自动重新发送查询。为了解决这个问题，DNS协议还使用TCP作为备用传输层协议。
> 
> DNS使用TCP的情况包括：
>
> 1. **大数据包：** 当DNS响应的数据包超过UDP的限制（通常为512字节），DNS服务器会使用TCP协议来传输响应。
>2. **可靠性要求：** 在某些情况下，对DNS响应的可靠性要求比较高，特别是对于一些重要的查询，服务器可能会使用TCP来确保数据的可靠传输。



2、解析出IP地址后，根据该IP地址和默认端口80，**和Web服务器三次握手建立TCP连接**

3、握手成功，浏览器发出读取文件（URL中域名后面部分对应的文件）的HTTP请求，发送给**WEB服务器**

4、WEB服务器对浏览器请求作出响应（解析用户请求、后端调用数据库处理请求、将结果返回给浏览器客户端）

5、释放TCP连接（这里需要判断是否开启了Keep-Alive）

6、浏览器解析资源、渲染css样式、js交互后显示网页内容





## OSI七层协议

**物理层（Physical Layer）：** 物理层是网络通信的最底层，它负责在物理媒介上传输比特流（0和1）。主要关注的是数据的传输、电压、数据传输速率、连接接口等物理特性。

**数据链路层（Data Link Layer）：** 数据链路层建立了两个直接相连的节点之间的数据链路，负责将比特流分组成数据帧，并处理帧的错误检测和纠正。它还负责流控制、访问控制和物理地址的寻址，保证数据在一个局域网中可靠传输。

- `ARP`

  用于将IP地址（网络层地址）解析为对应的MAC地址（数据链路层地址），从而实现在局域网中的主机之间的通信。ARP协议的基本原理如下：

  1. **ARP请求（ARP Request）：** 当主机A需要与另一个主机B进行通信时，它首先检查本地的ARP缓存表（ARP Cache），看是否已经知道主机B的MAC地址。如果缓存表中没有对应的MAC地址，主机A将发送一个ARP请求广播。该ARP请求包含了主机A的IP地址和MAC地址，并指示需要解析的目标IP地址（主机B的IP地址）。ARP请求的目标MAC地址字段设置为广播地址（FF:FF:FF:FF:FF:FF），以确保在局域网上的所有主机都能接收到该请求。
  2. **ARP响应（ARP Reply）：** 收到ARP请求的主机B会检查请求中的目标IP地址是否与自己的IP地址匹配。如果匹配，主机B会构建一个ARP响应报文，其中包含它自己的IP地址和MAC地址，并发送给主机A。ARP响应的目标MAC地址字段设置为主机A的MAC地址，以确保只有主机A能够接收到该响应。
  3. **ARP缓存更新：** 一旦主机A收到主机B的ARP响应，它将会将主机B的IP地址和MAC地址添加到自己的ARP缓存表中。这样，下次主机A需要与主机B通信时，就可以直接从缓存表中找到对应的MAC地址，而无需再发送ARP请求。
  4. **ARP缓存表：** ARP缓存表是每个主机维护的一个表格，用于存储IP地址和对应的MAC地址。在通信过程中，主机会根据需要不断更新ARP缓存表，以确保正确解析IP地址到MAC地址的映射关系。

  总结来说，ARP协议的基本原理是通过ARP请求和ARP响应来实现IP地址到MAC地址的解析。主机在通信前先查看自己的ARP缓存表，如果找不到对应的MAC地址，就发送ARP请求来询问其他主机，该IP地址对应的MAC地址是什么。然后目标主机收到ARP请求后，根据自己的IP地址进行匹配，如果匹配成功，就发送ARP响应来告诉请求主机自己的MAC地址。请求主机收到响应后，将IP地址和MAC地址的映射关系添加到自己的ARP缓存表中，以便后续通信直接使用。这样就实现了IP地址到MAC地址的解析和通信。

  

- `Ethernet`：**以太网**是数据链路层的一种具体实现，它定义了如何在局域网上传输数据。以太网帧的格式如下：

**网络层（Network Layer）：** 网络层负责数据的**路由选择和转发**，将数据包从源地址传送到目标地址，实现跨不同网络的数据传输。它使用IP地址来寻址，并处理不同子网之间的数据转发问题。

- `ICMP`(`Ping`的原理：发送**ICMP回显请求**以及**ICMP回显响应**报文的同时，记录两次时间戳差值)	
- `IP`

**传输层（Transport Layer）：** 传输层提供端到端的数据传输服务，确保数据在源和目标之间的可靠传输。它使用端口号来标识不同的应用程序，并提供数据的分段和重组，同时还负责流量控制和错误恢复。

**会话层（Session Layer）：** 会话层负责建立、管理和终止应用程序之间的会话或连接。它提供会话的同步、检查点、恢复和数据同步功能，确保应用程序能够在通信过程中进行交互

- `TLS`（https四次握手）
- `SSH`

**表示层（Presentation Layer）：** 表示层负责数据的格式转换和编码，确保应用程序能够正确解释和处理收到的数据。它处理数据的加密和解密，以及数据的压缩和解压缩

- 数据的序列化/反序列化

**应用层（Application Layer）：** 应用层是最高层，直接与用户的应用程序进行交互。它提供了各种网络服务和协议，如HTTP、FTP、SMTP等，使应用程序能够访问网络并进行数据交换

- `HTTP`
- `FTP`
- `DNS`



## Linux系统如何收发数据包的？

![img](https://github.com/amonstercat/PicGo/blob/main/dell/202403061643382.png?raw=true)

从上图的的网络协议栈，你可以看到：

- 应用程序需要通过**系统调用**，**来跟 Socket 层进行数据交互**；
- Socket 层的下面就是传输层、网络层和网络接口层；
- 最下面的一层，则是**网卡**驱动程序和硬件**网卡设备**；



网卡是计算机里的一个硬件，专门负责接收和发送网络包，当网卡接收到一个网络包后，会通过 DMA 技术，将网络包写入到指定的内存地址，也就是写入到 **Ring Buffer** ，这个是一个环形缓冲区，接着就会告诉操作系统这个网络包已经到达。

![img](https://github.com/amonstercat/PicGo/blob/main/dell/202403061652820.png?raw=true)

[linux系统是如何进行数据包收发的？](https://xiaolincoding.com/network/1_base/how_os_deal_network_package.html#linux-%E5%8F%91%E9%80%81%E7%BD%91%E7%BB%9C%E5%8C%85%E7%9A%84%E6%B5%81%E7%A8%8B)



## WireShark抓包







## 路由器工作原理



路由器的工作原理涉及路由选择、数据包转发和网络分割等过程，主要包括以下几个方面：

1. **路由选择：** 路由器通过路由选择算法确定数据包的最佳转发路径。路由选择算法考虑了多个因素，如目标地址、跳数、带宽、拥塞等，以确保数据包能够尽快、高效地到达目的地。路由选择通常是通过路由表来实现的，路由表中记录了不同网络的IP地址范围和对应的出口接口。
2. **数据包转发：** 当路由器收到一个数据包时，它会检查数据包的目标IP地址，并根据路由表选择最佳的转发路径。路由器会将数据包从接收端口转发到合适的出口端口，以便将数据包发送到下一个网络或目的地。在转发数据包时，路由器会使用数据链路层的MAC地址来确定下一跳的物理地址。
3. **网络分割：** 路由器将不同的网络分割成多个子网，并通过转发数据包实现不同子网之间的通信。每个子网拥有自己的IP地址范围，路由器根据目标IP地址来确定数据包应该转发到哪个子网。通过网络分割，路由器实现了对网络流量的控制和管理，避免了整个网络范围内的数据冲突和拥塞。
4. **数据包过滤：** 路由器可以根据配置的访问控制列表（ACL）来过滤和限制数据包的转发。ACL可以根据源IP地址、目标IP地址、端口号等条件来过滤数据包，从而实现网络的安全策略和访问控制。
5. **NAT（Network Address Translation）：** 一些路由器还支持NAT功能，它将内部私有IP地址转换为外部公共IP地址，实现内部网络与外部Internet的连接。NAT技术允许多个内部设备共享一个公共IP地址，提高了网络的安全性和私有性





## 如何基于UDP协议实现可靠传输？ :cry:



 TCP 协议四个方面的缺陷：

- 升级 TCP 的工作很困难；
- TCP 建立连接的延迟；
- TCP 存在队头阻塞问题；
- 网络迁移需要重新建立 TCP 连接；

现在市面上已经有基于 UDP 协议实现的可靠传输协议的成熟方案了，那就是 QUIC 协议，已经应用在了 HTTP/3。QUIC 协议也有类似 HTTP/2 Stream 与多路复用的概念，也是可以在同一条连接上并发传输多个 Stream，**Stream 可以认为就是一条 HTTP 请求**

这次，**聊聊 QUIC 是如何实现可靠传输的？又是如何解决上面 TCP 协议四个方面的缺陷**？

<img src="https://cdn.xiaolincoding.com//mysql/other/605d1026df934f20a5ee12f3c55aa6a7.png" alt="img" style="zoom:67%;" />

**1、Packet Header**

Packet Header 首次建立连接时和日常传输数据时使用的 Header 是不同的。如下图（*注意我没有把 Header 所有字段都画出来，只是画出了重要的字段*）：

![Packet Header](https://cdn.xiaolincoding.com//mysql/other/bcf3ccb6a15c4cdebe1cd0527fdd9a5e.png)

Packet Header 细分这两种：

- Long Packet Header 用于首次建立连接。
- Short Packet Header 用于日常传输数据。

QUIC 也是需要三次握手来建立连接的，主要目的是为了协商连接 ID。协商出连接 ID 后，后续传输时，双方只需要固定住连接 ID，从而实现连接迁移功能。所以，你可以看到日常传输数据的 Short Packet Header 不需要在传输 Source Connection ID 字段了，只需要传输 Destination Connection ID。

Short Packet Header 中的 `Packet Number` 是每个报文独一无二的编号，它是**严格递增**的，也就是说就算 Packet N 丢失了，重传的 Packet N 的 Packet Number 已经不是 N，而是一个比 N 大的值。


<img src="https://cdn.xiaolincoding.com//mysql/other/635813465fbb449882da2e2bee39f24e.png" alt="img" style="zoom:67%;" />

> 为什么要这么设计呢？

当 TCP 发生超时重传后，客户端发起重传，然后接收到了服务端确认 ACK 。由于客户端原始报文和重传报文序列号都是一样的，那么服务端针对这两个报文回复的都是相同的 ACK。

这样的话，客户端就无法判断出是「原始报文的响应」还是「重传报文的响应」，这样在计算 RTT（往返时间） 时应该选择从发送原始报文开始计算，还是重传原始报文开始计算呢？

- 如果算成原始请求的响应，但实际上是重传请求的响应（上图左），会导致采样 RTT 变大。
- 如果算成重传请求的响应，但实际上是原始请求的响应（上图右），又很容易导致采样 RTT 过小。

RTO （超时时间）是基于 RTT 来计算的，那么如果 RTT 计算不精准，那么 RTO （超时时间）也会不精确，这样可能导致重传的概率事件增大。

QUIC 报文中的 Packet Number 是严格递增的， 即使是重传报文，它的 Packet Number 也是递增的，这样就能更加精确计算出报文的 RTT。


![img](https://cdn.xiaolincoding.com//mysql/other/ca91985c9a94487a8a29db1249109717.png)

**如果 ACK 的 Packet Number 是 N+M，就根据重传报文计算采样 RTT。如果 ACK 的 Packet Number 是 N，就根据原始报文的时间计算采样 RTT，没有歧义性的问题**

另外，还有一个好处，**QUIC 使用的 Packet Number 单调递增的设计，可以让数据包不再像 TCP 那样必须有序确认，QUIC 支持乱序确认，当数据包Packet N 丢失后，只要有新的已接收数据包确认，当前发送窗口就会继续向右滑动**

待发送端获知数据包Packet N 丢失后，会将需要重传的数据包放到待发送队列，**重新编号**比如数据包Packet N+M 后重新发送给接收端，对重传数据包的处理跟发送新的数据包类似，这样就不会因为丢包重传将当前窗口阻塞在原地，从而解决了队头阻塞问题。

所以，Packet Number 单调递增的两个好处：

- 可以更加精确计算 RTT，没有 TCP 重传的歧义性问题；
- 可以支持乱序确认，因为丢包重传将当前窗口阻塞在原地，而 **TCP 必须是顺序确认的，丢包时会导致窗口不滑动**；





> 那么问题来了，既然重传数据包的 Packet N+M 与丢失数据包的 Packet N 编号并不一致，我们怎么确定这两个数据包的内容一样呢？

一个 Packet 报文中可以存放多个 QUIC Frame（以Stream类型的Frame为例，该Frame中有Stream ID+Offset）:

<img src="https://cdn.xiaolincoding.com//mysql/other/6a94d41ef3d14cb6b7846e73da6c3104.png" alt="img" style="zoom: 67%;" />



所以引入 Frame Header 这一层，**通过 Stream ID + Offset 字段信息实现数据的有序性**，通过比较两个数据包的 `Stream ID` 与 `Stream Offset` ，如果都是一致，就说明这两个数据包的内容一致。

举个例子，下图中，数据包 Packet N 丢失了，后面重传该数据包的编号为 Packet N+2，**丢失的数据包和重传的数据包 Stream ID 与 Offset 都一致，说明这两个数据包的内容一致**。这些数据包传输到接收端后，接收端能根据 Stream ID 与 Offset 字段信息将 Stream x 和 Stream x+y 按照顺序组织起来，然后交给应用程序处理。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/network/quic/Packet%E4%B8%A2%E5%A4%B1.jpeg)

总的来说，**QUIC 通过单向递增的 Packet Number，配合 Stream ID 与 Offset 字段信息，可以支持乱序确认而不影响数据包的正确组装**，摆脱了TCP 必须按顺序确认应答 ACK 的限制，解决了 TCP 因某个数据包重传而阻塞后续所有待发送数据包的问题



> QUIC如何实现更快的连接建立？
>
> 对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手（1RTT），再 TLS 握手（2RTT），所以需要 3RTT 的延迟才能传输数据，就算 Session 会话服用，也需要至少 2 个 RTT。
>
> HTTP/3 在传输数据前虽然需要 QUIC 协议握手，这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的。
>
> 如下图右边部分，HTTP/3 当会话恢复时，有效负载数据与第一个数据包一起发送，可以做到 0-RTT（下图的右下角）：
>
> <img src="https://github.com/amonstercat/PicGo/blob/main/dell/202403061850142.png?raw=true">
>
> 





## Cookie  Session  JWT



### **Cookie**

在HTTP请求中，Cookie信息存储在请求头部的"Cookie"字段中，并通过这个字段来发送给服务器。

Cookie的工作过程如下：

(1)服务器在响应浏览器的请求时，在响应头部设置一个名为"`Set-Cookie`"的字段，该字段包含了服务器要设置的Cookie信息。例如:

```http
Set-Cookie: session_id=abc123; HttpOnly; Secure; Max-Age=3600; Path=/
```

(2)浏览器接收到服务器响应后，会将这个Cookie信息保存在本地

(3)在后续的每个请求中，浏览器都会在请求头部添加一个名为"Cookie"的字段，值为之前保存的所有Cookie信息。例如：

```http
Cookie: session_id=abc123; other_cookie=xyz456
```

服务器收到请求后，会解析"Cookie"字段中的信息，从中提取出对应的数据，实现会话跟踪、用户状态管理等功能。





### **Session**

如果把用户名、密码等重要隐私都存到客户端的 Cookie 中，有泄密风险。为了更安全，故把机密信息保存到服务器上，这就是 `Session`。`Session`是服务器上维护的客户档案，**可以理解为服务器端数据库中有一张 user 表，里面存放了客户端的用户信息。SessionID 就是这张表的主键 ID**

> **Session机制通常依赖于Cookie来在客户端和服务器之间传输数据**。在典型的Web应用中，服务器会在客户端的浏览器中设置一个名为"session_id"（或其他自定义名称）的Cookie，用来唯一标识该用户的会话:
>
> `Set-Cookie: session_id=abc123; HttpOnly; Secure; Path=/`

基于Session传输数据的方式在某些情况下可能会面临以下问题： :astonished:

1. 状态管理：Session数据通常存储在服务器端，因此需要对会话状态进行管理。对于大量并发用户的系统，这可能导致**服务器负担过重，需要消耗更多的服务器资源来维护这些会话状态**。

2. 扩展性：由于Session数据存储在服务器端，所以在分布式系统中扩展会话管理可能会变得复杂。需要考虑如何在多个服务器之间共享会话数据或使用分布式缓存(`Redis`实现`session`共享)

   > Session共享是指在分布式系统中，多个服务器之间共享会话数据的问题。解决这个问题的方法可以有多种，以下是一些常见的解决方案：
   >
   > 1. 使用共享存储：将Session数据存储在所有服务器都可以访问的共享存储中，例如共享数据库、分布式缓存（如Redis、Memcached）或分布式文件系统。这样所有的服务器都可以从同一个存储位置读取和更新Session数据。
   > 2. 使用粘性会话（Sticky Sessions）：在负载均衡器中启用粘性会话配置，即确保同一个用户的请求总是发送到同一个后端服务器，这样在某个服务器上创建的Session可以在整个会话期间一直使用
   > 3. 使用分布式Session：使用专门的分布式Session管理方案，例如Spring Session等。这些方案通过将Session数据存储在共享存储中，同时使用Cookie或Header中的标识来跟踪用户的会话。
   > 4. 使用无状态认证：**避免在服务器端存储会话数据，而是使用无状态认证方案**，如JSON Web Token (JWT)。JWT将会话数据编码为Token，可以在客户端存储，这样就不需要在服务器端共享会话数据。
   > 5. 使用中央认证服务（`Centralized Authentication Service`）：采用单点登录（Single Sign-On，SSO）解决方案，引入一个独立的中央认证服务来管理用户的会话状态。这样用户只需要登录一次，就可以在多个相关系统中共享会话状态。

3. 内存消耗：随着用户数量的增加，**服务器需要存储和维护更多的Session数据**，这可能会导致内存消耗过大

4. 会话过期：Session通常有一个过期时间，一旦超过该时间，会话数据将被清除。这可能导致用户在一段时间内没有活动后需要重新登录或重新提交数据



`Cookie`和`Session`都是用于在Web应用中存储和管理用户状态信息的机制，但它们有一些关键的区别：

1. 存储位置：
   - Cookie：Cookie是存储在用户浏览器端的小段文本信息。当服务器响应浏览器的请求时，会在响应头中设置一个名为"Set-Cookie"的字段，浏览器会将这个Cookie保存在本地，以后每次请求都会自动携带这个Cookie信息
   - Session：Session是存储在服务器端的用户状态信息。当用户第一次访问服务器时，服务器会创建一个唯一的Session标识，并将其存储在服务器上。然后在用户的每次请求中，浏览器会携带这个Session标识，服务器通过它来识别用户并管理其状态
2. 存储内容：
   - Cookie：Cookie一般存储少量的文本信息，用于标识和存储用户的一些状态，如登录信息、用户偏好等
   - Session：Session在服务器端存储，因此可以存储更大量的数据，一般用于存储用户在网站上的交互信息、购物车内容、权限等
3. 安全性：
   - Cookie：Cookie存储在浏览器端，虽然可以设置Cookie的过期时间和安全标记（Secure和HttpOnly），但仍然容易受到一些安全攻击，如跨站脚本（XSS）和跨站请求伪造（CSRF）
   - Session：Session存储在服务器端，相对来说更安全，因为用户无法直接修改其中的数据，但也要防范Session劫持等安全问题







### JWT

JWT 的英文全称是 `JSON Web Token`。JWT 把所有信息都存在自己身上了，包括用户名密码、加密信息等，且以 JSON 对象存储的

**一个JWT实际上就是一个字符串，它由三部分组成，头部、载荷与签名**

**1. 头部（Header）**

头部用于描述关于该JWT的最基本的信息，例如其类型以及签名所用的算法等。这也可以被表示成一个JSON对象，下面字符串在头部指明了签名算法是HS256算法,**头部使用Base64编码，但不加密**

```text
{
  "alg": "HS256",
  "typ": "JWT"
}
```



**2. 载荷（payload）**

载荷就是是存储实际数据的部分。JWT的载荷可以包含自定义的声明（Claim），如用户ID、角色、权限等，**载荷同样使用Base64编码，但不进行加密**

定义一个payload:

```
{
  "sub": "john_doe",
  "role": "admin",
  "iat": 1626302604,
  "exp": 1626303504
}


```

这个例子中，载荷包含了以下信息：

- "sub"（Subject）：用户名，这里是"john_doe"。
- "role"：用户角色，这里是"admin"，表示用户具有管理员权限。
- "iat"（Issued At）：JWT的发行时间，这里是Unix时间戳，表示JWT的发行时间为2021年7月15日 10:30:04。
- "exp"（Expiration Time）：JWT的过期时间，这里也是Unix时间戳，表示JWT的过期时间为2021年7月15日 10:45:04



**3.签证（signature）**

jwt的第三部分是一个签名，signature 是对前两个部分的签名，防止数据被篡改。

```javascript
data = base64urlEncode( header ) + "." + base64urlEncode( payload );
signature = Hash( data, secret );
```

在 JWT 中，`secret` 是指用于生成和验证签名的密钥。当使用 HMAC 算法（如 HS256、HS384、HS512）时，`secret` 是一个对称密钥，由签发 JWT 的服务端生成并存储。具体来说，`secret` 的作用如下：

1. **生成签名：** 在签发 JWT 时，服务端会使用 `secret` 对头部和载荷进行签名生成签名部分。这是通过将头部和载荷序列化为 JSON 字符串，然后使用指定的哈希算法和 `secret` 进行哈希运算来实现的。
2. **验证签名：** 在验证 JWT 时，接收端需要获取到 JWT 中的签名部分，并使用与签发端相同的 `secret` 对头部和载荷进行相同的哈希运算。接收端会比较生成的签名部分与 JWT 中的签名部分是否一致，从而验证 JWT 的完整性和真实性。

由于 HMAC 算法使用的是对称密钥，因此需要确保签发 JWT 和验证 JWT 的两端都知道相同的 `secret`。**这意味着 `secret` 必须在签发 JWT 时与接收端共享，以便接收端能够使用相同的密钥来验证 JWT 的签名，即客户端发送jwt给服务器时，服务器已经有了这个secret密钥了！**



JWT的工作流程如下：

1. 用户向服务器发送登录请求，服务器验证用户的身份和凭据
2. 服务器在验证成功后生成一个JWT，将用户的信息和其他必要信息添加到JWT的载荷中
3. 服务器将JWT发送回客户端，客户端将其保存，通常存储在本地存储（`LocalStorage`）或会话存储（`SessionStorage`）中
4. 客户端在后续请求中，将JWT通过请求头或其他方式发送给服务器
5. 服务器接收到JWT后，使用之前设置的密钥来验证JWT的签名，并解析出用户信息和其他数据，完成用户认证和授权



以下是一个简单的例子：

假设有一个Web应用程序，用户通过用户名和密码登录，服务器验证用户信息后，使用JWT生成一个令牌，并将其返回给客户端。JWT的载荷中包含了用户名和用户角色信息。

**登录请求**： 客户端发送登录请求

```http
POST /login HTTP/1.1
Content-Type: application/json

{
  "username": "john_doe",
  "password": "secret123"
}
```

服务器验证用户名和密码成功后，**生成JWT并发送回客户端**：

```http
HTTP/1.1 200 OK
Content-Type: application/json

{
  "access_token": #JWT
  "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VybmFtZSI6ImpvaG5fZG9lIiwicm9sZSI6ImFkbWluIiwiaWF0IjoxNjI2MzAyNjA0LCJleHAiOjE2MjYzMDM1MDR9.BQzczqJLk5pODe0fojQGtfIhLOJ-i4Fm4tS7VqO8Bmo"
}
```

**后续请求**： 客户端在后续的请求中，在请求头中携带JWT作为身份认证信息：

```http
GET /api/data HTTP/1.1
Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VybmFtZSI6ImpvaG5fZG9lIiwicm9sZSI6ImFkbWluIiwiaWF0IjoxNjI2MzAyNjA0LCJleHAiOjE2MjYzMDM1MDR9.BQzczqJLk5pODe0fojQGtfIhLOJ-i4Fm4tS7VqO8Bmo
```

服务器接收到请求后，会解析JWT并验证签名和有效期。如果验证成功，服务器会根据JWT中的信息对用户进行授权，并返回请求的数据。这样，通过JWT，服务器可以在不需要存储会话信息的情况下，对用户进行身份验证和授权，实现了无状态的身份验证方案

> `Authorization: Bearer`是一种HTTP请求头，用于在客户端向服务器发送请求时携带身份验证凭证（通常是令牌）。这种身份验证方式通常与JWT（JSON Web Token）一起使用。
>
> 在使用JWT进行身份验证时，客户端通常在请求头中使用`Authorization: Bearer`头部来传递JWT令牌。这个头部的格式如下：
>
> ```http
> Authorization: Bearer <token>
> ```
>
> 其中，`<token>`是由服务器颁发的JWT令牌，它会放在`Bearer`后面，并用空格分隔。





## HTTP

### HTTP报文格式

```
[请求行/状态行]
[请求头/响应头]
[空行]
[请求体/响应体]
```

在HTTP协议中，头部（Header）和主体（Body）之间通过一个空行来进行分割。这个空行是由**回车符（CR）和换行符（LF）**组成的一行，即"\r\n"，这个空行标志着头部的结束和主体的开始

请求行或状态行包含了HTTP方法（GET、POST、PUT）**或HTTP协议版本**、状态码和状态描述（对于状态行）

请求头或响应头包含了一系列的键值对，用于传递关于请求或响应的附加信息。每个键值对以冒号（:）分隔，例如`Content-Type: application/json`

空行（即只包含回车符和换行符的行）用于分隔头部和主体。

请求体或响应体包含了实际的数据，例如HTML文档、JSON数据等

示例一个HTTP请求报文的例子：

```http
GET /index.html HTTP/1.1     请求行
Host: example.com          
User-Agent: Mozilla/5.0
Accept: text/html

[请求体]
```

在这个例子中，请求行为`GET /index.html HTTP/1.1`，请求头包括 `Host、User-Agent和Accept` 字段，空行之后是请求体（如果有）。

### HTTP首部字段（header）

HTTP首部字段根据用途可分为4种类型：

- 通用首部字段（General Header Fields） 请求和响应报文两方都会使用的首部字段

  ```
  Connetcion: Keep-Alive //长连接
  Cache-Control：no-cache
  Date: 创建报文的日期
  ```

- 请求首部字段（Request Header Fields）客户端向服务器发送请求的报文时使用的首部。补充了请求的附加内容、客户端信息、响应内容相关的优先等级信息

  ```
  Accept: text/plain     */* 表示可以接收所有类型数据
  Accept-Language: en-US  //能够接受的回应内容的自然语言列表
  Accept-Encoding: gzip, deflate  //能够接受的编码方式列表
  If-Modified-Since:  Sat, 29 Oct 2020 19:43:31 GMT  //让服务器判断该资源在该日期后是否被修改过
  If-Match:  If-Match: "737060cd8c284d8af7ad3082f209582d" 仅当客户端提供的实体与服务器上对应的实体相匹配时，才进行对应的操作
  If-None-Match： 比较实体标记(ETage)，不相等时才继续操作   与 If-Match相反
  User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:12.0) Gecko/20100101 Firefox/21.0
  Cookie:
  ```

- 响应首部字段（Response Header Fields）从服务器向客户端响应时使用的字段，补充响应的附加内容，也会要求客户端附加额外信息

  ```
  Location: 令客户端重定向的URI
  Server: 服务器的信息
  Proxy-Authenticate: 代理服务器要求客户端的验证信息
  Retry-After:   和状态码503一起使用的首部字段，表示下次请求服务器的时间
  ETag: 能够表示资源唯一资源的字符串
  Last-Modified: 该响应资源最后的修改时间
  Set-Cookie:
  ```

- 实体首部字段（Entiy Header Fields） 针对请求报文和响应报文的实体部分使用首部。补充了资源内容更新时间等实体有关的信息

  ```
  Content-Language:
  Content-Encoding:gzip  //实体的编码格式
  Content-Length：1000   //实体的大小（字节）
  Content-Type: text/html; Charset=utf-8  实体媒体类型
  Last-Modified: 资源最后的修改时间
  ```





### HTTPS

预备知识：

（1）混合加密：HTTPS 采用的是**对称加密**和**非对称加密**结合的「混合加密」方式

- 在通信建立前采用**非对称加密**的方式**交换「会话秘钥」**，后续就不再使用非对称加密。
- 在通信过程中全部使用**对称加密**的「会话秘钥」的方式加密明文数据。

（2）摘要算法+数字签名：

- 对密文进行哈希运算

![MAC](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E6%91%98%E8%A6%81%E7%AE%97%E6%B3%95.jpg)

- 同时对计算后的哈希值进行签名（私钥加密-公钥解密）

![数字签名](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D.jpg)

（3）数字证书（CA机构）

CA对服务器提供的公钥进行数字签名（**私钥加密**），并将服务器的公钥放在数字证书中，**客户端通过CA公钥解密数字证书**，既得到了服务器的公钥，又证明了权威性：

![Certificate-Authentication](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/CA.jpg)





在进行 HTTPS 通信时，**TLS 握手（TLS Handshake）是在 TCP 握手（TCP Handshake）之后进行的**。



SSL/TLS 基本流程如下：

- 客户端向服务器索要并验证服务器的公钥
- 双方协商生产「会话秘钥」
- 双方采用「会话秘钥」进行加密通信

前两步即`TLS`的建立，基于 `RSA` 算法的`TLS`四次握手过程如下:
![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/23-HTTPS%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.jpg)

*1. `ClientHello`*
首先，由客户端向服务器发起加密通信请求，也就是 `ClientHello` 请求。

在这一步，客户端主要向服务器发送以下信息：

（1）**客户端支持的 TLS 协议版本**，如 TLS 1.2 版本

（2）客户端生成的随机数（`Client Random`），后面用于生成「会话秘钥」条件之一。

（3）客户端支持的密码套件列表，如 RSA 加密算法

*2. `SeverHello`*

服务器收到客户端请求后，向客户端发出响应，也就是 `SeverHello`。服务器回应的内容有如下内容：

（1）确认 TLS 协议版本，如果浏览器不支持，则关闭加密通信(浏览器要匹配客户端的TLS协议)

（2）服务器生产的随机数（`Server Random`），也是后面用于生产「会话秘钥」条件之一

（3）确认的密码套件列表，如 RSA 加密算法

（4）**服务器的数字证书**

*3.客户端回应*

客户端收到服务器的回应之后，首先**通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性**。

如果证书没有问题，客户端会**从数字证书中取出服务器的公钥**，然后使用它加密报文，向服务器发送如下信息：

（1）一个随机数（`pre-master key`）。**该随机数会被服务器公钥加密（因为前两次交互产生的随机数有可能被窃听到）**。

（2）**加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信**。

（3）客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。

上面第一项的随机数是整个握手阶段的第三个随机数，会发给服务端，所以这个随机数客户端和服务端都是一样的。

**服务器和客户端有了这三个随机数（Client Random、Server Random、pre-master key），接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」**。

*4. 服务器的最后回应*

服务器收到客户端的第三个随机数（`pre-master key`）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。

然后，向客户端发送最后的信息：

（1）**加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信**

（2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验

至此，整个 TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信(流程的第三阶段)，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容







### HTTP演变 😶‍🌫️

#### http1.1

`Keep-Alive`:  早期的 `HTTP 1.0` 每发起一个请求，都要新建一次 TCP 连接（三次握手），而且是串行请求，做了无谓的 TCP 连接建立和断开，增加了通信开销,为了解决上述 TCP 连接问题，**HTTP/1.1** 提出了**长连接**的通信方式，也叫`Keep-Alive` ，这种方式的好处在于减少了 `TCP` 连接的重复建立和断开所造成的额外开销，减轻了服务器端的负载

管道传输: 同时http1.1支持管道传输：即在同一个 TCP 连接里面，客户端可以发起多个请求，**只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去**，但是**服务器必须按照接收请求的顺序发送对这些管道化请求的响应**，如果服务端在处理前面请求时耗时比较长，那么后续请求的处理都会被阻塞住，这称为响应端的队头堵塞。所以 **HTTP/1.1** 管道**解决了请求的队头阻塞（A请求发出后就可接着发送B、C请求）**，但是**没有解决响应的队头阻塞**( HTTP/1.1 管道化技术不是默认开启，而且浏览器基本都没有支持)



#### http2

1 安全性：`HTTP/2` 协议是基于 **HTTPS** 的，所以 `HTTP/2` 的安全性有了保障

2 压缩头部： HTTP/2 会**压缩头**（Header）如果同时发出多个请求，他们的头是一样的或是相似的，那么协议会帮你**消除重复的部分**

3 二进制格式： HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是**全面采用了二进制格式，头信息和数据体都是二进制，并且统称为帧**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/http2/%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%B8%A7.png" alt="HTTP/1 与 HTTP/2 " style="zoom:50%;" />



4 并发传输`Stream`: 

HTTP/1.1 的实现是基于请求-响应模型的。**同一个连接中，HTTP 完成一个事务（请求与响应），才能处理下一个事务**，也就是说在发出请求等待响应的过程中，是没办法做其他事情的，如果响应迟迟不来，那么后续的请求是无法发送的(默认没有开启管道传输)，也造成了**队头阻塞**的问题

**针对不同的 HTTP 请求用独一无二的 Stream ID 来区分，接收端可以通过 Stream ID 有序组装成 HTTP 消息，不同 Stream 的帧是可以乱序发送的，因此可以并发不同的 Stream(Stream 里可以包含 1 个或多个 Message，Message 对应 HTTP/1 中的请求或响应) ，也就是 HTTP/2 可以并行交错地发送请求和响应**,客户端/服务端在收到Stream后根据相同的`StreamID`有序组装成完整的HTTP消息。 比如下图，服务端**并行交错地**发送了两个响应： Stream 1 和 Stream 3，这两个 Stream 都是跑在一个 TCP 连接上，客户端收到后，会根据相同的 Stream ID 有序组装成 HTTP 消息

![HTTP2](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/http2%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8.webp)



>  比如`Server`收到了多个`stream 1`帧，会将所有ID相同的帧组装成一个`HTTP`消息



5 服务器主动推送：HTTP/2中服务端不再是被动地响应，可以**主动**向客户端发送消息，客户端和服务器**双方都可以建立 `Stream`**，`Stream ID` 也是有区别的，客户端建立的 `Stream ID` 必须是奇数号，而服务器建立的 `Stream ID` 必须是偶数号







**问题所在**：

`HTTP/2` 通过 `Stream` 的并发能力，解决了 `HTTP/1` 队头阻塞(请求端+响应端)的问题，看似很完美了，但是 HTTP/2 还是存在“队头阻塞”的问题，只不过问题不是在 HTTP 这一层面，**而是在 `TCP` 这一层**：

例如发送方发送了很多个 packet（1-6），每个 packet 都有自己的序号，可以认为是 TCP 的序列号，其中 packet 3 在网络中丢失了，即使 packet 4-6 被接收方收到后，由于内核中的 TCP 数据不是连续的，于是接收方的应用层就无法从内核中读取到**，只有等到 packet 3 重传后，接收方的应用层才可以从内核中读取到数据，这就是 HTTP/2 的队头阻塞问题，是在 TCP 层面发生的**。即一旦发生了丢包现象，就会**触发 TCP 的重传机制**，这样在一个 TCP 连接中的**所有的 HTTP 请求都必须等待这个丢了的包被重传回来**





#### http3(必看👀)



HTTP/1.1 和 HTTP/2 都有队头阻塞的问题：

- HTTP/1.1 中的管道（ pipeline）虽然解决了请求的队头阻塞，但是**没有解决响应的队头阻塞**，因为服务端需要按顺序响应收到的请求，如果服务端处理某个请求消耗的时间比较长，那么只能等响应完这个请求后， 才能处理下一个请求，这属于 HTTP 层队头阻塞
- HTTP/2 虽然通过多个请求复用一个 TCP 连接解决了 HTTP 的队头阻塞 ，但是**一旦发生丢包，就会阻塞住所有的 HTTP 请求**，这属于 TCP 层队头阻塞





HTTP/2 队头阻塞的问题是因为 TCP，所以 **HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！**

`UDP`发送是不管顺序，也不管丢包的，所以不会出现像 HTTP/2 队头阻塞的问题,且基于 UDP 的 **`QUIC` 协议** 可以实现类似 TCP 的可靠性传输！





> **没有队头阻塞的 QUIC**

QUIC 也借鉴 HTTP/2 里的 Stream 的概念，在一条 QUIC 连接上可以并发发送多个 HTTP 请求 (Stream)。

但是 **QUIC 给每一个 Stream 都分配了一个独立的滑动窗口，这样使得一个连接上的多个 Stream 之间没有依赖关系，都是相互独立的，各自控制的滑动窗口**。

假如 Stream2 丢了一个 UDP 包，也只会影响 Stream2 的处理，不会影响其他 Stream，与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响(因为这些stream是跑在一个tcp连接上的)

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/network/quic/quic%E6%97%A0%E9%98%BB%E5%A1%9E.jpeg)





**`QUIC`协议**(位于传输层！！！)有以下 3 个特点：

- 无队头阻塞 

- 更快的连接建立
- 连接迁移







(1) `QUIC` 协议也有类似 HTTP/2 `Stream` 与多路复用的概念，也是可以在同一条连接上并发传输多个 `Stream`，`Stream` 可以认为就是一条 HTTP 请求，同时 QUIC 有自己的一套机制可以保证传输的可靠性，**当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题**，这与 HTTP/2 不同，**HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响(因为涉及到TCP的ACK重传机制)**





(2) 对于 HTTP/1 和 HTTP/2 协议，`TCP` 和 `TLS` 是分层的，分别属于内核实现的传输层、`openssl` 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手，再 TLS 握手; 而`HTTP/3` 在传输数据前虽然需要 `QUIC` 协议握手，但是这个握手过程只需要 1 RTT( **HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是 QUIC 内部包含了 TLS**)，握手的目的是为确认双方的「连接 ID」，**连接迁移就是基于连接 ID 实现**





(3) 基于 TCP 传输协议的 HTTP 协议，是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 `TCP` 连接,**当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立连接**。而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下;而 `QUIC` 协议是通过**连接 ID** 来标记通信的两个端点，**客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的IP地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以无缝复用原连接，消除重连的成本**







### HTTP与RPC对比

首先要知道 TCP 有三个特点，面向连接、可靠、基于**字节流(无边界)**，而字节流就是01串，无法区分一条消息的边界，因此需要加入一些自定义规则，把每条要发送的数据都包装一下，比如加入**消息头**，**消息头里写清楚一个完整的包长度是多少**，根据这个长度可以继续接收数据，截取出来后它们就是我们真正要传输的**消息体**，基于 TCP 造出来的 `HTTP` 和**各类** `RPC` 协议，它们都只是定义了不同消息格式的**应用层协议**

早期电脑上各种联网软件作为**客户端（Client）需要跟服务端（Server）建立连接收发消息**，在这种C/S架构下，使用自家造的 `RPC` 协议就够了；而**浏览器（Browser）**不仅要能访问自家公司的**服务器（Server）**，还需要访问其他公司的网站服务器，因此它们需要有个统一的标准，HTTP 就是那个时代用于统一 **(B/S)** 的协议 ，下面来总结一下两者的主要区别：

#### 服务发现

要向某个服务发起请求，要先建立连接，这样就必须确定对方的 **IP地址和端口**，找到服务对应的IP端口的过程，就是**服务发现，**在 **HTTP** 中，知道服务的域名，就可以通过 **DNS **去解析得到背后的 IP 地址， 而 **RPC** 一般会有专门的**服务注册中心**去保存服务名和IP信息，比如`Nacos`、`Zookeeper`、**`Consul`** ,如果想要访问某个服务，消费者首先需要去注册中心获取到服务的IP 和端口信息

#### 底层连接形式

主流的 **HTTP/1.1** 协议为例，默认在建立底层 TCP 连接之后会一直保持这个连接（**Keep Alive**），之后的请求和响应都会复用这条连接，而 **RPC** 协议跟 HTTP 类似，也通过建立 TCP 长连接进行数据交互，但不同的地方在于RPC 协议一般还会再建个**连接池**，在请求量大的时候，建立多条连接放在池内，要发数据的时候就从池里取一条连接出来，**用完放回去，下次再复用**



#### 传输内容

基于 TCP 传输的消息就是 **消息头 Header +消息体 Body**

**Header** 是用于标记一些特殊信息，其中最重要的是**消息体长度**

**Body** 则是放我们真正需要传输的内容，而这些内容只能是二进制 01 串，所以 TCP 传字符串和数字都很方便，因为字符串可以转成编码再变成 01 串，而数字本身也能直接转为二进制。但结构体/对象呢，需要将它们转为二进制 01 串(序列化)，这就需要使用`Json`、`Protobuf`、`Hessian`、`Kryo`等序列化方法

主流的 HTTP/1.1，传的内容以字符串为主(Header 和 Body 都是如此),在 Body 这块，它使用 **Json** 来**序列化**结构体数据，而 RPC因为它定制化程度更高，可以采用体积更小的 `Protobuf` 或其他序列化协议去保存结构体/对象数据，同时也不需要像 HTTP 那样考虑各种浏览器行为，比如 `302` 重定向跳转等

HTTP/2 在前者的基础上做了很多改进(头信息和数据体都是二进制，并且统称为帧（frame）)，所以**性能可能比很多 RPC 协议还要好**，甚至连 `gRPC` 底层都直接用的 `HTTP/2`



**总结**：

-  纯裸 TCP 是能收发数据，但它是个**无边界**的数据流，上层需要定义**消息格式**用于定义**消息边界**。于是就有了各种协议，HTTP 和各类 RPC 协议就是在 TCP 之上定义的应用层协议
- RPC 本质上不算是协议，而是一种调用方式**，而像 gRPC 和 Thrift 这样的具体实现，才是协议，它们是实现了 RPC 调用的协议。目的是希望程序员能像调用本地方法那样去调用远端的服务方法。同时 RPC 有很多种实现方式，**不一定基于 TCP 协议
- **HTTP 主要用于 B/S 架构，而 RPC 更多用于 C/S 架构。但现在，B/S 和 C/S 在慢慢融合**，很多软件同时支持多端，所以对外一般用 HTTP 协议，而**内部集群的微服务之间则采用 RPC 协议进行通讯**



### HTTP状态码 :ear:

 ![ 五大类 HTTP 状态码 ](https://cdn.jsdelivr.net/gh/amonstercat/PicGo@master/202403081513864.png)

`1xx` 类状态码属于**提示信息**，是协议处理中的一种中间状态，实际用到的比较少。

`2xx` 类状态码表示服务器**成功**处理了客户端的请求，也是我们最愿意看到的状态。

- 「**200 OK**」是最常见的成功状态码，表示一切正常。如果是非 `HEAD` 请求，服务器返回的响应头都会有 body 数据。
- 「**204 No Content**」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。
- 「**206 Partial Content**」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。

`3xx` 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是**重定向**。

- 「**301 Moved Permanently**」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。
- 「**302 Found**」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。

301 和 302 都会在响应头里使用字段 `Location`，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。

- 「**304 Not Modified**」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。

`4xx` 类状态码表示客户端发送的**报文有误**，服务器无法处理，也就是错误码的含义。

- 「**400 Bad Request**」表示客户端请求的报文有错误，但只是个笼统的错误。
- 「**403 Forbidden**」表示服务器禁止访问资源，并不是客户端的请求出错。
- 「**404 Not Found**」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。
- 「**429 Too Many Requests**」该状态码表示客户端在给定的时间内发送了太多的请求，超出了服务器的处理能力或限制。服务器会通过这个状态码来告知客户端暂时无法处理请求，并建议客户端在稍后重试。

`5xx` 类状态码表示客户端请求报文正确，但是**服务器处理时内部发生了错误**，属于服务器端的错误码。

- 「**500 Internal Server Error**」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。
- 「**501 Not Implemented**」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。
- 「**502 Bad Gateway**」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。
- 「**503 Service Unavailable**」表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思。



### HTTP缓存

https://xiaolincoding.com/network/2_http/http_interview.html#http-%E7%BC%93%E5%AD%98%E6%8A%80%E6%9C%AF

（1）强制缓存

  强缓存指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边。

如下图中，返回的是 200 状态码，但在 size 项中标识的是 from disk cache，就是使用了强制缓存。

![img](https://cdn.jsdelivr.net/gh/amonstercat/PicGo@master/202403081524922.png)

强缓存是利用下面这两个 HTTP 响应头部（Response Header）字段实现的，它们都用来表示资源在客户端缓存的有效期：

- `Cache-Control`， 是一个相对时间；
- `Expires`，是一个绝对时间；

如果 HTTP 响应头部同时有 Cache-Control 和 Expires 字段的话，**Cache-Control 的优先级高于 Expires** 。

Cache-control 选项更多一些，设置更加精细，所以建议使用 Cache-Control 来实现强缓存。具体的实现流程如下：

- 当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小；
- 浏览器再次请求访问服务器中的该资源时，会先**通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期**，如果没有，则使用该缓存，否则重新请求服务器；
- 服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。



（2）协商缓存

某些请求的响应码是 `304`，这个是告诉浏览器可以使用本地缓存的资源，通常这种**通过服务端告知客户端是否可以使用缓存**的方式被称为协商缓存。

当使用 ETag 字段实现的协商缓存的过程：

- 当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 ETag 唯一标识，这个唯一标识的值是根据当前请求的资源生成的；
- 当浏览器再次请求访问服务器中的该资源时，首先会先检查强制缓存是否过期：
  - 如果没有过期，则直接使用本地缓存；
  - 如果缓存过期了，会在 Request 头部加上 If-None-Match 字段，该字段的值就是 ETag 唯一标识；
- 服务器再次收到请求后，会根据请求中的 If-None-Match 值与当前请求的资源生成的唯一标识进行比较：
  - **如果值相等，则返回 304 Not Modified，不会返回资源**；
  - 如果不相等，则返回 200 状态码和返回资源，并在 Response 头部加上新的 ETag 唯一标识；
- 如果浏览器收到 304 的请求响应状态码，则会从本地缓存中加载资源，否则更新资源。



## TCP 

### TCP的缺陷有哪些？

（1）升级 TCP 的工作很困难；

（2）**TCP 建立连接的延迟**：三次握手延迟（通过fast-open机制解决），https中四次握手和tcp三次握手无法结合在一起的，因为，TLS 是在应用层实现的握手，而 TCP 是在内核实现的握手，也正是 TCP 是在内核实现的，所以 TLS 是无法对 TCP 头部加密的，这意味着 TCP 的序列号都是明文传输，所以就存安全的问题。一个典型的例子就是攻击者伪造一个的 RST 报文强制关闭一条 TCP 连接，而攻击成功的关键则是 TCP 字段里的序列号位于接收方的滑动窗口内，该报文就是合法的；

（3）TCP 存在队头阻塞问题：**TCP 层必须保证收到的字节数据是完整且有序的**，如果序列号较低的 TCP 段在网络传输中丢失了，即使序列号较高的 TCP 段已经被接收了，应用层也无法从内核中读取到这部分数据。如下图：

<img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZfxxjvoTicwpUmESgBvvjqH5SYu8ia2MhC558SptjRWvg441iadibERibF7gaRia8PcuTWpxSicLwVk8icDiaw/640?wx_fmt=gif&wxfrom=5&wx_lazy=1&wx_co=1">

其中 `packet #3` 在网络中丢失了，即使 `packet #4-6` 被接收方收到后，由于内核中的 TCP 数据不是连续的，于是接收方的应用层就无法从内核中读取到，**只有等到 `packet #3` 重传后，接收方的应用层才可以从内核中读取到数据**。HTTP/2 多个请求是跑在一个 TCP 连接中的，那么当 TCP 丢包时，整个 TCP 都要等待重传，那么就会阻塞该 TCP 连接中的所有请求，所以 HTTP/2 队头阻塞问题就是因为 TCP 协议导致的。解决办法是通过QUIC协议中的Packet+StreamID+Offset来辨认重发包，且支持乱序确认来防止队头阻塞。

（4）网络迁移需要重新建立 TCP 连接：

基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接，那么**当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立 TCP 连接**。

![图片](https://github.com/amonstercat/PicGo/blob/main/dell/202403061754203.png?raw=true)

而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。

（5）TCP重传具有歧义性，发送重发包后无法精确计算RTT（通过QUIC协议来解决）。



### TCP Fast Open特性是什么？

TCP Fast Open 并不直接冲突于传统的三次握手过程，而是在其基础上进行了优化。在传统的 TCP 三次握手过程中，客户端和服务器之间进行了三次往返的握手，用于建立连接。而 **TCP Fast Open 允许在初始的 SYN 包中携带数据，从而在建立连接的同时传输数据，以减少建立连接的时延。**

具体来说，在 TCP Fast Open 中，客户端可以在发送 SYN 包时携带数据，这样服务器在接收到 SYN 包时就可以同时接收到客户端的数据，并在 SYN-ACK 包中对这些数据进行确认。因此，TCP Fast Open 仍然遵循了 TCP 的三次握手过程，只是在建立连接的同时进行了数据传输。

<img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZfxxjvoTicwpUmESgBvvjqH5aRa7S02Zd6b8sX8ibHjRicsMJTfBxQHQiaGpD9yCgdHop8IOC1rlVCrEA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1">

过程如下：

- 在第一次建立连接的时候，服务端在第二次握手产生一个 `Cookie` （已加密）并通过 SYN、ACK 包一起发给客户端，于是客户端就会缓存这个 `Cookie`，所以第一次发起 HTTP Get 请求的时候（第三次握手就可以直接传输数据），还是需要 2 个 RTT 的时延；
- 在下次请求的时候，客户端在 SYN 包带上 `Cookie` 发给服务端，就提前可以跳过三次握手的过程，因为 `Cookie` 中维护了一些信息，服务端可以从 `Cookie` 获取 TCP 相关的信息，这时发起的 HTTP GET 请求就只需要 1 个 RTT 的时延；









### SOCKET(重要！！)

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/3.jpg" alt="半连接队列与全连接队列" style="zoom:50%;" />

建立一个 TCP 连接是需要客户端与服务端达成下述三个信息的共识

- **Socket**：由 IP 地址和端口号组成(在TCP/IP网络中，一个套接字（Socket）连接通常由四元组唯一标识)
- **序列号**：用来解决乱序问题等
- **窗口大小**：用来做流量控制

从C语言的角度分析过程是这样的：

1、服务器创建套接字`socket`，`bind`至指定地址和端口，`listen`，循环`accpet`等待客户端接入，阻塞等待

2、客户端创建套接字`socket`，（`bind`指定地址和端口，**默认不`bind`，系统自动分配**），调用`connect()`方法向服务器发起连接请求（发送SYN包(包中初始化一个`Seg Num`)至服务器，第一次握手连接），阻塞等待

3、服务器接收到SYN包发送第二个SYN包至客户端，客户端接收到此包确认建立连接，发送`ACK`包至服务器

4、服务器接收到ACK包确认建立连接

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/SOCKET.webp)

- 服务端和客户端初始化 `socket`，得到文件描述符；
- 服务端调用 `bind`，将 `socket` 绑定在指定的 IP 地址和端口;
- 服务端调用 `listen`，进行监听(**执行 listen方法时，会创建半连接队列和全连接队列**)；
- 服务端调用 `accept`，等待客户端连接；
- 客户端调用 `connect`，向服务端的地址和端口发起连接请求(**TCP三次握手执行流程在这里，且服务端收到第一次握手后会将该`socket`放入半连接队列**)；
- **直到收到第三次握手，从半连接队列中取出一条`socket`连接放入到全连接队列中**，随后就等待服务端阻塞调用`accept()`从全连接队列中取一条连接出来，并返回一个已完成的`socket`，此时返回用于传输的 `socket` 的文件描述符()；
- 客户端调用 `write` 写入数据；服务端调用 `read` 读取数据；
- 客户端断开连接时，会调用 `close`，那么服务端 `read` 读取数据的时候，就会读取到了 `EOF`，待处理完数据后，服务端调用 `close`，表示连接关闭。

需要注意的是，**服务端调用 `accept` 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据(从半连接队列中取出一个连接放入全连接队列中，表示已完成三次握手建立连接)**

所以，监听的 socket 和真正用来传送数据的 socket，是「两个」 socket，一个叫作**监听 socket**，一个叫作**已完成连接 socket**

成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样

> - **半连接队列（SYN队列）**，服务端收到**第一次握手**后，会将`socket`加入到这个队列中，队列内的`socket`都处于`SYN_RECV` 状态。
> - **全连接队列（ACCEPT队列）**，在服务端收到**第三次握手**后，会将半连接队列的`socket`取出，放到全连接队列中。队列里的`socket`都处于 `ESTABLISHED`状态。这里面的连接，就**等着服务端执行accept()后被取出了。**
>
> 因此建立连接的过程中根本不需要`accept()`参与，**执行accept()只是为了从全连接队列里取出一条连接**

以下流程图方便理解：

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8Bsockett.webp" style="zoom: 67%;" />

### 与UDP区别

 UDP 面向无连接、支持一对多 多对多通信、且是一个包一个包的发送，**有边界**，故经常用于：

- 包总量较少的通信，如 `DNS` 、`SNMP` 等
- 视频、音频等多媒体通信(允许数
- 据丢失)
- 广播通信(TCP只支持一对一通信)
- https3 底层已经基于UDP实现了QUIC协议！


### MSS MTU分片是什么？

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/mss-mtu.webp" style="zoom: 67%;" />

- `MTU`：一个网络包的最大长度，以太网中一般为 `1500` 字节(一个IP数据包的最大长度)；
- `MSS`：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度(TCP报文段的有效数据长度)；

  如果交给IP层进行分片，当 IP 层有一个超过 `MTU` 大小的数据（TCP 头部 + TCP 数据）要发送，那么 IP 层就要进行分片，把数据分片成若干片，保证每一个分片都小于 MTU，**那么如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传**，因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。当某一个 IP 分片丢失后，接收方的 IP 层就无法组装成一个完整的 TCP 报文（头部 + 数据），也就无法将数据报文送到 TCP 层，所以接收方不会响应 ACK 给发送方，因为发送方迟迟收不到 ACK 确认报文，所以会触发超时重传，就会重发「整个 TCP 报文（头部 + 数据），所以为了达到最佳的传输效能， TCP 协议在**建立连接的时候通常要协商双方的 MSS 值**，当 TCP 层发现数据超过 MSS 时，则就先会进行分片，经过 TCP 层分片后，如果一个 TCP 分片丢失后，**进行重发时也是以 MSS 为单位**，而不用重传所有的分片，大大增加了重传的效率



### 三次握手四次挥手

1、为什么是三次握手？而不是两次/四次 

(1)阻止重复历史连接的初始化浪费服务器资源(客户端旧的SYN报文先到达，两次握手服务端则直接建立连接了，后面客户端发送RST报文的话，服务端就直接浪费掉了该连接；三次握手的话，服务端在收到旧SYN报文后还不会立即建立连接，这样即使后面客户端发送RST报文来取消旧SYN报文，服务端也不会损失太多资源，)

(2)**同步双方的初始序列号**,实现可靠传输，序列号机制的作用在于：

- 接收方可以去除重复的数据；
- 接收方可以根据数据包的序列号**按序**接收；
- 可以标识发送出去的数据包中， 哪些是已经被对方收到的（通过 ACK 报文中的序列号）

(3) 避免服务器资源浪费：如果是两次握手，假设客户端超时重传了SYN报文，服务端在旧的SYN和新的SYN报文时均会建立连接进入`Established`状态,而客户端实际上只想建立一次连接，这就造成了服务器的资源浪费




2、握手/挥手 丢失情况

针对握手：

(1)第一次握手丢失：客户端触发超时重传SYN报文，**重传的 SYN 报文的序列号也一样**，在 Linux 里，客户端的 SYN 报文最大重传次数由 `tcp_syn_retries`内核参数控制，一般是5，每次超时重传时间翻倍，如果达到上限后依旧没有收到服务端的ACK，则主动断开连接进入`Closed`态

(2)第二次握手丢失：**客户端就会触发超时重传机制，重传 SYN 报文**(第一次握手最大重传次数由 `tcp_syn_retries`内核参数决定);**服务端这边也会触发超时重传机制，重传 SYN-ACK 报文**，最大重传次数由 `tcp_synack_retries` 内核参数决定

(3)第三次握手丢失：**客户端收到服务端的 SYN-ACK 报文后，就会给服务端回一个 ACK 报文，也就是第三次握手，此时客户端状态进入到 ESTABLISH 状态。因为这个第三次握手的 ACK 是对第二次握手的 SYN 的确认报文，所以当第三次握手丢失了，如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数。注意，ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文**



针对挥手：

(1)第一次挥手丢失：客户端(主动关闭方)调用 `close` 函数后就会进入`Finish_Wait_1`状态，直到收到对方的`ACK`后进入`Finish_Wait_2`态，**如果第一次挥手丢失，客户端触发超时重传机制**，重传 FIN 报文，重发次数由 `tcp_orphan_retries` 参数控制

(2)第二次挥手丢失：**客户端触发超时重传机制，重传 FIN 报文**，直到收到服务端的第二次挥手(重发次数同样由 `tcp_orphan_retries` 参数控制)，或者达到最大的重传次数，而**服务端不会重传**(`ACK`报文不会重传,因为四次挥手是双向的，服务端不需要在收到第一次挥手后也关闭连接，故只需要回复对第一次挥手报文的ACK即可)

(3)第三次挥手丢失：服务端（被动关闭方）收到客户端（主动关闭方）的 FIN 报文后处于 `CLOSE_WAIT` 状态，当被动关闭方调用了 `close` 函数后，连接进入 `LAST_ACK` 状态，并等待客户端返回 ACK 来确认连接关闭，如果此次挥手丢失，服务端就会重发 FIN 报文，重发次数仍然由 `tcp_orphan_retries` 参数控制

(4)第四次挥手丢失：服务端（被动关闭方）没有收到 ACK 报文前，还是处于 `LAST_ACK` 状态,如果第四次挥手的 ACK 报文没有到达服务端，服务端就会重发 FIN 报文，重发次数仍然由`tcp_orphan_retries` 参数控制



3、如何避免SYN攻击？

- 增大 TCP 半连接队列；

- 开启 `tcp_syncookies`(跳过SYN队列来建立连接)；

  - 当 「 SYN 队列」满之后，后续服务端收到 SYN 包，不会丢弃，而是根据算法，计算出一个 `cookie` 值；

  - 将 cookie 值放到第二次握手报文的「序列号」里，然后服务端回第二次握手给客户端；

  - 服务端接收到客户端的应答报文时，服务端会检查这个 ACK 包的合法性。如果合法，将该连接对象放入到「 Accept 队列」。

  - 最后应用程序通过调用 `accpet()` 接口，从「 Accept 队列」取出的连接。

    可以看到，当开启了 `tcp_syncookies` 后，即使受到 SYN 攻击而导致 SYN 队列满时，也能保证正常的连接成功建立。

    `net.ipv4.tcp_syncookies` 参数主要有以下三个值：

    - 0 值，表示关闭该功能；
    - 1 值，表示仅当 SYN 半连接队列放不下时，再启用它；
    - 2 值，表示无条件开启功能；·

- 减少 SYN+ACK 重传次数



4、四次挥手流程图

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B.webp" style="zoom:75%;" />

(1) **主动关闭连接的，才有 TIME_WAIT 状态**

(2) `FIN_WAIT2`状态下客户端依旧可以接收被动关闭方(服务端)的数据

(3) 被动关闭方收到主动关闭方的FIN报文后就进入`CLOSED_WAIT`状态,此时被动关闭方依旧可以向对端发送数据，直到所有数据发送完成后发送FIN报文进入`LAST_ACK`状态







###  TIME_WAIT状态



#### 为什么TIME_WAIT等待时间为2MSL?



首先要清楚：网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以**一来一回需要`2MSL`(Maximum Segment Lifetime)的时间** ，然后我们来看看第四次挥手丢失的情况(因为**第四次挥手发起时主动关闭方才进入`TIME_WAIT`状态**)：被动关闭方没有收到断开连接的最后的 `ACK` 报文，就会触发超时重发 `FIN` 报文，主动关闭方在`TIME_WAIT`状态内接收到 `FIN` 后，就会重发 `ACK` 给被动关闭方，**即第四次挥手的`ACK`若在一个 `MSL` 内丢失，被动方重发的 `FIN` 会在第 2 个 `MSL` 内到达，`TIME_WAIT` 状态的连接可以应对，**下面画图来帮助理解一下：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/TIME-WAIT%E8%BF%9E%E6%8E%A5%E6%AD%A3%E5%B8%B8%E5%85%B3%E9%97%AD.drawio.jpg)







#### 为什么需要TIME_WAIT状态？

(1) *防止历史连接中的数据，被后面相同四元组的连接错误的接收* ：TCP 设计了 TIME_WAIT 状态，状态会持续 `2MSL` 时长，这个时间**足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立的连接所产生的**

(2)*保证「被动关闭连接」的一方，能被正确的关闭*：客户端必须等待足够长的时间，确保服务端能够收到 `ACK`，如果服务端没有收到 `ACK`，那么就会触发 TCP 重传机制，服务端会重新发送一个 `FIN`，这样一去一来刚好两个 `MSL` 的时间



#### TIME_WAIT状态过多的危害

客户端和服务端 TIME_WAIT 过多，造成的影响是不同的

**如果客户端（主动发起关闭连接方）的 TIME_WAIT 状态过多**，占满了所有源端口资源(客户端多个 ip+port 都处于time_wait态)，那么就无法对「目的 IP+ 目的 PORT」都一样的服务端发起连接了,注意：在这种场景下，**只要连接的是不同的服务端，端口是可以重复使用的，所以客户端还是可以向其他服务端发起连接的**，这是因为内核在定位一个连接的时候，是通过四元组（源IP、源端口、目的IP、目的端口）信息来定位的，并不会因为客户端的端口一样，而导致连接冲突

**如果服务端（主动发起关闭连接方）的 TIME_WAIT 状态过多**，并不会导致端口资源受限，因为服务端只监听一个端口，而且由于一个四元组唯一确定一个 TCP 连接，因此理论上服务端可以建立很多连接，但是 **TCP 连接过多，会占用系统资源**，**比如文件描述符、内存资源**、CPU 资源、线程资源等





####  服务器出现大量 TIME_WAIT 状态的原因有哪些？



首先要知道 TIME_WAIT 状态是主动关闭连接方才会出现的状态，所以**如果服务器出现大量的 TIME_WAIT 状态的 TCP 连接，就是说明服务器主动断开了很多 TCP 连接**

**什么场景下服务端会主动断开连接呢？**

- 第一个场景：HTTP通信双方没有使用长连接
- 第二个场景：HTTP 长连接超时
- 第三个场景：HTTP 长连接的请求数量达到上限

(1) **根据大多数 Web 服务的实现，不管哪一方禁用了 HTTP Keep-Alive，都是由服务端主动关闭连接**，那么此时服务端上就会出现 TIME_WAIT 状态的连接，故**当服务端出现大量的 TIME_WAIT 状态连接的时候，可以排查下是否客户端和服务端都开启了 HTTP Keep-Alive**，因为任意一方没有开启 HTTP `Keep-Alive`，都会导致服务端在处理完一个 HTTP 请求后，就主动关闭连接，此时服务端上就会出现大量的 TIME_WAIT 状态的连接。解决的方式也很简单，让客户端和服务端都开启 HTTP `Keep-Alive` 机制

(2) web 服务软件一般都会提供一个参数，用来指定 HTTP 长连接的超时时间(避免资源浪费)，比如 `nginx` 提供的 `keepalive_timeout` 参数，假设设置了 HTTP 长连接的超时时间是 60 秒，nginx 就会启动一个「定时器」，**假如客户端在完成一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，定时器的时间一到，nginx 就会触发回调函数来关闭该连接，那么此时服务端上就会出现 TIME_WAIT 状态的连接**

那么设想一下：如果有大量的客户端建立完 TCP 连接后，很长一段时间没有发送数据，那么就会由于HTTP 长连接超时，导致服务端主动关闭连接，从而产生大量处于 TIME_WAIT 状态的连接

(3)Web 服务器通常会有个参数，来**定义一条 HTTP 长连接上最大能处理的请求数量，当超过最大限制时，就会主动关闭连接**。如 `nginx` 的 `keepalive_requests` 这个参数，这个参数是指一个 HTTP 长连接建立之后，`nginx` 就会为这个连接设置一个计数器，记录这个 HTTP 长连接上已经接收并处理的客户端请求的数量。**如果达到这个参数设置的最大值时，则 nginx 会主动关闭这个长连接**，那么此时服务端上就会出现 `TIME_WAIT` 状态的连接

那么**对于一些 QPS 比较高的场景，比如超过 10000 QPS，甚至达到 30000 , 50000 甚至更高，如果 `keepalive_requests` 参数值是 100(默认值)，这时候就 nginx 就会很频繁地关闭连接，此时服务端上就会出大量的 `TIME_WAIT` 状态**



> 补充:服务器出现大量 CLOSE_WAIT 状态的原因有哪些？(从无法转换至`LASK_ACK`状态的角度答)
>
> 
>
> CLOSE_WAIT 状态是「被动关闭方」才会有的状态，而且如果「被动关闭方」没有调用 close 函数关闭连接，那么就无法发出 FIN 报文，从而无法使得 CLOSE_WAIT 状态的连接转变为 LAST_ACK 状态
>
> 所以，**当服务端出现大量 CLOSE_WAIT 状态的连接的时候，说明服务端的程序没有成功调用 close 函数关闭连接**





### TCP连接故障问题分析 :imp:

从 有无数据传输、是否开启TCP保活机制、进程崩溃/主机重启/拔掉网线 等角度来分析



#### 拔掉网线后，TCP连接还存在吗?

TCP连接在 Linux 内核中是一个名为 `struct socket` 的结构体，该结构体的内容包含 TCP 连接的状态等信息。**当拔掉网线的时候，操作系统并不会变更该结构体的任何内容**，所以TCP连接的状态也不会发生改变

1. 拔掉网线后，有数据传输

  在客户端拔掉网线后，服务端向客户端发送的数据报文会得不到任何的响应，在等待一定时长后，服务端就会触发超时重传机制，重传未得到响应的数据报文。**如果在服务端重传报文的过程中，客户端刚好把网线插回去了**，**由于拔掉网线并不会改变客户端的 TCP 连接状态(宕机重启会！！)，并且还是处于 `ESTABLISHED `状态，所以这时客户端是可以正常接收服务端发来的数据报文的**，然后客户端就会回送 `ACK` 响应报文;**如果在服务端重传报文的过程中，客户端一直没有将网线插回去**，服务端超时重传报文的次数达到一定阈值后，内核就会判定出该 TCP 有问题，然后通过 Socket 接口告诉应用程序该 TCP 连接出问题了，于是服务端的 TCP 连接就会断开。而等客户端插回网线后，如果客户端向服务端发送了数据，由于服务端已经没有与客户端相同四元组的 TCP 连接了，因此服务端内核就会回复 `RST` 报文，客户端收到后就会释放该 TCP 连接


2. 拔掉网线后，没有数据传输:

**针对拔掉网线后，没有数据传输的场景，还得看是否开启了 TCP `keep-alive` 机制 （TCP 保活）**，如果没有开启TCP `keepalive`机制，在客户端拔掉网线后，并且双方都没有进行数据传输，那么客户端和服务端的 TCP 连接将会一直保持存在;如果开启了 TCP 的`keepalive` 机制，在客户端拔掉网线后，即使双方都没有进行数据传输，在持续一段时间后 TCP 就会发送探测报文

- 如果**对端正常工作**,当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样**TCP 保活时间器会被重置**，等待下一个 TCP 保活时间的到来
- 如果**对端主机宕机（区分进程崩溃，进程崩溃会发送fin报文）**，当 TCP 保活的探测报文发送给对端后没有响应，连续几次达到保活探测次数（`tcp_retries`）后，**TCP会报告该 TCP 连接已经死亡**,并最终断开连接



#### 对于TCP通信端，断电和进程崩溃有什么区别？



前提是双方均未开启`Keep-Alive`

1、客户端主机崩溃了，服务端是**无法感知到的**，再加上服务端没有开启 TCP `keep-alive`，又没有数据交互的情况下，**服务端的 TCP 连接将会一直处于 ESTABLISHED 连接状态**，直到服务端重启进程;

2、客户端进程崩溃，那么客户端的操作系统就会感知到，就会给服务端发送`FIN`报文，然后与对方进行四次挥手



针对有数据传输的情况：

客户端主机宕机后，服务端向客户端发送的报文会得不到任何的响应，在一定时长后，服务端就会触发**超时重传**机制，重传未得到响应的报文，客户端主机重启完成后，内核就会接收重传的报文，然后根据报文的信息传递给对应的进程：

- 如果客户端主机上**没有**进程绑定该 TCP 报文的目标端口号，那么客户端内核就会**回复 RST 报文，重置该 TCP 连接**；
- 如果客户端主机上**有**进程绑定该 TCP 报文的目标端口号，由于客户端主机重启后，之前的 TCP 连接的数据结构已经丢失了，客户端内核里协议栈会发现找不到该 TCP 连接的 `socket` 结构体，于是就会**回复 RST 报文，重置该 TCP 连接**

所以，**只要有一方重启完成后，收到之前 TCP 连接的报文，都会回复 RST 报文，以断开连接**



**总结：**

如果「**客户端进程崩溃**」，客户端的进程在发生崩溃的时候，内核会发送 FIN 报文，与服务端进行四次挥手。

但是「**客户端主机宕机**」，那么是不会发生四次挥手的，具体后续会发生什么**还要看服务端会不会发送数据**

- 如果服务端会发送数据，由于客户端已经不存在，收不到数据报文的响应报文，服务端的数据报文会超时重传，当重传总间隔时长达到一定阈值（内核会根据 `tcp_retries2` 设置的值计算出一个阈值）后，会断开 TCP 连接；
- 如果服务端一直不会发送数据，再看服务端有没有开启 TCP keepalive 机制？
  - 如果有开启，服务端在一段时间没有进行数据交互时，会触发 TCP keepalive 机制，探测对方是否存在，如果探测到对方已经消亡，则会断开自身的 TCP 连接；
  - 如果没有开启，服务端的 TCP 连接会一直存在，并且一直保持在 ESTABLISHED 状态



#### 客户端/服务端突然出现故障会发生什么？

1、客户端出现故障

TCP具有`Keep-Alive`保活机制,每隔一个时间间隔，会向通信对方发送一个探测报文，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，**系统内核将错误信息通知给上层应用程序**

Linux 内核可以有对应的参数可以设置**保活时间、保活探测的次数、保活探测的时间间隔**，以下均为默认值：

```shell
net.ipv4.tcp_keepalive_time=7200  
保活时间是 7200 秒（2小时），2小时内如果没有任何连接相关的活动，则会启动保活机制
net.ipv4.tcp_keepalive_intvl=75  
表示每次检测间隔 75 秒；
net.ipv4.tcp_keepalive_probes=9
表示检测 9 次无响应，认为对方是不可达的，从而中断本次的连接
```

开启了 TCP 保活，需要考虑以下几种情况：

- 第一种，对端程序是正常工作的：当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 **TCP 保活时间会被重置**，等待下一个 TCP 保活时间的到来
- 第二种，对端主机宕机并**重启**： 当 TCP 保活的探测报文发送给重启后的对端后，对端是可以响应的，但由于已经没有了该连接的有效信息，**会产生一个 RST 报文**，这样很快就会发现 TCP 连接已经被重置
- 第三种，是对端主机宕机（*注意不是进程崩溃，**进程崩溃后操作系统在回收进程资源的时候，会发送 FIN 报文，而主机宕机则是无法感知的**，所以需要 TCP 保活机制来探测对方是不是发生了主机宕机*），或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，连续几次没有响应，达到保活探测次数后，**TCP 会报告该 TCP 连接已经死亡**



2、服务端出现故障

TCP的连接信息是由**内核**维护的，所以**当服务端的进程崩溃后**，**内核需要回收该进程的所有 TCP 连接资源，于是内核会发送第一次挥手 `FIN` 报文，后续的挥手过程也都是在内核完成，并不需要进程的参与**，所以即使服务端进程崩溃，还是能与客户端完成 `TCP` 四次挥手的过程







#### 服务端没有监听，若客户端发起连接建立会发生什么？

**服务端如果只 `bind` 了 IP 地址和端口，而没有调用 `listen` 的话，此时客户端对服务端发起了连接建立，服务端会回 `RST` 报文**





### 重传机制



1、超时重传

在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 `ACK` 确认应答报文，就会重发该数据，也就是我们常说的**超时重传**，超时重传时间`RTO`应该**略大于**`RTT`(往返时延)的值



2、快重传

快重传**不以时间为驱动，而是以数据驱动重传**，快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段，例如发送方先发送，seq1接收方收到，随后的seq2丢失，接收方返回ack2(表示收到seq2之前的数据),发送方在收到ack2之前又接连发送了seq3、seq4,而接收方在收到这两个seq后依然要返回ack2，这样发送方接连收到三个相同的ack2，**就会在定时器过期之前，重传丢失的 Seq2**

注意：ACK中的序列号告诉发送端，接收端已经成功接收到了序列号小于这个值的所有数据包，下一个期望接收的数据包的序列号是多少。

3、S-ACK(Selected-ACK) 协同原ACK实现重传确认

**选择性确认**需要在 TCP 头部「选项」字段里加一个 `SACK` 的东西，它**可以将已收到的数据的信息发送给「发送方」**，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以**只重传丢失的数据**

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/sack.webp" alt="SACK" style="zoom: 67%;" />



TCP接收端会有一个接收缓冲区，当收到不需要的`segment`时，会先缓存起来，直到后面缺失的丢失报文到达后再进行**延时确认**，加入`S-ACK`的好处就是TCP的发送端只需要发送丢失的那一段报文



4、 Duplicate-SACK



[D-SACK](https://xiaolincoding.com/network/3_tcp/tcp_feature.html#duplicate-sack)

### 拥塞控制算法

流量控制是避免「发送方」的数据填满「接收方」的缓存,是点对点的，而拥塞控制则是针对全局,发送窗口 `swnd` 和接收窗口 `rwnd` 是约等于的关系，加入了拥塞窗口的概念后，发送窗口的值是`swnd = min(cwnd, rwnd)`，也就是拥塞窗口和接收窗口中的最小值,拥塞窗口 `cwnd` 变化的规则为：

- 只要网络中没有出现拥塞(收到一个ACK报文)，`cwnd` 就会增大；
- 但网络中出现了拥塞，`cwnd` 就减少；



慢启动算法：**当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1  cwnd++ ——>swnd=cwnd;故发送方的发送窗口大小+1； **

**拥塞避免**算法：当拥塞窗口 `cwnd` 「超过」慢启动门限 `ssthresh` 就会进入拥塞避免算法，此时**每当收到一个 ACK 时，cwnd 增加 1/cwnd**



cwnd这么一直增长着后，网络就会慢慢进入了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进行重传。当触发了重传机制，也就进入了「拥塞发生算法」：



最开始的慢启动、拥塞避免算法就不再赘述，重点在于拥塞发生时采用的算法，要分情况讨论：

1. 如果发生的是超时重传，说明当前网络拥塞程度已经比较严重，这个时候，慢启动门限`ssthresh` 和 拥塞窗口`cwnd` 的值会发生变化：

- `ssthresh` 设为 `cwnd/2`，
- `cwnd` 重置为 `1` （实际上是恢复为 `cwnd` 初始化值）

接着，**重新开始慢启动算法**，**慢启动会突然减少数据流的，造成网络卡顿**



2. 如果发生的是快速重传（**即发送端连续收到三个重复ACK，发送端就会快速地重传，不必等待超时再重传**），说明网络拥塞情况不算严重（因为还能收到对方的ACK），则`ssthresh` 和 `cwnd` 变化如下：

- `cwnd = cwnd/2` ，也就是设置为原来的一半;
- `ssthresh = cwnd`;
- 进入快速恢复算法；

然后，进入快速恢复算法如下：

- 拥塞窗口 `cwnd = ssthresh + 3` （3 的意思是在进入拥塞避免算法前已经有3个 ACK 数据包被收到了，根据慢启动原理，每收到一个ACK就要加1 故为3）；
- 重传丢失的数据
- 如果再收到重复的 ACK，那么 cwnd 增加 1 ；:zipper_mouth_face:
- 如果收到新数据的 ACK 后，**把 cwnd 设置为第一步中的 ssthresh 的值**，原因是该 ACK 确认了新的数据，说明从 `duplicated ACK` 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态；

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E6%8B%A5%E5%A1%9E%E5%8F%91%E7%94%9F-%E5%BF%AB%E9%80%9F%E9%87%8D%E4%BC%A0.drawio.webp" style="zoom:80%;" />







### 粘包问题



TCP是面向字节流的协议，传输到缓冲区时后面一包数据紧接着前一包数据的尾巴。

- **原因**：
  - 由于 TCP 连接复用造成；
  - 因为 TCP 默认会使用 `Nagle` 算法，该算法会导致粘包（为了减少小分组数目，从而减少网络拥塞）；
  - **数据包过大**；
  - 网络延迟和拥堵：如果网络中存在较大的延迟或者拥堵，数据包可能会被缓存到接收方的接收缓冲区中，从而导致多个数据包合并成一个较大的数据包。即接收方不及时接收缓冲区的包，造成多个包接收。
- 解决方案：
  - 关闭 Nagle 算法
  - 尾部标记序列，加一个结束符表示包结束了
  - 头部标记分步骤接收，在 TCP 报文头部字段加一个表示包长度的字段
  - 消息长度固定：在每个数据包的头部添加固定长度的报文头，报文头中包含报文的长度信息，接收方先读取报文头，然后根据长度信息正确划分和处理数据
  - 应用层协议：在应用层上设计一种协议，将数据包装成独立的消息，消息中包含数据的长度信息或其他辅助信息

> `Nagle`算法是一种用于减少小数据包发送的网络优化算法。它在TCP协议中实现，旨在减少网络拥塞和提高网络吞吐量
>
> 
>
> TCP协议是一种可靠的面向连接的协议，它将数据切分成一个一个的数据包进行传输。`Nagle`算法的主要思想是将多个小数据包合并成一个较大的数据包进行发送，以减少网络传输的开销。
>
> `Nagle`算法的工作原理如下：
>
> 1. 当应用程序发送数据时，TCP先将数据放入发送缓冲区。
> 2. TCP等待一段时间（一般是200毫秒），看是否有更多数据到达。如果有更多数据，则继续等待。
> 3. 如果**等待时间到达或缓冲区中的数据达到一定大小（一般是MSS，最大报文段长度）**，TCP就会将缓冲区中的数据一并发送给接收方(**这就导致多个小报文段被合并成了一个大报文段，接收方收到大报文段时就无法区分边界**)
>
> 这种合并数据包的方式可以减少网络中的小数据包数量，从而减少网络的传输开销和降低网络拥塞的可能性









#  操作系统





## 进程管理









## 内存管理







# 数据结构与算法



## 排序算法





### 快速排序





### 堆排序





### 归并排序







## 雪花算法

传统雪花算法的实现如下：

```java
public class IdWorker{

    private long workerId;
    private long datacenterId;
    private long sequence;

    public IdWorker(long workerId, long datacenterId, long sequence){
        // sanity check for workerId
        if (workerId > maxWorkerId || workerId < 0) {
            throw new IllegalArgumentException(String.format("worker Id can't be greater than %d or less than 0",maxWorkerId));
        }
        if (datacenterId > maxDatacenterId || datacenterId < 0) {
            throw new IllegalArgumentException(String.format("datacenter Id can't be greater than %d or less than 0",maxDatacenterId));
        }
        System.out.printf("worker starting. timestamp left shift %d, datacenter id bits %d, worker id bits %d, sequence bits %d, workerid %d",
                timestampLeftShift, datacenterIdBits, workerIdBits, sequenceBits, workerId);

        this.workerId = workerId;
        this.datacenterId = datacenterId;
        this.sequence = sequence;
    }

    private long twepoch = 1288834974657L; //起始时间戳,用于用当前时间戳减去这个时间戳，算出偏移量

    private long workerIdBits = 5L; //worker占的位数
    private long datacenterIdBits = 5L; //datacenter占的位数


    /*
    00000000 00000000 00000000 00000001 //原码：1的二进制
    11111111 11111111 11111111 11111110 //取反码：1的二进制的反码
    11111111 11111111 11111111 11111111 //加1：-1的二进制表示（补码）

    -1 的二进制表示 先左移 5位，得到结果a;
    再让 -1 异或 a;
     */
    private long maxWorkerId = -1L ^ (-1L << workerIdBits); //利用位运算计算出5位能表示的最大正整数是31
    private long maxDatacenterId = -1L ^ (-1L << datacenterIdBits);//同理
    private long sequenceBits = 12L;//同一机器同一时间截（毫秒)的并发数所占位数


    //偏移量
    private long workerIdShift = sequenceBits; //12
    private long datacenterIdShift = sequenceBits + workerIdBits; //17
    private long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits; //22
    private long sequenceMask = -1L ^ (-1L << sequenceBits);  //4095    为了防止溢出

    private long lastTimestamp = -1L; //对比的上一次时间戳，起始值为最小值

    public long getWorkerId(){
        return workerId;
    }

    public long getDatacenterId(){
        return datacenterId;
    }

    public long getTimestamp(){
        return System.currentTimeMillis();
    }


    // 生成下一个唯一ID
    public synchronized long nextId() {
        long timestamp = timeGen();//获取当前时间戳

        //当前时间戳<上一次获取到的时间戳 —— 发生了时钟回拨
        if (timestamp < lastTimestamp) {
            System.err.printf("clock is moving backwards.  Rejecting requests until %d.", lastTimestamp);
            throw new RuntimeException(String.format("Clock moved backwards.  Refusing to generate id for %d milliseconds",
                    lastTimestamp - timestamp));
        }

        //如果两次生成id是在同一毫秒内
        if (lastTimestamp == timestamp) {
            sequence = (sequence + 1) & sequenceMask; //并发数+1
            if (sequence == 0) {                  //4095+1=4096
                timestamp = tilNextMillis(lastTimestamp); //更新时间戳 进入到下一毫秒
            }
        }
        //如果当前时间戳不同，说明已经进入了下一毫秒，序列号重新归零。
        else
        {
            sequence = 0;
        }

        lastTimestamp = timestamp;  //将当前时间戳记录为上一次的时间戳，以备下一次生成ID时使用。

        // 将各个部分组合成最终的ID ——先将每部分左移至对应部分，然后各部分通过或运算得到最终结果
        return ((timestamp - twepoch) << timestampLeftShift) |
                (datacenterId << datacenterIdShift) |
                (workerId << workerIdShift) |
                sequence;
    }


    // 在当前时间戳基础上等待，直到下一个毫秒
    private long tilNextMillis(long lastTimestamp) {

        long timestamp = timeGen();
        while (timestamp <= lastTimestamp) {
            timestamp = timeGen();
        }
        return timestamp;
    }


    //返回当前时间戳
    private long timeGen(){
        return System.currentTimeMillis();
    }


    //---------------测试---------------
    public static void main(String[] args) {
        IdWorker worker = new IdWorker(1,1,1);
        for (int i = 0; i < 30; i++) {
            System.out.println(worker.nextId()+"第"+i+"次生成");
        }
    }
}
```

在计算机中，负数的二进制是用`补码`来表示的。
假设我是用Java中的int类型来存储数字的，
int类型的大小是32个二进制位（bit），即4个字节（byte）。（1 byte = 8 bit）
那么十进制数字`3`在二进制中的表示应该是这样的：

```
00000000 00000000 00000000 00000011
// 3的二进制表示，就是原码
```

**补码的意义就是可以拿补码和原码（3的二进制）相加，最终加出一个“溢出的0”**

因此`-1`的二进制应该这样算：

```
00000000 00000000 00000000 00000001 //原码：1的二进制
11111111 11111111 11111111 11111110 //取反码：1的二进制的反码
11111111 11111111 11111111 11111111 //加1：-1的二进制表示（补码）
```

知道上述知识后，我们再来看看这段代码：

```java
    private long workerIdBits = 5L;
    private long maxWorkerId = -1L ^ (-1L << workerIdBits);       
```

`long maxWorkerId = -1L ^ (-1L << 5L)`的二进制运算过程如下：

**-1 左移 5，得结果a ：**

```apache
        11111111 11111111 11111111 11111111 //-1的二进制表示（补码）
  11111 11111111 11111111 11111111 11100000 //高位溢出的不要，低位补0
        11111111 11111111 11111111 11100000 //结果a
```

**-1 异或 a ：**

```apache
        11111111 11111111 11111111 11111111 //-1的二进制表示（补码）
    ^   11111111 11111111 11111111 11100000 //两个操作数的位中，相同则为0，不同则为1
---------------------------------------------------------------------------
        00000000 00000000 00000000 00011111 //最终结果31
```

那既然现在知道算出来`long maxWorkerId = -1L ^ (-1L << 5L)`中的`maxWorkerId = 31`，有什么含义？为什么要用左移5来算？如果你看过`概述`部分，请找到这段内容看看：

> `5位（bit）`可以表示的最大正整数是$2^{5}-1 = 31$，即可以用0、1、2、3、....31这32个数字，来表示不同的datecenterId或workerId

-1L ^ (-1L << 5L)结果是31，$2^{5}-1$的结果也是31，所以在代码中，`-1L ^ (-1L << 5L)`的写法是利用位运算计算出5位能表示的最大正整数是多少



再看最后得到最终结果的这块代码实现：

```java
 return ((timestamp - twepoch) << timestampLeftShift) |
                (datacenterId << datacenterIdShift) |
                (workerId << workerIdShift) |
                sequence;
```

它对各个部分（时间戳、数据中心ID、工作节点ID和序列号）进行位运算，然后通过或运算进行组合，生成一个最终的64位唯一ID：

- 例如传入的workerId为3，计算机中的表示为000000.....11，将其左移`workerIdShift`位数，即雪花算法中对应到的第13位-第17位，即该workerId在最终参与整体或运算时的样子位：0000000........... 0000000**0  0011**0000 00000000 (注意加粗部分 5位)



>  ^ 表示异或运算：不同取1，相同取0
>
>  | 表示位或运算：1|0=1 、1|1=1、 0|0=0 





然而传统雪花算法存在时间回拨的风险，如果一台机器上发生了时钟回拨，那么可能会再次生成重复性ID，接下来看看美团的`Leaf`方案是如何解决时间回拨问题的



**`Leaf-Segment`方案**(针对N个数据库不同步长生成唯一性ID的方案来做的改进)

第一种Leaf-segment方案，在使用数据库的方案上，做了如下改变： - 原方案每次获取ID都得读写一次数据库，造成数据库压力大。改为利用proxy server批量获取，每次获取一个segment(step决定大小)号段的值。用完之后再去数据库获取新的号段，可以大大的减轻数据库的压力。 - 各个业务不同的发号需求用biz_tag字段来区分，每个biz-tag的ID获取相互隔离，互不影响。如果以后有性能需求需要对数据库扩容，不需要上述描述的复杂的扩容操作，只需要对biz_tag分库分表就行。

数据库表设计如下：

```sql
+-------------+--------------+------+-----+-------------------+-----------------------------+
| Field       | Type         | Null | Key | Default           | Extra                       |
+-------------+--------------+------+-----+-------------------+-----------------------------+
| biz_tag     | varchar(128) | NO   | PRI |                   |                             |
| max_id      | bigint(20)   | NO   |     | 1                 |                             |
| step        | int(11)      | NO   |     | NULL              |                             |
| desc        | varchar(256) | YES  |     | NULL              |                             |
| update_time | timestamp    | NO   |     | CURRENT_TIMESTAMP | on update CURRENT_TIMESTAMP |
+-------------+--------------+------+-----+-------------------+-----------------------------+
```

重要字段说明：`biz_tag`用来区分业务，`max_id`表示该`biz_tag`目前所被分配的ID号段的最大值，step表示每次分配的号段长度。原来获取ID每次都需要写数据库，现在只需要把step设置得足够大，比如1000。那么只有当1000个号被消耗完了之后才会去重新读写一次数据库。读写数据库的频率从1减小到了1/step，大致架构如下图所示：(其中的`Leaf`可以看作是代理服务器 `proxy-server`)

![img](https://awps-assets.meituan.net/mit-x/blog-images-bundle-2017/5e4ff128.png)

test_tag在第一台Leaf机器上是1~1000的号段，当这个号段用完时，会去加载另一个长度为step=1000的号段，假设另外两台号段都没有更新，这个时候第一台机器新加载的号段就应该是3001~4000。同时数据库对应的biz_tag这条数据的max_id会从3000被更新成4000，更新号段的SQL语句如下：

```sql
Begin
UPDATE table SET max_id=max_id+step WHERE biz_tag=xxx
SELECT tag, max_id, step FROM table WHERE biz_tag=xxx
Commit
```

这种模式有以下优缺点：

优点：

- Leaf服务可以很方便的线性扩展，性能完全能够支撑大多数业务场景。
- ID号码是趋势递增的8byte的64位数字，满足上述数据库存储的主键要求。
- 容灾性高：Leaf服务内部有号段缓存，即使DB宕机，短时间内Leaf仍能正常对外提供服务。
- 可以自定义max_id的大小，非常方便业务从原有的ID方式上迁移过来。

缺点：

- **ID号码不够随机，能够泄露发号数量的信息**，不太安全。
- TP999数据波动大，**当号段使用完之后还是会hang在更新数据库的I/O上，会出现偶尔的尖刺**
- DB宕机会造成整个系统不可用。



对于第二个缺点，Leaf-segment做了一些优化，简单的说就是：**双buffer优化**

Leaf 取号段的时机是在号段消耗完的时候进行的，也就意味着号段临界点的ID下发时间取决于下一次从DB取回号段的时间，并且在这期间进来的请求也会因为DB号段没有取回来，导致线程阻塞。如果请求DB的网络和DB的性能稳定，这种情况对系统的影响是不大的，但是假如取DB的时候网络发生抖动，或者DB发生慢查询就会导致整个系统的响应时间变慢。

为此，我们希望DB取号段的过程能够做到无阻塞，**不需要在DB取号段的时候阻塞请求线程，即当号段消费到某个点时就异步的把下一个号段加载到内存中。而不需要等到号段用尽的时候才去更新号段**。这样做就可以很大程度上的降低系统的TP999指标。

> TP99 就是满足百分之九十九的网络请求所需要的最低耗时。 
>
> 同理 TP999 就是**满足千分之九百九十九的网络请求所需要的最低耗时**。

详细实现如下图所示：

![img](https://awps-assets.meituan.net/mit-x/blog-images-bundle-2017/f2625fac.png)

采用双buffer的方式，Leaf服务内部有两个号段缓存区segment。当前号段已下发10%时，如果下一个号段未更新，则另启一个更新线程去更新下一个号段。当前号段全部下发完后，如果下个号段准备好了则切换到下个号段为当前segment接着下发，循环往复。

- 每个biz-tag都有消费速度监控，通常推荐segment长度设置为服务高峰期发号QPS的600倍（10分钟），这样即使DB宕机，Leaf仍能持续发号10-20分钟不受影响。
- 每次请求来临时都会判断下个号段的状态，从而更新此号段，所以偶尔的网络抖动不会影响下个号段的更新







**`Leaf-SnowFlake`方案**(针对传统雪花算法做的改进)

Leaf-segment方案可以生成趋势递增的ID，同时ID号是可计算的，不适用于订单ID生成场景，比如竞对在两天中午12点分别下单，通过订单id号相减就能大致计算出公司一天的订单量，这个是不能忍受的。面对这一问题，我们提供了 Leaf-snowflake方案。

![img](https://awps-assets.meituan.net/mit-x/blog-images-bundle-2017/721ceeff.png)

Leaf-snowflake方案完全沿用snowflake方案的bit位设计，即是“1+41+10+12”的方式组装ID号。对于workerID的分配，当服务集群数量较小的情况下，完全可以手动配置。Leaf服务规模较大，动手配置成本太高。所以使用Zookeeper持久顺序节点的特性自动对snowflake节点配置wokerID。Leaf-snowflake是按照下面几个步骤启动的：

1. 启动Leaf-snowflake服务，连接Zookeeper，在leaf_forever父节点下检查自己是否已经注册过（是否有该顺序子节点）。
2. 如果有注册过直接取回自己的workerID（zk顺序节点生成的int类型ID号），启动服务。
3. 如果没有注册过，就在该父节点下面创建一个持久顺序节点，创建成功后取回顺序号当做自己的workerID号，启动服务。

![img](https://awps-assets.meituan.net/mit-x/blog-images-bundle-2017/a3f985a8.png)



> `Leaf-snowflake`方案如何解决时钟回拨问题？

![img](https://awps-assets.meituan.net/mit-x/blog-images-bundle-2017/1453b4e9.png)





## 一致性哈希算法



```java

import java.util.LinkedList;
import java.util.List;
import java.util.SortedMap;
import java.util.TreeMap;

//带虚拟节点的一致性哈希
public class ConsistentHash {


    /**
     * 待添加入Hash环的服务器列表
     */
    private static String[] servers = {"192.168.0.0:111", "192.168.0.1:111", "192.168.0.2:111",
            "192.168.0.3:111", "192.168.0.4:111"};

    /**
     * 真实结点列表,考虑到服务器上线、下线的场景，即添加、删除的场景会比较频繁，
     * 这里使用LinkedList会更好
     */
    private static List<String> realNodes = new LinkedList<String>();

    /**
     * 虚拟节点列表，key表示虚拟节点的hash值，value表示虚拟节点的名称
     */
    private static SortedMap<Integer, String> virtualNodes =
            new TreeMap<Integer, String>();


    /**
     * 虚拟节点的数目，这里写死，为了演示需要，一个真实结点对应5个虚拟节点
     */
    private static final int VIRTUAL_NODES = 5;

    static {
        for (int i = 0; i < servers.length; i++) {
            //先把真实节点用List存起来
            realNodes.add(servers[i]);
        }
        for(String  str : realNodes)
        {
            //针对每个真实Server节点，将其对应的所有虚拟节点映射到哈希环上
            for (int i = 0; i < VIRTUAL_NODES; i++) {
                String  virtualNodeName=str+"&&"+String.valueOf(i);
                int hash=getHash(virtualNodeName);
                virtualNodes.put(hash,virtualNodeName);
            }
        }
    }


    public static void main(String[] args) {
        String[]  requests={
                "127.0.0.1:1111",
                "221.226.0.1:2222",
                "10.211.0.1:3333",
                "291.226.0.1:2222",
                "100.211.0.1:3333"
        };
        for (int i = 0; i < requests.length; i++) {
            System.out.println("请求 "+i+requests[i]+
                    " ：的哈希值为"+getHash(requests[i])+
                    "，其被路由到的真实节点为"+getServer(requests[i]));
        }
    }

    private  static  String getServer(String request)
    {
        int reqHash=getHash(request);
        SortedMap<Integer,String> subMap = virtualNodes.tailMap(reqHash);
       //返回顺时针找到的第一个虚拟节点
        String virtualNode = subMap.get(subMap.firstKey());
        /*
        通过 virtualNode.substring(0, virtualNode.indexOf("&&"))，
        可以从虚拟节点的名称中提取真实节点的部分，即从开头到 "&&" 之前的部分。
         */
        return  virtualNode.substring(0,virtualNode.indexOf("&&"));
    }


    /**
     * 使用FNV1_32_HASH算法计算服务器的Hash值,这里不使用重写hashCode的方法
     */
    public  static int getHash(String server)
    {
        final   int primeNum= 16777619; //设置的常数质数—32位
        int     initialHash= (int) 2166136261L; //初始Hash值—32位
        for (int i = 0; i < server.length(); i++) {
            initialHash=(initialHash^server.charAt(i))*primeNum; //str.charAt(i) 返回的是字符对应的 Unicode 编码值（整数）
            initialHash+=initialHash<<13; //左移13位
            initialHash^=initialHash>>7;
            initialHash+=initialHash<<3;
            initialHash^=initialHash>>17;
            initialHash+=initialHash<<5;
            if (initialHash<0)
            { //如果算出来的值为负数 取其绝对值
                initialHash=Math.abs(initialHash);
            }
        }
        return  initialHash;
    }

}



//不带虚拟节点的一致性哈希
class  ConsistentHashWithoutVirtualNode{

    /*
    待添加入Hash环的服务器列表
     */
    private  static String[] servers={
            "192.168.0.0:111",
            "192.168.0.1:111",
            "192.168.0.2:111",
            "192.168.0.3:111",
            "192.168.0.4:111"
    };

    /*
    * 使用TreeMap来模拟哈希环
    key表示服务器的hash值，value表示服务器的ip+port(名称)
     */
    private  static SortedMap<Integer,String> sortedMap=new TreeMap<Integer,String>();

    //程序初始化时将all servers 放入 哈希环(TreeMap)上
    static {
        for (String server : servers) {
            int hash = getHash(server); //计算每个服务器的hash值
            System.out.println(server+"放入哈希环上，其Hash值为"+hash);
            sortedMap.put(hash, server);
        }
        System.out.println();
    }

    public static void main(String[] args) {
        String[] nodes={
                "127.0.0.1:1111",
                "221.226.0.1:2222",
                "192.168.100.1:8822",
                "10.211.0.1:3333"};
        for (int i = 0; i < nodes.length; i++) {
            System.out.println(nodes[i]+"的hash值为"+getHash(nodes[i])+
                    "请求被路由到的Server节点为"+getServer(nodes[i]));
        }
    }

    //外来请求映射到指定Server
    public  static String getServer(String node)
    {
        int nodeHash=getHash(node);
        //根据输入Key找到大于该key的子Map（子红黑树）
        SortedMap<Integer, String> subMap = sortedMap.tailMap(nodeHash);
        return  subMap.get(subMap.firstKey());//返回顺时针查找到的第一个Server节点的ip+port
    }

    //计算每个server的哈希值
    /*
    FNV1_32_HASH（Fowler-Noll-Vo）是一种非常简单但有效的哈希算法，
    用于将输入数据映射为一个32位的哈希值。
    FNV1_32_HASH 算法的核心步骤如下：
     初始化哈希值为一个称为“偏移基准”（offset basis）的常数。
     遍历输入数据的每个字节（或字符）：
     对当前字节的值执行异或操作。
     将结果乘以一个称为“质数”（prime number）的常数。
     最终得到的结果即为哈希值。
     */
    public  static int getHash(String server)
    {
        final   int primeNum= 16777619; //设置的常数质数—32位
        int     initialHash= (int) 2166136261L; //初始Hash值—32位
        for (int i = 0; i < server.length(); i++) {
            initialHash=(initialHash^server.charAt(i))*primeNum; //str.charAt(i) 返回的是字符对应的 Unicode 编码值（整数）
            initialHash+=initialHash<<13; //左移13位
            initialHash^=initialHash>>7;
            initialHash+=initialHash<<3;
            initialHash^=initialHash>>17;
            initialHash+=initialHash<<5;
            if (initialHash<0)
            { //如果算出来的值为负数 取其绝对值
                initialHash=Math.abs(initialHash);
            }
        }
        return  initialHash;
    }
}
```







## 红黑树



### 插入/删除操作

在二叉搜索树中，动态插入和删除操作可能导致树的不平衡，从而降低查找等操作的效率。为了保持平衡，红黑树采用了一系列策略，包括旋转和节点重着色等操作。以下是保持动态插入和删除操作平衡的详细步骤：

**1. 插入操作的平衡维护：**

插入新节点时，首先将节点插入二叉搜索树的适当位置，然后根据红黑树的性质进行调整。

a. **将新插入的节点着为红色。这不会违反红黑树的性质，因为插入红色节点不会破坏黑高度平衡**。

b. 检查父节点的颜色：

- 如果父节点是黑色，不会违反红黑树的性质，直接插入即可。
- **如果父节点是红色，需要继续进行调整。**

c. **进行旋转和重着色操作，以恢复红黑树的性质**。可能需要进行左旋、右旋、双旋等操作，以确保红黑树的性质得以保持。

**2. 删除操作的平衡维护：**

删除节点时，需要考虑删除节点的替代节点（后继或前驱节点），并根据红黑树的性质进行调整。

a. **如果要删除的节点有一个子节点，可以直接删除该节点，并用其子节点替代**。

b. 如果要删除的节点有两个子节点，需要找到其后继或前驱节点，将后继或前驱节点的值复制到要删除的节点，并将删除操作转换为删除后继或前驱节点。

c. 如果删除的节点和替代节点都是黑色，需要进行调整来保持红黑树的性质。

d. 进行旋转和重着色操作，以恢复红黑树的性质。与插入操作类似，可能需要进行左旋、右旋、双旋等操作，以保持红黑树的平衡。

通过以上步骤，红黑树在动态插入和删除操作时会自动进行调整，以保持树的平衡性质。这些调整操作能够确保红黑树的黑高度平衡，从而保证了树的高度保持在对数级别，使得基本操作的时间复杂度能够保持在 `O(log n)` 级别。总之，红黑树的平衡维护是通过旋转和重着色等操作来保持树的平衡性质的过程。





###  TreeMap实现一致性哈希





## 布隆过滤器

布隆过滤器的核心是一个由多个二进制位（通常是一个长的位数组或bitmap）组成的数据结构。初始时，所有的二进制位都被设置为0。当向布隆过滤器中添加一个元素时，**通过将该元素经过多个哈希函数的计算，得到多个哈希值，然后将对应的二进制位设置为1。**查询一个元素是否存在时，同样也是通过计算多个哈希值，并检查对应的二进制位是否都为1来判断。



布隆过滤器由「初始值都为 0 的位图数组」和「 N 个哈希函数」两部分组成。当我们在写入数据库数据时，在布隆过滤器里做个标记，这样下次查询数据是否在数据库时，只需要查询布隆过滤器，如果查询到数据没有被标记，说明不在数据库中。

布隆过滤器会通过 3 个操作完成标记：

- 第一步，使用 N 个哈希函数分别对数据做哈希计算，得到 N 个哈希值；
- 第二步，将第一步得到的 N 个哈希值对位图数组的长度取模，得到每个哈希值在位图数组的对应位置。
- 第三步，将每个哈希值在位图数组的对应位置的值设置为 1；



举个例子，假设有一个位图数组长度为 8，哈希函数 3 个的布隆过滤器:

![图片](https://cdn.xiaolincoding.com//mysql/other/86b0046c2622b2c4bda697f9bc0f5b28.png)

在数据库写入数据 x 后，把数据 x 标记在布隆过滤器时，数据 x 会被 3 个哈希函数分别计算出 3 个哈希值，然后在对这 3 个哈希值对 8 取模，假设取模的结果为 1、4、6，然后把位图数组的第 1、4、6 位置的值设置为 1。**当应用要查询数据 x 是否数据库时，通过布隆过滤器只要查到位图数组的第 1、4、6 位置的值是否全为 1，只要有一个为 0，就认为数据 x 不在数据库中**。

布隆过滤器由于是基于哈希函数实现查找的，高效查找的同时**存在哈希冲突的可能性**，比如数据 x 和数据 y 可能都落在第 1、4、6 位置，而事实上，可能数据库中并不存在数据 y，存在误判的情况。

所以，**查询布隆过滤器说数据存在，并不一定证明数据库中存在这个数据，但是查询到数据不存在，数据库中一定就不存在这个数据**

> 不同对象的哈希值有可能相等；
>
> 两个对象哈希值不同，这两个对象一定不是同一个对象；





## ZipList



`ZipList`它采用了**连续内存块的方式存储列表元素，不像普通的链表结构那样每个元素都需要单独分配内存**，**从而在一定程度上减少了内存碎片**，`zipList`本质就是一个空间连续的字节数组,`zipList`中包含多个节点(entry)，每个节点存储一个字符串值或整数值，每个节点通过`struct zlentry`结构表示:

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/ziplist.png)

可以看出，`ziplist`由列表头 + 列表节点 + 列表尾这三部分组成。每个组成部分作用说明如下：

- `zlbytes`占4字节，用于记录整个`ziplist`占用内存的总字节数，对于空表来说，`zlbytes`等于11
- `zltail`占4字节，用于记录表尾节点首地址距离ziplist起始地址有多少字节。设计这个字段的目的是为了快速定位表尾节点地址（ZIPLIST_ENTRY_TAIL)
- `zllen`占2字节，用于记录列表节点总数
- `ziplist`的每个`entry`结构都由三部分组成：
  - 前一节点长度信息：`previous_entry_length`
  - 当前节点编码信息：`encoding`
  - 当前节点内容：`content`

> **为什么要在元素较少的时候使用 `ziplist` ？**
>
> redis 中的集合容器中，很多情况都用到了链表的实现，元素和元素之间通过储存的关联指针有序的串联起来，但是这样的指针往往是 **随机I/O**，也就是指针地址是不连续的（分布不均匀）。而我们的 ziplist 它本身是一块连续的内存块，所以它的读写是 **顺序I/O**，**顺序I/O** 的效率肯定是高于 **随机I/O** 。你可能会问了，那为什么不都用 **顺序I/O** 的 ziplist 代替 **随机I/O** 呢，因为 ziplist 是连续内存，当你元素数量多了，意味着当你创建和扩展的时候需要操作更多的内存，所以 ziplist 针对元素少的时候才能提升效率。







## QuickList

2、`QuickList`

```java
typedef struct quicklistNode {
    struct quicklistNode *prev;  //前一个quicklistNode
    struct quicklistNode *next;  //后一个quicklistNode
    unsigned char *zl;           //quicklistNode指向的ziplist
    unsigned int sz;             //ziplist的字节大小
    unsigned int count : 16;     //ziplist中的元素个数
    unsigned int encoding : 2;   //编码格式，原生字节数组或压缩存储
    unsigned int container : 2;  //存储方式
    unsigned int recompress : 1; //数据是否被压缩
    unsigned int attempted_compress : 1; //数据能否被压缩
    unsigned int extra : 10;     //预留的bit位
} quicklistNode;
```

`quicklist` 实际上是 `zipList` 和 `linkedList` 的混合体，它将 `linkedList` 按段切分，每一段使用 `zipList` 来紧凑存储，多个 `zipList` 之间使用双向指针串接起来

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/QuickList.png" style="zoom: 80%;" />

> 为什么要这样设计`quickList`？
>
> 
>
> 基于ziplist存在的问题，要避免ziplist列表太大问题，因此将大ziplist分成一系列小的ziplist是一种思路。
>
> quicklist是由链表组成的结构，其中每个链表节点中都存在一个ziplist。是由ziplist改进而来，充分利用链表 + ziplist特性
>
> 



`quicklist`的常用操作

1. 插入

`quicklist`可以选择在头部或者尾部进行插入(`quicklistPushHead`和`quicklistPushTail`)，而不管是在头部还是尾部插入数据，都包含两种情况：

- 如果头节点（或尾节点）上`ziplist`大小没有超过限制（即`_quicklistNodeAllowInsert`返回1），那么新数据被直接插入到`ziplist`中（调用`ziplistPush`）
- 如果头节点（或尾节点）上`ziplist`太大了，那么新创建一个`quicklistNode`节点（对应地也会新创建一个`ziplist`），然后把这个新创建的节点插入到`quicklist`双向链表中。



2. 查找

`list`的查找操作主要是对`index`的， 我们的`quicklist`的节点是由一个一个的`ziplist`构成的每个`ziplist`都有大小。所以我们就只需要先根据我们每个`node`的个数，从而找到对应的`ziplist`，调用`ziplist`的`index`就能成功找到。







## SkipList



对于单链表来说，我们查找某个数据，只能从头到尾遍历链表，此时时间复杂度是 O(n)

那么怎么提高单链表的查找效率呢？看下图，对链表建立一级 `索引`，每两个节点提取一个结点到上一级，被抽出来的这级叫做 `索引` 或 `索引层`。

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8xMTk4OTQ3OS02ZTljODQyODFhZmRmNTI2LmpwZw?x-oss-process=image/format,png)

如果要查找13，就不需要将16前的结点全遍历一遍，只需要遍历索引，找到13，然后发现下一个结点是17，那么16一定是在 [13,17] 之间的，此时在13位置下降到原始链表层，找到16，加上一层索引后，查找一个结点需要遍历的结点个数减少了，也就是说查找效率提高了 



那么我们再加一级索引呢？
跟前面建立一级索引的方式相似，我们在第一级索引的基础上，每两个结点就抽出一个结点到第二级索引。此时再查找16，只需要遍历 6 个结点了，需要遍历的结点数量又减少了

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8xMTk4OTQ3OS01ZDM2NjQ2ODdmY2MxZTQ3LmpwZw?x-oss-process=image/format,png)

当结点数量多的时候，这种添加索引的方式，会使查询效率提高的非常明显







再比如下图展示了一个层级为 3 的跳表。

![img](https://cdn.xiaolincoding.com//mysql/other/2ae0ed790c7e7403f215acb2bd82e884.png)

图中头节点有 L0~L2 三个头指针，分别指向了不同层级的节点，然后每个层级的节点都通过指针连接起来：

- L0 层级共有 5 个节点，分别是节点1、2、3、4、5；
- L1 层级共有 3 个节点，分别是节点 2、3、5；
- L2 层级只有 1 个节点，也就是节点 3 

如果我们要在链表中查找节点 4 这个元素，只能从头开始遍历链表，需要查找 4 次，而使用了跳表后，只需要查找 2 次就能定位到节点 4，因为可以在头节点直接从 L2 层级跳到节点 3，然后再往前遍历找到节点 4

可以看到，这个查找过程就是在多个层级上跳来跳去，最后定位到元素。当数据量很大时，跳表的查找复杂度就是 `O(logN)`——>(将链表查找升级为二分查找)



那跳表节点是怎么实现多层级的呢？这就需要看「跳表节点」的数据结构了，如下：

```c++
typedef struct zskiplistNode {
    //Zset 对象的元素值
    sds ele;
    //元素权重值
    double score;
    //后向指针
    struct zskiplistNode *backward;
  
    //节点的level数组，保存每层上的前向指针和跨度
    struct zskiplistLevel {
        struct zskiplistNode *forward;
        unsigned long span;
    } level[];
} zskiplistNode;
```

`Zset` 对象要同时保存「元素」和「元素的权重」，对应到跳表节点结构里就是 sds 类型的 ele 变量和 `double` 类型的 `score` 变量。每个跳表节点都有一个后向指针（`struct zskiplistNode *backward`），指向前一个节点，目的是为了方便从跳表的尾节点开始访问节点，这样倒序查找时很方便。

跳表是一个带有层级关系的链表，而且每一层级可以包含多个节点，每一个节点通过指针连接起来，实现这一特性就是靠跳表节点结构体中的**`zskiplistLevel` 结构体类型的 `level` 数组**

level 数组中的每一个元素代表跳表的一层，也就是由 `zskiplistLevel` 结构体表示，比如 leve[0] 就表示第一层，leve[1] 就表示第二层。`zskiplistLevel` 结构体里定义了「指向下一个跳表节点的指针」和「跨度」，跨度时用来记录两个节点之间的距离



比如，下面这张图，展示了各个节点的跨度。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/3%E5%B1%82%E8%B7%B3%E8%A1%A8-%E8%B7%A8%E5%BA%A6.png)







跳表的查询：

查找一个跳表节点的过程时，跳表会从头节点的最高层开始，逐一遍历每一层。在遍历某一层的跳表节点时，会用跳表节点中的 SDS 类型的元素和元素的权重来进行判断，共有两个判断条件：

- 如果当前节点的权重「小于」要查找的权重时，跳表就会访问该层上的下一个节点。
- 如果当前节点的权重「等于」要查找的权重时，并且当前节点的 SDS 类型数据「小于」要查找的数据时，跳表就会访问该层上的下一个节点。

如果上面两个条件都不满足，或者下一个节点为空时，跳表就会使用目前遍历到的节点的 level 数组里的下一层指针，然后沿着下一层指针继续查找，这就相当于跳到了下一层接着查找

举个例子，下图有个 3 层级的跳表。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/3%E5%B1%82%E8%B7%B3%E8%A1%A8-%E8%B7%A8%E5%BA%A6.drawio.png)

如果要查找「元素：abcd，权重：4」的节点，查找的过程是这样的：

- 先从头节点的最高层开始，L2 指向了「元素：abc，权重：3」节点，这个节点的权重比要查找节点的小，所以要访问该层上的下一个节点；
- 但是该层的下一个节点是空节点（ leve[2]指向的是空节点），于是就会跳到「元素：abc，权重：3」节点的下一层去找，也就是 leve[1];
- 「元素：abc，权重：3」节点的 leve[1] 的下一个指针指向了「元素：abcde，权重：4」的节点，然后将其和要查找的节点比较。虽然「元素：abcde，权重：4」的节点的权重和要查找的权重相同，但是当前节点的 SDS 类型数据「大于」要查找的数据，所以会继续跳到「元素：abc，权重：3」节点的下一层去找，也就是 leve[0]；
- 「元素：abc，权重：3」节点的 leve[0] 的下一个指针指向了「元素：abcd，权重：4」的节点，该节点正是要查找的节点，查询结束











## BitMap









# 消息队列







## 消息队列是发布订阅模式还是生产者消费者模式？

消息队列可以用于实现发布订阅模式或生产者消费者模式，取决于具体的使用方式和设计。

1. 发布订阅模式： 在发布订阅模式中，消息队列充当了消息的中介，允许发布者发布消息而不必直接将消息传递给特定的订阅者。发布者将消息发布到队列中，然后订阅者从队列中订阅感兴趣的消息。当新的消息被发布到队列时，所有订阅者都会接收到该消息。这种模式广泛应用于解耦发布者和订阅者之间的关系，使得系统更加灵活和可扩展。
2. 生产者消费者模式： 在生产者消费者模式中，消息队列充当了生产者和消费者之间的缓冲区。生产者将消息放入队列，而消费者从队列中获取消息并进行处理。这样可以有效地解耦生产者和消费者，使它们能够以不同的速率工作而不会相互阻塞。这种模式在异步任务处理、流量控制和削峰填谷等场景中非常有用。

总结：消息队列本身不是绑定到特定模式的，而是一种通用的通信方式，可以根据实际需求使用发布订阅模式或生产者消费者模式。实际上，一些消息队列系统（如RabbitMQ）支持同时实现这两种模式，甚至更多其他通信模式，因此可以根据具体情况选择最适合的使用方式







## 使用消息队列的缺点？

优点不用多说，就是**在特殊场景下有其对应的好处**，**解耦**、**异步**、**削峰**





**引入 MQ 消息中间件实现系统解耦，会影响系统之间数据传输的一致性**。 在分布式系统中，如果两个节点之间存在数据同步，就会带来数据一致性的问题。同理，在这一讲你要解决的就是：消息生产端和消息消费端的消息数据一致性问题（也就是如何确保消息不丢失）。

而引入 MQ 消息中间件解决流量控制， 会使消费端处理能力不足从而导致消息积压，这也是你要解决的问题。



故缺点可以概括为以下几个：

- 系统可用性降低

  系统引入的外部依赖越多，越容易挂掉。本来你就是 A 系统调用 BCD 三个系统的接口就好了，ABCD 四个系统还好好的，没啥问题，你偏加个 MQ 进来，万一 MQ 挂了咋整？MQ 一挂，整套系统崩溃，你不就完了？

- 系统复杂度提高

  硬生生加个 MQ 进来，你怎么[保证消息没有重复消费](https://doocs.github.io/advanced-java/#/docs/high-concurrency/how-to-ensure-that-messages-are-not-repeatedly-consumed)？怎么[处理消息丢失的情况](https://doocs.github.io/advanced-java/#/docs/high-concurrency/how-to-ensure-the-reliable-transmission-of-messages)？怎么保证消息传递的顺序性？头大头大，问题一大堆，痛苦不已。

- 一致性问题

  A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致了。

  所以消息队列实际是一种非常复杂的架构，你引入它有很多好处，但是也得针对它带来的坏处做各种额外的技术方案和架构来规避掉，做好之后，你会发现，妈呀，系统复杂度提升了一个数量级，也许是复杂了 10 倍。
  
  



## 不同消息队列对比



[`Kafka`、`ActiveMQ`、`RabbitMQ`、`RocketMQ`] 有什么优缺点？

| 特性                     | ActiveMQ                              | RabbitMQ                                           | RocketMQ                                                     | Kafka                                                        |
| ------------------------ | ------------------------------------- | -------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 单机吞吐量               | 万级，比 RocketMQ、Kafka 低一个数量级 | 同 ActiveMQ                                        | 10 万级，支撑高吞吐                                          | 10 万级，高吞吐，一般**配合大数据类**的系统来进行实时数据计算、**日志采集**等场景 |
| topic 数量对吞吐量的影响 |                                       |                                                    | topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic | topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源 |
| 时效性                   | ms 级                                 | 微秒级，这是 RabbitMQ 的一大特点，延迟最低         | ms 级                                                        | 延迟在 ms 级以内                                             |
| 可用性                   | 高，基于主从架构实现高可用            | 同 ActiveMQ                                        | 非常高，分布式架构                                           | 非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 |
| 消息可靠性               | 有较低的概率丢失数据                  | 基本不丢                                           | 经过参数优化配置，可以做到 0 丢失                            | 同 RocketMQ                                                  |
| 功能支持                 | MQ 领域的功能极其完备                 | 基于 erlang 开发，并发能力很强，性能极好，延时很低 | MQ 功能较为完善，还是分布式的，扩展性好                      | 功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用 |







## 怎么保证消息队列消费的幂等性？

还是得结合业务来思考，这里给几个思路：

- 比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update 一下好吧。
- 比如你是写 Redis，那没问题了，反正每次都是 set，天然幂等性。
- 比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西，然后你这里消费到了之后，先根据这个 id 去比如 Redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 id 写 Redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。
- 比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。



在消息消费的过程中，如果出现失败的情况，通过补偿的机制发送方会执行重试，重试的过程就有可能产生重复的消息，那么如何解决这个问题？

这个问题其实可以换一种说法，就是如何解决消费端幂等性问题（幂等性，就是一条命令，任意多次执行所产生的影响均与一次执行的影响相同），只要消费端具备了幂等性，那么重复消费消息的问题也就解决了。

我们还是来看扣减京豆的例子，将账户 X 的金豆个数扣减 100 个，在这个例子中，我们可以通过改造业务逻辑，让它具备幂等性。

<img src="https://cdn.tobebetterjavaer.com/tobebetterjavaer/images/mq/100-budiushi-9d864624-2136-4770-942b-9a5f70c2aaf6.png" alt="img" style="zoom:67%;" />

最简单的实现方案，就是在数据库中建一张消息日志表， 这个表有两个字段：消息 ID 和消息执行状态。这样，我们消费消息的逻辑可以变为：在消息日志表中增加一条消息记录，然后再根据消息记录，异步操作更新用户京豆余额。

因为我们每次都会在插入之前检查是否消息已存在，所以就不会出现一条消息被执行多次的情况，这样就实现了一个幂等的操作。当然，基于这个思路，不仅可以使用关系型数据库，也可以通过 Redis 来代替数据库实现唯一约束的方案。

在这里我多说一句，想要解决“消息丢失”和“消息重复消费”的问题，有一个前提条件就是要实现一个全局唯一 ID 生成的技术方案。这也是面试官喜欢考察的问题，你也要掌握。









## 如何保证消息的可靠性传输？

数据的丢失问题，可能出现在生产者、MQ、消费者中，先从 `RabbitMQ` 来分析一下吧。

首先要知道`rabbitmq`是把消息存放在内存中的

> RabbitMQ和RocketMQ在消息存储和持久化方面有一些不同的策略
>
> 
>
> **RabbitMQ：** RabbitMQ默认情况下将消息存储在内存中，这使得它能够提供低延迟和高吞吐量的消息传递。然而，这也意味着如果RabbitMQ服务器在故障或重启时，内存中存储的消息将会丢失。
>
> 为了确保消息的持久性，RabbitMQ提供了持久化选项。当将消息标记为持久化时，RabbitMQ会将消息存储到磁盘上的持久化日志文件中，以便在重启后能够恢复消息。同时，队列、交换器和绑定的元数据也可以被标记为持久化，以确保在重启后能够恢复它们。
>
> 
>
> **RocketMQ：** RocketMQ在设计上更加偏向于数据持久性，它将消息默认存储在磁盘上。消息存储使用磁盘文件进行管理，这使得RocketMQ能够提供更高的消息持久性和数据安全性。
>
> RocketMQ支持多种存储模式，包括同步刷盘和异步刷盘，以及支持将消息存储到物理磁盘的 CommitLog 和消息索引文件。这些特性使得RocketMQ能够在面对重启、故障和崩溃时更好地保持数据的可靠性。



![rabbitmq-message-lose](https://doocs.github.io/advanced-java/docs/high-concurrency/images/rabbitmq-message-lose.png)



**1、生产者丢失消息**

一般来说，如果要确保说写 RabbitMQ 的消息别丢，可以开启 `confirm` 模式，在生产者那里设置开启 `confirm` 模式之后，你每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 `ack` 消息，告诉你说这个消息 ok 了。如果 RabbitMQ 没能处理这个消息，会回调你的一个 `nack` 接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。

事务机制和 `confirm` 机制最大的不同在于，**事务机制是同步的**，你提交一个事务之后会**阻塞**在那儿，但是 `confirm` 机制是**异步**的，你发送个消息之后就可以发送下一个消息，然后那个消息 RabbitMQ 接收了之后会异步回调你的一个接口通知你这个消息接收到了。

所以一般在生产者这块**避免数据丢失**，都是用 `confirm` 机制的。





**2、Rabbitmq丢失消息**

针对 `RabbitMQ` 自己弄丢了数据的情况，这时必须**开启 RabbitMQ 的持久化机制**，就是消息写入之后会持久化到磁盘，哪怕是 `RabbitMQ` 自己挂了，**恢复之后会自动读取之前存储的数据**，一般数据不会丢。除非极其罕见的是，`RabbitMQ` 还没持久化，自己就挂了，**可能导致少量数据丢失**，但是这个概率较小。

设置持久化有**两个步骤**：

- 创建 queue 的时候将其设置为持久化。这样就可以保证 RabbitMQ 持久化 queue 的元数据，但是它是不会持久化 queue 里的数据的
- 第二个是发送消息的时候将消息的 `deliveryMode` 设置为 2。就是将消息设置为持久化，此时 RabbitMQ 就会将消息持久化到磁盘上去

必须要同时设置这两个持久化才行，RabbitMQ 哪怕是挂了，再次重启，也会从磁盘上重启恢复 queue，恢复这个 queue 里的数据。

注意，哪怕是你给 RabbitMQ 开启了持久化机制，也有一种可能，就是这个消息写到了 RabbitMQ 中，但是还没来得及持久化到磁盘上，结果不巧，此时 RabbitMQ 挂了，就会导致内存里的一点点数据丢失。

所以，**持久化可以跟生产者那边的 `confirm` 机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者 `ack` 了，所以哪怕是在持久化到磁盘之前，RabbitMQ 挂了，数据丢了，生产者收不到 `ack` ，你也是可以自己重发的**





**3、消费端丢失消息**

为了保证消息从队列中可靠地到达消费者，`RabbitMQ` 提供了消息确认机制。消费者在声明队列时，可以指定 `noAck` 参数，当 `noAck=false`，`RabbitMQ` 会等待消费者显式发回 `ack` 信号后，才从内存（和磁盘，如果是持久化消息）中移去消息。否则，一旦消息被消费者消费，`RabbitMQ` 会在队列中立即删除它





## Rabbitmq

RabbitMQ的基本结构如下：

Producer 消息生产者，即生产方客户端，将消息发送给MQ

Consumer 消息消费者，即消费者客户端，接收MQ发送的信息

Broker 消息队列服务进程，此服务包括两部分：exchange、queue

Exchange 消息队列交换机，**交换机按照一定的规则将消息路由转发到队列，对消息进行过滤**。

Queue 消息队列，存储消息，消息到达队列并将消息转发给消费方。

信息发送接收流程如下：

发送消息：

- 生产者和broker建立TCP连接 即MQ的Connection
- 生产者和broker建立通道，通道是通过Connection创建的
- 生产者通过通道将消息发送给broker，由exchange将消息转发
- exchange将信息转发给指定的队列
  接收信息：

接收消息：

- 消费者和broker建立TCP连接
- 消费者和broker建立通道
- 消费者监听队列
- 当消息到达Queue时，broker默认将消息推送给消费者
- 消费者接收到消息
  



### 工作模式





### 高可用性



RabbitMQ 是比较有代表性的，因为是**基于主从**（非分布式）做高可用性的，我们就以 RabbitMQ 为例子讲解第一种 MQ 的高可用性怎么实现。RabbitMQ 有三种模式：单机模式、普通集群模式、镜像集群模式



[单机模式](https://doocs.github.io/advanced-java/#/docs/high-concurrency/how-to-ensure-high-availability-of-message-queues?id=单机模式)

单机模式，就是 Demo 级别的，一般就是本地启动了玩玩儿的，没人生产用单机模式



[普通集群模式（无高可用性）](https://doocs.github.io/advanced-java/#/docs/high-concurrency/how-to-ensure-high-availability-of-message-queues?id=普通集群模式（无高可用性）)

普通集群模式，意思就是在多台机器上启动多个 RabbitMQ 实例，每台机器启动一个。你**创建的 queue，只会放在一个 RabbitMQ 实例上**，**但是每个实例都同步 queue 的元数据**（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来

<img src="https://doocs.github.io/advanced-java/docs/high-concurrency/images/mq-7.png" alt="mq-7" style="zoom: 80%;" />

这种方式确实很麻烦，也不怎么好，**没做到所谓的分布式**，就是个普通集群。因为这导致你要么消费者每次随机连接一个实例然后拉取数据，要么固定连接那个 queue 所在实例消费数据，前者有**数据拉取的开销**，后者导致**单实例性能瓶颈**。

而且如果那个放 queue 的实例宕机了，会导致接下来其他实例就无法从那个实例拉取，如果你**开启了消息持久化**，让 RabbitMQ 落地存储消息的话，**消息不一定会丢**，得等这个实例恢复了，然后才可以继续从这个 queue 拉取数据。所以这个事儿就比较尴尬了，这就**没有什么所谓的高可用性**，**这方案主要是提高吞吐量的**，就是说让集群中多个节点来服务某个 queue 的读写操作







[镜像集群模式（高可用性）](https://doocs.github.io/advanced-java/#/docs/high-concurrency/how-to-ensure-high-availability-of-message-queues?id=镜像集群模式（高可用性）)

这种模式，才是所谓的 RabbitMQ 的高可用模式。跟普通集群模式不一样的是，在镜像集群模式下，你创建的 queue，**无论是元数据还是 queue 里的消息都会存在于多个实例上**，就是说，每个 RabbitMQ 节点都有这个 queue 的一个**完整镜像**，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把**消息同步**到多个实例的 queue 上。

![mq-8](https://doocs.github.io/advanced-java/docs/high-concurrency/images/mq-8.png)

那么**如何开启这个镜像集群模式**呢？其实很简单，RabbitMQ 有很好的管理控制台，就是在后台新增一个策略，这个策略是**镜像集群模式的策略**，指定的时候是可以要求数据同步到所有节点的，也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。

这样的话，好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。



坏处在于：

第一，这个性能开销也太大了吧，消息需要同步到所有机器上，导致网络带宽压力和消耗很重！

第二，这么玩儿，不是分布式的，就**没有扩展性可言**了，如果某个 queue 负载很重，你加机器，新增的机器也包含了这个 queue 的所有数据，并且**没有办法线性扩展**你的 queue ，说白了就是不够分布式  :sweat: :sweat:(没有将消息分散存储)







## Rocketmq



> Rocketmq中的topic是什么？

在`Rocketmq`中，"topic"（主题）是一种用来组织和标识消息的机制。它通常用于发布-订阅（`publish-subscribe`）模式的消息传递，其中消息的生产者将消息发布到一个或多个主题，而消费者可以订阅一个或多个主题来接收消息















# Nginx





​     

## 正/反向代理



1. 正向代理：

正向代理服务器代表客户端发起请求，客户端将请求发送给代理服务器，然后代理服务器将请求发送到目标服务器，并将响应返回给客户端。在这种情况下，代理服务器确实可以隐藏客户端的真实身份，因为目标服务器只能看到代理服务器的IP地址，无法直接识别真正的客户端。但并不是说代理服务器完全屏蔽了客户端，它只是起到了中间人的角色，帮助客户端访问外部资源



2. 反向代理：

反向代理服务器位于服务器端，它接收来自客户端的请求，并将这些请求分发给后端的多个服务器。客户端只知道反向代理的存在，不直接与后端服务器通信。在这种情况下，并不能说反向代理完全屏蔽了服务端，实际上，反向代理将请求分发给后端服务器，然后将后端服务器的响应返回给客户端





假设我们要达到一个效果，访问`127.0.0.1:9999`，反向代理到我们的网站https://www.aaa.cn

先看下`nginx`的配置：

```conf
server {
   listen 9999;  # 监听的端口
   server_name localhost;   # 表示nginx监听的地址
   location / {
        proxy_pass https://www.aaa.cn;   # 转发到 www.aaa.cn
   }
}
```

- listen：表示 nginx 监听的端口，也就是你在浏览器输入的端口号。
- server_name：表示 nginx 监听的地址，也就是你在浏览器输入的地址或者域名
- location：用来匹配不同的url，这里/代表根路径。
- proxy_pass：代理的指令，我们这里是代理到https://www.aaa.cn





## 如何实现负载均衡？



Nginx负载均衡是通过`upstream`模块来实现的，内置实现了三种负载策略，配置还是比较简单的

> `upstream` 模块是 `Nginx` 中的一个核心模块，用于定义一组后端服务器（也称为上游服务器），并为这些服务器实现负载均衡。通过 `upstream` 模块，您可以将请求分发给一组服务器，从而实现高可用性和性能优化



- 轮循（默认） 

Nginx根据请求次数，将每个请求均匀分配到每台服务器

- 最少连接 

将请求分配给连接数最少的服务器。Nginx会统计哪些服务器的连接数最少

- IP Hash 

绑定处理请求的服务器。第一次请求时，根据该客户端的IP算出一个HASH值，将请求分配到集群中的某一台服务器上。后面该客户端的所有请求，都将通过HASH算法，找到之前处理这台客户端请求的服务器，然后将请求交给它来处理



**轮询：**

```
http {

    # ... 省略其它配置

    upstream tomcats {
        server 192.168.0.100:8080;
        server 192.168.0.101:8080;
        server example.com:8080;
    }

    server {
        listen 80;

        location / {
            proxy_pass http://tomcats;
        }
    }

    # ... 省略其它配置
}
```



**权重：**

```
upstream tomcats {
    server 192.168.0.100:8080 weight=2;  # 2/6次
    server 192.168.0.101:8080 weight=3;  # 3/6次
    server 192.168.0.102:8080 weight=1;  # 1/6次
}
```







# Linux



## 常用命令





# 分布式





## CAP理论

CAP理论是分布式系统、特别是分布式存储领域中被讨论的最多的理论。其中C代表一致性 (Consistency)，A代表可用性 (Availability)，P代表分区容错性 (Partition tolerance)。CAP理论告诉我们C、A、P三者不能同时满足，最多只能满足其中两个(**因为分区容忍性（partition tolerance）的存在，就必定要求我们需要在系统可用性（availability）和数据一致性（consistency）中做出权衡**)，这就是著名的 `CAP` 定理。

`一致性 (Consistency)`: 一个写操作返回成功，那么之后的读请求都必须读到这个新数据；如果返回失败，那么所有读操作都不能读到这个数据。**所有节点访问同一份最新的数据。**

`可用性 (Availability)`: 对数据更新具备高可用性，请求能够及时处理，**非故障节点在合理的时间内返回合理响应**

`分区容错性 (Partition tolerance)`: **能容忍网络分区**——分布式系统出现网络分区时，仍然能够对外提供服务。**即被分隔的节点可以正常对外提供服务。**



**什么是网络分区？**

分布式系统中，多个节点之间的网络本来是连通的，但是因为某些故障（比如部分节点网络出了问题）某些节点之间不连通了，整个网络就分成了几块区域，这就叫 **网络分区**。

![partition-tolerance](https://oss.javaguide.cn/2020-11/partition-tolerance.png)



**不是所谓的“3 选 2”  :exclamation: :exclamation: :exclamation: **

大部分人解释这一定律时，常常简单的表述为：“一致性、可用性、分区容忍性三者你只能同时达到其中两个，不可能同时达到”。实际上这是一个非常具有误导性质的说法，而且在 CAP 理论诞生 12 年之后，CAP 之父也在 2012 年重写了之前的论文。

> **当发生网络分区的时候，如果我们要继续服务，那么强一致性和可用性只能 2 选 1。也就是说当网络分区之后保证 P 是前提，决定了 P 之后才有 C 和 A 的选择。也就是说分区容错性（Partition tolerance）我们是必须要实现的。**
>
> 简而言之就是：**CAP 理论中分区容错性 P 是一定要满足的，在此基础上，只能满足可用性 A 或者一致性 C。**

因此，**分布式系统理论上不可能选择 CA 架构，只能选择 CP 或者 AP 架构。** 比如 ZooKeeper、HBase 就是 CP 架构，Cassandra、Eureka 就是 AP 架构，Nacos 不仅支持 CP 架构也支持 AP 架构。

**为啥不可能选择 CA 架构呢？** 举个例子：若系统出现“分区”，系统中的某个节点在进行写操作。为了保证 C， 必须要禁止其他节点的读写操作，这就和 A 发生冲突了。如果为了保证 A，其他节点的读写操作正常的话，那就和 C 发生冲突了。

**选择 CP 还是 AP 的关键在于当前的业务场景，没有定论，比如对于需要确保强一致性的场景如银行一般会选择保证 CP 。**

另外，需要补充说明的一点是：**如果网络分区正常的话（系统在绝大部分时候所处的状态），也就说不需要保证 P 的时候，C 和 A 能够同时保证。**





这里以注册中心来探讨一下 CAP 的实际应用,注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小。

常见的可以作为注册中心的组件有：`ZooKeeper`、`Eureka`、`Nacos`...



1. ZooKeeper

**ZooKeeper 保证的是 CP。** 任何时刻对 ZooKeeper 的访问请求都能得到一致性的结果，同时系统对网络分割具备容错性，但是 Zookeeper 不能保证每次服务请求都是可达的。

**不能保证每次服务请求的可用性：**  从 Zookeeper 的实际应用情况来看，在使用 Zookeeper 获取服务列表时，如果此时的 Zookeeper 集群中的 Leader 宕机了，该集群就要进行 Leader 的选举，又或者 Zookeeper 集群中半数以上服务器节点不可用(例如有三个节点，如果节点一检测到节点三挂了 ，节点二也检测到节点三挂了，那这个节点才算是真的挂了)，那么此时将无法处理外来请求。所以说，Zookeeper 不能保证服务可用性



**进行`leader`选举时集群都是不可用**。在使用`ZooKeeper`获取服务列表时，当`leader`节点因为网络故障与其他节点失去联系时，**剩余`follower`节点会投票进行判断master节点是否下线(由单个节点判断到的主观下线到所有节点达成一致后判断master节点主观下线)， 下线后会重新进行leader选举**。问题在于，选举`leader`的时间太长， 且选举期间整个zk集群都是不可用的，这就导致在选举期间注册服务瘫痪，虽然服务能够最终恢复，但是漫长的选举时间导致的注册长期不可用是不能容忍的。所以说，`ZooKeeper`不能保证服务可用性



2. Eureka  (设计思想类似`Redis`的集群架构)

Eureka集群下每个节点之间都会**定时发送心跳，定时同步数据，没有master/slave之分，是一个完全去中心化的架构**

(`P2P`架构，节点之前通过`Gossip`协议定时进行信息同步)因此每个注册到Eureka下的实例都会定时同步ip，服务之间

的调用也是根据Eureka拿到的缓存服务数据进行调用。若一台Eureka服务宕机，其他Eureka在一定时间内未感知到这台Eureka服务宕机，各个服务之间还是可以正常调用

Eureka的集群中，只要有一台Eureka还在，就能保证注册服务可用（保证可用性），只不过查到的信息可能不是最新的（**不保证强一致性，只保证最终一致性**）。当数据出现不一致时，虽然A, B上的注册信息不完全相同，但每个Eureka节点依然能够正常对外提供服务，这会出现查询服务信息时如果请求A查不到，但请求B就能查到。如此保证了可用性，但牺牲了一致性。



3. Nacos

Nacos支持CP+AP模式，即Nacos可以根据配置识别为CP模式或AP模式，默认是AP模式。如果注册Nacos的client节点注册时ephemeral=true，那么Nacos集群对这个client节点的效果就是AP，采用distro协议实现；而注册Nacos的client节点注册时ephemeral=false，那么Nacos集群对这个节点的效果就是CP的，采用raft协议实现。根据client注册时的属性，AP，CP同时混合存在，只是对不同的client节点效果不同。Nacos可以很好的解决不同场景的业务需求。



> 在大多数分布式环境中，尤其是涉及到数据存储的场景，数据一致性应该是首先被保证的，这也是 Zookeeper 设计紧遵CP原则的重要原因。但是对于服务发现来说，情况就不太一样了，**针对同一个服务，即使注册中心的不同节点保存的服务提供者信息不尽相同，也并不会造成灾难性的后果。因为对于服务消费者来说，能消费才是最重要的，消费者虽然拿到可能不正确的服务实例信息后尝试消费一下，也要胜过因为无法获取实例信息而不去消费，导致系统异常要好。从这一点上来说，分布式服务注册中心AP模式要更优于CP模式。这也是为什么越来越多的人抛弃Zookeeper的原因所在。**
>
> 
>
> 总之，服务注册中心到底选用CP模型还是AP模型，还是要依照业务场景进行决定，如果对数据一致性要求较高，且可以容忍一定时间的不可用，就选用CP模型。反之，如果可以容忍一定时延的数据不一致性，但不能容忍不可用显现发生，则要选用AP模型。





## Base理论

**BASE** 是 **Basically Available（基本可用）**、**Soft-state（软状态）** 和 **Eventually Consistent（最终一致性）** 三个短语的缩写。BASE 理论是对 CAP 中一致性 C 和可用性 A 权衡的结果，其来源于对大规模互联网系统分布式实践的总结，是基于 CAP 定理逐步演化而来的(更具体地说，是对 CAP 中 AP 方案的一个补充。其基本思路就是：通过业务，牺牲强一致性而获得可用性，并允许数据在一段时间内是不一致的，但是最终达到一致性状态。)，它大大降低了我们对系统的要求

Base理论的核心思想是：即使无法做到强一致性（Strong Consistency，CAP 的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性（Eventual Consitency）,但是**自始至终要保证AP，即一定程度上牺牲了一致性来换取所有节点的可用性**



:ear: 可以这么理解：CAP理论中的C表示的是强一致性，而BASE理论想要达到的目标是最终一致性

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOC81LzI0LzE2MzkxNDgwNmQ5ZTE1YzY?x-oss-process=image/format,png" alt="BASE理论三要素" style="zoom:50%;" />



基本可用：指分布式系统在出现不可预知故障的时候，允许损失部分可用性。但是，这绝不等价于系统不可用。

**什么叫允许损失部分可用性呢？**

- **响应时间上的损失**: 正常情况下，处理用户请求需要 0.5s 返回结果，但是由于系统出现故障，处理用户请求的时间变为 3 s。
- **系统功能上的损失**：正常情况下，用户可以使用系统的全部功能，但是由于系统访问量突然剧增，系统的部分非核心功能无法使用。



软状态：软状态指允许系统中的数据存在中间状态（**CAP 理论中的数据不一致**），并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。



最终一致性：最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性



> 分布式一致性的 3 种级别：
>
> 1. **强一致性**：系统写入了什么，读出来的就是什么。
> 2. **弱一致性**：不一定可以读取到最新写入的值，也不保证多少时间之后读取到的数据是最新的，只是会尽量保证某个时刻达到数据一致的状态,甚至不能保证可以访问到修改。
> 3. **最终一致性**：弱一致性的升级版，系统会保证在一定时间内达到数据一致的状态。
>
> **业界比较推崇是最终一致性级别，但是某些对数据一致要求十分严格的场景比如银行转账还是要保证强一致性。**
>
> 









## Raft算法



>  首先来了解一下什么是拜占庭/非拜占庭算法？
>
>  
>
>  拜占庭将军问题（Byzantine Generals Problem）是在计算机科学中提出的一个著名问题，用来描述在分布式系统中节点之间的可靠通信问题。问题的背景设定是：一组拜占庭将军围绕一座城市展开进攻，这些将军之间需要通过消息交换来达成关于进攻还是撤退的共识。然而，存在一些叛徒将军，他们可能会发送虚假的消息来混淆其他将军，从而导致无法达成一致的决策。
>
>  
>
>  非拜占庭的一致性算法是一类用于分布式系统中的算法，用于确保在存在一些节点可能发生错误或者恶意行为的情况下，系统仍然能够在各个节点之间达成一致的状态或决策。这些错误可能包括**节点崩溃、消息丢失、消息延迟、恶意节点**等,一些著名的非拜占庭一致性算法包括：
>
>  1. Paxos：一种经典的一致性算法，用于确保分布式系统中的节点就某个值达成共识。
>  2. Raft：类似于Paxos，也是用于分布式一致性的算法，旨在更易于理解和实现。
>  3. ZooKeeper：分布式协调服务，提供了高级别的原语，可以用于实现各种分布式应用场景。
>  4. etcd：类似于ZooKeeper，用于分布式系统的配置管理和服务发现。
>  5. Consul：用于服务发现、配置和分布式一致性的工具。



Raft算法 正常工作时的流程如下图，也就是正常情况下日志复制的流程。Raft 中使用日志来记录所有操作，所有结点都有自己的日志列表来记录所有请求。算法将机器分成三种角色：**Leader**、**Follower** 和 **Candidate**。正常情况下只存在一个 `Leader`，其他均为 `Follower`，所有客户端都与 `Leader` 进行交互:

![tcCXcV](https://imgs.lfeng.tech/images/2023/04/tcCXcV.gif)

以下是Raft算法中的三个角色及其职责：

1. **领导者（Leader）：**
   - 领导者是Raft集群中的一个节点，负责协调和管理日志的复制和一致性。
   - 领导者接收客户端的写请求，并将其转化为一系列的日志条目。
   - 领导者将这些日志条目分发给其他节点，以确保集群中的所有节点都达到相同的状态。
   - 领导者周期性地向跟随者发送心跳消息，以保持其领导地位。如果跟随者长时间没有收到心跳，它们会开始寻找新的领导者。
2. **跟随者（Follower）：**
   - 跟随者是Raft集群中的普通节点，遵循领导者的指令并复制其日志。
   - 跟随者响应来自领导者的心跳消息，以维持领导者的地位。
   - 如果跟随者认为自己不再收到来自现任领导者的消息，它可以开始成为候选者，发起选举以寻找新的领导者。
3. **候选者（Candidate）：**
   - 候选者是在选举中寻找新领导者的节点，当跟随者认为现任领导者不可用时，它们可以成为候选者。
   - 候选者发起选举请求(发送RPC消息)，请求其他节点的投票支持。
   - 在一个选举周期内，节点只能投给一个候选者，候选者获得多数投票即可成为新的领导者。
   - 如果没有候选者获得多数投票，那么新的选举周期将在稍后重新开始。





所有操作采用类似**两阶段提交(`Two-Phase Commit Protocol`)**的方式，Leader 在收到来自客户端的请求后并不会执行，只是将其写入自己的日志列表中，然后将该操作发送给所有的 Follower。Follower 在收到请求后也只是写入自己的日志列表中然后回复 Leader，当有超过半数的结点写入后 Leader 才会提交该操作并返回给客户端，同时通知所有其他结点提交该操作。

通过这一流程保证了只要提交过后的操作一定在多数结点上留有记录（在日志列表中），从而保证了该数据不会丢失。





### Leader选举

在算法刚开始时，所有结点都是 `Follower`，每个结点都会有一个定时器(每个节点的定时器设置时间是不一致的)，每次收到来自 Leader 的信息就会更新该定时器(重新从0开始计时)



如果定时器超时，说明一段时间内没有收到 Leader 的消息，那么就可以认为 Leader 已死或者不存在，那么该结点就会转变成 Candidate，意思为准备竞争成为 Leader。

成为 Candidate 后结点会向所有其他结点发送请求投票的请求（RequestVote），其他结点在收到请求后会判断是否可以投给他并返回结果。Candidate 如果收到了半数以上的投票就可以成为 Leader，成为之后会立即并在任期内定期发送一个心跳信息通知其他所有结点新的 Leader 信息，并用来重置定时器，避免其他结点再次成为 Candidate。

如果 Candidate 在一定时间内没有获得足够的投票，那么就会进行一轮新的选举，直到其成为 Leader,或者其他结点成为了新的 Leader，自己变成 Follower。



1、比如A节点等待超时时间为200ms、B节点为280ms、C节点为120ms,那么C节点先超时，最先因为没有等到领导者Leader的心跳信息，发生超时

<img src="https://ask.qcloudimg.com/http-save/yehe-1065851/sexgnei3nn.png" alt="img" style="zoom:67%;" />

2、当C节点超时时间到了后，C节点成为候选者，并增加自己的任期编号，Term值从0更新为1，并给自己投了一票：

-  Node A: Term=0 
-  Node B: Term=0 
-  Node C: Term=1 Vote Count=1; 

<img src="https://ask.qcloudimg.com/http-save/yehe-1065851/shzzvffb0p.png" alt="img" style="zoom:67%;" />

此时没有一个节点是领导者，节点等待心跳超时后，会推荐自己**节点C**为候选人，向集群其他节点发起请求投票信息，此时任期编号 +1，自荐会获得自己的一票选票。



3、其他跟随者收到请求投票信息后，如果该候选人符合投票要求后，则将自己宝贵（因为每个任期内跟随者只能投给先来的候选人一票，后面来的候选人则不能在投票给它了）的一票投给该候选人，**同时更新任期编号**。



<img src="https://ask.qcloudimg.com/http-save/yehe-1065851/g1e7qaa88m.png" alt="img" style="zoom:67%;" />



4、当节点 C 赢得大多数选票后(须大于 n/2+1)，它会成为本次任期的领导者Leader

<img src="https://ask.qcloudimg.com/http-save/yehe-1065851/4kp2oup9yu.png" alt="img" style="zoom:67%;" />

5、随后领导者周期性发送心跳消息给其他节点，告知自己是领导者，同时刷新跟随者的超时时间，防止跟随者发起新的领导者选举。





> 关于任期`Term`的问题：
>
> 从以上的选举过程看，我们知道在 Raft 中的选举中是有任期机制的，顾名思义，每一任领导者，都有它专属的任期，当领导者更换后，任期也会增加，Raft 中的任期还要注意以下个细节：
>
> 1. 如果某个节点，发现自己的任期编号比其他节点小(收到其他节点的RPC消息)，则会将自己的任期编号更新比自己更大的值；
> 2. 从上面的选举过程看出，每次推荐自己成为候选人，都会自己给自身投一票；
> 3. 如果候选人或者领导者发现自己的任期编号比其它节点发来的RPC消息中的编号要小，则会立即更新自己为跟随者，这点很重要，按照我的理解，这个机制能够解决同一时间内有多个领导者的情况(解决了**集群脑裂现象**)，比如领导者 A 挂了之后，集群其他节点会选举出一个新的领导者 B，在节点 A 恢复之后，会接收来自新领导者的心跳消息**(此时新领导发来的消息中任期编号要大于自身的任期编号)，此时节点 A 会立即恢复成跟随者`Follower`状态)；**
> 4. **如果某个节点接收到比自己任期号小的请求，则会**拒绝这个请求。

Raft 定义了 **任期（Term）** 这一概念，**所有节点都会有 `currentTerm` 这个属性，就是该节点当前所处的任期**。

任期在 Raft 算法里起一个**逻辑时钟**的作用，第几个任期，即第几个 `term` 就类似于我国的第几个朝代这种概念，而领导人，就仿佛是朝代的君王。







### 日志同步

在 Raft 算法中，需要实现分布式一致性的数据被称作日志，我们 Java 后端绝大部分人谈到日志，一般会联想到项目通过 log4j 等日志框架输出的信息，而 Raft 算法中的数据提交记录，他们会按照时间顺序进行追加，Raft 也是严格按照时间顺序并已一定的格式写入日志文件中



领导者接收到客户端发来的请求(**只有Leader能够接收客户端的写请求**)，创建一个新的日志项，并将其追加到本地日志中，接着领导者通过追加条目 RPC 请求，将新的日志项复制到跟随者的本地日志中(**并行传输**)，当领导者收到大多数跟随者的成功响应之后，则将这条日志项应用到状态机中，可以理解成该条日志写成功了，最后领导者返回日志写成功的消息响应客户端，流程如下图所示：

![img](https://ask.qcloudimg.com/http-save/yehe-1065851/d73l7x0rtn.png)

可以看出，Raft 的复制过程中，领导者接收到大多数跟随者成功响应(返回ACK)，并且将日志项应用到状态机之后，**不需要将结果响应给跟随者，而是直接将成功消息响应给客户端**，这是一种优化方式，同时 Raft 会在下一次 RPC 追加日志请求中附加上本次的日志项信息。

以上仅仅只是一种没有发生任何问题的复制过程，在这过程中难免会发生节点宕机等问题，在这种情况下，Raft 是如何处理的呢？











## Distro协议



① 服务实例注册到 Nacos 节点后，通过 UDP 方式推送到所有服务实例。让其他服务实例感知到服务列表的变化。

② 如何复制数据到其他节点：当前 Nacos 节点开启 1s 的延迟任务，将数据同步给其他 Nacos 节点。（分区一致性）

第 ② 个知识点就是 Nacos 自研的 Distro 一致性协议的核心功能。

首先这个 Distro 协议是针对集群环境的，比如下面这三个集群节点组成了一个集群。服务 A 和服务 B 会往这个集群进行注册。

<img src="https://dl-harmonyos.51cto.com/images/202205/d5cf64594d3e79b939886544d4fb7f41b3113c.png" alt="5000 字 | 揭秘 Nacos 的 AP 架构 「Distro 一致性协议」（一）-开源基础软件社区" style="zoom: 50%;" />

我们知道 Nacos 它是支持两种分布式定理的：CP（分区一致性）和 AP（分区可用性） ，而 AP 是通过 Nacos 自研的 Distro 协议来保证的，CP 是通过 Nacos 的 JRaft 协议来保证的。

**因为注册中心作为系统中很重要的的一个服务，需要尽最大可能对外提供可用的服务**，所以选择 AP 来保证服务的高可用，另外 Nacos 还采取了心跳机制来自动完成服务数据补偿的机制，所以说 Distro 协议是弱一致性的。

如果采用 CP 协议，则需要当前集群可用的节点数过半才能工作。

Distro 协议是 Nacos 对于临时实例数据开发的一致性协议。

Distro 协议是集 Gossip + Eureka 协议的优点并加以优化后出现的。

**Gossip 协议有什么坑？**由于随机选取发送的节点，不可避免地存在消息重复发送给同一节点的情况，增加了网络的传输的压力，给消息节点带来额外的处理负载。

**Distro 协议的优化**：每个节点负责一部分数据，然后将数据同步给其他节点，有效地降低了消息冗余的问题。

关于临时实例数据：临时数据其实是存储在内存缓存中的，并且在其他节点在启动时会进行全量数据同步，然后节点也会定期进行数据校验。















## Sentinel



### Sentinel 入门

 这里先启动三个微服务:`orderservice`、`userservice`、`gateway`

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/nacos%20statrt.png)

在`order-service`中的`application.yaml`中配置`sentinel`相关规则：

```yaml
  cloud:
    nacos:
      server-addr: localhost:8848 # nacos服务地址
    sentinel:
      transport:
        dashboard: localhost:8899 # sentinel控制台地址
      web-context-unify: false # 关闭context整合
      datasource:
        flow:
          nacos:
            server-addr: localhost:8848 # nacos地址
            dataId: orderservice-flow-rules
            groupId: SENTINEL_GROUP
            rule-type: flow # 还可以是：degrade、authority、param-flow
```



然后在`sentinel`的安装目录下运行以下命令：

```shell
java -Dserver.port=8899 -jar sentinel-dashboard-1.8.1.jar
```

最后在浏览器输入 `localhost:8899/#dashboard`就可以看到`sentinel`的控制台了：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/sentinel1.png)



然后我们启动`jmeter`来测试这个远程调用的吞吐量：

**配置线程数为100、每个线程循环次数为100，Ramp-Up为1秒，**即每秒1w个请求打到该接口上：

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/jmeter.png" style="zoom:67%;" />



查看`jmeter`中的汇总报告： 可以看到该接口的`QPS`为 **633/sec**:

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/sentinel-res.png)



同时观察`sentinel`网页的控制台：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/order-sentinel.png)





也会实时显示出该接口的`QPS`

> 1. **QPS（Queries Per Second）：** QPS是衡量数据库、缓存等数据存取频率的指标。它表示每秒内处理的查询请求数量。对于数据库来说，QPS表示每秒内执行的查询语句数量；对于缓存来说，QPS表示每秒内处理的缓存请求数量。
> 2. **TPS（Transactions Per Second）：** TPS是衡量系统处理能力的指标，它表示每秒内完成的事务数量。事务可以是更广泛的操作，例如用户请求、HTTP请求、支付交易等，不仅仅局限于数据库查询。TPS可以包括多个不同类型的操作，反映了整个系统的综合性能。





### 簇点链路

簇点链路：就是项目内的**调用链路**————请求从进入`SpringMvc`的那一刻，首先会进入Controller，Controller调用Service,Service调用Mapper,这样`Controller—>Service—>Mapper`就是一个调用链路

链路中被监控的每个接口就是一个资源。默认情况下 sentinel 会监控`SpringMVC`的每一个端点（Endpoint），因此`SpringMVC`的每一个端点（Endpoint）就是调用链路中的一个资源。

**流控、熔断等都是针对簇点链路中的资源来设置的**，因此我们可以点击对应资源(`Controller`中的 **/order/orderId** )后面的按钮来设置规则：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E9%93%BE%E8%B7%AF%E6%B5%81%E6%8E%A7.png)

其含义是限制 `/order/{orderId}`这个资源的单机QPS为600，即每秒只允许600次请求，超出的请求会被拦截并报错。 具体每个接口的`QPS`可以通过`Jmeter`来进行压力测试(**增加线程数和每秒循环次数——模拟高并发**)得到该接口的QPS上限，然后设置该值



然后我们来模拟一下限流： 限制该资源的QPS上限阈值为10

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E6%B5%81%E6%8E%A7%20qps10.png)

然后在`jmeter`中查看结果树，可以看到每秒最多只能接收其他请求，剩余请求直接`fail-fast`:

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/res10.png" style="zoom:67%;" />

可以看到每秒只能接收10个请求，其他请求直接失败:

在HTTP 协议中，响应状态码 **429** :Too Many Requests` 表示**在一定的时间内用户发送了太多的请求，即超出了“频次限制”**。

```http
Thread Name:线程组 1-99
Sample Start:2023-08-15 15:17:07 CST
Load time:0
Connect Time:0
Latency:0
Size in bytes:212
Sent bytes:128
Headers size in bytes:168
Body size in bytes:44
Sample Count:1
Error Count:1
Data type ("text"|"bin"|""):text
Response code:429   #Too Many Requests
Response message:
```

被拒绝后的请求`Response Body`的内容为：

```json
{"msg": 请求被限流了, "status": 429}
```

同时在`sentinel`的`DashBoard`中可以看到通过的QPS的确被限制为`10/sec`了：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/blocked1%200.png)





### 流控模式

上述例子我们简单入门了一下`Sentinel`实现接口限流的用法，然后我们再来看一下流控的高级用法：

在添加限流规则时，点击高级选项，可以选择三种流控模式：

•直接：统计当前资源的请求，触发阈值时对当前资源直接限流，也是默认的模式(上述示例中采用的模式)

•**关联：**统计与当前资源相关的另一个资源，触发阈值时，对当前资源限流

•链路：统计从指定链路访问到本资源的请求，触发阈值时，对指定链路限流





**1、关联模式**

假设选课场景有以下两个关键资源：

1. **修改用户课程信息接口**（Resource: `/update-course-info`）：学生选课后，可能需要修改用户课程信息。
2. **查询课程信息接口**（Resource: `/query-course-info`）：学生可以查询已选课程的信息。

以下是可能的思路：

1. **定义规则：** 针对 `/update-course-info` 和 `/query-course-info` 接口，分别定义流控规则。你可以为每个接口设置适当的阈值、QPS（每秒查询数）限制等。
2. **关联规则：** 在关联流控模式下，你可以将 `/update-course-info` 和 `/query-course-info` 接口进行关联，表示这两个接口之间存在关联关系。
3. **设置关联策略：** 定义关联策略，指定一个阈值，表示当 `/update-course-info` 接口的流量达到一定值时，会影响 `/query-course-info` 接口的流控。
4. **流控效果：** 当 `/update-course-info` 接口的流量达到设定的阈值时，系统将开始对 `/query-course-info` 接口应用流控，限制同时的查询请求，确保系统的稳定性。





再来看一个订单修改和订单查询的关联限流案例：

- 在OrderController新建两个端点：/order/query和/order/update，无需实现业务

- 配置流控规则，当`/order/update`资源被访问的`QPS`超过5时，对`/order/query`请求限流



`OrderController`中代码如下：

```java
@RestController
@RequestMapping("order")
public class OrderController {

    @GetMapping("/query")
    public String queryOrder() {
        // 查询商品
        orderService.queryGoods();
        // 查询订单
        System.err.println("查询订单");
        return "查询订单成功";
    }
    
    @GetMapping("/update")
    public String updateOrder() {
        return "更新订单成功";
    }
}
```

 	



同时配置流控规则，当 `/order/update` 的QPS达到阈值5时，对 `/order/query` 做限流

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/liukong.png)

即被关联的资源达到某个阈值后，对第一行中的资源名 `/order/query` 进行限流





我们在jmeter中模拟`update`请求：

```http
POST  localhost:8088/order/update
```

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/gets.png)



可以看到`update`请求是没有被限流的，可以正常执行：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/ggggggg.png)



然后同时观察同一`controller`中的  `GET  localhost:8088/order/query`接口是否被限流：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E8%A2%AB%E9%99%90%E6%B5%81%E7%9A%84query.png)

可以发现在配置了流控规则(关联模式)后，当优先级高的资源 `/order/update` 触发阈值时，会对优先级较低的资源 `/order/query` 进行限流







**2、链路模式**



待补充 





### 流控效果



**流控效果是指请求达到流控阈值时应该采取的措施，包括三种**：

- 快速失败：达到阈值后，新的请求会被立即拒绝并抛出`FlowException`异常。是默认的处理方式

- **warm up：预热模式**，对超出阈值的请求同样是拒绝并抛出异常。但这种模式QPS的阈值会动态变化，从一个较小值逐渐增加到最大阈值

- 排队等待：让所有的请求按照先后次序排队执行，两个请求的间隔不能小于指定时长



**warm up**：

也叫预热模式，是应对服务冷启动的一种方案。请求阈值初始值是 `threshold / coldFactor`，持续指定时长后，逐渐提高到threshold值。而coldFactor的默认值是3

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E9%A2%84%E7%83%AD.png)



例如，我设置某个接口的 `QPS` 的`threshold`为10，预热时间为10秒，那么服务器启动时的初始QPS阈值就是 10 / 3 ，也就是3，然后在10秒后逐渐增长到10`QPS`







**排队等待**：

当请求超过QPS阈值时，快速失败和warm up 会拒绝新的请求并抛出异常。而排队等待则是让所有请求进入一个队列中，然后按照阈值允许的时间间隔依次执行。后来的请求必须等待前面执行完成，如果请求预期的等待时间超出最大时长，则会被拒绝。

例如：QPS = 5，意味着每200ms能处理一个队列中的请求；`timeout = 2000`，意味着预期等待超过2000ms的请求会被拒绝并抛出异常

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E6%8E%92%E9%98%9F.png)





总结一下，流控效果有哪些？

•快速失败：QPS超过阈值时，拒绝新的请求

•warm up： QPS超过阈值时，拒绝新的请求；QPS阈值是逐渐提升的，可以避免冷启动时高并发导致服务宕机

•排队等待：请求会进入队列，按照阈值允许的时间间隔依次执行请求；如果请求预期等待时长大于超时时间，直接拒绝







## 限流算法



### 计数器算法



**固定窗口计数器算法：**

固定窗口其实就是时间窗口。**固定窗口计数器算法** 规定了我们单位时间处理的请求数量。

假如我们规定系统中某个接口 1 分钟只能访问 33 次的话，使用固定窗口计数器算法的实现思路如下：

- 给定一个`Atomic`类型变量 `counter` 来记录当前接口处理的请求数量，初始值为 0（代表接口当前 1 分钟内还未处理请求）。
- 1 分钟之内每处理一个请求之后就将 `counter+1` ，当 `counter=33` 之后（也就是说在这 1 分钟内接口已经被访问 33 次的话），后续的请求就会被全部拒绝。
- 等到 1 分钟结束后，将 `counter` 重置 0，重新开始计数。

**这种限流算法无法保证限流速率，因而无法保证突然激增的流量，观察下图中的蓝色区域：**

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E5%9B%BA%E5%AE%9A%E7%AA%97%E5%8F%A3%E8%AE%A1%E6%95%B0%E5%99%A8.png)

4500-5500ms之间，到来请求实际上有6个了，而我们的系统1s内只能处理3个请求，因此存在这样的弊端

> 针对当前并发执行的次数，可以有三种统计方式：
>
> 
>
> 1. 使用`AomicInteger`来进行统计当前正在并发执行的次数，如果超过域值就简单粗暴的直接响应给用户，说明系统繁忙，请稍后再试或其它跟业务相关的信息
>
>    
>
>    弊端：使用 `AomicInteger` 简单粗暴超过域值就拒绝请求，可能只是瞬时的请求量高，也会拒绝请求
>
> 2. 使用 `Semaphore` 信号量来控制并发执行的次数，如果超过域值信号量，则进入阻塞队列中排队等待获取信号量进行执行。如果阻塞队列中排队的请求过多超出系统处理能力，则可以在拒绝请求。
>
>    相对`Atomic`优点：如果是瞬时的高并发，可以使请求在阻塞队列中排队，而不是马上拒绝请求，从而达到一个流量削峰的目的
>
> 3. 采用 `ThreadPoolExecutor`自定义线程池： 固定线程池大小,超出固定线程池和最大的线程数,拒绝线程请求;
>
> 







**滑动窗口计数器算法：**

**滑动窗口计数器算法** 算的上是固定窗口计数器算法的升级版。

滑动窗口计数器算法相比于固定窗口计数器算法的优化在于：**它把时间以一定比例分片** 。

例如我们的接口限流每分钟处理 60 个请求，我们可以把 1 分钟分为 60 个窗口。每隔 1 秒移动一次，每个窗口一秒只能处理 不大于 `60(请求数)/60（窗口数）` 的请求， 如果当前窗口的请求计数总和超过了限制的数量的话就不再处理其他请求。

很显然， **当滑动窗口的格子划分的越多，滑动窗口的滚动就越平滑，限流的统计就会越精确。**

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E8%AE%A1%E6%95%B0%E5%99%A8.png)

由上图可以看出：

第1400ms到来的请求，如果使用固定窗口计数器算法，系统判断1000ms-1500ms之间到来3个请求，是合理的，故接收请求，但实际上从第900ms到1500ms之间已经来了四个请求，系统实际上无法在1秒内处理第4个请求的；

而如果使用滑动窗口计数器，当第1400ms请求到来时，根据计算系统会将区间划分至500ms-1500ms之间，此时是系统就会判定该请求到来后，已经超出1s内所能处理的最大值，故丢弃







### 令牌桶算法



![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E4%BB%A4%E7%89%8C%E6%A1%B6%E7%AE%97%E6%B3%95.png)



设置令牌桶中的令牌数量时，一般要考虑服务器的并发数，以及缓冲能力

假如服务器的最大并发数为`1000QPS`，令牌桶中最大容纳令牌数量为1500，那我们就可以考虑将每秒生成的令牌数量设置为500/600，这样低峰期的话是没有问题的，而到达高峰期前，令牌桶中令牌数量也不会超出服务器所能承载的并发数太多，不会给服务器造成太大压力，







### 漏桶算法



漏桶算法的原理和**消息队列削峰**的思想非常类似

和消息队列对高并发请求的处理类似，将大量请求直接压入MQ，数据库作为MQ的消费者按照其固定的消费速率来从MQ中取消息，这样保证了数据库不会被突然到来的大量请求所击垮

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E6%BC%8F%E6%A1%B6.png)









## 降级与熔断



> 什么是微服务雪崩？

微服务调用链路中的某个服务故障，引起整个链路中的所有微服务都不可用，这就是雪崩

假设**发生了课程管理服务故障：** 假设课程管理服务负责存储和提供课程信息。如果这个服务发生故障，其他服务无法获取课程信息，这会导致用户无法查看、注册或管理课程，同时用户支付服务下单课程后无法查看下单成功的课程，导致支付服务也发生故障，教师管理微服务想要上新一门课程，但是由于课程管理服务故障，最终导致教师管理微服务也级联故障，最终导致微服务雪崩



解决雪崩问题的常见方式有四种：

- 超时处理：设定超时时间，请求超过一定时间没有响应就返回错误信息，不会无休止等待

  但是超时处理不能从根本上解决雪崩，假设设置超时响应时间为1s，但是客户端发来的请求速度远远大于1/s，这样时间一长依旧会导致雪崩

- 舱壁模式：限定每个业务能使用的线程数，避免耗尽整个tomcat的资源，因此也叫线程隔离(**`Hystrix`中的线程池隔离技术**)
- 熔断降级：由**断路器**统计业务执行的异常比例，如果超出阈值则会**熔断**该业务，拦截访问该业务的一切请求
- 流量控制：限制业务访问的QPS，避免服务因流量的突增而故障。

前三种方式是在已经发生故障的前提下避免微服务传播导致级联雪崩，而流量控制采取的是预防策略



前面接触到的`Sentinel`实现对资源的限流，只是预防策略，但是倘若某个被调用的微服务内部已经出现了故障，这时候即使采取限流策略依然会导致微服务级联雪崩，此时就应该采取熔断+降级策略来阻止微服务雪崩：





线程池隔离：

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E9%9A%94%E7%A6%BB.png" style="zoom:67%;" />



熔断器判定：

<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E7%86%94%E6%96%AD%E5%99%A8.png" style="zoom:67%;" />

不管是线程隔离还是熔断降级，都是对**服务调用方**的保护



在`SpringCloud`中，微服务调用都是通过`Feign`来实现的，因此实现客户端保护必须整合`Feign`和`Sentinel`

1.修改`OrderService`的`application.yml`文件，开启`Feign`的`Sentinel`功能

```yaml
feign:
  sentinel:
    enabled: true # 开启feign对sentinel的支持
```

开启这一选项后，该微服务下的所有`feign`远程调用都会被`sentinel dashboard`所监测到



2.给`FeignClient`编写失败后的降级逻辑

①方式一：`FallbackClass`，无法对远程调用的异常做处理

②方式二：`FallbackFactory`，**可以对远程调用的异常做处理**，我们选择这种



然后我们来看一个具体的例子：

```java
//OrderController中的通过用户ID来查询订单号的方法
public Order queryOrderByUserId(@PathVariable("orderId") Long orderId) {
        // 根据id查询订单并返回
        return orderService.queryOrderById(orderId);
    }
```

该方法实际上是通过`Feign`来远程调用`UserService`中的`findById`方法：

```java
public class OrderService {
  private UserClient userClient;
  public Order queryOrderById(Long orderId) {
        // 1.查询订单
        Order order = orderMapper.findById(orderId);
        // 2.用Feign远程调用
        User user = userClient.findById(order.getUserId());
        // 3.封装user到Order
        order.setUser(user);
        // 4.返回
        return order;
    }
}



@FeignClient(value = "userservice", fallbackFactory = UserClientFallbackFactory.class)
public interface UserClient {

    @GetMapping("/user/{id}")
    User findById(@PathVariable("id") Long id);
}
```

注意上述`@FeignClient`注解中的value属性表示被调用的目标微服务名称，这里为"`userservice`",

`userservice`的`application.yaml`中配置的服务名称(对应`nacos`中服务列表显示的名称)：

```yaml
spring:
  application:
    name: orderservice
```





编写失败降级的逻辑：

```java
public class UserClientFallbackFactory implements FallbackFactory<UserClient> {
    @Override
    public UserClient create(Throwable throwable) {
        return new UserClient() {
            @Override
            public User findById(Long id) {
                log.error("查询用户异常", throwable);
                return new User();
            }
        };
    }
}
```



**这样编写了降级逻辑后，当被调用的微服务 `userservice` 发生故障或异常时，降级逻辑会触发。当用户服务发生故障时，查询用户信息的降级逻辑会返回一个空的 `User` 对象。这是因为在 `UserClientFallbackFactory` 的 `create` 方法中，降级逻辑会创建一个新的 `UserClient` 实例，重写了 `findById` 方法，它会返回一个空的 `User` 对象**

**由于会返回一个空用户，故客户端暂时查询不到自己拥有的订单号，这也是可以接受的**



我们在`sentinel`的`dashboard`可以看到被监控的`feign`远程调用：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/feign-sentinel.png)



这样我们也可以通过`sentinel`的流控功能来设置一个适当的阈值，确保每秒只有一定数量的请求访问 `findById` 方法(被远程调用的方法)。这可以避免在用户服务出现问题时，过多的请求导致更严重的故障







### 信号量隔离

线程隔离有两种手段

- 信号量隔离：基于计数器模式，简单，开销小———`Sentinel`默认

- 线程池隔离: Hystrix默认策略



<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E7%BA%BF%E7%A8%8B%E9%9A%94%E7%A6%BB%E5%8C%BA%E5%88%AB.png" style="zoom: 67%;" />









这里我们先来看一下信号量隔离，通过配置`sentinel`流控规则中的线程数来实现



1.在添加限流规则时，可以选择两种阈值类型：



<img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E7%BA%BF%E7%A8%8B%E9%9A%94%E7%A6%BB.png" style="zoom:67%;" />

- QPS：就是每秒的请求数，在快速入门中已经演示过

- 线程数：是该资源能使用的tomcat线程数的最大值。也就是通过限制线程数量，实现舱壁模式。

设置好控制台显示如下：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/1111111111111.png)



2.然后在`jmeter`中设置一瞬间发起请求的线程数量为10：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E7%BA%BF%E7%A8%8B%E9%9A%94%E7%A6%BBjmeter.png)



3.发起测试请求：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/22222222222.png)

可以看到在这一瞬间(设置了`Ramp-Up`秒为0)**只有前5个线程的请求**得到了响应，后5个线程都走了降级逻辑，远程调用返回的都是空用户

我们最后再来理一下前后逻辑：

- 在`OrderController`中有一个`queryOrderByUserId`(通过用户id查询其所拥有的订单号)方法，在某个实际场景中可能有一瞬间有大量用户要查询自己所拥有的课程(**比如选课高峰期**)

- 该`queryOrderByUserId`方法中需要通过`Feign`来远程调用`userservice`中的某个查询方法`( findById`)，但是在高峰期QPS太高可能会导致服务器承受不住，继而导致微服务级联雪崩

- 考虑到第2点中的问题，我们在名为`orderservice`的微服务中通过配置以下选项，通过`sentinel`监测该微服务下的远程调用：

  ```yamL
  spring:
    application:
      name: orderservice
    cloud:
      sentinel:
        feign:
          enabled: true # 开启对Feign的监测
  ```

- 然后在`sentinel`的`dashboard`控制台来配置信号量，控制同一瞬间进行`feign`远程调用的线程数量(这里为了方便测试设置单机阈值为5)：

​    <img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E7%BA%BF%E7%A8%8B%E9%9A%94%E7%A6%BB.png" style="zoom:67%;" />

   

- 然后我们在jmeter中模拟一瞬间多线程请求，设置瞬间请求的线程数量为10，这样按理来说，前5个线程会正常响应，后5个线程会由于已经达到了设置的线程阈值，故远程调用异常，继而走降级逻辑：

  <img src="https://cdn.jsdelivr.net/gh/amonstercat/blog-images/22222222222.png" style="zoom:67%;" />

- 我们通过查看该http请求的`responsebody`也可以看到,返回的User对象为空

  ```http
  {"id":101,"price":699900,"name":"Apple 苹果 iPhone 12 ","num":1,"userId":1,"user":{"id":null,"username":null,"address":null}}
  ```

但是需要注意的是，我们上述所做的工作依旧是通过`sentinel`的流量控制对某一接口进行限流，当触发限流阈值(上述例子是触发线程数阈值)时，自动走我们所配置好的降级策略，但是这并没有涉及到熔断机制呀，所以我们接下来要通过断路器来实现服务熔断







### 服务熔断

熔断的思路是由**断路器**统计服务调用的异常比例、慢请求比例，如果超出阈值则会**熔断**该服务。即拦截访问该服务的一切请求；而当服务恢复时，断路器会放行访问该服务的请求

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E7%86%94%E6%96%AD11.png)

断路器熔断策略有三种：慢调用、异常比例、异常数

- 慢调用：业务的响应时长（RT）大于指定时长的请求认定为慢调用请求。在指定时间内，如果请求数量超过设定的最小数量，慢调用比例大于设定的阈值，则触发熔断。

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/%E7%86%94%E6%96%AD1111.png)

解读：RT超过500ms的调用是慢调用，统计最近10000ms内的请求，如果请求量超过10次，并且慢调用比例不低于0.5，则触发熔断，熔断时长为5秒。然后进入half-open状态，放行一次请求做测试。



- 异常比例或异常数：统计指定时间内的调用，如果调用次数超过指定的最小请求数，并且出现异常的比例达到设定的比例阈值（或超过指定异常数），则触发熔断









## 分布式事务



分布式事务是**指会涉及到操作多个数据库的事务。其实就是将对同一库事务的概念扩大到了对多个库的事务**。

目的是为了保证分布式系统中的数据一致性。

分布式事务处理的关键是必须有一种方法可以知道事务在任何地方所做的所有动作，提交或回滚事务的决定必须产生统一的结果（全部提交或全部回滚）

在分布式系统中，各个节点之间在物理上相互独立，通过网络进行沟通和协调。由于存在事务机制，可以保证每个独立节点上的数据操作可以满足 ACID。但是，相互独立的节点之间无法准确的知道其他节点中的事务执行情况。所以从理论上讲，两台机器理论上无法达到一致的状态。如果想让分布式部署的多台机器中的数据保持一致性，那么就要保证在所有节点的数据写操作，要不全部都执行，要么全部的都不执行。但是，一台机器在执行本地事务的时候无法知道其他机器中的本地事务的执行结果。所以他也就不知道本次事务到底应该 commit 还是 roolback。所以，常规的解决办法就是引入一个“协调者”的组件来统一调度所有分布式节点的执行。



### Two-P-C (XA模式)

2PC，是 Two-Phase-Comimit 的缩写，即「**二阶段提交**」，是计算机网络尤其是数据库领域内，为了使基于分布式系统架构的所有节点在进行**事务处理**过程中能够保持原子性和一致性而设计的一种协议。现在很多数据库都是采用的二阶段提交协议来完成**分布式事务**的处理。二阶段，顾名思义就是分两个阶段处理事务，流程如下：

阶段一：提交事务请求（”投票阶段“）

当要执行一个分布式事务的时候，事务发起者首先向协调者 `Coordinator` 发起事务请求，然后协调者会给所有参与者   `Participant` 发送 `prepare` 请求（其中包括事务内容）告诉参与者你们需要执行事务了，**如果能执行我发的事务内容那么就先执行但不提交，执行后请给我回复**。然后参与者收到 `prepare` 消息后，他们会开始执行事务（但不提交），并将 `Undo` 和 `Redo` 信息记入事务日志中，之后参与者就向协调者反馈是否准备好了



阶段二：执行事务提交

协调者根据各参与者的反馈情况决定最终是否可以提交事务，**如果反馈都是Yes，发送提交 `commit` 请求**，参与者提交成功后返回 `Ack` 消息，协调者接收后就完成了。**如果反馈是 No 或者超时未反馈，发送 `Rollback` 请求**，利用阶段一记录表的 `Undo` 信息执行回滚，并反馈给协调者 `Ack` ，中断消息



缺点：

- **单点故障问题**，如果协调者挂了那么整个系统都处于不可用的状态了
- **阻塞问题**，即当协调者发送 `prepare` 请求，参与者收到之后如果能处理那么它将会进行事务的处理但并不提交，这个时候会一直占用着资源不释放，如果此时协调者挂了，那么这些资源都不会再释放了，这会极大影响性能
- **数据不一致问题**，比如当第二阶段，协调者只发送了一部分的 `commit` 请求就挂了，那么也就意味着，收到消息的参与者会进行事务的提交，而后面没收到的则不会进行事务提交，那么这时候就会产生数据不一致性问题



最大的缺点在于：**2PC是CP设计，这是强一致性的，所以势必会损失可用性**，它的问题在于：

- 同步阻塞执行中所有参与者的事务都会阻塞，所占的锁及资源不会释放
- 数据不一致，在提交阶段如果出现网络故障部分参与者可能会收不到提交命令从而导致数据不一致
- 单点故障，作为事务处理重要组成的协调器存在单点问题





### Three-Phase-Comimit



阶段一：CanCommit

协调者向所有参与者发送 `CanCommit` 请求，参与者收到请求后会根据自身情况查看是否能执行事务，如果可以则返回 YES 响应并进入预备状态，否则返回 NO



阶段二：PreCommit

协调者根据参与者返回的响应来决定是否可以进行下面的 `PreCommit` 操作。如果上面参与者返回的都是 YES，那么协调者将向所有参与者发送 `PreCommit` 预提交请求，**参与者收到预提交请求后，会进行事务的执行操作，并将 Undo 和 Redo 信息写入事务日志中** ，最后如果参与者顺利执行了事务则给协调者返回成功的 `Ack` 响应。如果在第一阶段协调者收到了 **任何一个 NO** 的信息，或者 **在一定时间内** 并没有收到全部的参与者的响应，那么就会中断事务，它会向所有参与者发送中断请求 `abort`，参与者收到中断请求之后会立即中断事务，或者在一定时间内没有收到协调者的请求，它也会中断事务



阶段三：DoCommit

这个阶段其实和 `2PC` 的第二阶段差不多，如果协调者收到了所有参与者在 `PreCommit` 阶段的 YES 响应，那么协调者将会给所有参与者发送 `DoCommit` 请求，**参与者收到 DoCommit 请求后则会进行事务的提交工作**，完成后则会给协调者返回响应，协调者收到所有参与者返回的事务提交成功的响应之后则完成事务。若协调者在 `PreCommit` 阶段 **收到了任何一个 NO 或者在一定时间内没有收到所有参与者的响应** ，那么就会进行中断请求的发送，参与者收到中断请求后则会 **通过上面记录的回滚日志** 来进行事务的回滚操作，并向协调者反馈回滚状况，协调者收到参与者返回的消息后，中断事务。

![3PC](https://img.starfish.ink/zookeeper/3pc.png)

优缺点：

降低了参与者的阻塞范围，且能在单点故障后继续达成一致。

但是最重要的一致性并没有得到根本的解决，比如在 `PreCommit` 阶段，当一个参与者收到了请求之后其他参与者和协调者挂了或者出现了网络分区，这个时候收到消息的参与者都会进行事务提交，这就会出现数据不一致性问题。











### TCC





### SAGA

saga的定义是“长时间活动的事务”，即针对长事务提出的一种解决方案

所谓长事务，就是需要长时间执行的事务，这类事务往往需要访问大量的数据对象，其执行周期甚至能达到几周或几月。但传统的事务执行时需要锁定占用资源，如果在这样的一个场景下，资源被长期锁定，带来的性能消耗可想而知。因此我们引入了SAGA模式来解决长事务。

SAGA的工作原理呢，就比较好理解了：

SAGA模式由一串本地事务组成，每个本地事务都有自己回滚数据的补偿事务。事务之间串型执行，当正向执行的某一个事务出现报错，那么将执行这个事务的补偿事务，并且逆行执行之前事务的补偿事务

SAGA也是有两阶段的，一阶段是正向事务，二阶段是补偿事务

<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/72f6680dd75b4ecba79cb2d0ce402fa4~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="在这里插入图片描述" style="zoom:67%;" />

saga模式依然要求我们自己实现正向服务和补偿服务。但是它于TCC模式的区别之处在于：

- saga的模式设计使得它天然适合于长流程的业务。TCC要实现同样的长流程的话，需要多写一个confirm操作，并且要考虑如何将业务拆分为两部分
- saga模式在正向服务中时就已经提交了本地事务了，而补偿事务也比较好实现，将正向服务的结合逆向补偿即可。 比如正常服务是`update product set price=20 where price=30 and id=1;` 那么补偿服务就是`update product set price=30 where price=20 and id=1;`
- 比起TCC模式，saga模式更适用于一些老服务、第三方服务或者其他无法改造的服务，要接入到我们的分布式事务中时，就可以将其作为一个正向服务存在，而直接实现他的补偿服务即可。而TCC因为要对业务进行拆分为try-confirm-cancel，所以它不适用于不可改造的服务

同时，saga模式同样不需要全局锁，只需要结合本地事务加本地锁即可，所以性能依旧有保证。



> `saga`为什么适合长事务场景呢？

SAGA模式适合长事务的原因有以下几点：

1. **分步执行：** SAGA将长事务拆分为多个步骤，每个步骤都是一个局部事务。这样可以将长事务分解为多个短事务，减少每个事务的执行时间，降低锁竞争和数据库资源占用，从而提高系统的并发性能。
2. **局部回滚：** 在传统的两阶段提交中，如果在准备阶段某个参与者出现问题，整个全局事务可能会被回滚，导致长事务持续的阻塞。而在SAGA模式中，每个局部事务都有对应的补偿操作，**如果某个步骤失败，只需要回滚该步骤和之前的步骤，不会影响到后续步骤的执行，从而减少了长事务的阻塞时间**。
3. **容错性：** SAGA模式通过局部事务的补偿操作来处理部分失败的情况，从而提高了系统的容错性。即使某个步骤失败，系统仍然可以尝试通过执行补偿操作来将系统状态恢复到正确的状态。
4. **可伸缩性：** 由于SAGA模式将长事务拆分为多个步骤，不同步骤的局部事务可以并行执行，从而提高了系统的可伸缩性。这对于处理大量并发请求以及分布式系统的扩展性非常有益。

总之，SAGA模式通过将长事务分解为多个步骤，并引入局部事务和补偿操作的概念，有效地解决了长事务在分布式环境下可能出现的性能、可用性和可伸缩性问题，使系统更加健壮和可靠。



### AT  :disappointed:



AT模式是Seata独有的，先来看看Seata的架构图：

![img](https:////upload-images.jianshu.io/upload_images/4420767-e84da60c060f3631.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

`Seata Architecture` 有 3 个组件：TM（Transaction Manager）、RM（Resource Manager） 和 TC（Transaction Coordinator）。一个典型的事务过程：

1. **TM 向 TC 申请开启一个全局事务**，全局事务创建成功并生成一个全局唯一的 XID。
2. XID 在微服务调用链路的上下文中传播。
3. RM 向 TC 注册分支事务，将其纳入 XID 对应全局事务的管辖。
4. **TM 向 TC 发起针对 XID 的全局提交或回滚决议**。
5. TC 调度 **XID 下管辖的全部分支事务完成提交或回滚请求**。





分布式事务的解决方案有很多选择，但基于编程模型不变的需求，我们实际面临的选择就不多了。

最直接的选择就是 XA，Seata AT 模式的核心思路也是从审视 XA 的问题开始的。

<img src="https://upload-images.jianshu.io/upload_images/4420767-df427e999cc56037.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img" style="zoom: 50%;" />



如果用 XA 协议来支持分布式事务，会什么样？我们看一下：

![img](https:////upload-images.jianshu.io/upload_images/4420767-e95f7ada0e9c77c7.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

How Does XA Do ?

- 数据源（图中绿色的圈），要求用 XA 数据源。
- SQL 执行的前后，需要做 xa start 和 xa end 。
- 提交阶段，XA 的两阶段提交，先调用各个参与方的 prepare，再根据结果，调用参与方的 commit 或 rollback。

首先，上述这些工作，对于业务来说，都是额外的开销。多轮的交互，这个开销是不小的。

其次，我们注意到，我这里画了一些锁。分别在两个地方涉及到锁：

- 一个是数据，这好理解，XA 事务过程中，数据是被锁定的。
- 另一方面是连接，XA 事务过程中，连接也是被锁定的。至少在两阶段提交的 prepare 之前，连接是不能释放的（因为连接断开，这个连接上的 XA 分支就会回滚，整个事务也会被迫回滚）。

较之于数据的锁定（数据的锁定对于事务的隔离性是必要的机制），**连接的锁定带给整个业务系统的直接影响就是，限制了并发度。**



对比之前对 XA 分析，AT 的核心出发点，就是 **斩断** XA 可能带来的制约



**AT的实现核心就是在全局事务操作时生成反向Sql来实现数据回滚，需要在数据库额外附加UNDO_LOG表**

<img src="https://upload-images.jianshu.io/upload_images/4420767-2a68f3760a0825d5.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp" alt="img" style="zoom:50%;" />

还是看这个微服务场景下的分布式事务模型：

- **调用链路**上的 SQL 操作，当前服务调用完成后，直接**提交**，释放资源（解除了连接和本地事务的数据锁定）
- 业务数据提交的同时，把数据的 **回滚日志** 一并存放到回滚日志表里，以备全局回滚时使用(基于UndoLog)

这里面有两个关键：

第一，利用了 **数据库本地事务** 的特性，让回滚日志和业务数据的写入保证原子性：只要有业务数据提交成功，就一定有相应的回滚日志数据。

第二，考虑到实际业务的运行过程，绝大部分情况下最终是成功全局提交的。直接本地提交的机制，省去了绝大部分情况下，**两阶段提交的开销**

但是AT模式存在中间态：即多个微服务之间数据不一致性状态，但是这种不一致性是弱一致性(代表AP)，AT模式下依然会实现最终一致性







**AT模式主要特点**:

1. 最终一致性
2. 性能较XA高
3. 只在第一阶段获取锁，在第一阶段进行提交后释放锁。

在一阶段中，Seata会拦截 业务SQL ，首先解析SQL语义，找到要操作的业务数据，在数据被操作前，保存下来记录 undo log，然后执行 业务SQL 更新数据，更新之后再次保存数据 redo log，最后生成行锁，这些操作都在本地数据库事务内完成，这样保证了一阶段的原子性。

相对一阶段，二阶段比较简单，负责整体的回滚和提交，如果之前的一阶段中有本地事务没有通过，那么就执行全局回滚，否在执行全局提交，回滚用到的就是一阶段记录的 undo Log ，通过回滚记录生成反向更新SQL并执行，以完成分支的回滚。当然事务完成后会释放所有资源和删除所有日志。

AT流程分为两阶段，主要逻辑全部在第一阶段，第二阶段主要做回滚或日志清理的工作。流程如下：

![](https://cdn.jsdelivr.net/gh/amonstercat/blog-images/SEATA.png)

从上图中我们可以看到，订单服务中TM向TC申请开启一个全局事务，一般通过`@GlobalTransactional`标注开启，TC会返回一个全局事务ID(XID)，订单服务在执行本地事务之前，RM会先向TC注册一个分支事务， 订单服务依次生成undo log 执行本地事务，生成redo log 提交本地事务，向TC汇报，事务执行OK。

订单服务发起远程调用，将事务ID传递给库存服务，库存服务在执行本地事务之前，先向TC注册分支事务，库存服务同样生成undo Log和redo Log，向TC汇报，事务状态成功。

如果正常全局提交，TC通知每个RM一步清理掉本地undo和redo日志，如果存在一个服务执行失败，那么发起回滚请求。通过undo log进行回滚。









### 可靠消息最终一致性



可靠消息最终一致性方案是指当事务发起方执行完成本地事务后并发出一条消息，事务参与方(消息消费者)一定能够接收消息并处理事务成功，此方案强调的是只要消息发给事务参与方最终事务要达到一致。 此方案是利用消息中间件完成，如下图：   

<img src="https://it-blog-cn.com/assets/img/consis.53975859.png" alt="最终一致性" style="zoom:67%;" />

事务发起方（消息生产方）将消息发给消息中间件，事务参与方从消息中间件接收消息，事务参与方（消息消费方）和消息中间件之间都是通过网络通信，由于网络通信的不确定性会导致分布式事务问题。因此可靠消息最终一致性方案要解决以下几个问题：  

【1】本地事务与消息发送的原子性问题： 事务发起方在本地事务执行成功后消息必须发出去，否则就丢弃消息。即实现本地事务和消息发送的原子性，要么都成功，要么都失败。本地事务与消息发送的原子性问题是实现可靠消息最终一致性方案的关键问题。先来尝试下这种操作，先发送消息，再操作数据库：这种情况下无法保证数据库操作与发送消息的一致性，因为可能发送消息成功，据库操作失败。

```sql
begin transaction； 
    //1.发送MQ 
    //2.数据库操作 
commit transation;
```

【2】事务参与方接收消息的可靠性：事务参与方必须能够从消息队列接收到消息，如果接收消息失败可以重复接收消息。
【3】消息重复消费的问题：由于步骤2的存在，若某一个消费节点超时但是消费成功，此时消息中间件会重复投递此消息，就导致了消息的重复消费。要解决消息重复消费的问题就要实现事务参与方的方法幂等性。







RocketMQ 的设计中 broker 与 producer 端的双向通信能力，使得 broker 天生可以作为一个事务协调者存在；而 RocketMQ本身提供的存储机制为事务消息提供了持久化能力；RocketMQ 的高可用机制以及可靠消息设计则为事务消息在系统发生异常时依然能够保证达成事务的最终一致性。在 RocketMQ 4.3后实现了完整的事务消息，实际上是对本地消息表的一个封装，将本地消息表移动到了 MQ内部，解决Producer 端的消息发送与本地事务执行的原子性问题。

【执行流程如下】： 为方便理解我们还以注册送积分的例子来描述整个流程。Producer 即MQ发送方，本例中是用户服务，负责新增用户。MQ订阅方即消息消费方，本例中是积分服务，负责新增积分。 

【1】Producer 发送事务消息： Producer （MQ发送方）发送事务消息至MQ Server，MQ Server将消息状态标记为Prepared（预备状态），注意此时这条消息消费者（MQ订阅方）是无法消费到的。本例中，Producer 发送 ”增加积分消息“ 到MQ Server。 

【2】MQ Server回应消息发送成功： MQ Server接收到 Producer 发送给的消息则回应发送成功。表示 MQ已接收到消息。 

【3】Producer 执行本地事务： Producer 端执行业务代码逻辑，通过本地数据库事务控制。本例中，Producer 执行添加用户操作。 

【4】消息投递： 若 Producer 本地事务执行成功则自动向 MQServer发送 commit消息，MQ Server接收到 Commit消息后将“增加积分消息” 状态标记为可消费，此时MQ订阅方（积分服务）即正常消费消息。若Producer 本地事务执行失败则自动向 MQServer发送 Rollback消息，MQ Server接收到 Rollback消息后将删除“增加积分消息”。MQ订阅方（积分服务）消费消息，消费成功则向MQ回应ack，否则将重复接收消息。这里 ack默认自动回应，即程序执行正常则自动回应ack。 

【5】事务回查： 如果执行 Producer端本地事务过程中，执行端挂掉，或者超时，MQ Server将会不停的询问同组的其他 Producer来获取事务执行状态，这个过程叫事务回查。MQ Server会根据事务回查结果来决定是否投递消息。以上主干流程已由RocketMQ实现，对用户侧来说，用户需要分别实现本地事务执行以及本地事务回查方法，因此只需关注本地事务的执行状态（维护本地事务状态表）即可。

 RoacketMQ 提供了 RocketMQLocalTransactionListener接口：









## Nacos



### Nacos如何实现CP?



**1.RaftController**

raft集群内部节点间是通过暴露的 Restful接口，代码在 `RaftController`中。`RaftController`控制器是 Raft集群内部节点间通信使用的，具体的信息如下:

```
 1 POST HTTP://{ip:port}/v1/ns/raft/vote : 进行投票请求
 2 
 3 POST HTTP://{ip:port}/v1/ns/raft/beat : Leader向Follower发送心跳信息
 4 
 5 GET HTTP://{ip:port}/v1/ns/raft/peer : 获取该节点的RaftPeer信息
 6 
 7 PUT HTTP://{ip:port}/v1/ns/raft/datum/reload : 重新加载某日志信息
 8 
 9 POST HTTP://{ip:port}/v1/ns/raft/datum : Leader接收传来的数据并存入
10 
11 DELETE HTTP://{ip:port}/v1/ns/raft/datum : Leader接收传来的数据删除操作
12 
13 GET HTTP://{ip:port}/v1/ns/raft/datum : 获取该节点存储的数据信息
14 
15 GET HTTP://{ip:port}/v1/ns/raft/state : 获取该节点的状态信息{UP or DOWN}
16 
17 POST HTTP://{ip:port}/v1/ns/raft/datum/commit : Follower节点接收Leader传来得到数据存入操作
18 
19 DELETE HTTP://{ip:port}/v1/ns/raft/datum : Follower节点接收Leader传来的数据删除操作
20 
21 GET HTTP://{ip:port}/v1/ns/raft/leader : 获取当前集群的Leader节点信息
22 
23 GET HTTP://{ip:port}/v1/ns/raft/listeners : 获取当前Raft集群的所有事件监听者
```



**2.RaftPeerSet**

这个对象存储的是所有`raft`协议下的节点信息，存储的元素如下

```java
// 集群节点地址管理
private ServerListManager serverListManager;

// 周期数
private AtomicLong localTerm = new AtomicLong(0L);

// 当前周期内的Leader
private RaftPeer leader = null;

// 所有的节点信息
private Map<String, RaftPeer> peers = new HashMap<String, RaftPeer>();

// 暂时不清楚用途
private Set<String> sites = new HashSet<>();

// 本节点是否已准备完毕
private boolean ready = false;
```



**3.RaftCore**

该对象是`nacos`中`raft`协议的主要实现，在启动之初，会进行一系列初始化的操作，初始化的一系列操作完成后，此时集群还无法对外提供服务，因为此时`Leader`还未选举出来，需要在`MasterElection`选举`Leader`成功后才可以对外提供服务

每个节点启动时，都会认为自己可以作为`Leader`，因此都会以自己作为被选举人，向其他节点发起投票请求，而其他节点在接收到投票请求后的工作流程如下

```java
// 其他节点接收到投票请求后的反应
public RaftPeer receivedVote(RaftPeer remote) {
  // 被选举人是否在raft集群节点列表中
	if (!peers.contains(remote)) {
		throw new IllegalStateException("can not find peer: " + remote.ip);
	}

 	// 获取自身节点信息
	RaftPeer local = peers.get(NetUtils.localServer());
  // 如果被选举节点的周期数小于本节点的周期数，则将自己的投票投给自己并告诉被选举者
	if (remote.term.get() <= local.term.get()) {
		String msg = "received illegitimate vote" + ", voter-term:" + remote.term + ", votee-term:" + local.term;
		Loggers.RAFT.info(msg);
		if (StringUtils.isEmpty(local.voteFor)) {
			local.voteFor = local.ip;
		}
		return local;
	}
  // 满足投票条件后，本节点确认将自己的票投给被选举者
	local.resetLeaderDue();
	local.state = RaftPeer.State.FOLLOWER;
	local.voteFor = remote.ip;
	local.term.set(remote.term.get());
	Loggers.RAFT.info("vote {} as leader, term: {}", remote.ip, remote.term);
	return local;
```

通过以上步骤，最终选举出了`Leader`节点，接下来，就可以对外提供服务了

因为是`CP`模式，所以操作都是通过`Leader`节点进行传达的，`Follower`节点本身不与`Client`进行联系，`Follower`只能接受来自`Leader`的操作请求，因此就存在请求转发的问题。因此在`RaftCore`中的`singlePublish`以及`singleDelete`中，存在着对`Leader`节点的判断以及请求转发的逻辑



同时，还有一个重要的机制——心跳机制，`raft`通过心跳机制来维持`Leader`以及`Follower`的关系,核心代码如下：

```java
// 遍历所有的Follower节点进行发送心跳数据包
		for (final String server : peers.allServersWithoutMySelf()) {
			try {
				final String url = buildURL(server, API_BEAT);
				Loggers.RAFT.info("send beat to server " + server);
        // 采用异步HTTP请求进行心跳数据发送
				HttpClient.asyncHttpPostLarge(url, null, compressedBytes, new AsyncCompletionHandler<Integer>() {
					@Override
					public Integer onCompleted(Response response) throws Exception {
						if (response.getStatusCode() != HttpURLConnection.HTTP_OK) {
							Loggers.RAFT.error("NACOS-RAFT beat failed: {}, peer: {}", response.getResponseBody(), server);
            	MetricsMonitor.getLeaderSendBeatFailedException().increment();
						}
            // 成功后接收Follower节点的心跳回复(Follower节点的当前信息)进行节点更新操作
						peers.update(JSON.parseObject(response.getResponseBody(), RaftPeer.class));
						Loggers.RAFT.info("receive beat response from: {}", url);
						return 0;
```

心跳机制： Raft中使用心跳机制来触发Leader选举。心跳定时任务是在`GlobalExecutor`中，通过`GlobalExecutor.register(new HeartBeat())`注册心跳定时任务，具体操作包括： 

【1】重置Leader节点的heart timeout、election timeout

【2】sendBeat()发送心跳包





### Nacos如何实现AP？

Nacos在AP模式下的一致性策略就类似于Eureka，采用`Server`之间互相的数据同步来实现数据在集群中的同步、复制操作

**触发数据广播：**

```java
DistroConsistencyServiceImpl.java

@Override
public void put(String key, Record value) throws NacosException {
    onPut(key, value);
    taskDispatcher.addTask(key);
}
```

https://www.liaochuntao.cn/2019/05/09/java-web-32/



### 服务注册

1.在`Nacos Server`的`nacos-naming`工程下的`InstanceController`类中的`register`方法作为服务注册的入口：

```java
@RestController
@RequestMapping(UtilsAndCommons.NACOS_NAMING_CONTEXT + "/instance")
public class InstanceController {

    @Autowired
    private ServiceManager serviceManager;

    @CanDistro
    @PostMapping
    @Secured(parser = NamingResourceParser.class, action = ActionTypes.WRITE)
    public String register(HttpServletRequest request) throws Exception {
        //这里可以看出Nacos作为服务注册中心没有用到group
        //命名空间
        final String namespaceId = WebUtils
                .optional(request, CommonParams.NAMESPACE_ID, Constants.DEFAULT_NAMESPACE_ID);
        //服务名称
        final String serviceName = WebUtils.required(request, CommonParams.SERVICE_NAME);
        NamingUtils.checkServiceNameFormat(serviceName);
        
        //将服务注册注册请求参数转换成Instance
        final Instance instance = parseInstance(request);
        
        //注册实例
        serviceManager.registerInstance(namespaceId, serviceName, instance);
        return "ok";
    }
}
```



2.`serviceManager.registerInstance`注册服务实例

```JAVA
@Component
public class ServiceManager implements RecordListener<Service> {

    //Nacos的注册表
    private final Map<String, Map<String, Service>> serviceMap = new ConcurrentHashMap<>();

    @Resource(name = "consistencyDelegate")
    private ConsistencyService consistencyService;

    public void registerInstance(String namespaceId, String serviceName, Instance instance) throws NacosException {
        //创建一个空的服务
        createEmptyService(namespaceId, serviceName, instance.isEphemeral());
        
        //获取服务,从Nacos的注册表获取服务
        Service service = getService(namespaceId, serviceName);
        
        if (service == null) {
            throw new NacosException(NacosException.INVALID_PARAM,
                    "service not found, namespace: " + namespaceId + ", service: " + serviceName);
        }
        
        //新增实例
        addInstance(namespaceId, serviceName, instance.isEphemeral(), instance);
    }
    
    public void addInstance(String namespaceId, String serviceName, boolean ephemeral, Instance... ips)
            throws NacosException {
        
        String key = KeyBuilder.buildInstanceListKey(namespaceId, serviceName, ephemeral);
        
        //获取服务,从Nacos的注册表获取服务
        Service service = getService(namespaceId, serviceName);
        
        //加锁,同一时间同一命名空间下的同一服务，只能允许有一个服务注册请求
        synchronized (service) {
            //更新并返回总的instanceList列表
            List<Instance> instanceList = addIpAddresses(service, ephemeral, ips);
            
            //创建新的instance列表对象
            Instances instances = new Instances();
            instances.setInstanceList(instanceList);
            //将实例列表集合和key设置进consistencyService中
            consistencyService.put(key, instances);
        }
    }
    
    //获取服务
    public Service getService(String namespaceId, String serviceName) {
        if (serviceMap.get(namespaceId) == null) {
            return null;
        }
        return chooseServiceMap(namespaceId).get(serviceName);
    }   
}
```



**3.将服务注册请求放入到`ArrayBlockingQueue`阻塞队列中，并将服务实例存入DataStore中的dataMap中**



**4.将服务注册请求放入到ArrayBlockingQueue阻塞队列后，处理该阻塞队列中的任务，在Notifier中的run方法中处理该任务**

```
@DependsOn("ProtocolManager")
@org.springframework.stereotype.Service("distroConsistencyService")
public class DistroConsistencyServiceImpl implements EphemeralConsistencyService, DistroDataProcessor {
    
    private final DataStore dataStore;
    
    private volatile Notifier notifier = new Notifier();    
    
    public class Notifier implements Runnable {
        
        private ConcurrentHashMap<String, String> services = new ConcurrentHashMap<>(10 * 1024);
        
        private BlockingQueue<Pair<String, DataOperation>> tasks = new ArrayBlockingQueue<>(1024 * 1024);
        
        public int getTaskSize() {
            return tasks.size();
        }
        
        @Override
        public void run() {
            Loggers.DISTRO.info("distro notifier started");
            
            for (; ; ) {
                try {
                    //取出注册请求任务
                    Pair<String, DataOperation> pair = tasks.take();
                    //处理任务
                    handle(pair);
                } catch (Throwable e) {
                    Loggers.DISTRO.error("[NACOS-DISTRO] Error while handling notifying task", e);
                }
            }
        }
        
        private void handle(Pair<String, DataOperation> pair) {
            try {
                String datumKey = pair.getValue0();
                DataOperation action = pair.getValue1();
                
                services.remove(datumKey);
                
                int count = 0;
                
                if (!listeners.containsKey(datumKey)) {
                    return;
                }
                
                for (RecordListener listener : listeners.get(datumKey)) {
                    
                    count++;
                    
                    try {
                        //如果是一个数据变更动作，服务注册数据数据变更
                        if (action == DataOperation.CHANGE) {
                            //从dataStore中获取服务注册请求放入的服务实例集合
                            listener.onChange(datumKey, dataStore.get(datumKey).value);
                            continue;
                        }
                        //如果是一个数据删除动作
                        if (action == DataOperation.DELETE) {
                            listener.onDelete(datumKey);
                            continue;
                        }
                    } catch (Throwable e) {
                        Loggers.DISTRO.error("[NACOS-DISTRO] error while notifying listener of key: {}", datumKey, e);
                    }
                }
                
                if (Loggers.DISTRO.isDebugEnabled()) {
                    Loggers.DISTRO
                            .debug("[NACOS-DISTRO] datum change notified, key: {}, listener count: {}, action: {}",
                                    datumKey, count, action.name());
                }
            } catch (Throwable e) {
                Loggers.DISTRO.error("[NACOS-DISTRO] Error while handling notifying task", e);
            }
        }
    }
}
```



5.从dataStore中获取服务注册请求放入的服务实例集合，调用listener.onChange方法注册

```
public class Cluster extends com.alibaba.nacos.api.naming.pojo.Cluster implements Cloneable {

    @JsonIgnore
    private Set<Instance> persistentInstances = new HashSet<>();
    
    @JsonIgnore
    private Set<Instance> ephemeralInstances = new HashSet<>();

    public void updateIps(List<Instance> ips, boolean ephemeral) {
        //拿到cluster中旧的instance列表
        Set<Instance> toUpdateInstances = ephemeral ? ephemeralInstances : persistentInstances;
        
        HashMap<String, Instance> oldIpMap = new HashMap<>(toUpdateInstances.size());
        
        for (Instance ip : toUpdateInstances) {
            oldIpMap.put(ip.getDatumKey(), ip);
        }
         //updatedIps主要做的是找出oldipmap中的实例并返回
        List<Instance> updatedIPs = updatedIps(ips, oldIpMap.values());
        if (updatedIPs.size() > 0) {
            for (Instance ip : updatedIPs) {
                Instance oldIP = oldIpMap.get(ip.getDatumKey());
                
                // do not update the ip validation status of updated ips
                // because the checker has the most precise result
                // Only when ip is not marked, don't we update the health status of IP:
                if (!ip.isMarked()) {
                    ip.setHealthy(oldIP.isHealthy());
                }
                
                if (ip.isHealthy() != oldIP.isHealthy()) {
                    // ip validation status updated
                    Loggers.EVT_LOG.info("{} {SYNC} IP-{} {}:{}@{}", getService().getName(),
                            (ip.isHealthy() ? "ENABLED" : "DISABLED"), ip.getIp(), ip.getPort(), getName());
                }
                
                if (ip.getWeight() != oldIP.getWeight()) {
                    // ip validation status updated
                    Loggers.EVT_LOG.info("{} {SYNC} {IP-UPDATED} {}->{}", getService().getName(), oldIP.toString(),
                            ip.toString());
                }
            }
        }
        //找出新增的实例列表,即ips中的实例，oldipmap不存在的实例列表
        List<Instance> newIPs = subtract(ips, oldIpMap.values());
        if (newIPs.size() > 0) {
            Loggers.EVT_LOG
                    .info("{} {SYNC} {IP-NEW} cluster: {}, new ips size: {}, content: {}", getService().getName(),
                            getName(), newIPs.size(), newIPs.toString());
            
            for (Instance ip : newIPs) {
                //进行新实例的健康检查设置
                HealthCheckStatus.reset(ip);
            }
        }
        //找出oldipmap的ip的实例。不存在于ips中的实例
        List<Instance> deadIPs = subtract(oldIpMap.values(), ips);
        
        if (deadIPs.size() > 0) {
            Loggers.EVT_LOG
                    .info("{} {SYNC} {IP-DEAD} cluster: {}, dead ips size: {}, content: {}", getService().getName(),
                            getName(), deadIPs.size(), deadIPs.toString());
            
            for (Instance ip : deadIPs) {
                //将不存在新实例ip列表的值的健康检查删除
                HealthCheckStatus.remv(ip);
            }
        }
        
        toUpdateInstances = new HashSet<>(ips);
        
        //更新服务下cluster的intances列表
        if (ephemeral) {
            ephemeralInstances = toUpdateInstances;
        } else {
            persistentInstances = toUpdateInstances;
        }
    }
}
```

**最核心的就是updateIPs**

为了防止读写并发冲突，直接创建了一个新的HashMap，然后去操作新的HashMap，操作完了之后再去替换老的Map数据，CopyOnWrite的思想。最后还发布了服务变化事件。

- **服务注册通过CopyOnWrite支持并发读写的能力**
- Cluster类中的updateIPs方法中是对原服务IP列表的副本进行操作，注册完成替换原有服务IP列表即可，即CopyOnWrite操作，不需要加锁，性能高，存在服务延迟(AP)

Eureka防止读写冲突用的是多级缓存结构，多级缓存定时同步，客户端感知及时性不如Nacos。





### 服务心跳检测











## 负载均衡算法



### 一致性哈希

RPC框架中的一致性哈希实现为：

```java

public class IpHashLoadBalancer implements LoadBalancer{
    @Override
    public Instance select(List<Instance> instances , String address) {
        ConsistentHash ch = new ConsistentHash(instances, 160);//虚拟节点设置为了160
        HashMap<String,Instance> map = ch.map;
        return map.get(ch.getServer(address));
    }
}



//一致性hash 利用treemap实现
class ConsistentHash {
    
    //TreeMap中的key表示服务器的hash值，value表示服务器ip。模拟一个哈希环
    private static TreeMap<Integer,String> Nodes = new TreeMap();
    
    private static int VIRTUAL_NODES = 160;//虚拟节点个数，用户指定，默认160
    private static List<Instance> instances = new ArrayList<>();//真实物理节点集合
    public ConsistentHash(List<Instance> instances, int VIRTUAL_NODES){
        this.instances = instances;
        this.VIRTUAL_NODES = VIRTUAL_NODES;
    }
 
    public static HashMap<String,Instance> map = new HashMap<>();//将服务实例与ip地址一一映射
    //预处理 形成哈希环
    static {
        //程序初始化，将所有的服务器(真实节点与虚拟节点)放入Nodes（底层为红黑树）中
        for (Instance instance : instances) {
            String ip = instance.getIp();
            
            Nodes.put(getHash(ip),ip); //环上放入真实节点
            
            map.put(ip,instance);  // map中存放 真实节点的ip——Instance对应信息
            
            for(int i = 0; i < VIRTUAL_NODES; i++) {
                int hash = getHash(ip+"#"+i);
                Nodes.put(hash,ip); //环TreeMap上放入每个真实节点对应的虚拟节点
            }
        }
    }
    
    
    //得到请求被分配到的实例 —— 对应的Ip地址
    public  String getServer(String clientInfo) {
        int hash = getHash(clientInfo); // 计算客户端请求的hash,不需要放入环上！
        
        //得到大于该Hash值的子红黑树——————因为红黑树满足 AVL&&BST 
        SortedMap<Integer,String> subMap = Nodes.tailMap(hash);
        
        //获取该子树最小元素 ，即顺时针的第一个实例
        Integer nodeIndex = subMap.firstKey();
        
        //没有大于该元素的子树 取整树的第一个元素(想象成一个环，超过尾部则取第一个 key)
        if (nodeIndex == null) {
            nodeIndex = Nodes.firstKey();
        }   
         String virtualNodeIp = Nodes.get(nodeIndex);//通过虚拟节点的哈希值找到对应真实节点的IP
        
        return  map.get(virtualNodeIp); //// 返回真实节点对应的Instance
    }
    
    
    
    //使用FNV1_32_HASH算法计算服务器的Hash值,这里不使用重写hashCode的方法，最终效果没区别
    private static int getHash(String str) {
        final int p = 16777619;
        int hash = (int) 2166136261L;
        for (int i = 0; i < str.length(); i++) {
            hash = (hash^str.charAt(i))*p;
            hash +=hash <<13;
            hash ^=hash >>7;
            hash +=hash <<3;
            hash ^=hash >>17;
            hash +=hash <<5;
            //如果算出来的值为负数 取其绝对值
            if(hash < 0) {
                hash = Math.abs(hash);
            }
        }
        return hash;
    }
}
```



### 加权随机

```java

public class WeightRandom {

    public  static Map<String,Integer>  map=new HashMap<>(); //Map保存IP地址和权重的对应关系
    static {
        map.put("10.180.11.126:8888",6);
        map.put("10.180.11.128:8888",6);
        map.put("10.180.11.132:8888",6);
        map.put("10.180.11.144:8888",3);
        map.put("10.180.11.155:8888",3);
        map.put("10.180.11.166:8888",3);
    }
    static Random random = new Random();

    public  String getServer()
    {
        Set<String> keySet=map.keySet(); //取得IP地址list
        Iterator<String> iterator=keySet.iterator();
        List<String> serverList= new ArrayList<String>();
        while (iterator.hasNext())
        {  //遍历ip地址
            String  sever=iterator.next();
            int  weight=map.get(sever);
            for (int i = 0; i < weight; i++) {
                serverList.add(sever); //如果是权重为3的server,就添加3台该server到list集合中
            }
        }
        int randomPos=random.nextInt(serverList.size());
        String res= serverList.get(randomPos);
        return  res+"对应权重为： "+map.get(res);
    }
    public static void main(String[] args) {
        for (int i = 0; i < 10; i++) {
            System.out.println(new WeightRandom().getServer());
        }
    }
}

```







## Dubbo





## Netty



在了解 Netty 高性能原理之前我们需要先储备 I/O 模型的基本知识。

I/O 请求可以分为两个阶段，分别为调用阶段和执行阶段。

- 第一个阶段为**I/O 调用阶段**，即用户进程向内核发起系统调用。
- 第二个阶段为**I/O 执行阶段**。此时，内核等待 I/O 请求处理完成返回。该阶段分为两个过程：首先等待数据就绪，并写入内核缓冲区；随后将内核缓冲区数据拷贝至用户态缓冲区。

为了方便大家理解，可以看一下这张图：

<img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/Netty%20%e6%a0%b8%e5%bf%83%e5%8e%9f%e7%90%86%e5%89%96%e6%9e%90%e4%b8%8e%20RPC%20%e5%ae%9e%e8%b7%b5-%e5%ae%8c/assets/Ciqc1F-NAZ6Ae3bPAAHigveMsIQ514.png" alt="Drawing 0.png" style="zoom: 50%;" />

:heavy_exclamation_mark: 零拷贝就是减少了内核缓冲区———>用户缓冲区的一次拷贝







Netty 基于 **`主从 Reactors 多线程模型`** 做了一定的 **`改进`**，其中主`Reactor`在`Netty`中对应`Boss group` 线程组，子`Reactor`对应`Worker Group` 线程组。主`Reactor`仅负责建立连接，`工作简单`，一般设置1个线程就足够。在主`Reactor`建立好连接后，将其注册到`Worker Group`线程组，触发相应的IO事件，最终由`Pipeline`中的多个`Handler`进行有序处理

- BossGroup 线程维护Selector , 只关注Accecpt；
- 当接收到Accept事件，获取到对应的SocketChannel, 封装成 NIOScoketChannel并注册到 Worker 线程(事件循环)，并进行维护；
- 当Worker线程监听到selector 中通道发生自己感兴趣的事件后，就进行处理(就由handler)， 注意 handler 已经加入到通道

![netty thread](https://img-blog.csdnimg.cn/9637c27dfbdf47c5ac2b7f5546debf61.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5LiA5Liq5bCP56CB5Yac55qE6L-b6Zi25LmL5peF,size_17,color_FFFFFF,t_70,g_se,x_16)

- Netty抽象出两组线程池：BossGroup 和 WorkerGroup

  - BossGroup 专门负责接收客户端的连接
  - WorkerGroup 专门负责网络的读写

- BossGroup 和 WorkerGroup 类型都是 NioEventLoopGroup，NioEventLoopGroup 相当于一个 事件循环组，这个组中含有多个事件循环 ，每一个事件循环是 NioEventLoop

- NioEventLoop 表示一个不断循环的执行处理任务的线程， 每个NioEventLoop 都有一个selector , 用于监听绑定在其上的socket的网络通讯。

- NioEventLoopGroup 可以有多个线程, 即可以含有多个NioEventLoop

- 每个Boss Group 中的 NioEventLoop 循环执行的步骤：
  1）轮询accept 事件
  2）处理accept 事件，与client建立连接 , 生成 NioScocketChannel，并将其注册 Worker Group 上的某个 NIOEventLoop 上的 selector
  3）处理任务队列的任务，即 runAllTasks

  

- 每个 Worker Group 中的 NIOEventLoop 循环执行的步骤：
  1）轮询 read/write 事件
  2）处理 I/O 事件， 即 read/write 事件，在对应的 NioScocketChannel 上处理
  3）处理任务队列的任务 ， 即 runAllTasks

  

- 每个Worker NIOEventLoop 处理业务时，会使用 pipeline(管道)。pipeline中包含了 channel，即通过pipline可以获取到对应的 channel，并且pipline维护了很多的 handler(处理器)来对我们的数据进行一系列的处理。

- handler(处理器) 有Netty内置的，我们也可以自己定义



下面是Netty使用中很常见的一段代码:

```java
public class Server {
    public static void main(String[] args) throws Exception {
        EventLoopGroup bossGroup = new NioEventLoopGroup(1);
        EventLoopGroup workerGroup = new NioEventLoopGroup();
        try {
            ServerBootstrap b = new ServerBootstrap();
            b.group(bossGroup, workerGroup)
                    .channel(NioServerSocketChannel.class)
                    .childOption(ChannelOption.TCP_NODELAY, true)
                    .childAttr(AttributeKey.newInstance("childAttr"), "childAttrValue")
                    .handler(new ServerHandler())
                    .childHandler(new ChannelInitializer<SocketChannel>() {
                        @Override
                        public void initChannel(SocketChannel ch) {
                        }
                    });
            ChannelFuture f = b.bind(8888).sync();
            f.channel().closeFuture().sync();
        } finally {
            bossGroup.shutdownGracefully();
            workerGroup.shutdownGracefully();
        }
    }
}
```

**boss线程池作用：**

1. 接收客户端的连接，初始化Channel参数。
2. 将链路状态变更时间通知给ChannelPipeline。



**worker线程池作用：**

1. 异步读取通信对端的数据报，发送读事件到ChannelPipeline。
2. 异步发送消息到通信对端，调用ChannelPipeline的消息发送接口。
3. 执行系统调用Task。
4. 执行定时任务Task。



Netty通过Reactor模型基于多路复用器接收并处理用户请求，内部实现了两个线程池，boss线程池和work线程池，其中boss线程池的线程负责处理请求的accept事件，当接收到accept事件的请求时，把对应的socket封装到一个NioSocketChannel中，并交给work线程池，其中work线程池负责请求的read和write事件 

Netty 的 I/O 模型是基于非阻塞 I/O 实现的，底层依赖的是 JDK NIO 框架的多路复用器 Selector。一个多路复用器 Selector 可以同时轮询多个 Channel，采用 epoll 模式后，只需要一个线程负责 Selector 的轮询，就可以接入成千上万的客户端。

在 I/O 多路复用的场景下，当有数据处于就绪状态后，需要一个事件分发器（Event Dispatcher），它负责将读写事件分发给对应的读写事件处理器（Event Handler）。事件分发器有两种设计模式：Reactor 和 Proactor，**Reactor 采用同步 I/O， Proactor 采用异步 I/O** 



![6.png](https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/Netty%20%e6%a0%b8%e5%bf%83%e5%8e%9f%e7%90%86%e5%89%96%e6%9e%90%e4%b8%8e%20RPC%20%e5%ae%9e%e8%b7%b5-%e5%ae%8c/assets/Ciqc1F-NKE-AWqZfAARsOnKW3pg690.png)



上图所描述的便是 Netty 所采用的主从 Reactor 多线程模型，所有的 I/O 事件都注册到一个 I/O 多路复用器上，当有 I/O 事件准备就绪后，I/O 多路复用器会将该 I/O 事件通过事件分发器分发到对应的事件处理器中。该线程模型避免了同步问题以及多线程切换带来的资源开销，真正做到高性能、低延迟。







## 如何设计高并发系统？



[系统拆分](https://doocs.github.io/advanced-java/#/docs/high-concurrency/high-concurrency-design?id=系统拆分)

将一个系统拆分为多个子系统，用 dubbo 来搞。然后每个系统连一个数据库，这样本来就一个库，现在多个数据库，不也可以扛高并发么





[缓存](https://doocs.github.io/advanced-java/#/docs/high-concurrency/high-concurrency-design?id=缓存)

缓存，必须得用缓存。大部分的高并发场景，都是**读多写少**，那你完全可以在数据库和缓存里都写一份，然后读的时候大量走缓存不就得了。毕竟人家 redis 轻轻松松单机几万的并发。所以你可以考虑考虑你的项目里，那些承载主要请求的**读场景，怎么用缓存来抗高并发**





[MQ](https://doocs.github.io/advanced-java/#/docs/high-concurrency/high-concurrency-design?id=mq)

MQ，必须得用 MQ。可能你还是会出现高并发写的场景，比如说一个业务操作里要频繁搞数据库几十次，增删改增删改，疯了。那高并发绝对搞挂你的系统，你要是用 redis 来承载写那肯定不行，人家是缓存，数据随时就被 LRU 了，数据格式还无比简单，没有事务支持。所以该用 mysql 还得用 mysql 啊。那你咋办？用 MQ 吧，大量的写请求灌入 MQ 里，排队慢慢玩儿，**后边系统消费后慢慢写**，控制在 mysql 承载范围之内。所以你得考虑考虑你的项目里，那些承载复杂写业务逻辑的场景里，如何用 MQ 来异步写，提升并发性。MQ 单机抗几万并发也是 ok 的







[分库分表](https://doocs.github.io/advanced-java/#/docs/high-concurrency/high-concurrency-design?id=分库分表)

分库分表，可能到了最后数据库层面还是免不了抗高并发的要求，好吧，那么就将一个数据库拆分为多个库，多个库来扛更高的并发；然后将一个表**拆分为多个表**，每个表的数据量保持少一点，提高跑sql的性能





[读写分离](https://doocs.github.io/advanced-java/#/docs/high-concurrency/high-concurrency-design?id=读写分离)

读写分离，这个就是说大部分时候数据库可能也是读多写少，没必要所有请求都集中在一个库上吧，可以搞个主从架构，**主库写**入，**从库读**取，搞一个读写分离。**读流量太多**的时候，还可以**加更多的从库**





[ElasticSearch](https://doocs.github.io/advanced-java/#/docs/high-concurrency/high-concurrency-design?id=elasticsearch)

es 是分布式的，可以随便扩容，分布式天然就可以支撑高并发，因为动不动就可以扩容加机器来扛更高的并发。那么一些比较简单的查询、统计类的操作，可以考虑用 es 来承载，还有一些全文搜索类的操作，也可以考虑用 es 来承载。



上面的 6 点，基本就是高并发系统肯定要干的一些事儿，大家可以仔细结合之前讲过的知识考虑一下，到时候你可以系统的把这块阐述一下，然后每个部分要注意哪些问题，之前都讲过了，你都可以阐述阐述，表明你对这块是有点积累的。

说句实话，毕竟你真正厉害的一点，不是在于弄明白一些技术，或者大概知道一个高并发系统应该长什么样？其实实际上在真正的复杂的业务系统里，做高并发要远远比上面提到的点要复杂几十倍到上百倍。你需要考虑：哪些需要分库分表，哪些不需要分库分表，单库单表跟分库分表如何 join，哪些数据要放到缓存里去，放哪些数据才可以扛住高并发的请求，你需要完成对一个复杂业务系统的分析之后，然后逐步逐步的加入高并发的系统架构的改造，这个过程是无比复杂的，一旦做过一次，并且做好了，你在这个市场上就会非常的吃香。







# 杂项





## 设计模式六大原则







## CPU密集型和IO密集型



> `CPU密集型`与`I/O密集型`是在计算机上执行任务的两种策略，在并发执行任务场景下，我们需要选择使用多线程还是多进程：
>   如果是IO密集型任务，使用多线程，如果是CPU密集型任务，使用多进程。
>   前者指内存磁盘I/O使用率高，CPU使用率低；相反，后者指CPU使用率高，内存磁盘I/O使用率低。



针对**CPU密集型：**

`CPU密集型`，也叫`计算密集型`，一般是指服务器的硬盘、内存硬件性能相对CPU好很多，或者使用率低很多。系统运行CPU读写I/O(硬盘/内存)时可以在很短的时间内完成，几乎没有阻塞（等待I/O的实时间）时间，而CPU一直有大量运算要处理，因此CPU负载长期过高。

  CPU密集几乎无I/O阻塞，CPU一直会全速运行。`如果是单核情况下，开多线程是没有意义的`，说白了就是一个CPU来回切着运行而已，徒增线程切换的资源消耗，卵用没有。可见，CPU密集任务只有在`多核CPU上`、`开多线程`才可能提速。

  CPU使用率较高时（如我们训练算法模型、搞训练集），通常线程数只需要设置为CPU核心数的线程个数就可以了。单CPU对应单线程效率最高。

> 一般其计算公式可遵循：**CPU密集型核心线程数 = CPU核数**+1
>
> 
>
> 这种任务消耗的主要是 CPU 资源，可以将线程数设置为 N（CPU 核心数）+1。比 CPU 核心数多出来的一个线程是为了防止线程偶发的缺页中断，或者其它原因导致的任务暂停而带来的影响。一旦任务暂停，CPU 就会处于空闲状态，而在这种情况下多出来的一个线程就可以充分利用 CPU 的空闲时间。





针对**IO密集型：**

`I/O密集型`相反，一般是指服务器CPU的性能相对硬盘、内存硬件好很多，或者使用率低很多。系统运行多是CPU在等I/O (硬盘/内存) 的读写操作，此类情景下CPU负载并不高。

  I/O密集型的程序一般在达到性能极限时，CPU占用率仍然较低。这可能是因为任务本身需要大量I/O操作，而程序的逻辑做得并不好，没有充分利用CPU能力，导致`线程空余时间很多`。通常我们会开`CPU核心数`数倍的线程，在线程进行 I/O 操作 CPU 空闲时，启用其他线程继续使用 CPU，以提高 CPU 的使用率，充分利用CPU资源。

> 一般其计算公式可遵循：**I/O密集型核心线程数 = CPU核数 / （1-阻塞系数）**

  阻塞系数在在0到1范围内。一般为0.8~0.9之间，也可以取0.8或者0.9。对于双核CPU来说，它比较理想的线程数就是20，当然这都不是绝对的，需要根据实际情况以及实际业务来调整。

这种任务应用起来，系统会用大部分的时间来处理 I/O 交互，而线程在处理 I/O 的时间段内不会占用 CPU 来处理，这时就可以将 CPU 交出给其它线程使用。因此在 I/O 密集型任务的应用中，我们可以多配置一些线程，具体的计算方法是 2N



## RestFul风格

`REST`（Representational State Transfer）是一种设计理念，它强调资源的状态以及对资源进行操作的方式。RESTful风格是基于REST原则的应用程序设计规范，主要用于构建Web服务和API。以下是RESTful风格的一些主要特点：

1. 资源（Resource）：在RESTful风格中，每个实体（对象、数据等）都被视为一个资源，资源可以用URL进行唯一标识。
2. 表现层状态转换（Representational State Transfer）：资源的状态以及对资源的操作通过HTTP方法来表示。常用的HTTP方法包括GET（获取资源）、POST（创建资源）、PUT（更新资源）和DELETE（删除资源）等。
3. URL作为资源的唯一标识：每个资源都有唯一的URL，通过访问不同的URL来操作不同的资源。
4. 无状态性（Statelessness）：RESTful架构是无状态的，每个请求都是独立的，服务器不会保留客户端的状态信息。客户端必须包含所有必要的信息在请求中，服务器在每个请求之间没有任何记忆。
5. 使用HTTP协议：RESTful API通常使用HTTP协议作为通信协议，利用HTTP的方法、状态码、请求头等特性来表示资源状态和操作。





假设我们要构建一个用于管理图书信息的 RESTful API，以下是一些常见的 RESTful 风格的例子：

1、获取特定图书信息：使用 HTTP GET 方法和图书的唯一标识符（比如图书的ID）来获取特定图书的信息。

```
GET /books/{bookId}
```



2、更新图书信息：使用 HTTP PUT 方法和图书的唯一标识符来更新特定图书的信息。

```
PUT /books/{bookId}
```

(Put请求应当是**幂等**的，多次请求同一URL的PUT操作应该产生相同的结果，不会对服务器端资源产生重复的副作用    `Put`可以看作是`Update`)

> PUT 和 POST 是两种不同的 HTTP 请求方法，它们在使用方式和语义上有以下区别：
>
> 1. 语义不同：
>    - POST：用于向服务器提交数据，请求服务器创建新的资源。每次 POST 请求发送时，服务器通常会在资源上创建一个新的实例，并返回一个表示该实例的唯一标识（通常是资源的 URL）。
>    - PUT：用于向服务器提交数据，请求服务器更新已存在的资源。每次 PUT 请求发送时，客户端需要提供完整的更新数据，并指定更新的资源的位置。
> 2. 幂等性：
>    - POST：一般情况下，**POST 请求不是幂等的，多次请求同一个 POST 接口可能会创建多个相同的资源**。
>    - PUT：**PUT 请求应该是幂等的**，多次请求同一个 PUT 接口应该具有相同的效果。也就是说，多次使用相同的数据进行 PUT 请求，服务器的资源状态应该保持一致。
> 3. 使用场景：
>    - POST：**适用于创建新资源**，比如提交一个新的订单、创建一个新的用户账号等。因为每次请求都会创建一个新资源，因此 POST 请求可能会对服务器产生副作用（如新增资源）。
>    - PUT：**适用于更新已存在的资源**，比如更新用户资料、修改已有的文章等。PUT 请求通常用于替换整个资源，所以要求客户端提供完整的资源表述，即使只更新了部分字段。



3、搜索图书：可以通过查询参数来搜索图书，比如根据作者、标题等进行过滤。

```
GET /books?author=John%20Doe
```



再来看一个较为详细的例子：

1. 
   创建书籍资源：

   - POST /api/books
   
   - 请求体（Request Body）
   
   - ```json
     {
       "title": "RESTful API Design",
       "author": "John Doe",
       "year": 2023,
       "genre": "Technology"
     }
     ```
   
   - 响应（Response）：
   
   - ```json
     {
       "id": "123456",
       "title": "RESTful API Design",
       "author": "John Doe",
       "year": 2023,
       "genre": "Technology"
     }
     ```
   
     服务器在成功处理该请求后，创建了一本名为 "RESTful API Design" 的新书，并返回该书的唯一标识 "123456"(返回的ID具体为多少一般是根据数据库主键生成策略)
   
2. 更新书籍资源：

   - PUT /api/books/123456  (根据书的ID更新)

   - 请求体（Request Body）

   - ```json
     {
       "title": "Updated RESTful API Design",
       "author": "John Doe",
       "year": 2023,
       "genre": "Technology"
     }
     ```

   - 响应（Response）：

   - ```json
     {
       "id": "123456",
       "title": "Updated RESTful API Design",
       "author": "John Doe",
       "year": 2023,
       "genre": "Technology"
     }
     ```

   - 服务器接收到该请求后，使用提供的数据更新 ID 为 "123456" 的书籍资源，将书名从 "RESTful API Design" 更新为 "Updated RESTful API Design"。



**总结：** POST 用于创建新资源，每次请求都可能导致资源的新增，而 PUT 用于更新已存在的资源，要求客户端提供完整的资源数据以替换目标资源。同时，**PUT 请求应该是幂等的，多次请求相同的 PUT 接口应该具有相同的效果** 

 









## Oauth2.0



